{"title": "Text Classification with Data Science", "description": "One place in Data Science where multinomial naive Bayes is often used is in text classification, where the features are related to word counts or frequencies within the documents to be classified.In this data science project we will use the sparse word count features from the 20 Newsgroups corpus to show how we might classify these short documents into categories.#Output- [\u2018alt.atheism\u2019, \u2018comp.graphics\u2019, \u2018comp.os.ms-windows.misc\u2019, \u2018comp.sys.ibm.pc.hardware\u2019, \u2018comp.sys.mac.hardware\u2019, \u2018comp.windows.x\u2019, \u2018misc.forsale\u2019, \u2018rec.autos\u2019, \u2018rec.motorcycles\u2019, \u2018rec.sport.baseball\u2019, \u2018rec.sport.hockey\u2019, \u2018sci.crypt\u2019, \u2018sci.electronics\u2019, \u2018sci.med\u2019, \u2018sci.space\u2019, \u2018soc.religion.christian\u2019, \u2018talk.politics.guns\u2019, \u2018talk.politics.mideast\u2019, \u2018talk.politics.misc\u2019, \u2018talk.religion.misc\u2019]For simplicity, we will select just a few of these categories, and download the training and testing set:Here is a representative entry from the data:#Output-From: dmcgee@uluhe.soest.hawaii.edu (Don McGee)Subject: Federal HearingOriginator: dmcgee@uluheOrganization: School of Ocean and Earth Science and TechnologyDistribution: usaLines: 10Fact or rumor\u2026.? Madalyn Murray O\u2019Hare an atheist who eliminated theuse of the bible reading and prayer in public schools 15 years ago is nowgoing to appear before the FCC with a petition to stop the reading of theGospel on the airways of America. And she is also campaigning to removeChristmas programs, songs, etc from the public schools. If it is truethen mail to Federal Communications Commission 1919 H Street Washington DC20054 expressing your opposition to her request. Reference Petition number2493.In order to use this data for machine learning, we need to be able to convert the content of each string into a vector of numbers. For this we will use the TF\u2013IDF vectorizer, and create a pipeline that attaches it to a multinomial naive Bayes classifier:With this pipeline, we can apply the model to the training data, and predict labels for the test data:Now that we have predicted the labels for the test data, we can evaluate them to learn about the performance of the estimator. For example, here is the confusion matrix between the true and predicted labels for the test data:Evidently, even this very simple classifier can successfully separate space talk from computer talk, but it gets confused between talk about religion and talk about Christianity. This is perhaps an expected area of confusion.The very cool thing here is that we now have the tools to determine the category for any string, using the predict() method of this pipeline. Here\u2019s a quick utility function that will return the prediction for a single string:Let\u2019s try it out:sci.spacesoc.religion.christiancomp.graphicsRemember that this is nothing more sophisticated than a simple probability model for the (weighted) frequency of each word in the string; nevertheless, the result is striking. Even a very naive algorithm, when used carefully and trained on a large set of high-dimensional data, can be surprisingly effective.", "link": "https://thecleverprogrammer.com/2020/05/14/data-science-project-on-classification-of-text/", "tags": ["Classification", "Naive Bayes", "Classification"], "kind": "Project", "ml_libs": ["sklearn"], "host": "thecleverprogrammer.com", "language": "english", "date_project": "2020-05-14 17:30:05", "date_scraped": "2020-12-20 00:00:00", "words": 425, "sentences": 9, "sum_nltk": "One place in Data Science where multinomial naive Bayes is often used is in text classification, where the features are related to word counts or frequencies within the documents to be classified.In this data science project we will use the sparse word count features from the 20 Newsgroups corpus to show how we might classify these short documents into categories.#Output- [\u2018alt.atheism\u2019, \u2018comp.graphics\u2019, \u2018comp.os.ms-windows.misc\u2019, \u2018comp.sys.ibm.pc.hardware\u2019, \u2018comp.sys.mac.hardware\u2019, \u2018comp.windows.x\u2019, \u2018misc.forsale\u2019, \u2018rec.autos\u2019, \u2018rec.motorcycles\u2019, \u2018rec.sport.baseball\u2019, \u2018rec.sport.hockey\u2019, \u2018sci.crypt\u2019, \u2018sci.electronics\u2019, \u2018sci.med\u2019, \u2018sci.space\u2019, \u2018soc.religion.christian\u2019, \u2018talk.politics.guns\u2019, \u2018talk.politics.mideast\u2019, \u2018talk.politics.misc\u2019, \u2018talk.religion.misc\u2019]For simplicity, we will select just a few of these categories, and download the training and testing set:Here is a representative entry from the data:#Output-From: dmcgee@uluhe.soest.hawaii.edu (Don McGee)Subject: Federal HearingOriginator: dmcgee@uluheOrganization: School of Ocean and Earth Science and TechnologyDistribution: usaLines: 10Fact or rumor\u2026.?\nReference Petition number2493.In order to use this data for machine learning, we need to be able to convert the content of each string into a vector of numbers.\nFor this we will use the TF\u2013IDF vectorizer, and create a pipeline that attaches it to a multinomial naive Bayes classifier:With this pipeline, we can apply the model to the training data, and predict labels for the test data:Now that we have predicted the labels for the test data, we can evaluate them to learn about the performance of the estimator.", "sum_nltk_words": 209, "sum_nltk_runtime": 0.006, "sum_t5": "'alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.windows.x','misc.forsale','rec.autos','rec.motorcycles','rec.sport.baseball','rec", "sum_t5_words": 5, "sum_t5_runtime": 10.077, "runtime": 0.004, "nltk_category": "Miscellaneous", "nltk_category_score": 0.5223771929740906, "nltk_category_runtime": 34.047, "nltk_subcategory": "Machine Learning", "nltk_subcategory_score": 0.9909666776657104, "nltk_subcategory_runtime": 55.66, "category": "Miscellaneous", "category_score": 0.5223771929740906, "subcategory": "Machine Learning", "subcategory_score": 0.9909666776657104, "runtime_cat": 89.706, "programming_language": "Python", "ml_score": "1.0", "language_code": "en", "language_score": "0.9999978672124903", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "one place data science multinomial naive bayes often used text classification feature related word count frequency within document classifiedin data science project use sparse word count feature 20 newsgroups corpus show might classify short document categoriesoutput altatheism compgraphics composmswindowsmisc compsysibmpchardware compsysmachardware compwindowsx miscforsale recautos recmotorcycles recsportbaseball recsporthockey scicrypt scielectronics scimed scispace socreligionchristian talkpoliticsguns talkpoliticsmideast talkpoliticsmisc talkreligionmiscfor simplicity select category download training testing sethere representative entry dataoutputfrom dmcgeeuluhesoesthawaiiedu mcgeesubject federal hearingoriginator dmcgeeuluheorganization school ocean earth science technologydistribution usalines 10fact rumor madalyn murray ohare atheist eliminated theuse bible reading prayer public school 15 year ago nowgoing appear fcc petition stop reading thegospel airway america also campaigning removechristmas program song etc public school truethen mail federal communication commission 1919 h street washington dc20054 expressing opposition request reference petition number2493in order use data machine learning need able convert content string vector number use tfidf vectorizer create pipeline attache multinomial naive bayes classifierwith pipeline apply model training data predict label test datanow predicted label test data evaluate learn performance estimator example confusion matrix true predicted label test dataevidently even simple classifier successfully separate space talk computer talk get confused talk religion talk christianity perhaps expected area confusionthe cool thing tool determine category string using predict method pipeline here quick utility function return prediction single stringlets try outscispacesocreligionchristiancompgraphicsremember nothing sophisticated simple probability model weighted frequency word string nevertheless result striking even naive algorithm used carefully trained large set highdimensional data surprisingly effective", "tags_descriptive": ["Classification", "Naive Bayes", "Classification"]}