{"title": "Predict Diabetes with Machine Learning", "description": "According to the report of Centers of Disease Control and Prevention about one in seven adults in the United States have Diabetes. But by next few years this rate can move higher. With this in mind today, In this article, I will show you how you can use machine learning to Predict Diabetes using Python.Let\u2019s straightaway get into the data, you can download the data I have used in this article to Predict Diabetes below.Now let\u2019s import the data and gets started:The diabetes data set consists of 768 data points, with 9 features each:dimension of diabetes data: (768, 9)\u201cOutcome\u201d is the feature we are going to predict, 0 means No diabetes, 1 means diabetes. Of these 768 data points, 500 are labeled as 0 and 268 as 1:The k-Nearest Neighbors algorithm is arguably the simplest machine learning algorithm. Building the model consists only of storing the training data set. To make a prediction for a new point in the dataset, the algorithm finds the closest data points in the training data set \u2014 its \u201cnearest neighbors.\u201dFirst, Let\u2019s investigate whether we can confirm the connection between model complexity and accuracy:Let\u2019s check the accuracy score of the k-nearest neighbors algorithm to predict diabetes.Accuracy of K-NN classifier on training set: 0.79Accuracy of K-NN classifier on test set: 0.78Accuracy on training set: 1.000Accuracy on test set: 0.714The accuracy on the training set with Decision Tree Classifier is 100%, while the test set accuracy is much worse. This is an indicative that the tree is overfitting and not generalizing well to new data. Therefore, we need to apply pre-pruning to the tree.Now, I will do this again by doing set max_depth=3, limiting the depth of the tree decreases overfitting. This leads to a lower accuracy on the training set, but an improvement on the test set.Accuracy on training set: 0.773Accuracy on test set: 0.740Feature importance shows how important each feature is for the decision a decision tree classifier makes. It is a number between 0 and 1 for each feature, where 0 means \u201cnot used at all\u201d and 1 means \u201cperfectly predicts the target\u201d. The feature importance always sum to 1:Feature importances: [ 0.04554275 0.6830362 0. 0. 0. 0.27142106 0. 0. ]Now lets visualize the feature importance of decision tree to predict diabetes.So the Glucose feature is used the most to predict diabetes.Lets train a deep learning model to predict diabetes:Accuracy on training set: 0.71Accuracy on test set: 0.67The accuracy of the Multilayer perceptrons (MLP) is not as good as the other models at all, this is likely due to scaling of the data.\u00a0Deep learning algorithms also expect all input features to vary in a similar way, and ideally to have a mean of 0, and a variance of 1.\u00a0Now I will re-scale our data so that it fulfills these requirements to predict diabetes with a good accuracy.Accuracy on training set: 0.823Accuracy on test set: 0.802Now let\u2019s increase the number of iterations, alpha parameter and add stronger parameters to the weights of the model:Accuracy on training set: 0.795Accuracy on test set: 0.792The result is good, but we are not able to increase the test accuracy further. Therefore, our best model so far is default deep learning model after scaling. Now I will  plot a heat map of the first layer weights in a neural network learned on the to predict diabetes using the data set.I hope you liked this article to predict diabetes with Machine Learning. Feel free to ask your valuable questions in the comments section. Don\u2019t forget to subscribe for the daily newsletters below to receive daily posts notifications if you like my work.", "link": "https://thecleverprogrammer.com/2020/07/13/predict-diabetes-with-machine-learning/", "tags": ["DL", "Decision Tree", "KNN", "Classification"], "kind": "Project", "ml_libs": ["sklearn"], "host": "thecleverprogrammer.com", "language": "english", "date_project": "2020-07-13 10:47:52", "date_scraped": "2020-12-20 00:00:00", "words": 602, "sentences": 20, "sum_nltk": "With this in mind today, In this article, I will show you how you can use machine learning to Predict Diabetes using Python.Let\u2019s straightaway get into the data, you can download the data I have used in this article to Predict Diabetes below.Now let\u2019s import the data and gets started:The diabetes data set consists of 768 data points, with 9 features each:dimension of diabetes data: (768, 9)\u201cOutcome\u201d is the feature we are going to predict, 0 means No diabetes, 1 means diabetes.\n0. ]Now lets visualize the feature importance of decision tree to predict diabetes.So the Glucose feature is used the most to predict diabetes.Lets train a deep learning model to predict diabetes:Accuracy on training set: 0.71Accuracy on test set: 0.67The accuracy of the Multilayer perceptrons (MLP) is not as good as the other models at all, this is likely due to scaling of the data.\nNow I will re-scale our data so that it fulfills these requirements to predict diabetes with a good accuracy.Accuracy on training set: 0.823Accuracy on test set: 0.802Now let\u2019s increase the number of iterations, alpha parameter and add stronger parameters to the weights of the model:Accuracy on training set: 0.795Accuracy on test set: 0.792The result is good, but we are not able to increase the test accuracy further.", "sum_nltk_words": 211, "sum_nltk_runtime": 0.005, "sum_t5": "one in seven adults in the united states have diabetes. by next few years this rate could move higher. k-nearest neighbors algorithm is arguably the simplest machine learning algorithm. it finds the closest data points in the training data set \u2014 its \u201cnearest neighbors\u201d. accuracy on the training set is 100%, while the test set accuracy is much worse. this is an indicative that the tree is overfitting and not generalizing well to new data.", "sum_t5_words": 75, "sum_t5_runtime": 6.278, "runtime": 0.009, "nltk_category": "Healthcare", "nltk_category_score": 0.2535858750343323, "nltk_category_runtime": 20.844, "nltk_subcategory": "Machine Learning", "nltk_subcategory_score": 0.9770120978355408, "nltk_subcategory_runtime": 33.849, "category": "Healthcare", "category_score": 0.2535858750343323, "subcategory": "Machine Learning", "subcategory_score": 0.9770120978355408, "runtime_cat": 54.694, "programming_language": "Python", "ml_score": "1.0", "language_code": "en", "language_score": "0.9999964217422219", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "according report center disease control prevention one seven adult united state diabetes next year rate move higher mind today article show use machine learning predict diabetes using pythonlets straightaway get data download data used article predict diabetes belownow let import data get startedthe diabetes data set consists 768 data point 9 feature eachdimension diabetes data 768 9outcome feature going predict 0 mean diabetes 1 mean diabetes 768 data point 500 labeled 0 268 1the knearest neighbor algorithm arguably simplest machine learning algorithm building model consists storing training data set make prediction new point dataset algorithm find closest data point training data set nearest neighborsfirst let investigate whether confirm connection model complexity accuracylets check accuracy score knearest neighbor algorithm predict diabetesaccuracy knn classifier training set 079accuracy knn classifier test set 078accuracy training set 1000accuracy test set 0714the accuracy training set decision tree classifier 100 test set accuracy much worse indicative tree overfitting generalizing well new data therefore need apply prepruning treenow set max_depth3 limiting depth tree decrease overfitting lead lower accuracy training set improvement test setaccuracy training set 0773accuracy test set 0740feature importance show important feature decision decision tree classifier make number 0 1 feature 0 mean used 1 mean perfectly predicts target feature importance always sum 1feature importance 004554275 06830362 0 0 0 027142106 0 0 let visualize feature importance decision tree predict diabetesso glucose feature used predict diabeteslets train deep learning model predict diabetesaccuracy training set 071accuracy test set 067the accuracy multilayer perceptrons mlp good model likely due scaling data deep learning algorithm also expect input feature vary similar way ideally mean 0 variance 1 rescale data fulfills requirement predict diabetes good accuracyaccuracy training set 0823accuracy test set 0802now let increase number iteration alpha parameter add stronger parameter weight modelaccuracy training set 0795accuracy test set 0792the result good able increase test accuracy therefore best model far default deep learning model scaling plot heat map first layer weight neural network learned predict diabetes using data seti hope liked article predict diabetes machine learning feel free ask valuable question comment section dont forget subscribe daily newsletter receive daily post notification like work", "tags_descriptive": ["Deep Learning (DL)", "Decision Tree", "k-nearest neighbors (KNN)", "Classification"]}