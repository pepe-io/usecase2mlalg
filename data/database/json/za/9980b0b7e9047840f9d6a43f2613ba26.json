{"title": "Syntax-Aware Language Modeling with Recurrent Neural Networks", "link": "https://arxiv.org/abs/1803.03665", "tags": ["NLP", "Language Model", "Fashion"], "description": "Neural language models (LMs) are typically trained using only lexical features, such as surface forms of words. In this paper, we argue this deprives the LM of crucial syntactic signals that can be detected at high confidence using existing parsers. We present a simple but highly effective approach for training neural LMs using both lexical and syntactic information, and a novel approach for applying such LMs to unparsed text using sequential Monte Carlo sampling. In experiments on a range of corpora and corpus sizes, we show our approach consistently outperforms standard lexical LMs in character-level language modeling; on the other hand, for word-level models the models are on a par with standard language models. These results indicate potential for expanding LMs beyond lexical surface features to higher-level NLP features for character-level models.", "category": "Education & Research", "category_score": 1, "subcategory": "Machine Learning", "subcategory_score": 1, "ml_score": "1", "host": "zalando.com", "kind": "Article", "date_scraped": "2021-01-17 00:00:00", "learn_score": 0.5, "explore_score": 0, "compete_score": 0.75, "words": 132, "sentences": 5, "language_code": "en", "language": "english", "language_score": "0.9999975550276955", "runtime": 0.002, "description_lemmatized": "neural language model lm typically trained using lexical feature surface form word paper argue deprives lm crucial syntactic signal detected high confidence using existing parser present simple highly effective approach training neural lm using lexical syntactic information novel approach applying lm unparsed text using sequential monte carlo sampling experiment range corpus corpus size show approach consistently outperforms standard lexical lm characterlevel language modeling hand wordlevel model model par standard language model result indicate potential expanding lm beyond lexical surface feature higherlevel nlp feature characterlevel model", "tags_descriptive": ["Natural Language Processing (NLP)", "Language Model", "Fashion"]}