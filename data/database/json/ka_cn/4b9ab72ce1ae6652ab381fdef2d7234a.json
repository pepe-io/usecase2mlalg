{"title": "Automated Feature Engineering Basics ", "description": "Introduction: Automated Feature Engineering BasicsIn this notebook, we will walk through applying automated feature engineering to the Home Credit Default Risk dataset using the featuretools library. Featuretools is an open-source Python package for automatically creating new features from multiple tables of structured, related data. It is ideal tool for problems such as the Home Credit Default Risk competition where there are several related tables that need to be combined into a single dataframe for training (and one for testing). Feature EngineeringThe objective of feature engineering is to create new features (alos called explantory variables or predictors) to represent as much information from an entire dataset in one table.  Typically, this process is done by hand using pandas operations such as groupby, agg, or merge and can be very tedious. Moreover, manual feature engineering is limited both by human time constraints and imagination: we simply cannot conceive of every possible feature that will be useful. (For an example of using manual feature engineering, check out part one and part two applied to this competition). The importance of creating the proper features cannot be overstated because a machine learning model can only learn from the data we give to it. Extracting as much information as possible from the available datasets is crucial to creating an effective solution. Automated feature engineering aims to help the data scientist with the problem of feature creation by automatically building hundreds or thousands of new features from a dataset. Featuretools - the only library for automated feature engineering at the moment - will not replace the data scientist, but it will allow her to focus on more valuable parts of the machine learning pipeline, such as delivering robust models into production. Here we will touch on the concepts of automated feature engineering with featuretools and show how to implement it for the Home Credit Default Risk competition. We will stick to the basics so we can get the ideas down and then build upon this foundation in later work when we customize featuretools. We will work with a subset of the data because this is a computationally intensive job that is outside the capabilities of the Kaggle kernels. I took the work done in this notebook and ran the methods on the entire dataset with the results available here. At the end of this notebook, we'll look at the features themselves, as well as the results of modeling with different combinations of hand designed and automatically built features. If you are new to this competition, I suggest checking out this post to get started. For a good take on why features are so important, here's a blog post by one of the developers of Featuretools.", "link": "https://www.kaggle.com/willkoehrsen/automated-feature-engineering-basics", "tags": ["Feature Engineering"], "kind": ["Project", "(Notebook)"], "ml_libs": [], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2018-06-17 02:21:22", "date_scraped": "2020-12-12 20:47:32", "words": 449, "sentences": 18, "sum_nltk": "Introduction: Automated Feature Engineering BasicsIn this notebook, we will walk through applying automated feature engineering to the Home Credit Default Risk dataset using the featuretools library.\nFeaturetools is an open-source Python package for automatically creating new features from multiple tables of structured, related data.\nIt is ideal tool for problems such as the Home Credit Default Risk competition where there are several related tables that need to be combined into a single dataframe for training (and one for testing).\nFeature EngineeringThe objective of feature engineering is to create new features (alos called explantory variables or predictors) to represent as much information from an entire dataset in one table.\nAutomated feature engineering aims to help the data scientist with the problem of feature creation by automatically building hundreds or thousands of new features from a dataset.\nFeaturetools - the only library for automated feature engineering at the moment - will not replace the data scientist, but it will allow her to focus on more valuable parts of the machine learning pipeline, such as delivering robust models into production.\nHere we will touch on the concepts of automated feature engineering with featuretools and show how to implement it for the Home Credit Default Risk competition.", "sum_nltk_words": 197, "sum_nltk_runtime": 0.005, "sum_t5": "Featuretools is an open-source Python package for automatically creating new features from multiple tables of structured, related data. ideal tool for problems such as the Home Credit Default Risk competition where there are several related tables that need to be combined into a single dataframe. Feature engineering is to create new features to represent as much information from an entire dataset in one table. manual feature engineering is limited both by human time constraints and imagination. Featuretools will not replace the data scientist, but it will allow her to focus on", "sum_t5_words": 91, "sum_t5_runtime": 6.956, "runtime": 0.005, "nltk_category": "Justice, Law and Regulations", "nltk_category_score": 0.4662681818008423, "nltk_category_runtime": 16.317, "nltk_subcategory": "Judicial Applied", "nltk_subcategory_score": 0.9218368530273438, "nltk_subcategory_runtime": 26.223, "category": "Justice, Law and Regulations", "category_score": 0.4662681818008423, "subcategory": "Judicial Applied", "subcategory_score": 0.9218368530273438, "runtime_cat": 42.541, "programming_language": "Jupyter Notebook", "ml_score": "0.5", "engagement_score": "0.801", "language_code": "en", "language_score": "0.9999988512274163", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "introduction automated feature engineering basicsin notebook walk applying automated feature engineering home credit default risk dataset using featuretools library featuretools opensource python package automatically creating new feature multiple table structured related data ideal tool problem home credit default risk competition several related table need combined single dataframe training one testing feature engineeringthe objective feature engineering create new feature alos called explantory variable predictor represent much information entire dataset one table typically process done hand using panda operation groupby agg merge tedious moreover manual feature engineering limited human time constraint imagination simply cannot conceive every possible feature useful example using manual feature engineering check part one part two applied competition importance creating proper feature cannot overstated machine learning model learn data give extracting much information possible available datasets crucial creating effective solution automated feature engineering aim help data scientist problem feature creation automatically building hundred thousand new feature dataset featuretools library automated feature engineering moment replace data scientist allow focus valuable part machine learning pipeline delivering robust model production touch concept automated feature engineering featuretools show implement home credit default risk competition stick basic get idea build upon foundation later work customize featuretools work subset data computationally intensive job outside capability kaggle kernel took work done notebook ran method entire dataset result available end notebook well look feature well result modeling different combination hand designed automatically built feature new competition suggest checking post get started good take feature important here blog post one developer featuretools", "tags_descriptive": ["Feature Engineering"]}