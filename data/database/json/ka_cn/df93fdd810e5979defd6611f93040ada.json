{"title": "Deep Learning Benchmark [-0.0439]", "description": "SummaryI tried out a neural network for classification because Machine Learning. With the large number of samples and 1000 samples per class, the task seems to be well-suited for Deep Learning. As expected, the model achieved significant results. There is still some room for improvement, so maybe combining the model with XGBoost can help there. ApproachI used the subm.csv output file from ZFTurbo's Greedy children baseline [0.8168] kernel. As features, I used the children's wishlists and their id resulting in 11 features.", "link": "https://www.kaggle.com/batzner/deep-learning-benchmark-0-0439", "tags": [], "kind": ["Project", "(Notebook)"], "ml_libs": ["keras", "tensorflow"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2017-12-14 00:14:59", "date_scraped": "2020-12-13 16:57:44", "words": 82, "sentences": 6, "runtime": 0.001, "description_category": "Accommodation & Food", "description_category_score": 0.15411660075187683, "description_category_runtime": 8.651, "description_subcategory": "Machine Learning", "description_subcategory_score": 0.9987059831619263, "description_subcategory_runtime": 13.415, "category": "Accommodation & Food", "category_score": 0.15411660075187683, "subcategory": "Machine Learning", "subcategory_score": 0.9987059831619263, "runtime_cat": 22.066, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.659", "language_code": "en", "language_score": "0.9999971895580791", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "summaryi tried neural network classification machine learning large number sample 1000 sample per class task seems wellsuited deep learning expected model achieved significant result still room improvement maybe combining model xgboost help approachi used submcsv output file zfturbos greedy child baseline 08168 kernel feature used childrens wishlists id resulting 11 feature", "tags_descriptive": []}