{"title": "Giba Keras, 5-fold, log_specgram, curated only", "description": "In this notebook I present the basic keypoints of my attempt to tackle the problem. I hope you all find it helpfull. The key-points are:  I choose a np.log version of scipy.signal.spectrogram to transform 1-D audio signal to 2-D imaging. The model uses softmax activation function. During training I select random 1-seconds parts from the audio signals (see DataGenerator). I use a stratified version of k-fold based on the first class. That means that for stratification purposes I choose one of the many classes (see dictionary first_labels_set)  I calculate out-of-fold predictions (oof_y) which I use to estimate the lwlrap score. The test set is evaluated and averaged k=5 times. The evaluation is done using TestDataGenerator hence introducing some randomness and non-determinism (res_Y = model.predict_generator(test_gen, verbose=1)) The training process is optimizing categorical_crossentropy and monitors categorical_accuracy for termination. By using early stopping in each fold I implicitly introduce some overfitting on the validation set. I expect more stable estimation by using fixed number of iterations, but is is not my style :)  The whole kernel takes ~2 hours to train and a couple of minutes for inference if you use the pretrained weights I already attach.  (GIBA) Increased Window time to 1.5 * 44100 (GIBA) Added TTA at test time", "link": "https://www.kaggle.com/titericz/giba-keras-2-folds-from-scratch-lb-0-501", "tags": [], "kind": ["Project", "(Notebook)"], "ml_libs": ["sklearn", "keras", "tensorflow", "pattern"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2019-04-24 04:47:19", "date_scraped": "2020-12-12 20:05:18", "words": 212, "sentences": 12, "sum_nltk": "In this notebook I present the basic keypoints of my attempt to tackle the problem.\nThe key-points are:  I choose a np.log version of scipy.signal.spectrogram to transform 1-D audio signal to 2-D imaging.\nThe model uses softmax activation function.\nDuring training I select random 1-seconds parts from the audio signals (see DataGenerator).\nI use a stratified version of k-fold based on the first class.\nThat means that for stratification purposes I choose one of the many classes (see dictionary first_labels_set)  I calculate out-of-fold predictions (oof_y) which I use to estimate the lwlrap score.\nThe test set is evaluated and averaged k=5 times.\nThe evaluation is done using TestDataGenerator hence introducing some randomness and non-determinism (res_Y = model.predict_generator(test_gen, verbose=1)) The training process is optimizing categorical_crossentropy and monitors categorical_accuracy for termination.\nBy using early stopping in each fold I implicitly introduce some overfitting on the validation set.\nI expect more stable estimation by using fixed number of iterations, but is is not my style :)  The whole kernel takes ~2 hours to train and a couple of minutes for inference if you use the pretrained weights I already attach.\n(GIBA) Increased Window time to 1.5 * 44100 (GIBA) Added TTA at test time", "sum_nltk_words": 194, "sum_nltk_runtime": 0.002, "sum_t5": "a notebook tries to solve a problem of converting 1-D audio signal to 2-D imaging. a test set is evaluated and averaged k=5 times. the whole kernel takes 2 hours to train and a couple of minutes for inference. a new version of the giba software is available for download. a new version of the giba software is available for download. a new version of the giba software is available for download", "sum_t5_words": 72, "sum_t5_runtime": 6.274, "runtime": 0.0, "nltk_category": "Utilities", "nltk_category_score": 0.4672096073627472, "nltk_category_runtime": 21.931, "nltk_subcategory": "Machine Learning", "nltk_subcategory_score": 0.8988072872161865, "nltk_subcategory_runtime": 35.113, "category": "Utilities", "category_score": 0.4672096073627472, "subcategory": "Machine Learning", "subcategory_score": 0.8988072872161865, "runtime_cat": 57.044, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.686", "language_code": "en", "language_score": "0.9999961999231608", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "notebook present basic keypoints attempt tackle problem hope find helpfull keypoints choose nplog version scipysignalspectrogram transform 1d audio signal 2d imaging model us softmax activation function training select random 1seconds part audio signal see datagenerator use stratified version kfold based first class mean stratification purpose choose one many class see dictionary first_labels_set calculate outoffold prediction oof_y use estimate lwlrap score test set evaluated averaged k5 time evaluation done using testdatagenerator hence introducing randomness nondeterminism res_y modelpredict_generatortest_gen verbose1 training process optimizing categorical_crossentropy monitor categorical_accuracy termination using early stopping fold implicitly introduce overfitting validation set expect stable estimation using fixed number iteration style whole kernel take 2 hour train couple minute inference use pretrained weight already attach giba increased window time 15 44100 giba added tta test time", "tags_descriptive": []}