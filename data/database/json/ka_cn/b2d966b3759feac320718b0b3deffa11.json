{"title": "The fallacy of encoding assetCode ", "description": "The fallacy of encoding assetCodeBy @marketneutral There have been a few kernel shares of gradient-boosted decision trees (\"GBDT\"; e.g., lightgbm) applied directly to the data \"as is\" in this competition. The results of this show that assetCode (and assetName), as a categorical variable, is a substantially important feature. Does this make sense? If you simply know the ticker symbol should that add predictive power to the model? On the face of it, it seems implausible and that the use of assetCode rather is simply leaking future information and producing an overfit model. I investigate this idea in this kernel. Minimal ReproductionFirst, let's do a minimal reproduction. There is no effort here to do parameter tuning, or to create a great model per se. Here we just want to fit the bare minimum GBDT model and see what features the model thinks are important. We just want to reproduce in a minimal way that the model will find assetCode and assetName to be very important.", "link": "https://www.kaggle.com/marketneutral/the-fallacy-of-encoding-assetcode", "tags": ["Finance", "Exploratory Data Analysis", "Feature Engineering"], "kind": ["Project", "(Notebook)"], "ml_libs": ["sklearn", "lightgbm"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2018-10-16 17:48:42", "date_scraped": "2020-12-13 18:02:27", "words": 164, "sentences": 8, "runtime": 0.003, "description_category": "Finance", "description_category_score": 0.4272007346153259, "description_category_runtime": 14.565, "description_subcategory": "Marketing", "description_subcategory_score": 0.8806560039520264, "description_subcategory_runtime": 23.504, "category": "Finance", "category_score": 0.4272007346153259, "subcategory": "Marketing", "subcategory_score": 0.8806560039520264, "runtime_cat": 38.069, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.719", "language_code": "en", "language_score": "0.9999964477546879", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "fallacy encoding assetcodeby marketneutral kernel share gradientboosted decision tree gbdt eg lightgbm applied directly data competition result show assetcode assetname categorical variable substantially important feature make sense simply know ticker symbol add predictive power model face seems implausible use assetcode rather simply leaking future information producing overfit model investigate idea kernel minimal reproductionfirst let minimal reproduction effort parameter tuning create great model per se want fit bare minimum gbdt model see feature model think important want reproduce minimal way model find assetcode assetname important", "tags_descriptive": ["Finance", "Exploratory Data Analysis", "Feature Engineering"]}