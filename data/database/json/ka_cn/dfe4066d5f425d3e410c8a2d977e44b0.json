{"title": "Vision Transformer: goodbye_CNN[Training]", "description": "This kernel is one of the first Vision Transformer implementations, a simple way to achieve SOTA in vision classification with only a single transformer encoder, in Pytorch, based on \"https://github.com/lucidrains/vit-pytorch\" with much lower parameters. It challenges the paradigm of Convolutions for vision. It instead represents images as a set of visual tokens and applies visual transformers to find relationships between visual semantic concepts. Given an input image,it dynamically extracts a set of visual tokens from the image to obtain a compact representation for high-level semantics. Then, It uses visual transformers to operate over the visual tokens to densely model relationships between them. We replaced the attention layer with a more efficient network, called \"Linformer\". This is attention with only linear complexity in n, allowing for very long sequence lengths (1mil+) to be attended to on GPU. One can also use axial attention instead as was mention in their paper. The paper is under open review for ICLR 2021. The data management and pipeline is also based on \"https://www.kaggle.com/orkatz2/pulmonary-embolism-pytorch-train\".", "link": "https://www.kaggle.com/rythian47/vision-transformer-goodbye-cnn-training", "tags": [], "kind": ["Project", "(Notebook)"], "ml_libs": ["sklearn", "pytorch", "skimage", "albumentations"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2020-10-24 19:23:44", "date_scraped": "2020-12-13 16:49:33", "words": 168, "sentences": 10, "runtime": 0.002, "description_category": "Healthcare", "description_category_score": 0.08801013231277466, "description_category_runtime": 17.036, "description_subcategory": "Machine Learning", "description_subcategory_score": 0.9327669739723206, "description_subcategory_runtime": 27.761, "category": "Healthcare", "category_score": 0.08801013231277466, "subcategory": "Machine Learning", "subcategory_score": 0.9327669739723206, "runtime_cat": 44.796, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.679", "language_code": "en", "language_score": "0.9999981812589503", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "kernel one first vision transformer implementation simple way achieve sota vision classification single transformer encoder pytorch based httpsgithubcomlucidrainsvitpytorch much lower parameter challenge paradigm convolution vision instead represents image set visual token applies visual transformer find relationship visual semantic concept given input imageit dynamically extract set visual token image obtain compact representation highlevel semantics us visual transformer operate visual token densely model relationship replaced attention layer efficient network called linformer attention linear complexity n allowing long sequence length 1mil attended gpu one also use axial attention instead mention paper paper open review iclr 2021 data management pipeline also based httpswwwkagglecomorkatz2pulmonaryembolismpytorchtrain", "tags_descriptive": []}