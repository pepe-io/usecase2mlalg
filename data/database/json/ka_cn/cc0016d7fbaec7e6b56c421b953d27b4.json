{"title": "Different embeddings with Attention! [Fork][Fork]", "description": "Refer: Based on: https://www.kaggle.com/danofer/different-embeddings-with-attention-fork SRK: https://www.kaggle.com/sudalairajkumar/a-look-at-different-embeddings . There is not much changed from this kernel except the nueral net architecture and final weights of the embeddings. Code for attention layer is taken from Khoi Ngyuen: https://www.kaggle.com/suicaokhoailang/lstm-attention-baseline-0-652-lb CNN: https://www.kaggle.com/yekenot/2dcnn-textclassifier", "link": "https://www.kaggle.com/shujian/different-embeddings-with-attention-fork-fork", "tags": [], "kind": ["Project", "(Notebook)"], "ml_libs": ["sklearn", "keras"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2018-11-13 04:35:15", "date_scraped": "2020-12-13 16:20:42", "words": 38, "sentences": 3, "runtime": 0.001, "description_category": "Wholesale & Retail", "description_category_score": 0.06874267756938934, "description_category_runtime": 11.295, "description_subcategory": "Machine Learning", "description_subcategory_score": 0.7653598785400391, "description_subcategory_runtime": 17.201, "category": "Wholesale & Retail", "category_score": 0.06874267756938934, "subcategory": "Machine Learning", "subcategory_score": 0.7653598785400391, "runtime_cat": 28.496, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.758", "language_code": "en", "language_score": "0.9999964944137996", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "refer based httpswwwkagglecomdanoferdifferentembeddingswithattentionfork srk httpswwwkagglecomsudalairajkumaralookatdifferentembeddings much changed kernel except nueral net architecture final weight embeddings code attention layer taken khoi ngyuen httpswwwkagglecomsuicaokhoailanglstmattentionbaseline0652lb cnn httpswwwkagglecomyekenot2dcnntextclassifier", "tags_descriptive": []}