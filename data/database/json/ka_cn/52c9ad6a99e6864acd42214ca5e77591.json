{"title": "LB Probing Strategies - [0.890] - 2nd Place", "description": "LB Probing Techniques - Don't Overfit! II - 2nd Place SolutionIf this kernel, we discuss efficient strategies to probe the Kaggle leaderboard (LB) to gain information about the public test dataset. LR Logistic regression, SVC support vector classifiation, and LDA naive Bayes, are three methods that find linear hyperplanes to classify data. In \"Don't Overfit II\" competition, the public test dataset has 8 times more data than the training dataset. Instead of finding the hyperplane that classifies the training data, we would prefer to find the hyperplane that classifies the public test dataset. We can. Let's assume target=Heaviside(a0x0+a1x1+...a298x298+a299x299+noise)target=Heaviside(a0x0+a1x1+...a298x298+a299x299+noise) Our task is to determine the 300 hyperplane coefficients a_k. Assuming the a_k are independent, then the following code extracts them from the public test dataset via LB probing: var = 33 test = pd.read_csv('test.csv') sub = pd.read_csv('sample_submission.csv') sub['target'] = test[str(var)] sub.to_csv('submission'+str(var)+'.csv',index=False)     Then the value of a_k is the just LB_SCORE_K minus 0.500. For example a33=LB_SCORE33\u22120.500=0.671\u22120.500=0.171a33=LB_SCORE33\u22120.500=0.671\u22120.500=0.171 When a variable is negatively correlated with target (as opposed to positively correlated), then the LB_SCORE_K will be less than 0.500.  a217=LB_SCORE217\u22120.500=0.382\u22120.500=\u22120.118a217=LB_SCORE217\u22120.500=0.382\u22120.500=\u22120.118 It's that simple! By doing this, we can recover the a_k in 20 days (100 submissions) with the following 3 additional tricks:  Only probe the 100 most important a_k. If abs(CV_SCORE_K - 0.5) < 0.04 set a_k=0 and don't probe. Use train data plus public for more accuracy. Replace LB_SCORE_K with (8/9)*LB_SCORE_K + (1/9)*CV_SCORE_K. Apply L1-penalty. If abs(LB_SCORE_K - 0.5) < 0.04 then set a_k=0.    These additional tricks help prevent overfitting LB. Instead of modeling only the public test dataset and risk overfitting, we use information from both the training data plus public test data for a combined sample size of 2225. With this sample size, it was shown here that any variable with AUC of 0.54 or less by itself may be a useless variable. So we remove all variables with abs(AUC - 0.5) < 0.04 from our model where AUC = (8/9)*LB_AUC + (1/9)*CV_AUC to prevent overfitting useless variables. Note that we are using a linear approximation to find a_k since 0.3 < AUC < 0.7 as explained here.", "link": "https://www.kaggle.com/cdeotte/lb-probing-strategies-0-890-2nd-place", "tags": [], "kind": ["Project", "(Notebook)"], "ml_libs": ["sklearn"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2019-05-18 03:00:48", "date_scraped": "2020-12-12 19:05:08", "words": 356, "sentences": 19, "sum_nltk": "II - 2nd Place SolutionIf this kernel, we discuss efficient strategies to probe the Kaggle leaderboard (LB) to gain information about the public test dataset.\nIn \"Don't Overfit II\" competition, the public test dataset has 8 times more data than the training dataset.\nInstead of finding the hyperplane that classifies the training data, we would prefer to find the hyperplane that classifies the public test dataset.\nAssuming the a_k are independent, then the following code extracts them from the public test dataset via LB probing: var = 33 test = pd.read_csv('test.csv') sub = pd.read_csv('sample_submission.csv') sub['target'] = test[str(var)] sub.to_csv('submission'+str(var)+'.csv',index=False)     Then the value of a_k is the just LB_SCORE_K minus 0.500.\nIf abs(CV_SCORE_K - 0.5) < 0.04 set a_k=0 and don't probe.\nUse train data plus public for more accuracy.\nInstead of modeling only the public test dataset and risk overfitting, we use information from both the training data plus public test data for a combined sample size of 2225.\nWith this sample size, it was shown here that any variable with AUC of 0.54 or less by itself may be a useless variable.\nSo we remove all variables with abs(AUC - 0.5) < 0.04 from our model where AUC = (8/9)*LB_AUC + (1/9)*CV_AUC to prevent overfitting useless variables.", "sum_nltk_words": 203, "sum_nltk_runtime": 0.004, "sum_t5": "LR Logistic regression, SVC support vector classifiation, and LDA naive Bayes, are three methods that find linear hyperplanes to classify data. in \"Don't Overfit II\" competition, the public test dataset has 8 times more data than the training dataset. instead of finding the hyperplane that classifies the training data, we would prefer to find the hyperplane that classifies the public test dataset.", "sum_t5_words": 62, "sum_t5_runtime": 6.24, "runtime": 0.004, "nltk_category": "Finance", "nltk_category_score": 0.24631203711032867, "nltk_category_runtime": 24.776, "nltk_subcategory": "Machine Learning", "nltk_subcategory_score": 0.7285365462303162, "nltk_subcategory_runtime": 39.596, "category": "Finance", "category_score": 0.24631203711032867, "subcategory": "Machine Learning", "subcategory_score": 0.7285365462303162, "runtime_cat": 64.372, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.738", "language_code": "en", "language_score": "0.9999962280241028", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "lb probing technique dont overfit ii 2nd place solutionif kernel discus efficient strategy probe kaggle leaderboard lb gain information public test dataset lr logistic regression svc support vector classifiation lda naive bayes three method find linear hyperplanes classify data dont overfit ii competition public test dataset 8 time data training dataset instead finding hyperplane classifies training data would prefer find hyperplane classifies public test dataset let assume targetheavisidea0x0a1x1a298x298a299x299noisetargetheavisidea0x0a1x1a298x298a299x299noise task determine 300 hyperplane coefficient a_k assuming a_k independent following code extract public test dataset via lb probing var 33 test pdread_csvtestcsv sub pdread_csvsample_submissioncsv subtarget teststrvar subto_csvsubmissionstrvarcsvindexfalse value a_k lb_score_k minus 0500 example a33lb_score330500067105000171a33lb_score330500067105000171 variable negatively correlated target opposed positively correlated lb_score_k le 0500 a217lb_score2170500038205000118a217lb_score2170500038205000118 simple recover a_k 20 day 100 submission following 3 additional trick probe 100 important a_k abscv_score_k 05 004 set a_k0 dont probe use train data plus public accuracy replace lb_score_k 89lb_score_k 19cv_score_k apply l1penalty abslb_score_k 05 004 set a_k0 additional trick help prevent overfitting lb instead modeling public test dataset risk overfitting use information training data plus public test data combined sample size 2225 sample size shown variable auc 054 le may useless variable remove variable absauc 05 004 model auc 89lb_auc 19cv_auc prevent overfitting useless variable note using linear approximation find a_k since 03 auc 07 explained", "tags_descriptive": []}