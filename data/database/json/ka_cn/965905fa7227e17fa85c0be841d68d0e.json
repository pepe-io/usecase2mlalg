{"title": "Finding-Relative-Faces", "description": "This notebook got 77.20% accuracy as a public score. Besides, it has a 72.62% accuracy on training set, 70.90% accuracy on validation set and 70.95% accuracy on cross validation set. We can clearly say that it is a generalized model and it is not over-fitted! I have used 3 different face recognition models: VGG-Face, Facenet and OpenFace. These models find the embeddings of faces. Finding distances between embeddings can give a clue to find related ones. Herein, I included both cosine or euclidean distances as a feature. I expect that GBM classifier would find the weights for these models and metrics. I also added some additional features such as age, gender and emotion. Besides, only related ones are shared as a training set. I've generated data for unrelated ones and store in the file 'train_true_negative_features.csv'. On the other hands, related ones are stored in 'train_true_positive_features.csv' whereas test set is stored in 'testset_features.csv'. You can directly load these files and skip preprocessing steps. If you wonder how these similarities calculated, the following links might help you. Face Recognition models: VGG-Face: https://sefiks.com/2018/08/06/deep-face-recognition-with-keras/ Facenet: https://sefiks.com/2018/09/03/face-recognition-with-facenet-in-keras/ OpenFace: https://sefiks.com/2019/07/21/face-recognition-with-openface-in-keras/ Additional Features: Age and gender: https://sefiks.com/2019/02/13/apparent-age-and-gender-prediction-in-keras/ Emotion: https://sefiks.com/2018/01/01/facial-expression-recognition-with-keras/", "link": "https://www.kaggle.com/serengil/finding-relative-faces", "tags": ["DL", "Gradient Boosting"], "kind": ["Project", "(Notebook)"], "ml_libs": ["sklearn", "keras", "openface", "lightgbm"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2019-08-07 19:27:47", "date_scraped": "2020-12-13 16:27:41", "words": 192, "sentences": 14, "runtime": 0.002, "description_category": "Healthcare", "description_category_score": 0.14668111503124237, "description_category_runtime": 29.678, "description_subcategory": "General", "description_subcategory_score": 0.9702245593070984, "description_subcategory_runtime": 48.548, "category": "Healthcare", "category_score": 0.14668111503124237, "subcategory": "General", "subcategory_score": 0.9702245593070984, "runtime_cat": 78.226, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.657", "language_code": "en", "language_score": "0.9999977154799324", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "notebook got 7720 accuracy public score besides 7262 accuracy training set 7090 accuracy validation set 7095 accuracy cross validation set clearly say generalized model overfitted used 3 different face recognition model vggface facenet openface model find embeddings face finding distance embeddings give clue find related one herein included cosine euclidean distance feature expect gbm classifier would find weight model metric also added additional feature age gender emotion besides related one shared training set ive generated data unrelated one store file train_true_negative_featurescsv hand related one stored train_true_positive_featurescsv whereas test set stored testset_featurescsv directly load file skip preprocessing step wonder similarity calculated following link might help face recognition model vggface httpssefikscom20180806deepfacerecognitionwithkeras facenet httpssefikscom20180903facerecognitionwithfacenetinkeras openface httpssefikscom20190721facerecognitionwithopenfaceinkeras additional feature age gender httpssefikscom20190213apparentageandgenderpredictioninkeras emotion httpssefikscom20180101facialexpressionrecognitionwithkeras", "tags_descriptive": ["Deep Learning (DL)", "Gradient Boosting"]}