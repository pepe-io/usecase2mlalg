{"title": "Effective Feature Engineering", "description": "Effective feature engineeringSay, you have a model which takes 1 hour to train. Do you always need to wait for 1 hour to see the impact of a newly added feature? I talked with experienced Kaggers about feature engineering. They said that you get more accurate result when you check on the actual complex model you carefully built. But, it can be another risk if longer training time reduces the number of your trials. Traid-off: Accurate result <=> The number of trials How they work on a competition is like below.  EDA Build a simple model Try various features on a simple model Build a complex model Train with promising features  They go back and forth between steps during a competition. If you successfully setup an effective environment for experiments at the beginning of the competition, it puts you at an advantage. I created a Kernel dedicated for feature engineering for this competition. I'd like to share what I've done so far.  Correlation Score gain on a simple model Feature importances of Tree models Permutation importance SHAP values Score gain on a complex model  The upper things are faster but less accurate and lower things are more accurate but slower. I'm trying from the top of the list when I come up with a new idea. 1. CorrelationThis is the simplest way to see the relation between features. In here, if the value on the target is close to 0, it means that the feature may be irrelevant to the target.", "link": "https://www.kaggle.com/rejasupotaro/effective-feature-engineering", "tags": ["Feature Engineering"], "kind": ["Project", "(Notebook)"], "ml_libs": ["sklearn", "lightgbm"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2018-10-19 08:36:22", "date_scraped": "2020-12-13 16:17:21", "words": 255, "sentences": 14, "sum_nltk": "Effective feature engineeringSay, you have a model which takes 1 hour to train.\nThey said that you get more accurate result when you check on the actual complex model you carefully built.\nBut, it can be another risk if longer training time reduces the number of your trials.\nTraid-off: Accurate result <=> The number of trials How they work on a competition is like below.\nEDA Build a simple model Try various features on a simple model Build a complex model Train with promising features  They go back and forth between steps during a competition.\nIf you successfully setup an effective environment for experiments at the beginning of the competition, it puts you at an advantage.\nI created a Kernel dedicated for feature engineering for this competition.\nI'd like to share what I've done so far.\nCorrelation Score gain on a simple model Feature importances of Tree models Permutation importance SHAP values Score gain on a complex model  The upper things are faster but less accurate and lower things are more accurate but slower.\nIn here, if the value on the target is close to 0, it means that the feature may be irrelevant to the target.", "sum_nltk_words": 190, "sum_nltk_runtime": 0.003, "sum_t5": "a feature engineering competition is a competition for the best feature engineering. the competition is a test of the effectiveness of feature engineering. the top three features are the correlation and the shapability. the lower things are more accurate but slower. the upper things are faster but less accurate.. the lower things are more accurate but slower.. the higher things are faster but less accurate.. the lower things are more accurate but slower.", "sum_t5_words": 73, "sum_t5_runtime": 4.671, "runtime": 0.002, "nltk_category": "Finance", "nltk_category_score": 0.2775513827800751, "nltk_category_runtime": 16.5, "nltk_subcategory": "Machine Learning", "nltk_subcategory_score": 0.3795227110385895, "nltk_subcategory_runtime": 27.263, "category": "Finance", "category_score": 0.2775513827800751, "subcategory": "Machine Learning", "subcategory_score": 0.3795227110385895, "runtime_cat": 43.765, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.778", "language_code": "en", "language_score": "0.9999967035954764", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "effective feature engineeringsay model take 1 hour train always need wait 1 hour see impact newly added feature talked experienced kaggers feature engineering said get accurate result check actual complex model carefully built another risk longer training time reduces number trial traidoff accurate result number trial work competition like eda build simple model try various feature simple model build complex model train promising feature go back forth step competition successfully setup effective environment experiment beginning competition put advantage created kernel dedicated feature engineering competition id like share ive done far correlation score gain simple model feature importance tree model permutation importance shap value score gain complex model upper thing faster le accurate lower thing accurate slower im trying top list come new idea 1 correlationthis simplest way see relation feature value target close 0 mean feature may irrelevant target", "tags_descriptive": ["Feature Engineering"]}