{"title": "Similarity DenseNet", "description": "OverviewThe goal of this competition is identifying individual whales in images. Despite several whales are well represented in images, most of whales are unique or shown only in a few pictures. In particular, the train dataset includes 25k images and 5k unique whale ids. In addition, ~10k of images show unique whales ('new_whale' label). Checking public kernels suggests that a classical approach for classification problems based on softmax prediction for all classes is working quite well for this particular problem. However, strong class imbalance, handling labels represented by just several images, and 'new_whale' label deteriorates this approach. In addition, form the using this model for production, the above approach doesn't sound right since expansion of the model to identify new whales not represented in the train dataset would require retraining the model with increased softmax size. Meanwhile, the task of this competition could be reconsidered as checking similarities that suggests one-shot based learning algorithm to be applicable. This approach is less susceptible to data imbalance in this competition, can naturally handle 'new_whale' class, and is scalable in terms of a model for production (new classes can be added without retraining the model). There are several public kernels targeted at using similarity based approach. First of all, it is an amazing kernel posted by Martin Piotte, which discusses Siamese Neural Network architecture in details. A fork of this kernel reports 0.822 public LB score after training for 400 epochs. There is also a quite interesting public kernel discussing Triplet Neural Network architecture, which is supposed to overperform Siamese architecture (check links in this discussion). Since both positive and negative examples are provided, the gradients are appeared to be more stable, and the network is not only trying to get away from negative or get close to positive example but arranges the prediction to fulfil both. In this kernel I provide an example of a network inspired by Triplet architecture that is capable to reach ~0.81 public LB score after training within the kernel time limit in my preliminary test. Training for more epochs is supposed to improve the prediction even further. The main trick of this kernel is using batch all loss. If the forward pass is completed for all images in a batch, why shouldn't I compare all of them when calculate the loss function? why should I limit myself by just several triplets? I have designed a loss function in such a way that allows performing all vs. all comparison within each batch, in other words for a batch of size 32 instead of comparing 32 triplets or 64 pairs the network performs processing of 9216 pairs of images at the same time. If training is done on multiple GPUs, the number of compared pares could be boosted even further since it it proportional to bs^2. Such a huge number of processed pairs further stabilizes gradients in comparison with triplet loss and allows more effective mapping of the input into the embedding space since not only pairs or triplets but entire picture is seen at the same time. This approach also allows effective search for hard negative examples at the later stage of training since each image is compared with all images in a batch. I tried to boost the search of the most difficult negative examples even further by selection of most similar negative examples to an anchor image when build triplets. Moreover, I added metric learning that boosts the performance of the model really a lot. In my preliminary test for V2 setup I got 0.606->0.655 improvement after I started calculating distance as d^2 = (v1-v2).T x A x (v1-v2) instead of Euclidian (v1-v2).T x (v1-v2), where A is a trainable matrix parameter. It can be considered as a trainable deformation of the space. However, the above form of the metric is quite slow at the inference time when distances for all image pairs are calculated. Also, it is quite difficult to impose a constrain on A during training to make it positive semi defined. Therefore, I use an alternative approximation formulation for distance calculation that is much faster at the inference time, symmetric and always positive, and have similar (or slightly better) performance with accounting for nonlinear coordinate transformations. To prevent predictions being spread too much in the embedding space, which deteriorates generalization, I added a compactificcation term to the loss that boosted the score from 0.74 to ~0.771 (V9). When I switched from ResNeXt50 to DenseNet169 backbone I got 0.771 -> ~0.81 improvement, and it appeared that DenseNet121 works a little bit better. I switched to using cropped rescaled square images since they work better. The idea behind rectangular images generated without distortion of images, which I used in the first versions of the kernel, is the following. Since bounding boxes have different aspect ratio, each image has different degree of distortion when rescaled to square one, which could negatively affect training. However, it looks that the setup when the tail is occupying approximately the same area in the image, no matter what is its orientation and distortion, works better. Looking at the produced images I really do not understand why. In my preliminary test for V7 I could get a boost from ~0.70 to ~0.75 public LB after this modification. In the current setup, the images are cropped according to bounding boxes (thanks to this fork and to Martin Piotte for posting the original kernel) and rescaled to 224x224 square images. Milestones of the kernel score improvement and corresponding modifications are summorized in this discussion. This kernel is written with using fast.ai 0.7 since a newer version of fast.ai doesn't work well in kaggle: using more than one core for data loading leads to bus error \"DataLoader worker (pid 137) is killed by signal: Bus error\". Therefore, when I tried to write similar kernel with fast.ai 1.0, it appeared to be much slower, more than 1 hour per epoch vs. 20-30 min with this kernel if ResNet34 and images of size 576x192 are used. People interested in fast.ai 1.0 could check an example of Siamese network here. Also since fast.ai 0.7 is not really designed to build Siamese and Triplet networks, some parts are a little bit far away from a standard usage of the library. Highlights: Batch all loss, metric learning, mining hard negative examples", "link": "https://www.kaggle.com/iafoss/similarity-densenet121-0-805lb-kernel-time-limit", "tags": ["DL", "Classification", "CNN"], "kind": ["Project", "(Notebook)"], "ml_libs": ["sklearn", "pytorch", "Pillow"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2019-02-18 03:47:18", "date_scraped": "2020-12-12 21:28:20", "words": 1052, "sentences": 45, "sum_nltk": "Checking public kernels suggests that a classical approach for classification problems based on softmax prediction for all classes is working quite well for this particular problem.\nIn addition, form the using this model for production, the above approach doesn't sound right since expansion of the model to identify new whales not represented in the train dataset would require retraining the model with increased softmax size.\nThere is also a quite interesting public kernel discussing Triplet Neural Network architecture, which is supposed to overperform Siamese architecture (check links in this discussion).\nIn this kernel I provide an example of a network inspired by Triplet architecture that is capable to reach ~0.81 public LB score after training within the kernel time limit in my preliminary test.\nall comparison within each batch, in other words for a batch of size 32 instead of comparing 32 triplets or 64 pairs the network performs processing of 9216 pairs of images at the same time.\nThis approach also allows effective search for hard negative examples at the later stage of training since each image is compared with all images in a batch.\nI tried to boost the search of the most difficult negative examples even further by selection of most similar negative examples to an anchor image when build triplets.", "sum_nltk_words": 208, "sum_nltk_runtime": 0.012, "sum_t5": "goal of competition is identifying individual whales in images. train dataset includes 25k images and 5k unique whale ids. 10k of images show unique whales ('new_whale' label). but strong class imbalance, handling labels represented by just several images, and 'new_whale' label deteriorates this approach. competition could be reconsidered as checking similarities suggests one-shot based learning algorithm to be applicable.", "sum_t5_words": 59, "sum_t5_runtime": 6.544, "runtime": 0.005, "nltk_category": "Media & Publishing", "nltk_category_score": 0.2935390770435333, "nltk_category_runtime": 17.015, "nltk_subcategory": "Machine Learning", "nltk_subcategory_score": 0.9292218685150146, "nltk_subcategory_runtime": 27.11, "category": "Media & Publishing", "category_score": 0.2935390770435333, "subcategory": "Machine Learning", "subcategory_score": 0.9292218685150146, "runtime_cat": 44.125, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.777", "language_code": "en", "language_score": "0.9999977344704152", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "overviewthe goal competition identifying individual whale image despite several whale well represented image whale unique shown picture particular train dataset includes 25k image 5k unique whale id addition 10k image show unique whale new_whale label checking public kernel suggests classical approach classification problem based softmax prediction class working quite well particular problem however strong class imbalance handling label represented several image new_whale label deteriorates approach addition form using model production approach doesnt sound right since expansion model identify new whale represented train dataset would require retraining model increased softmax size meanwhile task competition could reconsidered checking similarity suggests oneshot based learning algorithm applicable approach le susceptible data imbalance competition naturally handle new_whale class scalable term model production new class added without retraining model several public kernel targeted using similarity based approach first amazing kernel posted martin piotte discus siamese neural network architecture detail fork kernel report 0822 public lb score training 400 epoch also quite interesting public kernel discussing triplet neural network architecture supposed overperform siamese architecture check link discussion since positive negative example provided gradient appeared stable network trying get away negative get close positive example arranges prediction fulfil kernel provide example network inspired triplet architecture capable reach 081 public lb score training within kernel time limit preliminary test training epoch supposed improve prediction even main trick kernel using batch loss forward pas completed image batch shouldnt compare calculate loss function limit several triplet designed loss function way allows performing v comparison within batch word batch size 32 instead comparing 32 triplet 64 pair network performs processing 9216 pair image time training done multiple gpus number compared pares could boosted even since proportional bs2 huge number processed pair stabilizes gradient comparison triplet loss allows effective mapping input embedding space since pair triplet entire picture seen time approach also allows effective search hard negative example later stage training since image compared image batch tried boost search difficult negative example even selection similar negative example anchor image build triplet moreover added metric learning boost performance model really lot preliminary test v2 setup got 06060655 improvement started calculating distance d2 v1v2t x x v1v2 instead euclidian v1v2t x v1v2 trainable matrix parameter considered trainable deformation space however form metric quite slow inference time distance image pair calculated also quite difficult impose constrain training make positive semi defined therefore use alternative approximation formulation distance calculation much faster inference time symmetric always positive similar slightly better performance accounting nonlinear coordinate transformation prevent prediction spread much embedding space deteriorates generalization added compactificcation term loss boosted score 074 0771 v9 switched resnext50 densenet169 backbone got 0771 081 improvement appeared densenet121 work little bit better switched using cropped rescaled square image since work better idea behind rectangular image generated without distortion image used first version kernel following since bounding box different aspect ratio image different degree distortion rescaled square one could negatively affect training however look setup tail occupying approximately area image matter orientation distortion work better looking produced image really understand preliminary test v7 could get boost 070 075 public lb modification current setup image cropped according bounding box thanks fork martin piotte posting original kernel rescaled 224x224 square image milestone kernel score improvement corresponding modification summorized discussion kernel written using fastai 07 since newer version fastai doesnt work well kaggle using one core data loading lead bus error dataloader worker pid 137 killed signal bus error therefore tried write similar kernel fastai 10 appeared much slower 1 hour per epoch v 2030 min kernel resnet34 image size 576x192 used people interested fastai 10 could check example siamese network also since fastai 07 really designed build siamese triplet network part little bit far away standard usage library highlight batch loss metric learning mining hard negative example", "tags_descriptive": ["Deep Learning (DL)", "Classification", "Convolutional Neural Network (CNN)"]}