{"title": "lessons learnt from fast.ai lectures Part-2", "description": "This notebooks is inspired by 2nd Lecture of Fast.ai's ML course. In this notebook, we will be talking about some of the best practices (of removing features) which can save you alot of computation and at the same time increase your score. In particular:  Features importance Removing redundant features Removing temporal features  For all of these topics we will discuss the theory, code and interpretation as well. Hope you all will enjoy it. This is my second kernel, so please comment and let me know the things that you liked and things that you want me to improve. I would love you hear from you. Note: I highly recommend going through the Part-1 as this notebook is basically the continuation of it. Alot of code written here is directly taken from Part-1.", "link": "https://www.kaggle.com/ankursingh12/lessons-learnt-from-fast-ai-lectures-part-2", "tags": ["Random Forest", "Feature Engineering"], "kind": ["Project", "(Notebook)"], "ml_libs": ["sklearn"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2019-01-15 13:06:39", "date_scraped": "2020-12-12 17:19:45", "words": 134, "sentences": 8, "runtime": 0.002, "description_category": "Utilities", "description_category_score": 0.1037106141448021, "description_category_runtime": 11.619, "description_subcategory": "Machine Learning", "description_subcategory_score": 0.769102931022644, "description_subcategory_runtime": 17.855, "category": "Utilities", "category_score": 0.1037106141448021, "subcategory": "Machine Learning", "subcategory_score": 0.769102931022644, "runtime_cat": 29.474, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.605", "language_code": "en", "language_score": "0.9999978925137388", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "notebook inspired 2nd lecture fastais ml course notebook talking best practice removing feature save alot computation time increase score particular feature importance removing redundant feature removing temporal feature topic discus theory code interpretation well hope enjoy second kernel please comment let know thing liked thing want improve would love hear note highly recommend going part1 notebook basically continuation alot code written directly taken part1", "tags_descriptive": ["Random Forest", "Feature Engineering"]}