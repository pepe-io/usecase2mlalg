{"title": "Turbo Charging Andrew's Pytorch", "description": "This kernel is forked from Andrew's Pytorch Kernel https://www.kaggle.com/artgor/segmentation-in-pytorch-using-convenient-tools I have done a couple things to speed things up and allow for larger models. The first one is that I resized the dataset before hand so that we do not need to do this repetitively for each epoch. This takes our epoch time down from ~23 minutes down to ~7 minutes using the same resnet 50 unet architecture. You can do whatever you like with this additional time, train more models, more epochs, larger backbones, etc. The second thing I have done is add in nvidia apex so we can do mixed precision training. This roughly halves memory usage on the GPU and allows us to fit larger models or larger batch sizes. This has allowed me to train the larger se_resnext101_32x4d backbone in a shorter amount of time while also getting a better score.", "link": "https://www.kaggle.com/ryches/turbo-charging-andrew-s-pytorch", "tags": [], "kind": ["Project", "(Notebook)"], "ml_libs": ["albumentations", "sklearn", "opencv-python", "pattern", "pytorch"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2019-09-26 03:23:50", "date_scraped": "2020-12-13 18:07:53", "words": 145, "sentences": 7, "runtime": 0.0, "description_category": "Real Estate, Rental & Leasing", "description_category_score": 0.4325862526893616, "description_category_runtime": 14.192, "description_subcategory": "Machine Learning", "description_subcategory_score": 0.986186683177948, "description_subcategory_runtime": 22.781, "category": "Real Estate, Rental & Leasing", "category_score": 0.4325862526893616, "subcategory": "Machine Learning", "subcategory_score": 0.986186683177948, "runtime_cat": 36.973, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.724", "language_code": "en", "language_score": "0.9999988377428615", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "kernel forked andrew pytorch kernel httpswwwkagglecomartgorsegmentationinpytorchusingconvenienttools done couple thing speed thing allow larger model first one resized dataset hand need repetitively epoch take epoch time 23 minute 7 minute using resnet 50 unet architecture whatever like additional time train model epoch larger backbone etc second thing done add nvidia apex mixed precision training roughly half memory usage gpu allows u fit larger model larger batch size allowed train larger se_resnext101_32x4d backbone shorter amount time also getting better score", "tags_descriptive": []}