{"title": "Bayesian Model Averaging in PyMC3", "description": "Spike-and-Slab Model:  An attempt to imitate the winning stategy from Don't Overfit IBayesian tools have come a long way since Tim Salimans wrote his own Gibbs sampler for the first competition.  These days, it's extremely rare for people to write their own samplers.  Instead, higher level modeling languages like PyMC3 and Stan are used to specify the model with a back-end \"inference engine\" doing the sampling. However, learning how to specify models properly and using the high-level tools to fit them still requires overcoming a learning curve and thinking a bit differently than the traditional data science workflow, so here's a notebook to help get started. I actually prefer Stan, but the Spike-and-Slab model has discrete parameters that are not possible to fit. EDIT:  I've changed the prior on the coefficients to StudentT(3,0,1).  We don't want to over-regularize the included variables. EDIT (again):  A normal prior works even better.  For .86 score, use p=.05 for hyperprior on xi and N(0,.75) as a prior for beta.", "link": "https://www.kaggle.com/melondonkey/bayesian-spike-and-slab-in-pymc3", "tags": [], "kind": ["Project", "(Notebook)"], "ml_libs": ["theano"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2019-03-24 23:50:05", "date_scraped": "2020-12-12 19:05:08", "words": 172, "sentences": 9, "runtime": 0.0, "description_category": "Economics", "description_category_score": 0.06353083997964859, "description_category_runtime": 16.948, "description_subcategory": "Student", "description_subcategory_score": 0.8345224261283875, "description_subcategory_runtime": 27.37, "category": "Economics", "category_score": 0.06353083997964859, "subcategory": "Student", "subcategory_score": 0.8345224261283875, "runtime_cat": 44.318, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.715", "language_code": "en", "language_score": "0.9999962530454196", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "spikeandslab model attempt imitate winning stategy dont overfit ibayesian tool come long way since tim salimans wrote gibbs sampler first competition day extremely rare people write sampler instead higher level modeling language like pymc3 stan used specify model backend inference engine sampling however learning specify model properly using highlevel tool fit still requires overcoming learning curve thinking bit differently traditional data science workflow here notebook help get started actually prefer stan spikeandslab model discrete parameter possible fit edit ive changed prior coefficient studentt301 dont want overregularize included variable edit normal prior work even better 86 score use p05 hyperprior xi n075 prior beta", "tags_descriptive": []}