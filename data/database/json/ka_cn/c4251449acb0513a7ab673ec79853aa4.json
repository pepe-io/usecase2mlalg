{"title": "Transformer Baseline [0.672 LB]", "description": "TL;DR Feature engineering: https://www.kaggle.com/braquino/5-fold-lstm-attention-fully-commented-0-694  Transformer kernel from Quora competition: https://www.kaggle.com/shujian/transformer-initial-attempt  And of course: https://arxiv.org/abs/1706.03762   Major changes to the original Transformer architecture: No decoder, basically we cut it in half. We're doing classical classification not auto-regression like in machine translation so it's not needed.  No masked attention. Like above, we do not need to ensure causality in inference like machine transalation, so we can afford to make the information flow freely.", "link": "https://www.kaggle.com/suicaokhoailang/transformer-baseline-0-672-lb", "tags": [], "kind": ["Project", "(Notebook)"], "ml_libs": ["sklearn", "keras", "tensorflow"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2019-01-31 04:26:01", "date_scraped": "2020-12-13 18:09:07", "words": 75, "sentences": 4, "runtime": 0.0, "description_category": "Wholesale & Retail", "description_category_score": 0.07551240175962448, "description_category_runtime": 11.934, "description_subcategory": "Preventative and Reactive", "description_subcategory_score": 0.5359610915184021, "description_subcategory_runtime": 18.831, "category": "Wholesale & Retail", "category_score": 0.07551240175962448, "subcategory": "Preventative and Reactive", "subcategory_score": 0.5359610915184021, "runtime_cat": 30.767, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.712", "language_code": "en", "language_score": "0.9999958124976136", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "tldr feature engineering httpswwwkagglecombraquino5foldlstmattentionfullycommented0694 transformer kernel quora competition httpswwwkagglecomshujiantransformerinitialattempt course httpsarxivorgabs170603762 major change original transformer architecture decoder basically cut half classical classification autoregression like machine translation needed masked attention like need ensure causality inference like machine transalation afford make information flow freely", "tags_descriptive": []}