{"title": "Augmenting the Data", "description": "This notebook is currently a test site for augmenting data by looking at previous ideas and possibly trying new ones. Here are three ideas, one for adding translations, one for creating synthetic data, and one for interjecting noise/variations. TranslationsThis idea originally came from the first Toxic challenge in which translation was used as an encoder-decoder. Pavel Ostyakov's A simple technique for extending dataset explains how translating an english comment to another language, and then back to english, can improve model accuracy. With this being a multilingual competition, there have been similar ideas implemented but maybe not in this exact way. In this notebook I'm using Google Translator via the googletrans package.", "link": "https://www.kaggle.com/jpmiller/augmenting-the-data", "tags": ["NLP"], "kind": ["Project", "(Notebook)"], "ml_libs": [], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2020-05-03 05:51:02", "date_scraped": "2020-12-13 12:15:35", "words": 111, "sentences": 6, "runtime": 0.0, "description_category": "Wholesale & Retail", "description_category_score": 0.11525217443704605, "description_category_runtime": 10.951, "description_subcategory": "Student", "description_subcategory_score": 0.3738745152950287, "description_subcategory_runtime": 16.51, "category": "Wholesale & Retail", "category_score": 0.11525217443704605, "subcategory": "Student", "subcategory_score": 0.3738745152950287, "runtime_cat": 27.461, "programming_language": "Jupyter Notebook", "ml_score": "0.5", "engagement_score": "0.736", "language_code": "en", "language_score": "0.9999968909178042", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "notebook currently test site augmenting data looking previous idea possibly trying new one three idea one adding translation one creating synthetic data one interjecting noisevariations translationsthis idea originally came first toxic challenge translation used encoderdecoder pavel ostyakovs simple technique extending dataset explains translating english comment another language back english improve model accuracy multilingual competition similar idea implemented maybe exact way notebook im using google translator via googletrans package", "tags_descriptive": ["Natural Language Processing (NLP)"]}