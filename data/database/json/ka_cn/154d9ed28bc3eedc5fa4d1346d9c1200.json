{"title": "Backtesting - Cross-Validation for TimeSeries", "description": "Backtesting - Cross-Validation for TimeSeries The goal of this kernel is to introduce forecasters to the concept of backtesting and provide a basic implementation. Although in this competition we can directly see the test data, as a learning opportunity it is still important to apply forecasting best practices in our attempts. Backtesting is the time series equivalent of cross-validation. It is an attempt to bootstrap the data in such a way that we can estimate the expected test error. We cannot use cross-validation directly since this is sequenced data. Order must be respected to avoid peeking. There are two major methods of backtesting: sliding window and expanding window. In Sliding Window, we keep the same training size and slide the window across the data to create multiple train-test pairs. This may be a good strategy if you have a fixed size model (some neural network implementations and other machine learning methods.). It's also good for initial model development as it will result in faster model builds.  In Expanding Window, we expand the training size from some starting size to a maximum size. This method provides a good balance between creating enough training-test pairs while maximizing the amount of data your models receive.   By using these strategies we can have better estimation of the test error of the various models. These methods can also be used for density forecasting (evaluating the full quantiles and prediction intervals of model forecasts rather than just the mean forecast) I hope it helps. This is my first Kernel, so let me know how I can improve it to help out the community. Cheers!  Calvin Credit to Uber's Engineering Blog for some of the photos and ideas.", "link": "https://www.kaggle.com/cworsnup/backtesting-cross-validation-for-timeseries", "tags": [], "kind": ["Project", "(Notebook)"], "ml_libs": [], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2018-09-01 22:03:23", "date_scraped": "2020-12-12 18:46:39", "words": 285, "sentences": 16, "sum_nltk": "Backtesting - Cross-Validation for TimeSeries The goal of this kernel is to introduce forecasters to the concept of backtesting and provide a basic implementation.\nAlthough in this competition we can directly see the test data, as a learning opportunity it is still important to apply forecasting best practices in our attempts.\nBacktesting is the time series equivalent of cross-validation.\nIt is an attempt to bootstrap the data in such a way that we can estimate the expected test error.\nWe cannot use cross-validation directly since this is sequenced data.\nIn Sliding Window, we keep the same training size and slide the window across the data to create multiple train-test pairs.\nThis may be a good strategy if you have a fixed size model (some neural network implementations and other machine learning methods.).\nThis method provides a good balance between creating enough training-test pairs while maximizing the amount of data your models receive.\nBy using these strategies we can have better estimation of the test error of the various models.\nThese methods can also be used for density forecasting (evaluating the full quantiles and prediction intervals of model forecasts rather than just the mean forecast) I hope it helps.", "sum_nltk_words": 189, "sum_nltk_runtime": 0.003, "sum_t5": "backtesting is the time series equivalent of cross-validation. it is an attempt to bootstrap the data in such a way that we can estimate the expected test error. order must be respected to avoid peeking. backtesting is my first kernel, so let me know how I can improve it. backtesting is a time series equivalent of cross-validation. it's a good strategy if you have a fixed size model.", "sum_t5_words": 68, "sum_t5_runtime": 5.755, "runtime": 0.003, "nltk_category": "Utilities", "nltk_category_score": 0.6015299558639526, "nltk_category_runtime": 16.766, "nltk_subcategory": "Machine Learning", "nltk_subcategory_score": 0.7450140714645386, "nltk_subcategory_runtime": 26.833, "category": "Utilities", "category_score": 0.6015299558639526, "subcategory": "Machine Learning", "subcategory_score": 0.7450140714645386, "runtime_cat": 43.6, "programming_language": "R notebook", "ml_score": "0.5", "engagement_score": "0.72", "language_code": "en", "language_score": "0.9999969360486136", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "backtesting crossvalidation timeseries goal kernel introduce forecaster concept backtesting provide basic implementation although competition directly see test data learning opportunity still important apply forecasting best practice attempt backtesting time series equivalent crossvalidation attempt bootstrap data way estimate expected test error cannot use crossvalidation directly since sequenced data order must respected avoid peeking two major method backtesting sliding window expanding window sliding window keep training size slide window across data create multiple traintest pair may good strategy fixed size model neural network implementation machine learning method also good initial model development result faster model build expanding window expand training size starting size maximum size method provides good balance creating enough trainingtest pair maximizing amount data model receive using strategy better estimation test error various model method also used density forecasting evaluating full quantiles prediction interval model forecast rather mean forecast hope help first kernel let know improve help community cheer calvin credit ubers engineering blog photo idea", "tags_descriptive": []}