{"title": "Graph Transfomer", "description": "A previous version of this code got a public LB of 0.01299 and is described in https://www.kaggle.com/c/nfl-big-data-bowl-2020/discussion/119430 Since competition end I have implemented few improvements, and in particular all piece of the transformer architecture.  The code uses keras functional model api, which makes it way ore compact than the transformer implementations one can find online.  I also included some data cleaning that was shared by top teams, namely using S = 10 * Dis, and averaging A in 2017.  The CV is improved by about 0.00025, which could bring LB around 0.01275, not top, but still of interest for a model without any feature engineering besides distance matrix computation.", "link": "https://www.kaggle.com/cpmpml/graph-transfomer", "tags": [], "kind": ["Project", "(Notebook)"], "ml_libs": ["sklearn", "keras", "tensorflow"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2020-01-08 20:30:33", "date_scraped": "2020-12-13 14:21:44", "words": 112, "sentences": 4, "runtime": 0.0, "description_category": "Real Estate, Rental & Leasing", "description_category_score": 0.1169261634349823, "description_category_runtime": 11.532, "description_subcategory": "Machine Learning", "description_subcategory_score": 0.44412314891815186, "description_subcategory_runtime": 18.029, "category": "Real Estate, Rental & Leasing", "category_score": 0.1169261634349823, "subcategory": "Machine Learning", "subcategory_score": 0.44412314891815186, "runtime_cat": 29.561, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.747", "language_code": "en", "language_score": "0.9999973261848497", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "previous version code got public lb 001299 described httpswwwkagglecomcnflbigdatabowl2020discussion119430 since competition end implemented improvement particular piece transformer architecture code us kera functional model api make way ore compact transformer implementation one find online also included data cleaning shared top team namely using 10 dis averaging 2017 cv improved 000025 could bring lb around 001275 top still interest model without feature engineering besides distance matrix computation", "tags_descriptive": []}