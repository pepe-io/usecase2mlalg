{"title": "QUEST : CV analysis on Different Splitting Methods", "description": "1. This notebook is about \"Splitting and CV\"Good day everybody! In this competition, one important aspect is that \"Public LB is based on 13% of total test data, which is only 476 examples\". So it is intuitively clear that our own CV score is more reliable than public LB, e.g. if we do 5-folds split, we will have 20% of training data, around 1200 examples. Moreover, we can average over 5-folds and get even more reliable number, right? It seems to me that in this imbalance-multi-label problem (explained below), splitting is not easy. So in this notebook, we will investigate and compare 3 splitting approaches which I know of:  KFold GroupKFold MultilabelStratifiedKFold  The goal of this notebook is to compare CV from these methods among themselves, and also to Public LB. Since this notebook is not about optimizing LB, we will save time by using a very fast model training from @abhishek's kernel which in turn originated from @abazdyrev's kernel. We will see that this same model will have different CV behaviors depending on splitting methods. Therefore, when talking about CV vs. LB, it's important to understand this different behaviors. In particular, when teaming up with other people, be sure that different CV calculation (if any) will not mislead your team. Note that this is all I know about splitting. At the end of the article, if anybody know a better method, or have better insights, and would like to share in the comment section, it will be very much appreciate!!", "link": "https://www.kaggle.com/ratthachat/quest-cv-analysis-on-different-splitting-methods", "tags": [], "kind": ["Project", "(Notebook)"], "ml_libs": ["sklearn", "keras", "tensorflow", "pytorch"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2019-12-13 06:00:28", "date_scraped": "2020-12-12 20:20:08", "words": 253, "sentences": 13, "sum_nltk": "In this competition, one important aspect is that \"Public LB is based on 13% of total test data, which is only 476 examples\".\nSo it is intuitively clear that our own CV score is more reliable than public LB, e.g. if we do 5-folds split, we will have 20% of training data, around 1200 examples.\nMoreover, we can average over 5-folds and get even more reliable number, right?\nSo in this notebook, we will investigate and compare 3 splitting approaches which I know of:  KFold GroupKFold MultilabelStratifiedKFold  The goal of this notebook is to compare CV from these methods among themselves, and also to Public LB.\nSince this notebook is not about optimizing LB, we will save time by using a very fast model training from @abhishek's kernel which in turn originated from @abazdyrev's kernel.\nWe will see that this same model will have different CV behaviors depending on splitting methods.\nLB, it's important to understand this different behaviors.\nNote that this is all I know about splitting.\nAt the end of the article, if anybody know a better method, or have better insights, and would like to share in the comment section, it will be very much appreciate!!", "sum_nltk_words": 193, "sum_nltk_runtime": 0.003, "sum_t5": "this notebook is about \"Splitting and CV\" the goal of this notebook is to compare CV from these methods among themselves. it's important to understand this different behaviors when talking about splitting. if anybody know a better method, or have better insights, please share in the comment section. if anybody know a better method, or have better insights, please share in the comment section. if anybody know a better method, or have better insights, please share in the comment section.", "sum_t5_words": 80, "sum_t5_runtime": 6.113, "runtime": 0.0, "nltk_category": "Finance", "nltk_category_score": 0.518470823764801, "nltk_category_runtime": 18.475, "nltk_subcategory": "Machine Learning", "nltk_subcategory_score": 0.7596818804740906, "nltk_subcategory_runtime": 29.502, "category": "Finance", "category_score": 0.518470823764801, "subcategory": "Machine Learning", "subcategory_score": 0.7596818804740906, "runtime_cat": 47.977, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.732", "language_code": "en", "language_score": "0.9999973174038765", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "1 notebook splitting cvgood day everybody competition one important aspect public lb based 13 total test data 476 example intuitively clear cv score reliable public lb eg 5folds split 20 training data around 1200 example moreover average 5folds get even reliable number right seems imbalancemultilabel problem explained splitting easy notebook investigate compare 3 splitting approach know kfold groupkfold multilabelstratifiedkfold goal notebook compare cv method among also public lb since notebook optimizing lb save time using fast model training abhisheks kernel turn originated abazdyrevs kernel see model different cv behavior depending splitting method therefore talking cv v lb important understand different behavior particular teaming people sure different cv calculation mislead team note know splitting end article anybody know better method better insight would like share comment section much appreciate", "tags_descriptive": []}