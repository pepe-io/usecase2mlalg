{"title": "Cross-validation, weighted linear blending, errors", "description": "This notebook is meant to be a proof of concept for ideas discussed in this thread. Hopefully it shows that cross-validation can be done even within existing time limits, and that it can be done even better than here with multi-processing and other tricks. In my hands cross-validation has produced scores that agree very well with LB scores - the difference is usually on the order of 0.001. That should give us comfort compared to single runs of individual methods on fold splits and random seeds that are crafted to give the best LB score. Further down the line there is a brief example of how to use out-of-fold predictions to calculate linear blending weights by minimization. Several plots closer to the end will show how individual methods differ in types of prediction errors. Lastly, all out-of-fold files and submission files will be saved if you wish to play with them locally. Fairness warning: This script will not give you a 0.43xx score at the push of a button. You will have to work on your own and modify concepts presented here in order to get that kind of score. A big thank you to @apapiu for his original Ridge script, as the initial data processing here is based on his work. It is a shame that his script has less than 40 votes, while other scripts using his strategy have more votes just because they advertise better LB scores. You know what to do if you agree with me.", "link": "https://www.kaggle.com/tilii7/cross-validation-weighted-linear-blending-errors", "tags": [], "kind": ["Project", "(Notebook)"], "ml_libs": ["sklearn", "lightgbm"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2017-12-17 17:48:43", "date_scraped": "2020-12-13 14:05:42", "words": 250, "sentences": 12, "sum_nltk": "Hopefully it shows that cross-validation can be done even within existing time limits, and that it can be done even better than here with multi-processing and other tricks.\nIn my hands cross-validation has produced scores that agree very well with LB scores - the difference is usually on the order of 0.001.\nThat should give us comfort compared to single runs of individual methods on fold splits and random seeds that are crafted to give the best LB score.\nFurther down the line there is a brief example of how to use out-of-fold predictions to calculate linear blending weights by minimization.\nSeveral plots closer to the end will show how individual methods differ in types of prediction errors.\nFairness warning: This script will not give you a 0.43xx score at the push of a button.\nYou will have to work on your own and modify concepts presented here in order to get that kind of score.\nA big thank you to @apapiu for his original Ridge script, as the initial data processing here is based on his work.\nIt is a shame that his script has less than 40 votes, while other scripts using his strategy have more votes just because they advertise better LB scores.", "sum_nltk_words": 198, "sum_nltk_runtime": 0.003, "sum_t5": "cross-validation has produced scores that agree very well with LB scores. the difference is usually on the order of 0.001. a brief example of how to use out-of-fold predictions to calculate linear blending weights by minimization. this script will not give you a 0.43xx score at the push of a button. you will have to work on your own and modify concepts presented here in order to get that kind of score.", "sum_t5_words": 72, "sum_t5_runtime": 4.792, "runtime": 0.003, "nltk_category": "Finance", "nltk_category_score": 0.1889529675245285, "nltk_category_runtime": 17.395, "nltk_subcategory": "General", "nltk_subcategory_score": 0.2380359172821045, "nltk_subcategory_runtime": 27.683, "category": "Finance", "category_score": 0.1889529675245285, "subcategory": "General", "subcategory_score": 0.2380359172821045, "runtime_cat": 45.078, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.733", "language_code": "en", "language_score": "0.9999976003702393", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "notebook meant proof concept idea discussed thread hopefully show crossvalidation done even within existing time limit done even better multiprocessing trick hand crossvalidation produced score agree well lb score difference usually order 0001 give u comfort compared single run individual method fold split random seed crafted give best lb score line brief example use outoffold prediction calculate linear blending weight minimization several plot closer end show individual method differ type prediction error lastly outoffold file submission file saved wish play locally fairness warning script give 043xx score push button work modify concept presented order get kind score big thank apapiu original ridge script initial data processing based work shame script le 40 vote script using strategy vote advertise better lb score know agree", "tags_descriptive": []}