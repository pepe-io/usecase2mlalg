{"title": "Pytorch approach", "description": "Pytorch approachIn this kernel I work with data from Google QUEST Q&A Labeling competition. In this challenge we work with... opinions. This could help Q&A systems, so let's try! Code will, of course, be in Pytorch Change log V25: Adding USE like in https://www.kaggle.com/ldm314/universal-sentence-encoder-keras-nn/ V26: changing preprocessing V32: reverting to previous preprocessing approach. Use more models for predictions. v33: fixed model paths it doesn't work, so revert to previous version. V37: adding bert embeddings (not using bert itself for training) like in this kernel: https://www.kaggle.com/abhishek/distilbert-use-features-oof V40: limit the number of epochs for training (due to 2h limit). Use some preprocessed embeddings instead of creating them in kernel.", "link": "https://www.kaggle.com/artgor/pytorch-approach", "tags": ["DL", "Classification"], "kind": ["Project", "(Notebook)"], "ml_libs": ["keras", "nltk", "gensim", "tensorflow", "sklearn", "spacy"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2019-12-01 10:17:19", "date_scraped": "2020-12-12 20:20:08", "words": 107, "sentences": 8, "runtime": 0.001, "description_category": "Justice, Law and Regulations", "description_category_score": 0.10711492598056793, "description_category_runtime": 14.509, "description_subcategory": "Machine Learning", "description_subcategory_score": 0.7253046035766602, "description_subcategory_runtime": 22.949, "category": "Justice, Law and Regulations", "category_score": 0.10711492598056793, "subcategory": "Machine Learning", "subcategory_score": 0.7253046035766602, "runtime_cat": 37.459, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.742", "language_code": "en", "language_score": "0.9999972181798817", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "pytorch approachin kernel work data google quest qa labeling competition challenge work opinion could help qa system let try code course pytorch change log v25 adding use like httpswwwkagglecomldm314universalsentenceencoderkerasnn v26 changing preprocessing v32 reverting previous preprocessing approach use model prediction v33 fixed model path doesnt work revert previous version v37 adding bert embeddings using bert training like kernel httpswwwkagglecomabhishekdistilbertusefeaturesoof v40 limit number epoch training due 2h limit use preprocessed embeddings instead creating kernel", "tags_descriptive": ["Deep Learning (DL)", "Classification"]}