{"title": "Preprocessing Pipeline and Convnet Trainer", "description": "OverviewThe Passenger Screening Algorithm Challenge asks the data science community to assist with improving threat detection at US airports while minimizing false positives to avoid long lines and delays. (Can I get an amen!).  This notebook is a follow up to my first effort for this contest called Exploratory Data Analysis and Example Generation (I'll call it EDA from now on).  As I mentioned in the EDA notebook, the HD-AIT system files supplied in this contest range from 10MB to approximately 2GB per subject.  In the instructions, the organizers suggest that one may even be able to win the contest with one of the smaller image suites. In that notebook, in addition to a review of the data and its vagueries, I supplied some basic building blocks for a preprocessing pipeline. In this notebook, I continue the series with a full preprocessing pipeline using the building blocks from before as well as a first pass through a CNN based on the Alexnet using Tensorflow.  Clearly, no one is going to win the contest with this method, but I thought it would be helpful to everyone working on this to have an end to end working pipeline.  I hope you find it useful, and if you do, I hope you'll give me an up vote! As previously noted, I'm not an expert on these systems or the related scans.  If you see something I've misunderstood or you think I've made an error, let me know and I'll correct it.  TSA has made it harder for people to get into this contest by disallowing even masked images to be protrayed on Kaggle, so you'll have to put these scripts in your own environment to take them around the track.  In any event, I am convinced that data science can improve the predictive veracity of these scans.  I'll get off the soap box now and move on. To begin I collect all of the imports used in the notebook at the top.  It makes it easier when you're converting to a preprocessing script.  Make sure to take note of the last import, tsahelper. You will need to install tsahelper and uncomment this line in order for this pipeline to work. The tsahelper package is made from the EDA and is now available as a pip install (no warranties!).", "link": "https://www.kaggle.com/jbfarrar/preprocessing-pipeline-and-convnet-trainer", "tags": ["CNN"], "kind": ["Project", "(Notebook)"], "ml_libs": ["tensorflow"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2017-10-18 13:01:33", "date_scraped": "2020-12-13 15:06:52", "words": 396, "sentences": 18, "sum_nltk": "OverviewThe Passenger Screening Algorithm Challenge asks the data science community to assist with improving threat detection at US airports while minimizing false positives to avoid long lines and delays.\nThis notebook is a follow up to my first effort for this contest called Exploratory Data Analysis and Example Generation (I'll call it EDA from now on).\nAs I mentioned in the EDA notebook, the HD-AIT system files supplied in this contest range from 10MB to approximately 2GB per subject.\nIn that notebook, in addition to a review of the data and its vagueries, I supplied some basic building blocks for a preprocessing pipeline.\nIn this notebook, I continue the series with a full preprocessing pipeline using the building blocks from before as well as a first pass through a CNN based on the Alexnet using Tensorflow.\nClearly, no one is going to win the contest with this method, but I thought it would be helpful to everyone working on this to have an end to end working pipeline.\nIn any event, I am convinced that data science can improve the predictive veracity of these scans.\nMake sure to take note of the last import, tsahelper.\nYou will need to install tsahelper and uncomment this line in order for this pipeline to work.", "sum_nltk_words": 204, "sum_nltk_runtime": 0.004, "sum_t5": "this notebook is a follow up to my first effort for this contest. the notebook is a follow up to my first effort for this contest. the organizers suggest that one may even be able to win the contest with one of the smaller image suites. the notebook is a full preprocessing pipeline using the building blocks from before. back to mail online home. back to the page you came from.. back to the page you came from.", "sum_t5_words": 78, "sum_t5_runtime": 6.329, "runtime": 0.005, "nltk_category": "Utilities", "nltk_category_score": 0.2307673841714859, "nltk_category_runtime": 18.223, "nltk_subcategory": "Machine Learning", "nltk_subcategory_score": 0.5852659940719604, "nltk_subcategory_runtime": 29.223, "category": "Utilities", "category_score": 0.2307673841714859, "subcategory": "Machine Learning", "subcategory_score": 0.5852659940719604, "runtime_cat": 47.447, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.747", "language_code": "en", "language_score": "0.9999974562909075", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "overviewthe passenger screening algorithm challenge asks data science community assist improving threat detection u airport minimizing false positive avoid long line delay get amen notebook follow first effort contest called exploratory data analysis example generation ill call eda mentioned eda notebook hdait system file supplied contest range 10mb approximately 2gb per subject instruction organizer suggest one may even able win contest one smaller image suite notebook addition review data vagueries supplied basic building block preprocessing pipeline notebook continue series full preprocessing pipeline using building block well first pas cnn based alexnet using tensorflow clearly one going win contest method thought would helpful everyone working end end working pipeline hope find useful hope youll give vote previously noted im expert system related scan see something ive misunderstood think ive made error let know ill correct tsa made harder people get contest disallowing even masked image protrayed kaggle youll put script environment take around track event convinced data science improve predictive veracity scan ill get soap box move begin collect import used notebook top make easier youre converting preprocessing script make sure take note last import tsahelper need install tsahelper uncomment line order pipeline work tsahelper package made eda available pip install warranty", "tags_descriptive": ["Convolutional Neural Network (CNN)"]}