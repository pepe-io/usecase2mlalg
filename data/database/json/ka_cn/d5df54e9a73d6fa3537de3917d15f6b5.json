{"title": "Detailed guide to custom training with TPUs", "description": "A detailed guide to custom training with TPUs - Flower Classification  In this notebook, we will go through, step by step, training models with TPUs in a custom way. These includes: use tf.data.Dataset as input pipeline perform a custom training loop correctly define loss function make the custom training loop even faster gradient accumulation with TPUs apply oversampling to deal with imbalanced data Have fun with a special data augmentaion - Perspective transformation  This kernel is based on the following kernels with my own extension (I keep some code in these 2 notebooks):  Getting started with 100+ flowers on TPU - by Martin G\u00f6rner.  Custom Training Loop with 100+ flowers on TPU - by Martin G\u00f6rner.", "link": "https://www.kaggle.com/yihdarshieh/detailed-guide-to-custom-training-with-tpus", "tags": ["DL", "Classification", "Exploratory Data Analysis"], "kind": ["Project", "(Notebook)"], "ml_libs": ["sklearn", "keras", "tensorflow"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2020-08-28 18:49:06", "date_scraped": "2020-12-12 19:56:26", "words": 120, "sentences": 3, "runtime": 0.0, "description_category": "Utilities", "description_category_score": 0.04198036715388298, "description_category_runtime": 11.249, "description_subcategory": "Machine Learning", "description_subcategory_score": 0.5474826097488403, "description_subcategory_runtime": 17.176, "category": "Utilities", "category_score": 0.04198036715388298, "subcategory": "Machine Learning", "subcategory_score": 0.5474826097488403, "runtime_cat": 28.425, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.698", "language_code": "en", "language_score": "0.9999973487574723", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "detailed guide custom training tpus flower classification notebook go step step training model tpus custom way includes use tfdatadataset input pipeline perform custom training loop correctly define loss function make custom training loop even faster gradient accumulation tpus apply oversampling deal imbalanced data fun special data augmentaion perspective transformation kernel based following kernel extension keep code 2 notebook getting started 100 flower tpu martin gorner custom training loop 100 flower tpu martin gorner", "tags_descriptive": ["Deep Learning (DL)", "Classification", "Exploratory Data Analysis"]}