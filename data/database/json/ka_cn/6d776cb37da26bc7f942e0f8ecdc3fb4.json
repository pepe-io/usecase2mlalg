{"title": "Lyft 3D: Join all lidars, annotations from scratch", "description": "Main goal here is to learn to work with the data as-is (because not all needed features are presnet in the SDK), join all lidars into one point cloud and apply annotations to make sure we're not missing anything. EDIT as @alexamadori pointed out in comments, most scenes have data only from one lidar, so merging all 3 lidars might not make much sense. Still writing this kernel was useful to me to understand the data and coordinate systems better. Overview of what we're doing below:  we load lidar data (3d points), these points are in coordinate system of the lidar, rotated and translated relative to the car using sensor information of the lidar, we translate points from lidar coordinate frame to car coordinate frame, this allows us to merge data from all 3 lidars annotations and submission are in global coordinates. We translate annotations into the car coordinates, which allows to have both the data and annotations in the same (car) coordinate frame, which can then be used for training  We learn:  how the raw data looks like, so that we understand how SDK works better and can extend it if needed (also if you see any missing features, file issues at https://github.com/lyft/nuscenes-devkit/issues/) how to translate objects between various coordinate frames  In terms of custom packages, we'll use only pyquaternion which is also used by Lyft SDK.", "link": "https://www.kaggle.com/lopuhin/lyft-3d-join-all-lidars-annotations-from-scratch", "tags": [], "kind": ["Project", "(Notebook)"], "ml_libs": [], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2019-09-15 17:26:35", "date_scraped": "2020-12-12 16:08:03", "words": 232, "sentences": 5, "sum_nltk": "Main goal here is to learn to work with the data as-is (because not all needed features are presnet in the SDK), join all lidars into one point cloud and apply annotations to make sure we're not missing anything.\nEDIT as @alexamadori pointed out in comments, most scenes have data only from one lidar, so merging all 3 lidars might not make much sense.\nOverview of what we're doing below:  we load lidar data (3d points), these points are in coordinate system of the lidar, rotated and translated relative to the car using sensor information of the lidar, we translate points from lidar coordinate frame to car coordinate frame, this allows us to merge data from all 3 lidars annotations and submission are in global coordinates.\nWe translate annotations into the car coordinates, which allows to have both the data and annotations in the same (car) coordinate frame, which can then be used for training  We learn:  how the raw data looks like, so that we understand how SDK works better and can extend it if needed (also if you see any missing features, file issues at https://github.com/lyft/nuscenes-devkit/issues/) how to translate objects between various coordinate frames  In terms of custom packages, we'll use only pyquaternion which is also used by Lyft SDK.", "sum_nltk_words": 213, "sum_nltk_runtime": 0.002, "sum_t5": "the goal here is to learn to work with the data as-is. join all lidars into one point cloud and apply annotations. pyquaternion is also used by the Lyft SDK. if you see any missing features, file issues at https://github.com/lyft/nuscenes-devkit/issues/.. if you see any missing features, file issues at https://github.com/lyft/nuscenes-", "sum_t5_words": 50, "sum_t5_runtime": 5.302, "runtime": 0.002, "nltk_category": "Education & Research", "nltk_category_score": 0.3945560157299042, "nltk_category_runtime": 19.337, "nltk_subcategory": "Quality", "nltk_subcategory_score": 0.6150063276290894, "nltk_subcategory_runtime": 30.86, "category": "Education & Research", "category_score": 0.3945560157299042, "subcategory": "Quality", "subcategory_score": 0.6150063276290894, "runtime_cat": 50.197, "programming_language": "Jupyter Notebook", "ml_score": "0.5", "engagement_score": "0.699", "language_code": "en", "language_score": "0.9999968178970721", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "main goal learn work data asis needed feature presnet sdk join lidar one point cloud apply annotation make sure missing anything edit alexamadori pointed comment scene data one lidar merging 3 lidar might make much sense still writing kernel useful understand data coordinate system better overview load lidar data 3d point point coordinate system lidar rotated translated relative car using sensor information lidar translate point lidar coordinate frame car coordinate frame allows u merge data 3 lidar annotation submission global coordinate translate annotation car coordinate allows data annotation car coordinate frame used training learn raw data look like understand sdk work better extend needed also see missing feature file issue httpsgithubcomlyftnuscenesdevkitissues translate object various coordinate frame term custom package well use pyquaternion also used lyft sdk", "tags_descriptive": []}