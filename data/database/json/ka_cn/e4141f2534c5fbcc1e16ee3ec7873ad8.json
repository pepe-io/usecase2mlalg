{"title": "Optimise Blending Weights with Bonus :0", "description": "Model Blending Weights OptimisationThis demo shows how to use scipy.optimize to optimise your model blending weights using your models' OOFs. UPDATE: Getting rid of the penalty term by using 'SLSQP' solver with a relatively small tolerance and Jacobian matrix. UPDATE: Calculate the gradients with paper and pencil to accelerate the optimisation... UPDATE: Add numba gradient function", "link": "https://www.kaggle.com/gogo827jz/optimise-blending-weights-with-bonus-0", "tags": [], "kind": ["Project", "(Notebook)"], "ml_libs": [], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2020-11-08 18:01:18", "date_scraped": "2020-12-13 13:16:12", "words": 56, "sentences": 4, "runtime": 0.005, "description_category": "Finance", "description_category_score": 0.14074823260307312, "description_category_runtime": 7.109, "description_subcategory": "Machine Learning", "description_subcategory_score": 0.5310714244842529, "description_subcategory_runtime": 10.741, "category": "Finance", "category_score": 0.14074823260307312, "subcategory": "Machine Learning", "subcategory_score": 0.5310714244842529, "runtime_cat": 17.851, "programming_language": "Jupyter Notebook", "ml_score": "0.5", "engagement_score": "0.727", "language_code": "en", "language_score": "0.9999979928908418", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "model blending weight optimisationthis demo show use scipyoptimize optimise model blending weight using model oofs update getting rid penalty term using slsqp solver relatively small tolerance jacobian matrix update calculate gradient paper pencil accelerate optimisation update add numba gradient function", "tags_descriptive": []}