{"title": "Train EfficientNet-B0 w/ 36 tiles_256 [LB0.87]", "description": "PANDA EfficientNet-B0 Baseline with 36 x tiles_256Hi everyone, I'm here to show you how to train a single efficientnet-b0 model to get LB 0.87 Inference kernel is https://www.kaggle.com/haqishen/panda-inference-w-36-tiles-256 If you find find any of the following idea helps, please upvote me, THANKS! Summary of This Baseline Using tiling method based on https://www.kaggle.com/iafoss/panda-16x128x128-tiles Simply setting the N = 36 and sz=256 then extract from median resolution   Create 6x6 big image from 36 tiles Efficientnet-B0 Binning label E.g. label = [0,0,0,0,0] means isup_grade = 0 label = [1,1,1,0,0] means isup_grade = 3 label = [1,1,1,1,1] means isup_grade = 5     BCE loss Augmentation on both tile level and big image level CosineAnnealingLR for one round  MEMOThe full training process need over 10h to run so you should run it on your own machine. Update Version 1 Baseline   Version 2, 3 Add some Markdown Text   Version 4 Fix init_lr from 3e-5 to 3e-4   Version 5 Add warmup scheduler Add training log for this version   Version 6 Fix the bug that train from scratch. Now it's train from ImageNet pretrained weights. Actually I haven't tried train from scratch yet.   Version 7, 8 Update accuracy calculate. Fix tiny bug.", "link": "https://www.kaggle.com/haqishen/train-efficientnet-b0-w-36-tiles-256-lb0-87", "tags": [], "kind": ["Project", "(Notebook)"], "ml_libs": ["sklearn", "pytorch", "skimage", "albumentations"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2020-06-05 06:35:57", "date_scraped": "2020-12-13 16:03:25", "words": 210, "sentences": 7, "sum_nltk": "PANDA EfficientNet-B0 Baseline with 36 x tiles_256Hi everyone, I'm here to show you how to train a single efficientnet-b0 model to get LB 0.87 Inference kernel is https://www.kaggle.com/haqishen/panda-inference-w-36-tiles-256 If you find find any of the following idea helps, please upvote me, THANKS!\nSummary of This Baseline Using tiling method based on https://www.kaggle.com/iafoss/panda-16x128x128-tiles Simply setting the N = 36 and sz=256 then extract from median resolution   Create 6x6 big image from 36 tiles Efficientnet-B0 Binning label E.g. label = [0,0,0,0,0] means isup_grade = 0 label = [1,1,1,0,0] means isup_grade = 3 label = [1,1,1,1,1] means isup_grade = 5     BCE loss Augmentation on both tile level and big image level CosineAnnealingLR for one round  MEMOThe full training process need over 10h to run so you should run it on your own machine.\nUpdate Version 1 Baseline   Version 2, 3 Add some Markdown Text   Version 4 Fix init_lr from 3e-5 to 3e-4   Version 5 Add warmup scheduler Add training log for this version   Version 6 Fix the bug that train from scratch.\nNow it's train from ImageNet pretrained weights.\nActually I haven't tried train from scratch yet.\nVersion 7, 8 Update accuracy calculate.\nFix tiny bug.", "sum_nltk_words": 202, "sum_nltk_runtime": 0.002, "sum_t5": "a single efficientnet-b0 model can be trained to get LB 0.87. the baseline is based on a 256x256 grid. the full training process need over 10h to run so you should run it on your own machine. version 7, 8 Update accuracy calculate. Fix tiny bug. a new version of the baseline is available for download............", "sum_t5_words": 56, "sum_t5_runtime": 5.702, "runtime": 0.003, "nltk_category": "Biotechnological & Life Sciences", "nltk_category_score": 0.23657089471817017, "nltk_category_runtime": 26.032, "nltk_subcategory": "Machine Learning", "nltk_subcategory_score": 0.9651875495910645, "nltk_subcategory_runtime": 41.674, "category": "Biotechnological & Life Sciences", "category_score": 0.23657089471817017, "subcategory": "Machine Learning", "subcategory_score": 0.9651875495910645, "runtime_cat": 67.705, "programming_language": "Jupyter Notebook", "ml_score": "0.7", "engagement_score": "0.768", "language_code": "en", "language_score": "0.9999977448683415", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "panda efficientnetb0 baseline 36 x tiles_256hi everyone im show train single efficientnetb0 model get lb 087 inference kernel httpswwwkagglecomhaqishenpandainferencew36tiles256 find find following idea help please upvote thanks summary baseline using tiling method based httpswwwkagglecomiafosspanda16x128x128tiles simply setting n 36 sz256 extract median resolution create 6x6 big image 36 tile efficientnetb0 binning label eg label 00000 mean isup_grade 0 label 11100 mean isup_grade 3 label 11111 mean isup_grade 5 bce loss augmentation tile level big image level cosineannealinglr one round memothe full training process need 10h run run machine update version 1 baseline version 2 3 add markdown text version 4 fix init_lr 3e5 3e4 version 5 add warmup scheduler add training log version version 6 fix bug train scratch train imagenet pretrained weight actually havent tried train scratch yet version 7 8 update accuracy calculate fix tiny bug", "tags_descriptive": []}