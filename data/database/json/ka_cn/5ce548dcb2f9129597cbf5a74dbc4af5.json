{"title": "Plant Pathology 2020 - Pytorch", "description": "Plant Pathology 2020Implemented / planned [] - Starter code [] - 5-Folds CV [] - Albumentations [] - Visualize training history [-] - Schedulers [-] - Train longer (without overfitting) [-] - Experimenting with ResNets [-] - Experimenting with EfficientNets [-] - Experimenting with SEResNeXts [-] - Experimenting with different input image size [-] - TTA [-] - OHEM [-] - Pseudo labelling [-] - Mixup [-] - Cutmix [-] - Cutout  Notebook Versions v1: Starter code v4: 5-Folds CV. The gap between local and public score seems a bit high, probably because of the small number of validation samples. I added 5-folds (for now, simple k-fold) CV to see whether it reduces the difference.  v5: More augmentations. I try to train for more epochs. To prevent overfitting, I added more augmentations. v6: Changed to softmax + cross entropy. I used Sigmoid+BCE, not sure why. Note: There was no overfit during training (v5), but the CV-LB gap is still high. v8: According to my EDA the classes are not balanced (multiple_deseases is only 5%). I replace KFold to StratifiedKFold. v9: Input image size: 256px -> 512px    Version Net #Folds #Epochs Local LB Public LB Notes     v1 Resnet-18 1 10 0.972 0.923 Starter code   v4 Resnet-18 5 5 0.950 0.941 5-folds CV   v5 Resnet-18 5 10 0.971 0.935 More augmentations   v6 Resnet-18 5 5 0.971 0.937 Softmax + CE   v8 Resnet-18 5 10 0.970 0.944 StratifiedKFold   v9 Resnet-18 5 10 n.a. n.a. 512px input", "link": "https://www.kaggle.com/pestipeti/plant-pathology-2020-pytorch", "tags": ["Classification", "CV"], "kind": ["Project", "(Notebook)"], "ml_libs": ["sklearn", "pytorch", "albumentations"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2020-03-11 22:55:14", "date_scraped": "2020-12-13 15:33:04", "words": 262, "sentences": 14, "sum_nltk": "Plant Pathology 2020Implemented / planned [] - Starter code [] - 5-Folds CV [] - Albumentations [] - Visualize training history [-] - Schedulers [-] - Train longer (without overfitting) [-] - Experimenting with ResNets [-] - Experimenting with EfficientNets [-] - Experimenting with SEResNeXts [-] - Experimenting with different input image size [-] - TTA [-] - OHEM [-] - Pseudo labelling [-] - Mixup [-] - Cutmix [-] - Cutout  Notebook Versions v1: Starter code v4: 5-Folds CV.\nThe gap between local and public score seems a bit high, probably because of the small number of validation samples.\nI added 5-folds (for now, simple k-fold) CV to see whether it reduces the difference.\nTo prevent overfitting, I added more augmentations.\nNote: There was no overfit during training (v5), but the CV-LB gap is still high.\nv9: Input image size: 256px -> 512px    Version Net #Folds #Epochs Local LB Public LB Notes     v1 Resnet-18 1 10 0.972 0.923 Starter code   v4 Resnet-18 5 5 0.950 0.941 5-folds CV   v5 Resnet-18 5 10 0.971 0.935 More augmentations   v6 Resnet-18 5 5 0.971 0.937 Softmax + CE   v8 Resnet-18 5 10 0.970 0.944 StratifiedKFold   v9 Resnet-18 5 10 n.a. n.a. 512px input", "sum_nltk_words": 214, "sum_nltk_runtime": 0.003, "sum_t5": "v1: Starter code v4: 5-Folds CV; v6: softmax + cross entropy. v9: StratifiedKFold; v10: n.a. n.a. n.a. n.a. n.a. n.a. n.a. n.a. n.a. n.a. n.a. n.a. n.a. n", "sum_t5_words": 28, "sum_t5_runtime": 6.948, "runtime": 0.002, "nltk_category": "Wholesale & Retail", "nltk_category_score": 0.1985630989074707, "nltk_category_runtime": 26.293, "nltk_subcategory": "Preventative and Reactive", "nltk_subcategory_score": 0.8031094670295715, "nltk_subcategory_runtime": 42.791, "category": "Wholesale & Retail", "category_score": 0.1985630989074707, "subcategory": "Preventative and Reactive", "subcategory_score": 0.8031094670295715, "runtime_cat": 69.084, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.75", "language_code": "en", "language_score": "0.9999956095529052", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "plant pathology 2020implemented planned starter code 5folds cv albumentations visualize training history scheduler train longer without overfitting experimenting resnets experimenting efficientnets experimenting seresnexts experimenting different input image size tta ohem pseudo labelling mixup cutmix cutout notebook version v1 starter code v4 5folds cv gap local public score seems bit high probably small number validation sample added 5folds simple kfold cv see whether reduces difference v5 augmentation try train epoch prevent overfitting added augmentation v6 changed softmax cross entropy used sigmoidbce sure note overfit training v5 cvlb gap still high v8 according eda class balanced multiple_deseases 5 replace kfold stratifiedkfold v9 input image size 256px 512px version net fold epoch local lb public lb note v1 resnet18 1 10 0972 0923 starter code v4 resnet18 5 5 0950 0941 5folds cv v5 resnet18 5 10 0971 0935 augmentation v6 resnet18 5 5 0971 0937 softmax ce v8 resnet18 5 10 0970 0944 stratifiedkfold v9 resnet18 5 10 na na 512px input", "tags_descriptive": ["Classification", "Computer Vision (CV)"]}