{"title": "Step-By-Step Explanation of Scoring Metric", "description": "RationaleI found the explanation for the scoring metric on this competition a little confusing, and I wanted to create a  guide for those who are just entering or haven't made it too far yet. The metric used for this competition is defined as the mean average precision at different intersection over union (IoU) thresholds. This tells us there are a few different steps to getting the score reported on the leaderboard. For each image...  For each submitted nuclei \"prediction\", calculate the Intersection of Union metric with each \"ground truth\" mask in the image. Calculate whether this mask fits at a range of IoU thresholds. At each threshold, calculate the precision across all your submitted masks.  Average the precision across thresholds.  Across the dataset...  Calculate the mean of the average precision for each image.", "link": "https://www.kaggle.com/stkbailey/step-by-step-explanation-of-scoring-metric", "tags": [], "kind": ["Project", "(Notebook)"], "ml_libs": [], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2018-03-21 15:37:59", "date_scraped": "2020-12-12 18:38:54", "words": 138, "sentences": 10, "runtime": 0.002, "description_category": "Utilities", "description_category_score": 0.4082726240158081, "description_category_runtime": 12.383, "description_subcategory": "Student", "description_subcategory_score": 0.48913758993148804, "description_subcategory_runtime": 19.298, "category": "Utilities", "category_score": 0.4082726240158081, "subcategory": "Student", "subcategory_score": 0.48913758993148804, "runtime_cat": 31.681, "programming_language": "Jupyter Notebook", "ml_score": "0.5", "engagement_score": "0.757", "language_code": "en", "language_score": "0.9999963292778482", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "rationalei found explanation scoring metric competition little confusing wanted create guide entering havent made far yet metric used competition defined mean average precision different intersection union iou threshold tell u different step getting score reported leaderboard image submitted nucleus prediction calculate intersection union metric ground truth mask image calculate whether mask fit range iou threshold threshold calculate precision across submitted mask average precision across threshold across dataset calculate mean average precision image", "tags_descriptive": []}