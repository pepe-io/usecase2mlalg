{"title": "Multi-GPU tensorflow convnet [0.65]", "description": "Open tensorflow kernel with CLI download, Multi-GPU support and much moreCode @GitHub Just run a VGG-like convnet baseline while you analyze the data! Works on Linux with Python 3.5+. Features:  CLI data download Data validation with SHA256 hash Simple data visualization Train-Valid splitting Low memory footprint data streams Base VGG-like convnet Multi-GPU training with a single argument! TensorBoard training tracking  Quick startInstall tensorflow and 7z. Clone repo and install the requirements git clone https://github.com/Cognexa/cdiscount-kernel && cd cdiscount-kernel pip3 install -r requirements.txt --user Download dataset with kaggle-cli (this may take a while, 3 hours in my case) # requires >57Gb of free space KG_USER=\"<YOUR KAGGLE USERNAME\" KG_PASS=\"<YOUR KAGGLE PASSWORD>\" cxflow dataset download cdc Or if you have downloaded the data earlier: mkdir data # mv/cp your etracted files to data directory Validate your download and see the example data: # in the root directory (cdiscount-kernel) cxflow dataset validate cdc cxflow dataset show cdc # now see the newly created visual directory Create a random validation split with 10% of the data and start training: cxflow dataset split cdc cxflow train cdc model.n_gpus=<NUMBER OF GPUS TO USE> Observe the training with TensorBoard (note: a summary is written only after each epoch) tensorboard --logdir=log UPDATE [LB 0.65]important: update cxflow and cxflow-tensorflow with pip3 install cxflow cxflow-tensorflow --user --upgrade Main features:  XCeption net (https://arxiv.org/abs/1610.02357) Fast random data access  Resize the data to dataset.size with (this may take a few hours) cxflow dataset resize cdc/xception.yaml cxflow dataset split cdc/xception.yaml Run the training with cxflow train cdc/xception.yaml Training procedure that reached 0.65:  Train with original size, LR 0.0001, 4 middle flow repeats until stalled Fine-tune with 128x128, LR 0.0001, 0.5 dropout, 0.00001 weight decay until stalled Fine-tune as above but with LR 0.00001 (10x smaller)  Tips:  Use small images right away The final GlobalAveragePooling may be a bottleneck Net does not overfit so far, no augmentations needed  Example output: 2017-09-16 00:22:14.000262: INFO    @common         : Creating dataset 2017-09-16 00:22:14.000776: INFO    @common         :   CDCNaiveDataset created 2017-09-16 00:22:14.000777: INFO    @common         : Creating a model 2017-09-16 00:22:20.000724: INFO    @model          :   Creating TF model on 2 GPU devices 2017-09-16 00:22:21.000362: INFO    @cdc_net        : Flatten shape `(?, 8192)` 2017-09-16 00:22:21.000387: INFO    @cdc_dataset    : Loading metadata 2017-09-16 00:22:26.000826: INFO    @cdc_net        : Output shape `(?, 5270)` 2017-09-16 00:22:26.000893: INFO    @cdc_net        : Flatten shape `(?, 8192)` 2017-09-16 00:22:26.000901: INFO    @cdc_net        : Output shape `(?, 5270)` 2017-09-16 00:22:29.000351: INFO    @common         :   CDCNaiveNet created 2017-09-16 00:22:29.000354: INFO    @common         : Creating hooks 2017-09-16 00:22:29.000355: INFO    @common         :   ShowProgress created 2017-09-16 00:22:29.000355: INFO    @common         :   ComputeStats created 2017-09-16 00:22:29.000355: INFO    @common         :   LogVariables created 2017-09-16 00:22:29.000356: INFO    @common         :   LogProfile created 2017-09-16 00:22:29.000356: INFO    @common         :   SaveEvery created 2017-09-16 00:22:29.000356: INFO    @common         :   SaveBest created 2017-09-16 00:22:29.000357: INFO    @common         :   CatchSigint created 2017-09-16 00:22:29.000357: INFO    @common         :   StopAfter created 2017-09-16 00:22:30.000968: INFO    @common         :   WriteTensorBoard created 2017-09-16 00:22:30.000968: INFO    @common         : Creating main loop 2017-09-16 00:22:30.000968: INFO    @common         : Running the main loop 2017-09-16 03:13:01.000457: INFO    @log_variables  : After epoch 1 2017-09-16 03:13:01.000457: INFO    @log_variables  :   train loss mean: 4.243194 2017-09-16 03:13:01.000457: INFO    @log_variables  :   train accuracy mean: 0.320435 2017-09-16 03:13:01.000457: INFO    @log_variables  :   valid loss mean: 3.313541 2017-09-16 03:13:01.000457: INFO    @log_variables  :   valid accuracy mean: 0.434122 2017-09-16 03:13:03.000486: INFO    @save           : Model saved to: ./log/CDCNaiveNet_2017-09-16-00-22-14_ngz6u4_b/model_1.ckpt 2017-09-16 03:13:05.000217: INFO    @save           : Model saved to: ./log/CDCNaiveNet_2017-09-16-00-22-14_ngz6u4_b/model_best.ckpt 2017-09-16 03:13:05.000219: INFO    @log_profile    :   T read data:    1594.948686 2017-09-16 03:13:05.000219: INFO    @log_profile    :   T train:    8347.117133 2017-09-16 03:13:05.000219: INFO    @log_profile    :   T eval: 282.549242 2017-09-16 03:13:05.000219: INFO    @log_profile    :   T hooks:    8.592250 2017-09-16 03:13:05.000219: INFO    @main_loop      : Epochs done: 1 2017-09-16 06:03:17.000103: INFO    @log_variables  : After epoch 2 2017-09-16 06:03:17.000103: INFO    @log_variables  :   train loss mean: 2.952012 2017-09-16 06:03:17.000103: INFO    @log_variables  :   train accuracy mean: 0.480100 2017-09-16 06:03:17.000103: INFO    @log_variables  :   valid loss mean: 2.863293 2017-09-16 06:03:17.000104: INFO    @log_variables  :   valid accuracy mean: 0.496674 2017-09-16 06:03:18.000840: INFO    @save           : Model saved to: ./log/CDCNaiveNet_2017-09-16-00-22-14_ngz6u4_b/model_2.ckpt 2017-09-16 06:03:20.000762: INFO    @save           : Model saved to: ./log/CDCNaiveNet_2017-09-16-00-22-14_ngz6u4_b/model_best.ckpt 2017-09-16 06:03:20.000764: INFO    @log_profile    :   T read data:    1581.478134 2017-09-16 06:03:20.000764: INFO    @log_profile    :   T train:    8342.576470 2017-09-16 06:03:20.000764: INFO    @log_profile    :   T eval: 281.916230 2017-09-16 06:03:20.000764: INFO    @log_profile    :   T hooks:    8.502520 2017-09-16 06:03:20.000764: INFO    @main_loop      : Epochs done: 2  ... AboutThis kernel is written in cxflow-tensorflow, a plugin for cxflow framework. Make sure you check it out! A simple submission script will be added soon, stay tuned!", "link": "https://www.kaggle.com/blazeka/multi-gpu-tensorflow-convnet-0-65", "tags": [], "kind": ["Project", "(Notebook)"], "ml_libs": ["tensorflow"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2017-09-29 10:34:06", "date_scraped": "2020-12-12 17:44:11", "words": 1191, "sentences": 5, "sum_nltk": "Open tensorflow kernel with CLI download, Multi-GPU support and much moreCode @GitHub Just run a VGG-like convnet baseline while you analyze the data!\nFeatures:  CLI data download Data validation with SHA256 hash Simple data visualization Train-Valid splitting Low memory footprint data streams Base VGG-like convnet Multi-GPU training with a single argument!\nAboutThis kernel is written in cxflow-tensorflow, a plugin for cxflow framework.", "sum_nltk_words": 61, "sum_nltk_runtime": 0.005, "sum_t5": "tensorflow kernel supports multi-gpu and a cdiscount-kernel. tensorboard supports a tensorboard and a tensorboard-like convnet. tensorboard supports a tensorboard and a tensorboard-like mkdir. tensorboard supports a tensorboard and a tensorboard-like mkdir.", "sum_t5_words": 31, "sum_t5_runtime": 6.888, "runtime": 0.006, "nltk_category": "Economics", "nltk_category_score": 0.17185910046100616, "nltk_category_runtime": 7.607, "nltk_subcategory": "Quality", "nltk_subcategory_score": 0.5604857802391052, "nltk_subcategory_runtime": 11.953, "category": "Economics", "category_score": 0.17185910046100616, "subcategory": "Quality", "subcategory_score": 0.5604857802391052, "runtime_cat": 19.561, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.763", "language_code": "en", "language_score": "0.9999970691086508", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "open tensorflow kernel cli download multigpu support much morecode github run vgglike convnet baseline analyze data work linux python 35 feature cli data download data validation sha256 hash simple data visualization trainvalid splitting low memory footprint data stream base vgglike convnet multigpu training single argument tensorboard training tracking quick startinstall tensorflow 7z clone repo install requirement git clone httpsgithubcomcognexacdiscountkernel cd cdiscountkernel pip3 install r requirementstxt user download dataset kagglecli may take 3 hour case requires 57gb free space kg_useryour kaggle username kg_passyour kaggle password cxflow dataset download cdc downloaded data earlier mkdir data mvcp etracted file data directory validate download see example data root directory cdiscountkernel cxflow dataset validate cdc cxflow dataset show cdc see newly created visual directory create random validation split 10 data start training cxflow dataset split cdc cxflow train cdc modeln_gpusnumber gpus use observe training tensorboard note summary written epoch tensorboard logdirlog update lb 065important update cxflow cxflowtensorflow pip3 install cxflow cxflowtensorflow user upgrade main feature xception net httpsarxivorgabs161002357 fast random data access resize data datasetsize may take hour cxflow dataset resize cdcxceptionyaml cxflow dataset split cdcxceptionyaml run training cxflow train cdcxceptionyaml training procedure reached 065 train original size lr 00001 4 middle flow repeat stalled finetune 128x128 lr 00001 05 dropout 000001 weight decay stalled finetune lr 000001 10x smaller tip use small image right away final globalaveragepooling may bottleneck net overfit far augmentation needed example output 20170916 002214000262 info common creating dataset 20170916 002214000776 info common cdcnaivedataset created 20170916 002214000777 info common creating model 20170916 002220000724 info model creating tf model 2 gpu device 20170916 002221000362 info cdc_net flatten shape 8192 20170916 002221000387 info cdc_dataset loading metadata 20170916 002226000826 info cdc_net output shape 5270 20170916 002226000893 info cdc_net flatten shape 8192 20170916 002226000901 info cdc_net output shape 5270 20170916 002229000351 info common cdcnaivenet created 20170916 002229000354 info common creating hook 20170916 002229000355 info common showprogress created 20170916 002229000355 info common computestats created 20170916 002229000355 info common logvariables created 20170916 002229000356 info common logprofile created 20170916 002229000356 info common saveevery created 20170916 002229000356 info common savebest created 20170916 002229000357 info common catchsigint created 20170916 002229000357 info common stopafter created 20170916 002230000968 info common writetensorboard created 20170916 002230000968 info common creating main loop 20170916 002230000968 info common running main loop 20170916 031301000457 info log_variables epoch 1 20170916 031301000457 info log_variables train loss mean 4243194 20170916 031301000457 info log_variables train accuracy mean 0320435 20170916 031301000457 info log_variables valid loss mean 3313541 20170916 031301000457 info log_variables valid accuracy mean 0434122 20170916 031303000486 info save model saved logcdcnaivenet_20170916002214_ngz6u4_bmodel_1ckpt 20170916 031305000217 info save model saved logcdcnaivenet_20170916002214_ngz6u4_bmodel_bestckpt 20170916 031305000219 info log_profile read data 1594948686 20170916 031305000219 info log_profile train 8347117133 20170916 031305000219 info log_profile eval 282549242 20170916 031305000219 info log_profile hook 8592250 20170916 031305000219 info main_loop epoch done 1 20170916 060317000103 info log_variables epoch 2 20170916 060317000103 info log_variables train loss mean 2952012 20170916 060317000103 info log_variables train accuracy mean 0480100 20170916 060317000103 info log_variables valid loss mean 2863293 20170916 060317000104 info log_variables valid accuracy mean 0496674 20170916 060318000840 info save model saved logcdcnaivenet_20170916002214_ngz6u4_bmodel_2ckpt 20170916 060320000762 info save model saved logcdcnaivenet_20170916002214_ngz6u4_bmodel_bestckpt 20170916 060320000764 info log_profile read data 1581478134 20170916 060320000764 info log_profile train 8342576470 20170916 060320000764 info log_profile eval 281916230 20170916 060320000764 info log_profile hook 8502520 20170916 060320000764 info main_loop epoch done 2 aboutthis kernel written cxflowtensorflow plugin cxflow framework make sure check simple submission script added soon stay tuned", "tags_descriptive": []}