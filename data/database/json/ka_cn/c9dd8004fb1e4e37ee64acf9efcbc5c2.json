{"title": "Can we Trust CV and LB?", "description": "Can we Trust CV and LB?Kaggle's \"Don't Overfit II\" is a unique competition where the training dataset only has 250 observations and the public test dataset has 1975 observations. Can we trust the training dataset CV and public dataset LB? Do higher AUC scores on these small datasets indicate that a more accurate model was found? In this kernel we explore this question with four experiments. We find that we can trust LB but must be careful trusting CV. Afterward in the appendix, using insights from these experiments, we estimate how many useful variables exist in the real dataset. Experiment 1 : CV with 300 useless variablesLet's create a synthetic sample of size 250. We will create 300 useless variables and a completely random (meaningless) target and see what CV says.", "link": "https://www.kaggle.com/cdeotte/can-we-trust-cv-and-lb", "tags": [], "kind": ["Project", "(Notebook)"], "ml_libs": ["sklearn", "pattern"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2019-05-06 01:05:03", "date_scraped": "2020-12-12 19:05:08", "words": 131, "sentences": 6, "runtime": 0.001, "description_category": "Biotechnological & Life Sciences", "description_category_score": 0.07326307892799377, "description_category_runtime": 11.291, "description_subcategory": "Machine Learning", "description_subcategory_score": 0.3030202090740204, "description_subcategory_runtime": 17.657, "category": "Biotechnological & Life Sciences", "category_score": 0.07326307892799377, "subcategory": "Machine Learning", "subcategory_score": 0.3030202090740204, "runtime_cat": 28.949, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.676", "language_code": "en", "language_score": "0.9999982578664162", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "trust cv lbkaggles dont overfit ii unique competition training dataset 250 observation public test dataset 1975 observation trust training dataset cv public dataset lb higher auc score small datasets indicate accurate model found kernel explore question four experiment find trust lb must careful trusting cv afterward appendix using insight experiment estimate many useful variable exist real dataset experiment 1 cv 300 useless variableslets create synthetic sample size 250 create 300 useless variable completely random meaningless target see cv say", "tags_descriptive": []}