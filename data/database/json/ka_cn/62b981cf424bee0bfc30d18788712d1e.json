{"title": "Cleaning the data for rapid prototyping (fastai)", "description": "Let's try to clean up the dataset as best as we can, and create something we can do some model prototyping with! For prototyping we'll want something that's small, and ideally fits within Kaggle's 20GB limit so we can upload it as a dataset for others to easily work with. (If you're just looking for the dataset created with this notebook, you can find it here.) After cleaning up the data and create a prototyping dataset, we will use it to train and submit a model. You can see the followup notebook that uses this data here: From Prototyping To Submission Here are the issues that we will address.  Fix images with incorrect RescaleIntercept Remove some images if they have little useful information (e.g. they don't actually contain brain tissue) Resample this dataset to 2/1 split of with/without haemorrhage, so we have a smaller dataset for quick prototyping Crop the images to just contain the brain, and save the size of the crop in case it's important Do histogram rescaling and then save JPEG 256x256 px images  We'll be using the fastai.medical.imaging library here - for more information about this see the notebook Some DICOM gotchas to be aware of. We'll also use the same basic setup that's in the notebook.", "link": "https://www.kaggle.com/jhoward/cleaning-the-data-for-rapid-prototyping-fastai", "tags": [], "kind": ["Project", "(Notebook)"], "ml_libs": [], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2019-10-24 20:27:50", "date_scraped": "2020-12-13 16:47:30", "words": 213, "sentences": 6, "sum_nltk": "Let's try to clean up the dataset as best as we can, and create something we can do some model prototyping with!\nFor prototyping we'll want something that's small, and ideally fits within Kaggle's 20GB limit so we can upload it as a dataset for others to easily work with.\n(If you're just looking for the dataset created with this notebook, you can find it here.) After cleaning up the data and create a prototyping dataset, we will use it to train and submit a model.\nYou can see the followup notebook that uses this data here: From Prototyping To Submission Here are the issues that we will address.\nFix images with incorrect RescaleIntercept Remove some images if they have little useful information (e.g. they don't actually contain brain tissue) Resample this dataset to 2/1 split of with/without haemorrhage, so we have a smaller dataset for quick prototyping Crop the images to just contain the brain, and save the size of the crop in case it's important Do histogram rescaling and then save JPEG 256x256 px images  We'll be using the fastai.medical.imaging library here - for more information about this see the notebook Some DICOM gotchas to be aware of.\nWe'll also use the same basic setup that's in the notebook.", "sum_nltk_words": 207, "sum_nltk_runtime": 0.002, "sum_t5": "we'll use the dataset to train and submit a model. we'll also use the same basic setup that's in the notebook. the notebook will be available in a few days. it's available here: from prototyping to submission... if you're interested in learning more about the notebook, please click here... if you're interested in learning more about the notebook, please click here.", "sum_t5_words": 61, "sum_t5_runtime": 4.745, "runtime": 0.003, "nltk_category": "Utilities", "nltk_category_score": 0.43221545219421387, "nltk_category_runtime": 19.388, "nltk_subcategory": "Machine Learning", "nltk_subcategory_score": 0.6430996656417847, "nltk_subcategory_runtime": 31.387, "category": "Utilities", "category_score": 0.43221545219421387, "subcategory": "Machine Learning", "subcategory_score": 0.6430996656417847, "runtime_cat": 50.775, "programming_language": "Jupyter Notebook", "ml_score": "0.5", "engagement_score": "0.756", "language_code": "en", "language_score": "0.9999982559522633", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "let try clean dataset best create something model prototyping prototyping well want something thats small ideally fit within kaggles 20gb limit upload dataset others easily work youre looking dataset created notebook find cleaning data create prototyping dataset use train submit model see followup notebook us data prototyping submission issue address fix image incorrect rescaleintercept remove image little useful information eg dont actually contain brain tissue resample dataset 21 split withwithout haemorrhage smaller dataset quick prototyping crop image contain brain save size crop case important histogram rescaling save jpeg 256x256 px image well using fastaimedicalimaging library information see notebook dicom gotchas aware well also use basic setup thats notebook", "tags_descriptive": []}