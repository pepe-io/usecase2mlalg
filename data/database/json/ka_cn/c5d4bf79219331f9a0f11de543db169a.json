{"title": "Model Interpretation with Voting Classifier(Hard)", "description": "Feature Selector Baseline Don't Overfit  Outline of the Notebook  Step.1 Read Dataset Step.2 Display dataset Step.3 Remove unwanted columns Step.4 Create Instance of Feature Selector Step.5 Missing Value Step.6 Single Unique Value Step.7 Plot Feature Importances Step.8 Low Importance Features Step.9 Removing Features Step.10 Handling One-Hot Features Step.11 Model Training Step.12 Model Evaluation Framework to check Importance Step.13 Model Training and Evaluation Framework to check Importance   Reference Github : https://github.com/WillKoehrsen/feature-selector Reference Kernel :  1. https://www.kaggle.com/sovchinnikov/logistic-regression 2. https://www.kaggle.com/artgor/how-to-not-overfit/", "link": "https://www.kaggle.com/ashishpatel26/model-interpretation-with-voting-classifier-hard", "tags": [], "kind": ["Project", "(Notebook)"], "ml_libs": ["sklearn", "lightgbm"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2019-02-18 13:36:05", "date_scraped": "2020-12-12 19:05:08", "words": 82, "sentences": 3, "runtime": 0.002, "description_category": "Real Estate, Rental & Leasing", "description_category_score": 0.21047450602054596, "description_category_runtime": 13.109, "description_subcategory": "Machine Learning", "description_subcategory_score": 0.35495293140411377, "description_subcategory_runtime": 20.267, "category": "Real Estate, Rental & Leasing", "category_score": 0.21047450602054596, "subcategory": "Machine Learning", "subcategory_score": 0.35495293140411377, "runtime_cat": 33.375, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.728", "language_code": "en", "language_score": "0.9999943795489032", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "feature selector baseline dont overfit outline notebook step1 read dataset step2 display dataset step3 remove unwanted column step4 create instance feature selector step5 missing value step6 single unique value step7 plot feature importance step8 low importance feature step9 removing feature step10 handling onehot feature step11 model training step12 model evaluation framework check importance step13 model training evaluation framework check importance reference github httpsgithubcomwillkoehrsenfeatureselector reference kernel 1 httpswwwkagglecomsovchinnikovlogisticregression 2 httpswwwkagglecomartgorhowtonotoverfit", "tags_descriptive": []}