{"title": "M5 - Custom features", "description": "from eli5 documentation (seems it's perfect explanation) The idea is the following: feature importance can be measured by looking at how much the score (accuracy, mse, rmse, mae, etc. - any score we\u2019re interested in) decreases when a feature is not available. To do that one can remove feature from the dataset, re-train the estimator and check the score. But it requires re-training an estimator for each feature, which can be computationally intensive. Also, it shows what may be important within a dataset, not what is important within a concrete trained model. To avoid re-training the estimator we can remove a feature only from the test part of the dataset, and compute score without using this feature. It doesn\u2019t work as-is, because estimators expect feature to be present. So instead of removing a feature we can replace it with random noise - feature column is still there, but it no longer contains useful information. This method works if noise is drawn from the same distribution as original feature values (as otherwise estimator may fail). The simplest way to get such noise is to shuffle values for a feature, i.e. use other examples\u2019 feature values - this is how permutation importance is computed.  It's not good when feature remove (replaced by noise) but we have better score. Simple and easy.", "link": "https://www.kaggle.com/kyakovlev/m5-custom-features", "tags": [], "kind": ["Project", "(Notebook)"], "ml_libs": ["sklearn", "lightgbm"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2020-04-24 01:10:16", "date_scraped": "2020-12-13 13:22:57", "words": 220, "sentences": 13, "sum_nltk": "from eli5 documentation (seems it's perfect explanation) The idea is the following: feature importance can be measured by looking at how much the score (accuracy, mse, rmse, mae, etc.\n- any score we\u2019re interested in) decreases when a feature is not available.\nTo do that one can remove feature from the dataset, re-train the estimator and check the score.\nBut it requires re-training an estimator for each feature, which can be computationally intensive.\nTo avoid re-training the estimator we can remove a feature only from the test part of the dataset, and compute score without using this feature.\nIt doesn\u2019t work as-is, because estimators expect feature to be present.\nSo instead of removing a feature we can replace it with random noise - feature column is still there, but it no longer contains useful information.\nThis method works if noise is drawn from the same distribution as original feature values (as otherwise estimator may fail).\nThe simplest way to get such noise is to shuffle values for a feature, i.e. use other examples\u2019 feature values - this is how permutation importance is computed.\nIt's not good when feature remove (replaced by noise) but we have better score.", "sum_nltk_words": 188, "sum_nltk_runtime": 0.003, "sum_t5": "feature importance can be measured by looking at how much the score decreases when a feature is not available. to remove feature from dataset, re-train estimator and check score. but it requires re-training estimator for each feature, which can be computationally intensive. instead of removing feature we can replace it with random noise. this method works if noise is drawn from same distribution as original value. it's not good when feature remove (replaced by noise) but we have better score.", "sum_t5_words": 80, "sum_t5_runtime": 5.237, "runtime": 0.004, "nltk_category": "Utilities", "nltk_category_score": 0.2527328431606293, "nltk_category_runtime": 18.581, "nltk_subcategory": "General", "nltk_subcategory_score": 0.40746253728866577, "nltk_subcategory_runtime": 29.665, "category": "Utilities", "category_score": 0.2527328431606293, "subcategory": "General", "subcategory_score": 0.40746253728866577, "runtime_cat": 48.246, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.759", "language_code": "en", "language_score": "0.9999966428805434", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "eli5 documentation seems perfect explanation idea following feature importance measured looking much score accuracy mse rmse mae etc score interested decrease feature available one remove feature dataset retrain estimator check score requires retraining estimator feature computationally intensive also show may important within dataset important within concrete trained model avoid retraining estimator remove feature test part dataset compute score without using feature doesnt work asis estimator expect feature present instead removing feature replace random noise feature column still longer contains useful information method work noise drawn distribution original feature value otherwise estimator may fail simplest way get noise shuffle value feature ie use example feature value permutation importance computed good feature remove replaced noise better score simple easy", "tags_descriptive": []}