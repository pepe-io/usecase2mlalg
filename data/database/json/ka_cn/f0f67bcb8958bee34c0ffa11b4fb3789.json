{"title": "From EDA to the Top (LB 0.367)", "description": "IntroductionIn this competition, we are challenged to build a model that predicts the total ride duration of taxi trips in New York City. There are quite a few EDA kernels and some of them are excellent. Here I try to focus more on the feature extraction. In this Kernel you could find a few general kaggle related tips and a some modeling improvement ideas as well. My main goal is to craft the best possible feature set for XGB with the given Kernel limitations. My current best submission is still based on this script. My best single model with these features reached LB 0.371. Linear combination of several models gave LB 0.368. Stacking added marginal improvement to 0.367. Please feel free to fork and use the features and search better parameters. With this simple notebook we  Explore the dataset Extract 59 useful features Create simple 80-20 train - validation set Train XGBregressor Analyze Feature Importance Score test set and submit Check XGB parameter search result for further improvements  References  I used a few feature extraction ideas from Nir Malbin's Kernel Thanks for oscarleo for this external dataset", "link": "https://www.kaggle.com/gaborfodor/from-eda-to-the-top-lb-0-367", "tags": ["Geospatial Analysis", "Xgboost", "Feature Engineering"], "kind": ["Project", "(Notebook)"], "ml_libs": ["sklearn", "xgboost"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2017-09-17 14:08:34", "date_scraped": "2020-12-13 14:39:46", "words": 190, "sentences": 11, "runtime": 0.0, "description_category": "Justice, Law and Regulations", "description_category_score": 0.03510511294007301, "description_category_runtime": 15.583, "description_subcategory": "Machine Learning", "description_subcategory_score": 0.8684424757957458, "description_subcategory_runtime": 24.612, "category": "Justice, Law and Regulations", "category_score": 0.03510511294007301, "subcategory": "Machine Learning", "subcategory_score": 0.8684424757957458, "runtime_cat": 40.196, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.803", "language_code": "en", "language_score": "0.9999958050013673", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "introductionin competition challenged build model predicts total ride duration taxi trip new york city quite eda kernel excellent try focus feature extraction kernel could find general kaggle related tip modeling improvement idea well main goal craft best possible feature set xgb given kernel limitation current best submission still based script best single model feature reached lb 0371 linear combination several model gave lb 0368 stacking added marginal improvement 0367 please feel free fork use feature search better parameter simple notebook explore dataset extract 59 useful feature create simple 8020 train validation set train xgbregressor analyze feature importance score test set submit check xgb parameter search result improvement reference used feature extraction idea nir malbins kernel thanks oscarleo external dataset", "tags_descriptive": ["Geospatial Analysis", "Xgboost", "Feature Engineering"]}