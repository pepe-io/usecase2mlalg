{"title": "Dataset Decomposition Techniques", "description": "Dataset Decomposition TechniquesProblem Statement: Santander Value PredictionSantander Group wants to identify the value of transactions for each potential customer. This is a first step that Santander needs to nail in order to personalize their services at scale. The dataset can be downloaded from this link. In this kernel I have explained different approaches for dataset decomposition. IntroductionThe purpose of this kernel is to walkthrough different dataset decomposition techniques and their implementations.   Decomposition of dataset into lower dimensions often becomes an important task while deailing with datasets having larger number of features. Dimensionality Reduction refers to the process of converting a dataset having vast dimensions into a dataset with lesser number of dimensions. This process is done by ensuring that the information conveyed by the original dataset is not lost. Credits:  https://www.kaggle.com/arthurtok/interactive-intro-to-dimensionality-reduction  Contents Dataset Preparation     Feature Statistics     Eigen Values and Eigen Vectors    Principal Components Analysis \u00a0\u00a0\u00a0\u00a0 4.1 Finding Right Number of Components \u00a0\u00a0\u00a0\u00a0 4.2 PCA Implementation \u00a0\u00a0\u00a0\u00a0 4.3 Variants of PCA   Truncated SVD    Fast ICA    Factor Analysis    Non-Negative Matrix Factorization   Gaussian Random Projection   Sparse Random Projection   tSNE Visualization   Baseline Model with Decomposition Features", "link": "https://www.kaggle.com/shivamb/dataset-decomposition-techniques", "tags": ["Feature Engineering", "Dimensionality Reduction"], "kind": ["Project", "(Notebook)"], "ml_libs": ["sklearn", "lightgbm"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2018-07-04 20:35:41", "date_scraped": "2020-12-13 17:15:37", "words": 216, "sentences": 9, "sum_nltk": "Dataset Decomposition TechniquesProblem Statement: Santander Value PredictionSantander Group wants to identify the value of transactions for each potential customer.\nThis is a first step that Santander needs to nail in order to personalize their services at scale.\nThe dataset can be downloaded from this link.\nIn this kernel I have explained different approaches for dataset decomposition.\nIntroductionThe purpose of this kernel is to walkthrough different dataset decomposition techniques and their implementations.\nDecomposition of dataset into lower dimensions often becomes an important task while deailing with datasets having larger number of features.\nDimensionality Reduction refers to the process of converting a dataset having vast dimensions into a dataset with lesser number of dimensions.\nThis process is done by ensuring that the information conveyed by the original dataset is not lost.\nCredits:  https://www.kaggle.com/arthurtok/interactive-intro-to-dimensionality-reduction  Contents Dataset Preparation     Feature Statistics     Eigen Values and Eigen Vectors    Principal Components Analysis \u00a0\u00a0\u00a0\u00a0 4.1 Finding Right Number of Components \u00a0\u00a0\u00a0\u00a0 4.2 PCA Implementation \u00a0\u00a0\u00a0\u00a0 4.3 Variants of PCA   Truncated SVD    Fast ICA    Factor Analysis    Non-Negative Matrix Factorization   Gaussian Random Projection   Sparse Random Projection   tSNE Visualization   Baseline Model with Decomposition Features", "sum_nltk_words": 206, "sum_nltk_runtime": 0.003, "sum_t5": "a dataset with vast dimensions is converting it into a dataset with lesser number of dimensions. this process ensures that the information conveyed by the original dataset is not lost. a dataset with vast dimensions is converting it into a dataset with lesser number of dimensions. a kernel is a toolkit for analyzing a dataset to determine its value. it is also a toolkit for analyzing a dataset to determine its value.", "sum_t5_words": 72, "sum_t5_runtime": 4.61, "runtime": 0.0, "nltk_category": "Real Estate, Rental & Leasing", "nltk_category_score": 0.27041423320770264, "nltk_category_runtime": 21.526, "nltk_subcategory": "Student", "nltk_subcategory_score": 0.35728174448013306, "nltk_subcategory_runtime": 34.37, "category": "Real Estate, Rental & Leasing", "category_score": 0.27041423320770264, "subcategory": "Student", "subcategory_score": 0.35728174448013306, "runtime_cat": 55.896, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.75", "language_code": "en", "language_score": "0.9999974625075587", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "dataset decomposition techniquesproblem statement santander value predictionsantander group want identify value transaction potential customer first step santander need nail order personalize service scale dataset downloaded link kernel explained different approach dataset decomposition introductionthe purpose kernel walkthrough different dataset decomposition technique implementation decomposition dataset lower dimension often becomes important task deailing datasets larger number feature dimensionality reduction refers process converting dataset vast dimension dataset lesser number dimension process done ensuring information conveyed original dataset lost credit httpswwwkagglecomarthurtokinteractiveintrotodimensionalityreduction content dataset preparation feature statistic eigen value eigen vector principal component analysis 41 finding right number component 42 pca implementation 43 variant pca truncated svd fast ica factor analysis nonnegative matrix factorization gaussian random projection sparse random projection tsne visualization baseline model decomposition feature", "tags_descriptive": ["Feature Engineering", "Dimensionality Reduction"]}