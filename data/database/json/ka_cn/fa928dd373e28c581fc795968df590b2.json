{"title": "5th Place Solution Code", "description": "All this code might seem a little overwhelming at first, but it is really not that complex. There are seven parts:  Preprocessing Training NN1 Training NN2 Training NN3 Image Extractor Training LightGBM Training xlearn Stacking  I'll briefly describe each of them. PreprocessingIn the preprocessing part, external data sources are loaded and the features are processed by:  scaling them appropriately building frequency encoded features of some variables binning some features scaling some features logarithmically  Furthermore, the image activations of a pretrained Densenet121 model are extracted for all features twice (once on the regular images, once on horizontally flipped images). The important variables in this section are:  train_df and test_df - Dataframes holding raw data and all processed tabular features all_cat_features - List of strings determining all available categorical features. all_num_features - List of strings determining all available numerical features. \u00ecmg_features_train, img_features_train_flipped and \u00ecmg_features_test - numpy arrays consisting of the 1024d image activations extracted from Densenet121 for the first image of each pet. train_text_tokens and test_text_tokens - numpy arrays consisting of tokenized words, later used in the RNN models.  Training NN1NN1 is trained with MSE loss using regular image features and a TfIdf representation of text. Important variables:  train_preds_nn_1 - (n_repeats x n_train) numpy array consisting of out-of-fold train predictions. test_preds_nn_1 - (n_repeats x n_test x n_splits) numpy array consisting of test predictions of each fold.  Training NN2NN1 is trained with MSE loss using regular image features and a non-trainable 300d crawl embedding for text. Important variables:  train_preds_nn_2 - (n_repeats x n_train) numpy array consisting of out-of-fold train predictions. test_preds_nn_2 - (n_repeats x n_test x n_splits) numpy array consisting of test predictions of each fold.  Training NN3NN3 is trained with SmoothL1 loss using horizontally flipped image features and a trainable 200d GloVe embedding for text. Important variables:  train_preds_nn_3 - (n_repeats x n_train) numpy array consisting of out-of-fold train predictions. test_preds_nn_3 - (n_repeats x n_test x n_splits) numpy array consisting of test predictions of each fold.  Image ExtractorTrains an image activation extractor NN on train + test data. Input are the 1024d Densenet121 features. The model is trained to predict Age, Breed1 and Type of pets. Important variables:  train_activations - (n_train x 80) numpy array consisting of extracted image activations for the train set. Consists of 64 activations from the first hidden layer + 16 activations of the second hidden layer for each pet. test_activations - (n_test x 80) numpy array consisting of extracted image activations for the test set. Consists of 64 activations from the first hidden layer + 16 activations of the second hidden layer for each pet.  Training LightGBMText features are represented by 120d SVD of a TfIdf matrix for the LightGBM model. The 64d activations from the first hidden layer of the image extractor NN are used to represent images. Important variables:  train_preds_lgb - (n_repeats x n_train) numpy array consisting of out-of-fold train predictions. test_preds_lgb - (n_repeats x n_test x n_splits) numpy array consisting of test predictions of each fold.  Training xlearnText features are represented by 10d SVD of a TfIdf matrix for the xlearn model. The 16d activations from the second hidden layer of the image extractor NN are used to represent images. All numerical features are binned in quantile bins and treated as categorical. . Important variables:  train_preds_ffm - (n_repeats x n_train) numpy array consisting of out-of-fold train predictions. test_preds_ffm - (n_repeats x n_test x n_splits) numpy array consisting of test predictions of each fold.  StackingCombines the previously generated predictions using a linear regression. The scores are converted to labels by following the train distribution. Important variables:  fixed_scores - the final labels for each pet.", "link": "https://www.kaggle.com/bminixhofer/5th-place-solution-code", "tags": ["DL", "Classification", "Feature Engineering"], "kind": ["Project", "(Notebook)"], "ml_libs": ["keras", "nltk", "tensorflow", "lightgbm", "sklearn", "pattern", "pytorch"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2020-07-26 15:05:10", "date_scraped": "2020-12-13 15:07:40", "words": 617, "sentences": 36, "sum_nltk": "The important variables in this section are:  train_df and test_df - Dataframes holding raw data and all processed tabular features all_cat_features - List of strings determining all available categorical features.\n\u00ecmg_features_train, img_features_train_flipped and \u00ecmg_features_test - numpy arrays consisting of the 1024d image activations extracted from Densenet121 for the first image of each pet.\nImportant variables:  train_preds_nn_3 - (n_repeats x n_train) numpy array consisting of out-of-fold train predictions.\nImportant variables:  train_preds_nn_3 - (n_repeats x n_train) numpy array consisting of out-of-fold train predictions.\nImportant variables:  train_preds_nn_3 - (n_repeats x n_train) numpy array consisting of out-of-fold train predictions.\ntest_preds_nn_3 - (n_repeats x n_test x n_splits) numpy array consisting of test predictions of each fold.\ntest_preds_nn_3 - (n_repeats x n_test x n_splits) numpy array consisting of test predictions of each fold.\nImportant variables:  train_activations - (n_train x 80) numpy array consisting of extracted image activations for the train set.\nImportant variables:  train_preds_lgb - (n_repeats x n_train) numpy array consisting of out-of-fold train predictions.\ntest_preds_lgb - (n_repeats x n_test x n_splits) numpy array consisting of test predictions of each fold.\n. Important variables:  train_preds_ffm - (n_repeats x n_train) numpy array consisting of out-of-fold train predictions.\ntest_preds_ffm - (n_repeats x n_test x n_splits) numpy array consisting of test predictions of each fold.", "sum_nltk_words": 202, "sum_nltk_runtime": 0.008, "sum_t5": "training NN1NN1 is trained with MSE loss using regular image features. training NN2NN1 is trained with MSE loss using regular image features. training NN3 training xlearn Stacking. xlearn. xlearn. xlearn. xlearn. xlearn. xlearn. xlearn. xlearn. xlearn", "sum_t5_words": 36, "sum_t5_runtime": 7.039, "runtime": 0.01, "nltk_category": "Utilities", "nltk_category_score": 0.7478520274162292, "nltk_category_runtime": 31.323, "nltk_subcategory": "Machine Learning", "nltk_subcategory_score": 0.7804180979728699, "nltk_subcategory_runtime": 51.471, "category": "Utilities", "category_score": 0.7478520274162292, "subcategory": "Machine Learning", "subcategory_score": 0.7804180979728699, "runtime_cat": 82.794, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.736", "language_code": "en", "language_score": "0.9999975678748867", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "code might seem little overwhelming first really complex seven part preprocessing training nn1 training nn2 training nn3 image extractor training lightgbm training xlearn stacking ill briefly describe preprocessingin preprocessing part external data source loaded feature processed scaling appropriately building frequency encoded feature variable binning feature scaling feature logarithmically furthermore image activation pretrained densenet121 model extracted feature twice regular image horizontally flipped image important variable section train_df test_df dataframes holding raw data processed tabular feature all_cat_features list string determining available categorical feature all_num_features list string determining available numerical feature img_features_train img_features_train_flipped img_features_test numpy array consisting 1024d image activation extracted densenet121 first image pet train_text_tokens test_text_tokens numpy array consisting tokenized word later used rnn model training nn1nn1 trained mse loss using regular image feature tfidf representation text important variable train_preds_nn_1 n_repeats x n_train numpy array consisting outoffold train prediction test_preds_nn_1 n_repeats x n_test x n_splits numpy array consisting test prediction fold training nn2nn1 trained mse loss using regular image feature nontrainable 300d crawl embedding text important variable train_preds_nn_2 n_repeats x n_train numpy array consisting outoffold train prediction test_preds_nn_2 n_repeats x n_test x n_splits numpy array consisting test prediction fold training nn3nn3 trained smoothl1 loss using horizontally flipped image feature trainable 200d glove embedding text important variable train_preds_nn_3 n_repeats x n_train numpy array consisting outoffold train prediction test_preds_nn_3 n_repeats x n_test x n_splits numpy array consisting test prediction fold image extractortrains image activation extractor nn train test data input 1024d densenet121 feature model trained predict age breed1 type pet important variable train_activations n_train x 80 numpy array consisting extracted image activation train set consists 64 activation first hidden layer 16 activation second hidden layer pet test_activations n_test x 80 numpy array consisting extracted image activation test set consists 64 activation first hidden layer 16 activation second hidden layer pet training lightgbmtext feature represented 120d svd tfidf matrix lightgbm model 64d activation first hidden layer image extractor nn used represent image important variable train_preds_lgb n_repeats x n_train numpy array consisting outoffold train prediction test_preds_lgb n_repeats x n_test x n_splits numpy array consisting test prediction fold training xlearntext feature represented 10d svd tfidf matrix xlearn model 16d activation second hidden layer image extractor nn used represent image numerical feature binned quantile bin treated categorical important variable train_preds_ffm n_repeats x n_train numpy array consisting outoffold train prediction test_preds_ffm n_repeats x n_test x n_splits numpy array consisting test prediction fold stackingcombines previously generated prediction using linear regression score converted label following train distribution important variable fixed_scores final label pet", "tags_descriptive": ["Deep Learning (DL)", "Classification", "Feature Engineering"]}