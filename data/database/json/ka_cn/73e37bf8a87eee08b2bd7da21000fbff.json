{"title": "XGB Fraud with Magic - [0.9600]", "description": "XGB Fraud with Magic scores LB 0.96This model is part of the 1st place solution to Kaggle's \"IEEE-CIS Fraud Detection\" competition. When this model is ensembled together with Konstantin's CatBoost and LGBM models, the result achieves public LB 0.9677 and private LB 0.9459 taking first place here In this kernel, we build two XGB models. The first model does not use the magic features and achieves LB 0.95. The second model uses the magic features and achieves LB 0.96. In the appendix, we demonstrate how to increase LB further with post processing. Reading one million rows of data from disk and engineering features takes 5 minutes using Pandas and CPU. Alternatively if we use RAPIDS cuDF and GPU, it takes only 20 seconds! CPU times are displayed beneath code blocks below and GPU 15x speed up is demonstrated here.", "link": "https://www.kaggle.com/cdeotte/xgb-fraud-with-magic-0-9600", "tags": [], "kind": ["Project", "(Notebook)"], "ml_libs": ["sklearn", "xgboost"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2020-02-02 00:12:36", "date_scraped": "2020-12-12 21:40:28", "words": 139, "sentences": 7, "runtime": 0.005, "description_category": "Utilities", "description_category_score": 0.011082151904702187, "description_category_runtime": 13.291, "description_subcategory": "Fraud", "description_subcategory_score": 0.9821422100067139, "description_subcategory_runtime": 20.761, "category": "Utilities", "category_score": 0.011082151904702187, "subcategory": "Fraud", "subcategory_score": 0.9821422100067139, "runtime_cat": 34.052, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.789", "language_code": "en", "language_score": "0.9999943334763827", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "xgb fraud magic score lb 096this model part 1st place solution kaggles ieeecis fraud detection competition model ensembled together konstantins catboost lgbm model result achieves public lb 09677 private lb 09459 taking first place kernel build two xgb model first model use magic feature achieves lb 095 second model us magic feature achieves lb 096 appendix demonstrate increase lb post processing reading one million row data disk engineering feature take 5 minute using panda cpu alternatively use rapid cudf gpu take 20 second cpu time displayed beneath code block gpu 15x speed demonstrated", "tags_descriptive": []}