{"title": "Fine-tuning ResNet34 on ship detection", "description": "OverviewResnet34 is commonly used as an encoder for U-net and SSD, boosting the model performance and training time since you do not need to train the model from scratch. However, in particular cases it makes sense to do fine-tuning of Resnet34 model before using it as a decoder for object localization or image segmentation. In this competition the size of ship masks is much smaller than the size of images that leads to quite unbalanced training with ~1 positive pixel per 1000 negative ones. If images with no ships are used, instead of ~1:1000 you will end up with ~1:10000 unbalance, which is quite tough. Moreover, the training time is ~4 times longer since you need to process more images in each epoch. So, it is reasonable to drop empty images and focus only on ones with ships. Meanwhile, since the current dataset is quite different from ImageNet, the empty images are quite helpful in fine-tuning your encoder on a pseudo task - ship detection. Moreover, when the training of your U-net or SSD model is completed, you can run the model on images without ships, add false positives (~4000 in my case) as negative example to you training set, and train the model for several additional epochs. Finally, a good model focused on a single task, ship detection, can boost the final score when you stack up it with U-net or SSD. If you predict a ship for an empty image you will get automatically zero score for it, and since PLB has ~85% of empty images, prediction of empty images is quite important. In this notebook I want to share how to pretrain Resnet34 (or higher end models) on a ship detection task. After training of the head layers of the model on 256x256 rescaled images for one epoch the accuracy has reached 93.7%. The following fine-tuning of entire model for 2 more epochs with learning rate annealing boosted the accuracy to ~97%. If the training is continued for several epochs with a new data set composed of images of 384x384 resolution, the accuracy could be boosted to ~98%. Unfortunately, continuing training the model on full resolution, 768x768, images leaded to reduction of the accuracy that is likely attributed to insufficient model capacity.", "link": "https://www.kaggle.com/iafoss/fine-tuning-resnet34-on-ship-detection", "tags": ["DL", "Classification", "Classification", "CNN"], "kind": ["Project", "(Notebook)"], "ml_libs": ["sklearn", "pytorch"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2018-08-26 17:35:11", "date_scraped": "2020-12-12 16:28:05", "words": 375, "sentences": 15, "sum_nltk": "In this competition the size of ship masks is much smaller than the size of images that leads to quite unbalanced training with ~1 positive pixel per 1000 negative ones.\nMeanwhile, since the current dataset is quite different from ImageNet, the empty images are quite helpful in fine-tuning your encoder on a pseudo task - ship detection.\nMoreover, when the training of your U-net or SSD model is completed, you can run the model on images without ships, add false positives (~4000 in my case) as negative example to you training set, and train the model for several additional epochs.\nFinally, a good model focused on a single task, ship detection, can boost the final score when you stack up it with U-net or SSD.\nAfter training of the head layers of the model on 256x256 rescaled images for one epoch the accuracy has reached 93.7%.\nThe following fine-tuning of entire model for 2 more epochs with learning rate annealing boosted the accuracy to ~97%.\nIf the training is continued for several epochs with a new data set composed of images of 384x384 resolution, the accuracy could be boosted to ~98%.", "sum_nltk_words": 185, "sum_nltk_runtime": 0.004, "sum_t5": "overviewResnet34 is commonly used as an encoder for U-net and SSD. it boosts the model performance and training time since you do not need to train the model from scratch. however, in particular it makes sense to do fine-tuning of Resnet34 model before using it as a decoder for object localization or image segmentation. empty images are quite helpful in fine-tuning your encoder on a pseudo task - ship detection.", "sum_t5_words": 70, "sum_t5_runtime": 6.512, "runtime": 0.01, "nltk_category": "Utilities", "nltk_category_score": 0.5824726223945618, "nltk_category_runtime": 16.792, "nltk_subcategory": "Machine Learning", "nltk_subcategory_score": 0.9616758823394775, "nltk_subcategory_runtime": 26.518, "category": "Utilities", "category_score": 0.5824726223945618, "subcategory": "Machine Learning", "subcategory_score": 0.9616758823394775, "runtime_cat": 43.31, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.772", "language_code": "en", "language_score": "0.9999952175704638", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "overviewresnet34 commonly used encoder unet ssd boosting model performance training time since need train model scratch however particular case make sense finetuning resnet34 model using decoder object localization image segmentation competition size ship mask much smaller size image lead quite unbalanced training 1 positive pixel per 1000 negative one image ship used instead 11000 end 110000 unbalance quite tough moreover training time 4 time longer since need process image epoch reasonable drop empty image focus one ship meanwhile since current dataset quite different imagenet empty image quite helpful finetuning encoder pseudo task ship detection moreover training unet ssd model completed run model image without ship add false positive 4000 case negative example training set train model several additional epoch finally good model focused single task ship detection boost final score stack unet ssd predict ship empty image get automatically zero score since plb 85 empty image prediction empty image quite important notebook want share pretrain resnet34 higher end model ship detection task training head layer model 256x256 rescaled image one epoch accuracy reached 937 following finetuning entire model 2 epoch learning rate annealing boosted accuracy 97 training continued several epoch new data set composed image 384x384 resolution accuracy could boosted 98 unfortunately continuing training model full resolution 768x768 image leaded reduction accuracy likely attributed insufficient model capacity", "tags_descriptive": ["Deep Learning (DL)", "Classification", "Classification", "Convolutional Neural Network (CNN)"]}