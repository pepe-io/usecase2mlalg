{"title": "Pytorch/XLA for TPU with multiprocessing", "description": "Using all 8 cores of a v3 TPU using pytorch/XLA", "link": "https://www.kaggle.com/dhananjay3/pytorch-xla-for-tpu-with-multiprocessing", "tags": [], "kind": ["Project", "(Notebook)"], "ml_libs": ["pytorch", "tensorflow", "spacy"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2020-03-05 04:25:54", "date_scraped": "2020-12-12 19:56:26", "words": 10, "sentences": 1, "runtime": 0.001, "description_category": "Media & Publishing", "description_category_score": 0.28363022208213806, "description_category_runtime": 2.702, "description_subcategory": "Quality", "description_subcategory_score": 0.5685349702835083, "description_subcategory_runtime": 4.013, "category": "Media & Publishing", "category_score": 0.28363022208213806, "subcategory": "Quality", "subcategory_score": 0.5685349702835083, "runtime_cat": 6.715, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.691", "language_code": "en", "language_score": "0.9999976541296809", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "using 8 core v3 tpu using pytorchxla", "tags_descriptive": []}