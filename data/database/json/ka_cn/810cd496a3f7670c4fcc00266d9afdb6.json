{"title": "Google QUEST: First data introduction", "description": "Google QUEST Q&A LabelingImproving automated understanding of complex question answer content Computers are really good at answering questions with single, verifiable answers. But, humans are often still better at answering questions about opinions, recommendations, or personal experiences. ... In this competition, you\u2019re challenged to use this new dataset to build predictive algorithms for different subjective aspects of question-answering.   The competition is Notebook-only competition. Your Notebook will re-run automatically against an unseen test set. This competition data is small, only made of 6079 rows of train dataset. So I think this competition is easy for beginners to participate in terms of computational resource (unless you use BERT or any other heavy models to get good score), compared to the past competition hosted by Google like Open Image Challenges which requires a lot of GPU resources to train the model.", "link": "https://www.kaggle.com/corochann/google-quest-first-data-introduction", "tags": ["Exploratory Data Analysis", "Feature Engineering"], "kind": ["Project", "(Notebook)"], "ml_libs": ["xgboost", "lightgbm", "sklearn", "pattern", "catboost"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2019-11-23 10:54:07", "date_scraped": "2020-12-12 20:20:08", "words": 140, "sentences": 8, "runtime": 0.003, "description_category": "Education & Research", "description_category_score": 0.21904586255550385, "description_category_runtime": 12.566, "description_subcategory": "Machine Learning", "description_subcategory_score": 0.5108122825622559, "description_subcategory_runtime": 19.992, "category": "Education & Research", "category_score": 0.21904586255550385, "subcategory": "Machine Learning", "subcategory_score": 0.5108122825622559, "runtime_cat": 32.558, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.702", "language_code": "en", "language_score": "0.9999964740811075", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "google quest qa labelingimproving automated understanding complex question answer content computer really good answering question single verifiable answer human often still better answering question opinion recommendation personal experience competition youre challenged use new dataset build predictive algorithm different subjective aspect questionanswering competition notebookonly competition notebook rerun automatically unseen test set competition data small made 6079 row train dataset think competition easy beginner participate term computational resource unless use bert heavy model get good score compared past competition hosted google like open image challenge requires lot gpu resource train model", "tags_descriptive": ["Exploratory Data Analysis", "Feature Engineering"]}