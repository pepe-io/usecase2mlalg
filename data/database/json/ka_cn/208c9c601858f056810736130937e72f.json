{"title": "Deep Learning For NLP: Zero To Transformers & BERT", "description": "About this NotebookNLP is a very hot topic right now and as belived by many experts '2020 is going to be NLP's Year' ,with its ever changing dynamics it is experiencing a boom , same as computer vision once did. Owing to its popularity Kaggle launched two NLP competitions recently and me being a lover of this Hot topic prepared myself to join in my first Kaggle Competition. As I joined the competitions and since I was a complete beginner with Deep Learning Techniques for NLP, all my enthusiasm took a beating when I saw everyone Using all  kinds of BERT , everything just went over my head,I thought to quit but there is a special thing about Kaggle ,it just hooks you. I thought I have to learn someday , why not now , so I braced myself and sat on the learning curve. I wrote a kernel on the Tweet Sentiment Extraction competition that has now got a gold medal , it can be viewed here : https://www.kaggle.com/tanulsingh077/twitter-sentiment-extaction-analysis-eda-and-model  After 10 days of extensive learning(finishing all the latest NLP approaches) , I am back here to share my leaning , by writing a kernel that starts from the very Basic RNN's to built over , all the way to BERT . I invite you all to come and learn alongside with me and take a step closer towards becoming an NLP expert", "link": "https://www.kaggle.com/tanulsingh077/deep-learning-for-nlp-zero-to-transformers-bert", "tags": ["DL", "NLP", "Transfer Learning"], "kind": ["Project", "(Notebook)"], "ml_libs": ["keras", "tensorflow", "sklearn", "vocabulary", "pytorch"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2020-04-13 19:19:47", "date_scraped": "2020-12-13 12:15:35", "words": 235, "sentences": 6, "sum_nltk": "About this NotebookNLP is a very hot topic right now and as belived by many experts '2020 is going to be NLP's Year' ,with its ever changing dynamics it is experiencing a boom , same as computer vision once did.\nOwing to its popularity Kaggle launched two NLP competitions recently and me being a lover of this Hot topic prepared myself to join in my first Kaggle Competition.\nAs I joined the competitions and since I was a complete beginner with Deep Learning Techniques for NLP, all my enthusiasm took a beating when I saw everyone Using all  kinds of BERT , everything just went over my head,I thought to quit but there is a special thing about Kaggle ,it just hooks you.\nI wrote a kernel on the Tweet Sentiment Extraction competition that has now got a gold medal , it can be viewed here : https://www.kaggle.com/tanulsingh077/twitter-sentiment-extaction-analysis-eda-and-model  After 10 days of extensive learning(finishing all the latest NLP approaches) , I am back here to share my leaning , by writing a kernel that starts from the very Basic RNN's to built over , all the way to BERT .\nI invite you all to come and learn alongside with me and take a step closer towards becoming an NLP expert", "sum_nltk_words": 209, "sum_nltk_runtime": 0.002, "sum_t5": "Kaggle launched two competitions for NLP enthusiasts. notebookNLP is a hot topic right now and is experiencing a boom. i wrote a kernel on the tweet-sentiment-extaction analysis competition that has now got a gold medal. i invite you all to come and learn alongside me. i am a complete beginner with deep learning techniques for NLP. i am a nl expert and have been a mentor to many.", "sum_t5_words": 68, "sum_t5_runtime": 5.958, "runtime": 0.0, "nltk_category": "Education & Research", "nltk_category_score": 0.06477759033441544, "nltk_category_runtime": 19.537, "nltk_subcategory": "Student", "nltk_subcategory_score": 0.530832827091217, "nltk_subcategory_runtime": 31.101, "category": "Education & Research", "category_score": 0.06477759033441544, "subcategory": "Student", "subcategory_score": 0.530832827091217, "runtime_cat": 50.64, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.782", "language_code": "en", "language_score": "0.9999962942040694", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "notebooknlp hot topic right belived many expert 2020 going nlp year ever changing dynamic experiencing boom computer vision owing popularity kaggle launched two nlp competition recently lover hot topic prepared join first kaggle competition joined competition since complete beginner deep learning technique nlp enthusiasm took beating saw everyone using kind bert everything went headi thought quit special thing kaggle hook thought learn someday braced sat learning curve wrote kernel tweet sentiment extraction competition got gold medal viewed httpswwwkagglecomtanulsingh077twittersentimentextactionanalysisedaandmodel 10 day extensive learningfinishing latest nlp approach back share leaning writing kernel start basic rnns built way bert invite come learn alongside take step closer towards becoming nlp expert", "tags_descriptive": ["Deep Learning (DL)", "Natural Language Processing (NLP)", "Transfer Learning"]}