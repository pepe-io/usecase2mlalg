{"title": "[fastai v1] Densenet169", "description": "This model is based on fastai 0.7 because thats what we get in kaggle, as soon as pytorch v1 is released and the kernels are updated I'll adjust for the changes I guess. For now I only did standard stuff and used the new suggested learning rate methods of the 1 cycle learning policy as described here:  blog post by Sylvain Gugger summarizing the following papers original papers by leslie smith on hyperparameter tuning   and Superconvergence, the 1 cycle policy learning  Next things I planned would be to properly crop the images so it only includes the 32x32 sized patch that is the important part of the image, and check the augmentation settings. I already set up some functionality to use hyperopt to optimiize the hyperparameters of the one cycle parameters, this will come in another kernel. I also still need to check how many augmentation in the TTA  as used here I would also like check how the accuracy (or in this case ROC-AUC) changes with the different resnet18/34/50", "link": "https://www.kaggle.com/guntherthepenguin/fastai-v1-densenet169", "tags": [], "kind": ["Project", "(Notebook)"], "ml_libs": ["sklearn", "pytorch"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2019-01-27 14:07:08", "date_scraped": "2020-12-12 20:43:30", "words": 175, "sentences": 4, "runtime": 0.005, "description_category": "Media & Publishing", "description_category_score": 0.15905539691448212, "description_category_runtime": 15.765, "description_subcategory": "Machine Learning", "description_subcategory_score": 0.9300199747085571, "description_subcategory_runtime": 24.971, "category": "Media & Publishing", "category_score": 0.15905539691448212, "subcategory": "Machine Learning", "subcategory_score": 0.9300199747085571, "runtime_cat": 40.737, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.725", "language_code": "en", "language_score": "0.9999984356447831", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "model based fastai 07 thats get kaggle soon pytorch v1 released kernel updated ill adjust change guess standard stuff used new suggested learning rate method 1 cycle learning policy described blog post sylvain gugger summarizing following paper original paper leslie smith hyperparameter tuning superconvergence 1 cycle policy learning next thing planned would properly crop image includes 32x32 sized patch important part image check augmentation setting already set functionality use hyperopt optimiize hyperparameters one cycle parameter come another kernel also still need check many augmentation tta used would also like check accuracy case rocauc change different resnet183450", "tags_descriptive": []}