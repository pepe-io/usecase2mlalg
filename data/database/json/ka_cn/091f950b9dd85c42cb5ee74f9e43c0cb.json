{"title": "Preliminary Data Analysis Using Word2Vec", "description": "A simple anaysis of the dataset using nltk and Word2VecThis notebook goes over the dataset in the following order:  Read the data into a dataframe using pandas library. Cleaning unnecessary data (unique or null columns). Analyzing data distributions. Analyzing text data via keywords and summarization. Tokenizing (Lemmatization and stopwording) for further analysis. Analyzing word distributions for any surface correlations. Creating a word cloud of the whole text. Using Word2Vec to check the correlation between text and the classes.   Disclaimer: I couldn't find a way to upload the trained word2vec weight vectors to kaggle kernel, so I just attached the results as markdown. More thorough version can be found on my github. This kernel has been tested with python 3.6 (x64) on Windows.", "link": "https://www.kaggle.com/umutto/preliminary-data-analysis-using-word2vec", "tags": [], "kind": ["Project", "(Notebook)"], "ml_libs": ["sklearn", "nltk", "gensim"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2017-09-13 07:40:47", "date_scraped": "2020-12-13 14:17:31", "words": 125, "sentences": 11, "runtime": 0.002, "description_category": "Justice, Law and Regulations", "description_category_score": 0.1982523649930954, "description_category_runtime": 12.791, "description_subcategory": "Textual Analysis", "description_subcategory_score": 0.5198374390602112, "description_subcategory_runtime": 19.713, "category": "Justice, Law and Regulations", "category_score": 0.1982523649930954, "subcategory": "Textual Analysis", "subcategory_score": 0.5198374390602112, "runtime_cat": 32.504, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.737", "language_code": "en", "language_score": "0.9999989824660347", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "simple anaysis dataset using nltk word2vecthis notebook go dataset following order read data dataframe using panda library cleaning unnecessary data unique null column analyzing data distribution analyzing text data via keywords summarization tokenizing lemmatization stopwording analysis analyzing word distribution surface correlation creating word cloud whole text using word2vec check correlation text class disclaimer couldnt find way upload trained word2vec weight vector kaggle kernel attached result markdown thorough version found github kernel tested python 36 x64 window", "tags_descriptive": []}