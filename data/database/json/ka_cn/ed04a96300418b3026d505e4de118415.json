{"title": "Feature Selection with Null Importances", "description": "Feature selecture using target permutationThe notebook uses a procedure described in this article. Feature selection process using target permutation tests actual importance significance against the distribution of feature importances when fitted to noise (shuffled target). The notebook implements the following steps  :  Create the null importances distributions : these are created fitting the model over several runs on a shuffled version of the target. This shows how the model can make sense of a feature irrespective of the target. Fit the model on the original target and gather the feature importances. This gives us a benchmark whose significance can be tested against the Null Importances Distribution for each feature test the actual importance: Compute the probabability of the actual importance wrt the null distribution. I will use a very simple estimation using occurences while the article proposes to fit known distribution to the gathered data. In fact here I'll compute 1 - the proba so that things are in the right order. Simply compare the actual importance to the mean and max of the null importances. This will give sort of a feature importance that allows to see major features in the dataset. Indeed the previous method may give us lots of ones.    For processing time reasons, the notebook will only cover application_train.csv but you can extend it as you wish.", "link": "https://www.kaggle.com/ogrellier/feature-selection-with-null-importances", "tags": [], "kind": ["Project", "(Notebook)"], "ml_libs": ["sklearn", "lightgbm"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2018-06-14 08:44:05", "date_scraped": "2020-12-12 20:47:32", "words": 226, "sentences": 12, "sum_nltk": "Feature selecture using target permutationThe notebook uses a procedure described in this article.\nFeature selection process using target permutation tests actual importance significance against the distribution of feature importances when fitted to noise (shuffled target).\nThe notebook implements the following steps  :  Create the null importances distributions : these are created fitting the model over several runs on a shuffled version of the target.\nThis shows how the model can make sense of a feature irrespective of the target.\nFit the model on the original target and gather the feature importances.\nThis gives us a benchmark whose significance can be tested against the Null Importances Distribution for each feature test the actual importance: Compute the probabability of the actual importance wrt the null distribution.\nI will use a very simple estimation using occurences while the article proposes to fit known distribution to the gathered data.\nSimply compare the actual importance to the mean and max of the null importances.\nThis will give sort of a feature importance that allows to see major features in the dataset.\nFor processing time reasons, the notebook will only cover application_train.csv but you can extend it as you wish.", "sum_nltk_words": 187, "sum_nltk_runtime": 0.002, "sum_t5": "notebook uses a procedure described in this article. it tests actual importance significance against the distribution of feature importances when fitted to noise (shuffled target) this shows how the model can make sense of a feature irrespective of the target. for processing time reasons, the notebook will only cover application_train.csv but you can extend it as you wish.. if you want to extend the notebook, please contact us at john.mccarthy@gmail.com.", "sum_t5_words": 70, "sum_t5_runtime": 4.928, "runtime": 0.004, "nltk_category": "Utilities", "nltk_category_score": 0.431147038936615, "nltk_category_runtime": 16.481, "nltk_subcategory": "Machine Learning", "nltk_subcategory_score": 0.9003032445907593, "nltk_subcategory_runtime": 26.559, "category": "Utilities", "category_score": 0.431147038936615, "subcategory": "Machine Learning", "subcategory_score": 0.9003032445907593, "runtime_cat": 43.041, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.822", "language_code": "en", "language_score": "0.9999987437773246", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "feature selecture using target permutationthe notebook us procedure described article feature selection process using target permutation test actual importance significance distribution feature importance fitted noise shuffled target notebook implement following step create null importance distribution created fitting model several run shuffled version target show model make sense feature irrespective target fit model original target gather feature importance give u benchmark whose significance tested null importance distribution feature test actual importance compute probabability actual importance wrt null distribution use simple estimation using occurences article proposes fit known distribution gathered data fact ill compute 1 proba thing right order simply compare actual importance mean max null importance give sort feature importance allows see major feature dataset indeed previous method may give u lot one processing time reason notebook cover application_traincsv extend wish", "tags_descriptive": []}