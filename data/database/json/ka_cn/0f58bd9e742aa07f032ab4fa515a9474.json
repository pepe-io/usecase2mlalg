{"title": "Deep Dreaming Dali (Keras DeepDream)", "description": "DeepDream DeepDream uses a convolutional neural network to find and enhance patterns in images via algorithmic pareidolia, thus creating a dream-like hallucinogenic appearance in the deliberately over-processed images (wiki).  In this kernel I will explore DeepDream by using a both an InceptionV3 and a VGG-16 pretrained model in Keras. The choice of your convnet will affect your visualisation, as different architectures result in different learned features. Inception for example has been trained on (amongst others) many images of animals and the use of this convnet in a DeepDream often outputs pictures with a lot of eye-like features. By playing around with the different architectures, I will try to understand more on how they work. Inspiration for this kernel were kernels by Carlo Alberto and by Paul Mooney, which both use PyTorch .  Most of the code is from keras/deepdream found on the github of the Keras Team. I've also used the book Deep Learning with Python by Fran\u00e7ois Chollet, which gives insights on how the DeepDream algorithm (and deep learning in general) works. In the case of DeepDream an arbitrary image is fed to the network and is analyzed. The activation of an layer is maximized and the networks is asked to enhance whatever it detected. Each layer of the network deals with features at a different level of abstraction, so the complexity of features we generate depends on which layer we choose to enhance (source). In short:  Load the original image. Define a number of processing scales (i.e. image shapes), from smallest to largest. Resize the original image to the smallest scale. For every scale, starting with the smallest (i.e. current one): Run gradient ascent Upscale image to the next scale Reinject the detail that was lost at upscaling time   Stop when we are back to the original size.  To obtain the detail lost during upscaling, we simply take the original image, shrink it down, upscale it, and compare the result to the (resized) original image.", "link": "https://www.kaggle.com/bonovandoo/deep-dreaming-dali-keras-deepdream", "tags": [], "kind": ["Project", "(Notebook)"], "ml_libs": ["keras", "tensorflow", "pattern"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2018-11-16 18:22:53", "date_scraped": "2020-12-13 15:04:10", "words": 333, "sentences": 18, "sum_nltk": "DeepDream DeepDream uses a convolutional neural network to find and enhance patterns in images via algorithmic pareidolia, thus creating a dream-like hallucinogenic appearance in the deliberately over-processed images (wiki).\nInception for example has been trained on (amongst others) many images of animals and the use of this convnet in a DeepDream often outputs pictures with a lot of eye-like features.\nIn the case of DeepDream an arbitrary image is fed to the network and is analyzed.\nEach layer of the network deals with features at a different level of abstraction, so the complexity of features we generate depends on which layer we choose to enhance (source).\nDefine a number of processing scales (i.e. image shapes), from smallest to largest.\nResize the original image to the smallest scale.\nFor every scale, starting with the smallest (i.e. current one): Run gradient ascent Upscale image to the next scale Reinject the detail that was lost at upscaling time   Stop when we are back to the original size.\nTo obtain the detail lost during upscaling, we simply take the original image, shrink it down, upscale it, and compare the result to the (resized) original image.", "sum_nltk_words": 186, "sum_nltk_runtime": 0.003, "sum_t5": "deepdream uses a convolutional neural network to find and enhance patterns in images via algorithmic pareidolia. the choice of your convnet will affect your visualisation, as different architectures result in different learned features. most of the code is from keras/deepdream found on the github of the Keras Team. inspiration for this kernel were kernels by Carlo Alberto and by Paul Mooney, which both use PyTorch.", "sum_t5_words": 65, "sum_t5_runtime": 6.476, "runtime": 0.005, "nltk_category": "Utilities", "nltk_category_score": 0.3859062194824219, "nltk_category_runtime": 17.975, "nltk_subcategory": "Machine Learning", "nltk_subcategory_score": 0.9185625314712524, "nltk_subcategory_runtime": 28.839, "category": "Utilities", "category_score": 0.3859062194824219, "subcategory": "Machine Learning", "subcategory_score": 0.9185625314712524, "runtime_cat": 46.814, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.716", "language_code": "en", "language_score": "0.9999964483620086", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "deepdream deepdream us convolutional neural network find enhance pattern image via algorithmic pareidolia thus creating dreamlike hallucinogenic appearance deliberately overprocessed image wiki kernel explore deepdream using inceptionv3 vgg16 pretrained model kera choice convnet affect visualisation different architecture result different learned feature inception example trained amongst others many image animal use convnet deepdream often output picture lot eyelike feature playing around different architecture try understand work inspiration kernel kernel carlo alberto paul mooney use pytorch code kerasdeepdream found github kera team ive also used book deep learning python francois chollet give insight deepdream algorithm deep learning general work case deepdream arbitrary image fed network analyzed activation layer maximized network asked enhance whatever detected layer network deal feature different level abstraction complexity feature generate depends layer choose enhance source short load original image define number processing scale ie image shape smallest largest resize original image smallest scale every scale starting smallest ie current one run gradient ascent upscale image next scale reinject detail lost upscaling time stop back original size obtain detail lost upscaling simply take original image shrink upscale compare result resized original image", "tags_descriptive": []}