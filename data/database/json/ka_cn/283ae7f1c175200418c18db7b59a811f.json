{"title": "FAT2019 2d-cnn with mixup, LB 0.634", "description": "Fork from mhiro, https://www.kaggle.com/mhiro2/simple-2d-cnn-classifier-with-pytorch . Single model resnet18 with curated subset, to get the LB 0.634. commit V4 is for model training and commit V5 is for prediction and submission. Added:  Predefined NNs such as resnet18, resnet 34, alexnet, vgg; Data augmentation mixup() added for the train data; Optimizers, lr schedules (CyclicLR, ReduceLROnPlateau, CosineAnnealingLR) can be selected; loss function weighted_BCEWithLogits added;  Model change can increase the lb to 0.65+. Feel free to check the code, setup and discuss here. My confusion: Several guys report local lwlrap around 0.86 with LB around 0.7. https://www.kaggle.com/c/freesound-audio-tagging-2019/discussion/91881#latest-535068 However for mine: With resnet18, local lwlrap is about 0.7324, while LB is 0.634. While with a self private model, almost same train setup, add \"k-fold averaging\", LB can be 0.7+ with local lwlrap around 0.76.", "link": "https://www.kaggle.com/sailorwei/fat2019-2d-cnn-with-mixup-lb-0-673", "tags": [], "kind": ["Project", "(Notebook)"], "ml_libs": ["sklearn", "pytorch"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2019-05-25 00:56:55", "date_scraped": "2020-12-12 20:05:18", "words": 131, "sentences": 8, "runtime": 0.0, "description_category": "Wholesale & Retail", "description_category_score": 0.12187816947698593, "description_category_runtime": 19.847, "description_subcategory": "Machine Learning", "description_subcategory_score": 0.9423638582229614, "description_subcategory_runtime": 32.154, "category": "Wholesale & Retail", "category_score": 0.12187816947698593, "subcategory": "Machine Learning", "subcategory_score": 0.9423638582229614, "runtime_cat": 52.003, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.69", "language_code": "en", "language_score": "0.9999973610410939", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "fork mhiro httpswwwkagglecommhiro2simple2dcnnclassifierwithpytorch single model resnet18 curated subset get lb 0634 commit v4 model training commit v5 prediction submission added predefined nns resnet18 resnet 34 alexnet vgg data augmentation mixup added train data optimizers lr schedule cycliclr reducelronplateau cosineannealinglr selected loss function weighted_bcewithlogits added model change increase lb 065 feel free check code setup discus confusion several guy report local lwlrap around 086 lb around 07 httpswwwkagglecomcfreesoundaudiotagging2019discussion91881latest535068 however mine resnet18 local lwlrap 07324 lb 0634 self private model almost train setup add kfold averaging lb 07 local lwlrap around 076", "tags_descriptive": []}