{"title": "CNN Architectures : VGG, ResNet, Inception + TL", "description": "CNN Architectures : VGG, Resnet, InceptionNet, XceptionNetUseCases : Image Feature Extraction + Transfer Learning A Gold mine dataset for comuter vision is the ImageNet dataset. It consists of about 14 M hand-labelled annotated images which contains over 22,000 day-to-day categories. Every year ImageNet competition is hosted in which the smaller version of this dataset (with 1000 categories) is used with an aim to accurately classify the images. Many winning solutions of the ImageNet Challenge have used state of the art convolutional neural network architectures to beat the best possible accuracy thresholds. In this kernel, I have discussed these popular architectures such as VGG16, 19, ResNet, AlexNet etc. In the end, I have explained how to generate image features using pretrained models and use them in machine learning models. Contents From the high level perspective, I have discussed three main components  1. CNN Architectures     1. 1 VGG16 1.2 VGG19  1.3 InceptionNet 1.4 Resnet  1.5 XceptionNet  2. Image Feature Extraction   3. Transfer Learning   1. CNN Architectures1.1 \u00a0\u00a0 VGG16 VGG16 was publised in 2014 and is one of the simplest (among the other cnn architectures used in Imagenet competition). It's Key Characteristics are:  This network contains total 16 layers in which weights and bias parameters are learnt.     A total of 13 convolutional layers are stacked one after the other and 3 dense layers for classification.      The number of filters in the convolution layers follow an increasing pattern (similar to decoder architecture of autoencoder).      The informative features are obtained by max pooling layers applied at different steps in the architecture.     The dense layers comprises of 4096, 4096, and 1000 nodes each.    The cons of this architecture are that it is slow to train and produces the model with very large size.     The VGG16 architecture is given below:  Implementation : VGG16Let's see how we can create this architecture using python's keras library. The following code block shows the implementation of VGG16 in keras.", "link": "https://www.kaggle.com/shivamb/cnn-architectures-vgg-resnet-inception-tl", "tags": ["DL", "CNN"], "kind": ["Project", "(Notebook)"], "ml_libs": ["sklearn", "keras", "pattern"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2018-10-29 11:56:17", "date_scraped": "2020-12-12 18:58:25", "words": 357, "sentences": 20, "sum_nltk": "CNN Architectures : VGG, Resnet, InceptionNet, XceptionNetUseCases : Image Feature Extraction + Transfer Learning A Gold mine dataset for comuter vision is the ImageNet dataset.\nEvery year ImageNet competition is hosted in which the smaller version of this dataset (with 1000 categories) is used with an aim to accurately classify the images.\nMany winning solutions of the ImageNet Challenge have used state of the art convolutional neural network architectures to beat the best possible accuracy thresholds.\nIn this kernel, I have discussed these popular architectures such as VGG16, 19, ResNet, AlexNet etc.\nIn the end, I have explained how to generate image features using pretrained models and use them in machine learning models.\nImage Feature Extraction   3.\nCNN Architectures1.1 \u00a0\u00a0 VGG16 VGG16 was publised in 2014 and is one of the simplest (among the other cnn architectures used in Imagenet competition).\nIt's Key Characteristics are:  This network contains total 16 layers in which weights and bias parameters are learnt.\nThe number of filters in the convolution layers follow an increasing pattern (similar to decoder architecture of autoencoder).\nThe informative features are obtained by max pooling layers applied at different steps in the architecture.\nThe following code block shows the implementation of VGG16 in keras.", "sum_nltk_words": 197, "sum_nltk_runtime": 0.004, "sum_t5": "imagenet dataset contains over 22,000 day-to-day categories. each year ImageNet competition is hosted in which the smaller version of this dataset is used. many winning solutions of the ImageNet Challenge have used state of the art convolutional neural network architectures. cnn's john sutter discusses popular architectures such as VGG16, 19, ResNet, XceptionNet etc.. sutter: \"the imagenet dataset is a gold mine for comuter vision\"", "sum_t5_words": 64, "sum_t5_runtime": 6.706, "runtime": 0.003, "nltk_category": "Government and Public Works", "nltk_category_score": 0.37117859721183777, "nltk_category_runtime": 19.687, "nltk_subcategory": "Machine Learning", "nltk_subcategory_score": 0.7460162043571472, "nltk_subcategory_runtime": 31.942, "category": "Government and Public Works", "category_score": 0.37117859721183777, "subcategory": "Machine Learning", "subcategory_score": 0.7460162043571472, "runtime_cat": 51.629, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.814", "language_code": "en", "language_score": "0.9999961268047692", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "cnn architecture vgg resnet inceptionnet xceptionnetusecases image feature extraction transfer learning gold mine dataset comuter vision imagenet dataset consists 14 handlabelled annotated image contains 22000 daytoday category every year imagenet competition hosted smaller version dataset 1000 category used aim accurately classify image many winning solution imagenet challenge used state art convolutional neural network architecture beat best possible accuracy threshold kernel discussed popular architecture vgg16 19 resnet alexnet etc end explained generate image feature using pretrained model use machine learning model content high level perspective discussed three main component 1 cnn architecture 1 1 vgg16 12 vgg19 13 inceptionnet 14 resnet 15 xceptionnet 2 image feature extraction 3 transfer learning 1 cnn architectures11 vgg16 vgg16 publised 2014 one simplest among cnn architecture used imagenet competition key characteristic network contains total 16 layer weight bias parameter learnt total 13 convolutional layer stacked one 3 dense layer classification number filter convolution layer follow increasing pattern similar decoder architecture autoencoder informative feature obtained max pooling layer applied different step architecture dense layer comprises 4096 4096 1000 node con architecture slow train produce model large size vgg16 architecture given implementation vgg16lets see create architecture using python kera library following code block show implementation vgg16 kera", "tags_descriptive": ["Deep Learning (DL)", "Convolutional Neural Network (CNN)"]}