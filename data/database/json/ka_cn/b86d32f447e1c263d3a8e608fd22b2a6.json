{"title": "Hyperparameter Grid Search with XGBoost", "description": "Here is an example of XGBoost hyperparameter tuning by doing a grid search. For reasons of expediency, the notebook will run only a randomized grid search. However, I will provide a code for brute-force grid search as well - you only need to uncomment that portion if you decide to run this notebook locally. Although random grid search will work most of the time if you test at least 20-50 different parameter combinations, I STRONGLY recommend that you use something like Bayesian optimization for hyperparameter searching as it is more comprehensive and time-efficient. I will try to publish an example of it later.", "link": "https://www.kaggle.com/tilii7/hyperparameter-grid-search-with-xgboost", "tags": [], "kind": ["Project", "(Notebook)"], "ml_libs": ["sklearn", "xgboost"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2017-10-14 00:58:22", "date_scraped": "2020-12-13 15:44:39", "words": 103, "sentences": 5, "runtime": 0.001, "description_category": "Wholesale & Retail", "description_category_score": 0.08558119833469391, "description_category_runtime": 9.662, "description_subcategory": "Tools", "description_subcategory_score": 0.22273795306682587, "description_subcategory_runtime": 14.555, "category": "Wholesale & Retail", "category_score": 0.08558119833469391, "subcategory": "Tools", "subcategory_score": 0.22273795306682587, "runtime_cat": 24.216, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.836", "language_code": "en", "language_score": "0.9999962051948297", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "example xgboost hyperparameter tuning grid search reason expediency notebook run randomized grid search however provide code bruteforce grid search well need uncomment portion decide run notebook locally although random grid search work time test least 2050 different parameter combination strongly recommend use something like bayesian optimization hyperparameter searching comprehensive timeefficient try publish example later", "tags_descriptive": []}