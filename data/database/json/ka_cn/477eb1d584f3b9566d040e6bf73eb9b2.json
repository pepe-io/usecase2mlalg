{"title": "APTOS 2019: DenseNet Keras Starter", "description": "About this kernelIn this kernel, we will explore the complete workflow for the APTOS 2019 competition. We will go through:  Loading & Exploration: A quick overview of the dataset Resize Images: We will resize both the training and test images to 224x224, so that it matches the ImageNet format. Mixup & Data Generator: We show how to create a data generator that will perform random transformation to our datasets (flip vertically/horizontally, rotation, zooming). This will help our model generalize better to the data, since it is fairly small (only ~3000 images). Quadratic Weighted Kappa: A thorough overview of the metric used for this competition, with an intuitive example. Check it out! Model: We will use a DenseNet-121 pre-trained on ImageNet. We will finetune it using Adam for 15 epochs, and evaluate it on an unseen validation set. Training & Evaluation: We take a look at the change in loss and QWK score through the epochs.  Unused MethodsThroughout V15-V18 of this kernel, I ablated a few methods that I presented in this kernel. The highest LB score was achieved after I removed:  Mixup Optimized Threshold  I decided to keep them in the kernel if it ever becomes useful for you. Citations & Resources I had the idea of using mixup from KeepLearning's ResNet50 baseline. Since the implementation was in PyTorch, I instead used an open-sourced keras implementation. The transfer learning procedure is mostly inspired from my previous kernel for iWildCam. The workflow was however heavily modified since then. Used similar method as Abhishek to find the optimal threshold. Lex's kernel prompted me to try using Multilabel instead of multiclass classification, which slightly improved the kappa score.", "link": "https://www.kaggle.com/xhlulu/aptos-2019-densenet-keras-starter", "tags": ["Classification", "Healthcare", "CNN"], "kind": ["Project", "(Notebook)"], "ml_libs": ["sklearn", "keras", "tensorflow"], "host": "kaggle.com", "license": "Apache-2.0", "language": "english", "date_project": "2019-07-26 16:37:02", "date_scraped": "2020-12-12 16:39:24", "words": 279, "sentences": 16, "sum_nltk": "About this kernelIn this kernel, we will explore the complete workflow for the APTOS 2019 competition.\nWe will go through:  Loading & Exploration: A quick overview of the dataset Resize Images: We will resize both the training and test images to 224x224, so that it matches the ImageNet format.\nMixup & Data Generator: We show how to create a data generator that will perform random transformation to our datasets (flip vertically/horizontally, rotation, zooming).\nQuadratic Weighted Kappa: A thorough overview of the metric used for this competition, with an intuitive example.\nModel: We will use a DenseNet-121 pre-trained on ImageNet. We will finetune it using Adam for 15 epochs, and evaluate it on an unseen validation set.\nTraining & Evaluation: We take a look at the change in loss and QWK score through the epochs.\nThe highest LB score was achieved after I removed:  Mixup Optimized Threshold  I decided to keep them in the kernel if it ever becomes useful for you.\nThe transfer learning procedure is mostly inspired from my previous kernel for iWildCam. The workflow was however heavily modified since then.\nUsed similar method as Abhishek to find the optimal threshold.\nLex's kernel prompted me to try using Multilabel instead of multiclass classification, which slightly improved the kappa score.", "sum_nltk_words": 204, "sum_nltk_runtime": 0.004, "sum_t5": "this kernel explores the complete workflow for the APTOS 2019 competition. we will resize both the training and test images to 224x224. we will use a DenseNet-121 pre-trained on ImageNet. we will finetune it using Adam for 15 epochs, and evaluate it on an unseen validation set. the highest LB score was achieved after I removed: Mixup Optimized Threshold.", "sum_t5_words": 59, "sum_t5_runtime": 6.107, "runtime": 0.0, "nltk_category": "Biotechnological & Life Sciences", "nltk_category_score": 0.1386028528213501, "nltk_category_runtime": 20.463, "nltk_subcategory": "Machine Learning", "nltk_subcategory_score": 0.7835044264793396, "nltk_subcategory_runtime": 32.794, "category": "Biotechnological & Life Sciences", "category_score": 0.1386028528213501, "subcategory": "Machine Learning", "subcategory_score": 0.7835044264793396, "runtime_cat": 53.258, "programming_language": "Jupyter Notebook", "ml_score": "1.0", "engagement_score": "0.789", "language_code": "en", "language_score": "0.9999977428769986", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "kernelin kernel explore complete workflow aptos 2019 competition go loading exploration quick overview dataset resize image resize training test image 224x224 match imagenet format mixup data generator show create data generator perform random transformation datasets flip verticallyhorizontally rotation zooming help model generalize better data since fairly small 3000 image quadratic weighted kappa thorough overview metric used competition intuitive example check model use densenet121 pretrained imagenet finetune using adam 15 epoch evaluate unseen validation set training evaluation take look change loss qwk score epoch unused methodsthroughout v15v18 kernel ablated method presented kernel highest lb score achieved removed mixup optimized threshold decided keep kernel ever becomes useful citation resource idea using mixup keeplearnings resnet50 baseline since implementation pytorch instead used opensourced kera implementation transfer learning procedure mostly inspired previous kernel iwildcam workflow however heavily modified since used similar method abhishek find optimal threshold lexs kernel prompted try using multilabel instead multiclass classification slightly improved kappa score", "tags_descriptive": ["Classification", "Healthcare", "Convolutional Neural Network (CNN)"]}