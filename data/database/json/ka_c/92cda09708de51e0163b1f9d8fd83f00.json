{"title": "Don't Overfit! II", "description": "A Fistful of SamplesLong ago, in the distant, fragrant mists of time, there was a competition\u2026 It was not just any competition. It was a competition that challenged mere mortals to model a 20,000x200 matrix of continuous variables using only 250 training samples\u2026 without overfitting. Data scientists \u2015 including Kaggle's very own Will Cukierski \u2015 competed by the hundreds. Legends were made. (Will took 5th place, and eventually ended up working at Kaggle!) People overfit like crazy. It was a Kaggle-y, data science-y madhouse. So\u2026 we're doing it again. Don't Overfit II: The Overfittening This is the next logical step in the evolution of weird competitions. Once again we have 20,000 rows of continuous variables, and a mere handful of training samples. Once again, we challenge you not to overfit. Do your best, model without overfitting, and add, perhaps, to your own legend. In addition to bragging rights, the winner also gets swag.  Enjoy! Acknowledgments We hereby salute the hard work that went into the original competition, created by Phil Brierly. Thank you!", "link": "https://www.kaggle.com/c/dont-overfit-ii", "tags": ["Classification", "Feature Engineering", "Random Forest", "Exploratory Data Analysis", "Model Explainability", "Model Comparison"], "kind": ["Project", "(Competition)", "(Dataset)"], "host": "kaggle.com", "date_project": "2019-05-08 01:59:00", "words": 174, "sentences": 14, "runtime": 0.003, "description_category": "Media & Publishing", "description_category_score": 0.408040314912796, "description_category_runtime": 17.027, "description_subcategory": "Quality", "description_subcategory_score": 0.5372768044471741, "description_subcategory_runtime": 27.104, "category": "Media & Publishing", "category_score": 0.408040314912796, "subcategory": "Quality", "subcategory_score": 0.5372768044471741, "runtime_cat": 44.132, "engagement_score": "0.687", "language_code": "en", "language": "english", "language_score": "0.9999968113660821", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "fistful sampleslong ago distant fragrant mist time competition competition competition challenged mere mortal model 20000x200 matrix continuous variable using 250 training sample without overfitting data scientist including kaggles cukierski competed hundred legend made took 5th place eventually ended working kaggle people overfit like crazy kaggley data sciencey madhouse dont overfit ii overfittening next logical step evolution weird competition 20000 row continuous variable mere handful training sample challenge overfit best model without overfitting add perhaps legend addition bragging right winner also get swag enjoy acknowledgment hereby salute hard work went original competition created phil brierly thank", "tags_descriptive": ["Classification", "Feature Engineering", "Random Forest", "Exploratory Data Analysis", "Model Explainability", "Model Comparison"]}