{"title": "Jigsaw Multilingual Toxic Comment Classification", "description": "Use TPUs to identify toxicity comments across multiple languagesIt only takes one toxic comment to sour an online discussion. The Conversation AI team, a research initiative founded by Jigsaw and Google, builds technology to protect voices in conversation. A main area of focus is machine learning models that can identify toxicity in online conversations, where toxicity is defined as anything rude, disrespectful or otherwise likely to make someone leave a discussion. If these toxic contributions can be identified, we could have a safer, more collaborative internet. In the previous 2018 Toxic Comment Classification Challenge, Kagglers built multi-headed models to recognize toxicity and several subtypes of toxicity. In 2019, in the Unintended Bias in Toxicity Classification Challenge, you worked to build toxicity models that operate fairly across a diverse range of conversations. This year, we're taking advantage of Kaggle's new TPU support and challenging you to build multilingual models with English-only training data. Jigsaw's API, Perspective, serves toxicity models and others in a growing set of languages (see our documentation for the full list). Over the past year, the field has seen impressive multilingual capabilities from the latest model innovations, including few- and zero-shot learning. We're excited to learn whether these results \"translate\" (pun intended!) to toxicity classification. Your training data will be the English data provided for our previous two competitions and your test data will be Wikipedia talk page comments in several different languages.  As our computing resources and modeling capabilities grow, so does our potential to support healthy conversations across the globe. Develop strategies to build effective multilingual models and you'll help Conversation AI and the entire industry realize that potential. Disclaimer: The dataset for this competition contains text that may be considered profane, vulgar, or offensive.  To get started with TPUs:  Read the TPU documentation one-pager Then jump right into the Getting Started Notebooks for this competition  Quick note: a TPU is a network-connected accelerator and requires a couple extra lines in your code. Flipping the TPU switch in your notebook will not, by itself, accelerate your code.", "link": "https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification", "tags": ["NLP", "Transfer Learning"], "kind": ["Project", "(Competition)", "(Dataset)"], "host": "kaggle.com", "date_project": "2020-06-23 01:59:00", "words": 345, "sentences": 16, "sum_nltk": "Use TPUs to identify toxicity comments across multiple languagesIt only takes one toxic comment to sour an online discussion.\nA main area of focus is machine learning models that can identify toxicity in online conversations, where toxicity is defined as anything rude, disrespectful or otherwise likely to make someone leave a discussion.\nIn 2019, in the Unintended Bias in Toxicity Classification Challenge, you worked to build toxicity models that operate fairly across a diverse range of conversations.\nThis year, we're taking advantage of Kaggle's new TPU support and challenging you to build multilingual models with English-only training data.\nYour training data will be the English data provided for our previous two competitions and your test data will be Wikipedia talk page comments in several different languages.\nAs our computing resources and modeling capabilities grow, so does our potential to support healthy conversations across the globe.\nTo get started with TPUs:  Read the TPU documentation one-pager Then jump right into the Getting Started Notebooks for this competition  Quick note: a TPU is a network-connected accelerator and requires a couple extra lines in your code.\nFlipping the TPU switch in your notebook will not, by itself, accelerate your code.", "sum_nltk_words": 192, "sum_nltk_runtime": 0.004, "sum_t5": "the Conversation AI team builds technology to protect voices in conversation. machine learning models can identify toxicity in online conversations. this year, we're challenging you to build multilingual models with English-only training data. develop strategies to build effective multilingual models. a TPU is a network-connected accelerator and requires a couple extra lines in your code. a winner will be announced on november 8. a tpu is a scalable, scalable, and scalable platform", "sum_t5_words": 72, "sum_t5_runtime": 6.807, "runtime": 0.0, "nltk_category": "Media & Publishing", "nltk_category_score": 0.7028095722198486, "nltk_category_runtime": 17.224, "nltk_subcategory": "Machine Learning", "nltk_subcategory_score": 0.8872539401054382, "nltk_subcategory_runtime": 27.278, "category": "Media & Publishing", "category_score": 0.7028095722198486, "subcategory": "Machine Learning", "subcategory_score": 0.8872539401054382, "runtime_cat": 44.501, "engagement_score": "0.67", "language_code": "en", "language": "english", "language_score": "0.9999956743530904", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "use tpus identify toxicity comment across multiple languagesit take one toxic comment sour online discussion conversation ai team research initiative founded jigsaw google build technology protect voice conversation main area focus machine learning model identify toxicity online conversation toxicity defined anything rude disrespectful otherwise likely make someone leave discussion toxic contribution identified could safer collaborative internet previous 2018 toxic comment classification challenge kagglers built multiheaded model recognize toxicity several subtypes toxicity 2019 unintended bias toxicity classification challenge worked build toxicity model operate fairly across diverse range conversation year taking advantage kaggles new tpu support challenging build multilingual model englishonly training data jigsaw api perspective serf toxicity model others growing set language see documentation full list past year field seen impressive multilingual capability latest model innovation including zeroshot learning excited learn whether result translate pun intended toxicity classification training data english data provided previous two competition test data wikipedia talk page comment several different language computing resource modeling capability grow potential support healthy conversation across globe develop strategy build effective multilingual model youll help conversation ai entire industry realize potential disclaimer dataset competition contains text may considered profane vulgar offensive get started tpus read tpu documentation onepager jump right getting started notebook competition quick note tpu networkconnected accelerator requires couple extra line code flipping tpu switch notebook accelerate code", "tags_descriptive": ["Natural Language Processing (NLP)", "Transfer Learning"]}