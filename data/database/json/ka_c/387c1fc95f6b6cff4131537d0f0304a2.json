{"title": "Freesound Audio Tagging 2019", "description": "Automatically recognize sounds and apply tags of varying naturesOne year ago, Freesound and Google\u2019s Machine Perception hosted an audio tagging competition challenging Kagglers to build a general-purpose auto tagging system. This year they\u2019re back and taking the challenge to the next level with multi-label audio tagging, doubled number of audio categories, and a noisier than ever training set. If you like raising your ML game, this challenge is for you.  Here's the background: Some sounds are distinct and instantly recognizable, like a baby\u2019s laugh or the strum of a guitar. Other sounds are difficult to pinpoint. If you close your eyes, could you tell the difference between the sound of a chainsaw and the sound of a blender? Because of the vastness of sounds we experience, no reliable automatic general-purpose audio tagging systems exist. A significant amount of manual effort goes into tasks like annotating sound collections and providing captions for non-speech events in audiovisual content. To tackle this problem, Freesound (an initiative by MTG-UPF that maintains a collaborative database with over 400,000 Creative Commons Licensed sounds) and Google Research\u2019s Machine Perception Team  (creators of AudioSet, a large-scale dataset of manually annotated audio events with over 500 classes) have teamed up to develop the dataset for this new competition. To win this competition, Kagglers will develop an algorithm to tag audio data automatically using a diverse vocabulary of 80 categories. If successful, your systems could be used for several applications, ranging from automatic labelling of sound collections to the development of systems that automatically tag video content or recognize sound events happening in real time. Ready to raise your game? Join the competition! Note, this competition is similar in nature to this competition  with a new dataset, and multi-class labels.  Organizers  Eduardo Fonseca, MTG-UPF, Barcelona Manoj Plakal, Google's Sound Understanding, New York Frederic Font, MTG-UPF, Barcelona Dan Ellis, Google's Sound Understanding, New York   This is a Kernels-only competition. Refer to Kernels Requirements for details.", "link": "https://www.kaggle.com/c/freesound-audio-tagging-2019", "tags": ["DL", "Classification", "LSTM", "CNN"], "kind": ["Project", "(Competition)", "(Dataset)"], "host": "kaggle.com", "date_project": "2019-06-18 00:22:00", "words": 331, "sentences": 13, "sum_nltk": "Automatically recognize sounds and apply tags of varying naturesOne year ago, Freesound and Google\u2019s Machine Perception hosted an audio tagging competition challenging Kagglers to build a general-purpose auto tagging system.\nThis year they\u2019re back and taking the challenge to the next level with multi-label audio tagging, doubled number of audio categories, and a noisier than ever training set.\nIf you like raising your ML game, this challenge is for you.\nBecause of the vastness of sounds we experience, no reliable automatic general-purpose audio tagging systems exist.\nTo tackle this problem, Freesound (an initiative by MTG-UPF that maintains a collaborative database with over 400,000 Creative Commons Licensed sounds) and Google Research\u2019s Machine Perception Team  (creators of AudioSet, a large-scale dataset of manually annotated audio events with over 500 classes) have teamed up to develop the dataset for this new competition.\nTo win this competition, Kagglers will develop an algorithm to tag audio data automatically using a diverse vocabulary of 80 categories.\nIf successful, your systems could be used for several applications, ranging from automatic labelling of sound collections to the development of systems that automatically tag video content or recognize sound events happening in real time.", "sum_nltk_words": 190, "sum_nltk_runtime": 0.004, "sum_t5": "freesound and google\u2019s machine perception hosted an audio tagging competition last year. this year they\u2019re taking the challenge to the next level with multi-label audio tagging, doubled number of audio categories, and a noisier than ever training set. to win this competition, Kagglers will develop an algorithm to tag audio data automatically using a diverse vocabulary of 80 categories. if successful, your systems could be used for several applications, ranging from automatic labelling of sound collections to the", "sum_t5_words": 78, "sum_t5_runtime": 6.9, "runtime": 0.004, "nltk_category": "Education & Research", "nltk_category_score": 0.4888857901096344, "nltk_category_runtime": 18.509, "nltk_subcategory": "Machine Learning", "nltk_subcategory_score": 0.9447815418243408, "nltk_subcategory_runtime": 29.813, "category": "Education & Research", "category_score": 0.4888857901096344, "subcategory": "Machine Learning", "subcategory_score": 0.9447815418243408, "runtime_cat": 48.323, "engagement_score": "0.638", "language_code": "en", "language": "english", "language_score": "0.9999965488608471", "learn_score": 1, "explore_score": 0, "compete_score": 0, "description_lemmatized": "automatically recognize sound apply tag varying naturesone year ago freesound google machine perception hosted audio tagging competition challenging kagglers build generalpurpose auto tagging system year theyre back taking challenge next level multilabel audio tagging doubled number audio category noisier ever training set like raising ml game challenge here background sound distinct instantly recognizable like baby laugh strum guitar sound difficult pinpoint close eye could tell difference sound chainsaw sound blender vastness sound experience reliable automatic generalpurpose audio tagging system exist significant amount manual effort go task like annotating sound collection providing caption nonspeech event audiovisual content tackle problem freesound initiative mtgupf maintains collaborative database 400000 creative common licensed sound google research machine perception team creator audioset largescale dataset manually annotated audio event 500 class teamed develop dataset new competition win competition kagglers develop algorithm tag audio data automatically using diverse vocabulary 80 category successful system could used several application ranging automatic labelling sound collection development system automatically tag video content recognize sound event happening real time ready raise game join competition note competition similar nature competition new dataset multiclass label organizer eduardo fonseca mtgupf barcelona manoj plakal google sound understanding new york frederic font mtgupf barcelona dan elli google sound understanding new york kernelsonly competition refer kernel requirement detail", "tags_descriptive": ["Deep Learning (DL)", "Classification", "Long short-term memory (LSTM)", "Convolutional Neural Network (CNN)"]}