date;date_scraped;description;dislikes;likes;links;ml_slugs;ml_terms;score_likes;score_views;tags;title;topic;url;views;words
2017-02-08;2021-02-01;"Our Twitter feed is available here: https://twitter.com/karolyzsolnai The paper ""Cone Tracing for Furry Object Rendering"" is available here: http://gaps-zju.org/mlchai/resources/qin2014cone.pdf http://gaps-zju.org/mlchai/";4.0;628.0;['http://gaps-zju.org/mlchai/resources/qin2014cone.pdf', 'http://gaps-zju.org/mlchai/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-640498/'];[];[];0.619;0.772;[];Fast Photorealistic Fur and Hair With Cone Tracing;Cone Tracing for Furry Object Rendering;https://www.youtube.com/watch?v=-all65C-dh0;19280.0;20.0
2016-02-28;2021-02-01;"Image and color editing is an actively researched topic with really cool applications that you will see in a second. Most of the existing solutions are either easy to use but lack in expressiveness, or they are expressive, but too complex for novices to use. Computation time is also an issue as some of the operations in photoshop can take more than a minute to carry out. Using a naive color transfer technique would destroy a sizeable part of the dynamic range of the input image image, and hence, legitimate features which are all preserved if we use this algorithm instead. The paper ""Palette-based Photo Recoloring"" is available here: http://gfx.cs.princeton.edu/pubs/Chang 2015 PPR/index.php The thumbnail background image was created by zoutedrop (CC BY 2.0) - https://flic.kr/p/5E32Cc";0.0;94.0;['http://gfx.cs.princeton.edu/pubs/Chang_2015_PPR/index.php', 'https://flic.kr/p/5E32Cc'];[];[];0.495;0.701;[];Interactive Photo Recoloring;Palette-based Photo Recoloring;https://www.youtube.com/watch?v=-dbkE4FFPrI;3120.0;125.0
2015-08-29;2021-02-01;"Artificial neural networks were inspired by the human brain and simulate how neurons behave when they are shown a sensory input (e.g., images, sounds, etc). They are known to be excellent tools for image recognition, any many other problems beyond that - they also excel at weather predictions, breast cancer cell mitosis detection, brain image segmentation and toxicity prediction among many others. Deep learning means that we use an artificial neural network with multiple layers, making it even more powerful for more difficult tasks. This time they have been shown to be apt at reproducing the artistic style of many famous painters, such as Vincent Van Gogh and Pablo Picasso among many others. All the user needs to do is provide an input photograph and a target image from which the artistic style will be learned. I promised some links, so here they come! The paper ""A Neural Algorithm of Artistic Style"" is available here: http://arxiv.org/abs/1508.06576v1 Disclaimer: I was not part of this research project, I am merely providing commentary on this work. Recommended for you - Two Minute Papers episode on Artificial Neural Networks: https://www.youtube.com/watch?v=rCWTO... Picasso meets Gandalf: http://mashable.com/2015/08/29/computer-photos/ A nice website with many results: https://deepart.io/ More examples with Picasso and some sketches: http://imgur.com/a/jeJB6 Google DeepMind's Deep Q-learning algorithm plays Atari games: https://www.youtube.com/watch?v=V1eYn... The first implementations / source code packages are now available: 1. http://gitxiv.com/posts/jG46ukGod8R7Rdtud/a-neural-algorithm-of-artistic-style 2. https://github.com/kaishengtai/neuralart 3. https://github.com/jcjohnson/neural-style A great read on Deep Dreaming Neural Networks: http://googleresearch.blogspot.co.uk/2015/06/inceptionism-going-deeper-into-neural.html Many of you have asked for the code. Some people were experimenting with it in the Machine Learning reddit. Check it out: https://www.reddit.com/r/MachineLearning/comments/3imx1m/a neural algorithm of artistic style/";21.0;1990.0;['http://arxiv.org/abs/1508.06576v1', 'http://mashable.com/2015/08/29/computer-photos/', 'https://deepart.io/', 'http://imgur.com/a/jeJB6', 'http://gitxiv.com/posts/jG46ukGod8R7Rdtud/a-neural-algorithm-of-artistic-style', 'https://github.com/kaishengtai/neuralart', 'https://github.com/jcjohnson/neural-style', 'http://googleresearch.blogspot.co.uk/2015/06/inceptionism-going-deeper-into-neural.html', 'https://www.reddit.com/r/MachineLearning/comments/3imx1m/a_neural_algorithm_of_artistic_style/', 'https://creativecommons.org/licenses/by/4.0/', 'http://incompetech.com/music/royalty-free/index.html?isrc=USUAN1100666', 'http://incompetech.com/'];[];['neural network', 'neuron', 'predict', 'layer', 'machine learning', 'detect', 'artificial neural network', 'deep learning', 'recogn', 'recommend', 'image segmentation'];0.679;0.836;['Recommender', 'NN', 'DL', 'ANN', 'Image Segmentation', 'ML'];Deep Neural Network Learns Van Gogh's Art;A Neural Algorithm of Artistic Style;https://www.youtube.com/watch?v=-R9bJGNHltQ;170514.0;267.0
2016-05-25;2021-02-01;"The paper ""Surface-Only Liquids"" is available here: http://www.cs.columbia.edu/cg/surfaceliquids/";3.0;324.0;['http://www.cs.columbia.edu/cg/surfaceliquids/', 'https://flic.kr/p/9Ruz12'];[];[];0.579;0.745;[];Surface-Only Liquids;Surface-Only Liquids;https://www.youtube.com/watch?v=-rf_MDh-FiE;9104.0;8.0
2015-11-29;2021-02-01;"Humanity is getting closer and closer to creating human-level intelligence. The question nowadays is not if it will happen, but when it will be happen. Through recursive self-improvement, machine intelligence may quickly surpass the level of humans, creating an artificial superintelligent entity. The intelligence of such entity is so unfathomable, that we cannot even wrap our head around what it would be capable of, just as ants cannot grasp the concept of radio waves. Elon Musk compares creating an artificial superintelligence to ""summoning the demon"", and he offered 10 million dollars to research a safe way to develop this technology. Recommended for you: Are We Living In a Computer Simulation? - https://www.youtube.com/watch?v=ATN9o... A great article on Superintelligence on Wait But Why (there are two parts): http://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html http://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html A talk from Tim Urban, author of Wait But Why: https://www.youtube.com/watch?v=O7xfJ... One more excellent article reflecting on the article above: http://lukemuehlhauser.com/a-reply-to-wait-but-why-on-machine-superintelligence/ Nick Bostrom - Artificial Superintelligence: http://www.amazon.com/gp/product/0199678111?ref =cm sw r awd fkm-tb0J07SSW Elon Musk's $10 million for ethical AI research: http://www.forbes.com/sites/ericmack/2015/01/15/elon-musk-puts-down-10-million-to-fight-skynet/ A neat study from the Machine Intelligence Research Institute (MIRI): https://intelligence.org/files/CEV.pdf Nick Bostrom's poll on when we will achieve superintelligence: http://sophia.de/pdf/2014PT-AIpolls... A science paper claims that our knowledge about the genetic human-mammal differences may be misguided: http://www.plosgenetics.org/article/info%3Adoi%2F10.1371%2Fjournal.pgen.1004525 Excellent discussions on superintelligence: https://www.youtube.com/watch?v=MnT1x... https://www.youtube.com/watch?v=pywF6... https://www.youtube.com/watch?v=h9NB0...";41.0;911.0;['http://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html', 'http://waitbutwhy.com/2015/01/artificial-intelligence-revolution-2.html', 'http://lukemuehlhauser.com/a-reply-to-wait-but-why-on-machine-superintelligence/', 'http://www.amazon.com/gp/product/0199678111?ref_=cm_sw_r_awd_fkm-tb0J07SSW', 'http://www.forbes.com/sites/ericmack/2015/01/15/elon-musk-puts-down-10-million-to-fight-skynet/', 'https://intelligence.org/files/CEV.pdf', 'http://sophia.de/pdf/2014_PT-AI_polls.pdf', 'http://www.plosgenetics.org/article/info%3Adoi%2F10.1371%2Fjournal.pgen.1004525'];['AI'];['recommend'];0.638;0.789;['AI', 'Recommender'];Artificial Superintelligence [Audio only];;https://www.youtube.com/watch?v=08V_F19HUfI;32376.0;212.0
2017-09-20;2021-02-01;"The paper ""Emergence of Locomotion Behaviours in Rich Environments"" is available here: https://arxiv.org/abs/1707.02286 Our";20.0;1612.0;['https://arxiv.org/abs/1707.02286', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-1834465/'];[];[];0.669;0.799;[];DeepMind's AI Learns Locomotion From Scratch;Emergence of Locomotion Behaviours in Rich Environments;https://www.youtube.com/watch?v=14zkfDTN_qo;44585.0;14.0
2015-12-20;2021-02-01;"As there is a lot of progress in simulating the motion of fluids, and paint is a fluid, then why not simulate the process of painting on a canvas? The simulations with this technique are so detailed that even the bristle interactions are taken into consideration, therefore one can capture artistic brush stroke effects like stabbing. Traditional techniques cannot even come close to simulating such sophisticated effects. The paper ""Wetbrush: GPU-based 3D painting simulation at the bristle level"" is available here: http://web.cse.ohio-state.edu/~whmin/publications.html Recommended for you: Adaptive Fluid Simulations - https://www.youtube.com/watch?v=dH1s4...";0.0;313.0;['http://web.cse.ohio-state.edu/~whmin/publications.html'];[];['recommend'];0.578;0.737;['Recommender'];Painting with Fluid Simulations;Wetbrush: GPU-based 3D painting simulation at the bristle level;https://www.youtube.com/watch?v=1aVSb-UbYWc;7406.0;90.0
2016-06-12;2021-02-01;"OpenAI's Gym is available here: https://gym.openai.com/ OpenAI - Non-profit AI company by Elon Musk and Sam Altman https://www.youtube.com/watch?v=AbcRl... Google DeepMind's paper ""Unifying Count-Based Exploration and Intrinsic Motivation"" and video on reniforcement learning and curiosity: https://arxiv.org/pdf/1606.01868v1.pdf https://www.youtube.com/watch?v=0yI2w... Link to the mentioned research project at Experiment: 1. https://experiment.com/projects/opening-your-mind-s-eye-collaborating-with-a-computer-to-reveal-visual-imagination?s=discover 2. https://experiment.com/projects/yvgjmnuxsnavvjuhxzwf";8.0;406.0;['https://gym.openai.com/', 'https://arxiv.org/pdf/1606.01868v1.pdf', 'https://experiment.com/projects/opening-your-mind-s-eye-collaborating-with-a-computer-to-reveal-visual-imagination?s=discover', 'https://experiment.com/projects/yvgjmnuxsnavvjuhxzwf', 'https://experiment.com/', 'https://pixabay.com/en/dumbbell-training-fitness-room-940375/'];['AI'];['fit'];0.593;0.774;['AI'];Reinforcement Learning with OpenAI's Gym;;https://www.youtube.com/watch?v=1PNhuHa7lS0;19946.0;48.0
2017-04-09;2021-02-01;"The paper ""Real-Time Oil Painting on Mobile Hardware"" is available here: http://graphics.cs.kuleuven.be/publications/SD2016RTOPOMH/index.html In addition: It is mentioned that mobile devices typically have a lower resolution display than desktop computers. While this is true, a more important limiting factor is screen real estate, and the fact that a resolution of the simulation is significantly lower on a phone given the vast differences in processing power. These are challenging limitations that are difficult to overcome.";8.0;429.0;['http://graphics.cs.kuleuven.be/publications/SD2016RTOPOMH/index.html', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-1125445/', 'https://pixabay.com/photo-1138275/'];[];[];0.596;0.752;[];Real-Time Oil Painting on Mobile;Real-Time Oil Painting on Mobile Hardware;https://www.youtube.com/watch?v=1SHW1-qKKpY;10891.0;73.0
2017-04-27;2021-02-01;"The paper ""3DMatch: Learning Local Geometric Descriptors from RGB-D Reconstructions"" is available here: http://3dmatch.cs.princeton.edu/ Recommended for you: Our earlier episode on Siamese networks - https://www.youtube.com/watch?v=a3sgF...";4.0;554.0;[];[];['recommend'];0.612;0.758;['Recommender'];AI Learns Geometric Descriptors From Depth Images;3DMatch: Learning Local Geometric Descriptors from RGB-D Reconstructions;https://www.youtube.com/watch?v=1U3YKnuMS7g;12764.0;25.0
2017-12-03;2021-02-01;"The paper ""Feature Visualization"" is available here: https://distill.pub/2017/feature-visualization/ Our";9.0;1055.0;['https://distill.pub/2017/feature-visualization/', 'https://distill.pub/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/'];[];[];0.648;0.775;[];How Do Neural Networks See The World? Pt 2.;Feature Visualization;https://www.youtube.com/watch?v=1zvohULpe_0;21093.0;9.0
2017-12-21;2021-02-01;"The paper ""Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm"" is available here: https://arxiv.org/pdf/1712.01815.pdf Our";68.0;2575.0;['https://arxiv.org/pdf/1712.01815.pdf', 'https://www.chess.com/news/view/google-s-alphazero-destroys-stockfish-in-100-game-match', 'http://forum.computerschach.de/cgi-bin/mwf/topic_show.pl?tid=9653', 'https://ratings.fide.com/top.phtml?list=men', 'https://www.fide.com/fide/handbook.html?id=172&view=article', 'https://chess24.com/en/watch/live-tournaments/alphazero-vs-stockfish/1/1/1', 'https://stockfishchess.org/', 'https://pixabay.com/photo-1483735/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/'];[];['reinforcement learning'];0.691;0.816;['RL'];AlphaZero: DeepMind's New Chess AI;Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm;https://www.youtube.com/watch?v=2ciR6rA85tg;80447.0;19.0
2018-07-20;2021-02-01;"Two Minute Papers Merch: US: http://twominutepapers.com/ EU/Worldwide: https://shop.spreadshirt.net/TwoMinutePapers/ The blog post ""Retro Contest: Results"" and the corresponding paper is available here: 1. https://blog.openai.com/first-retro-contest-retrospective/ 2. https://arxiv.org/abs/1804.03720 Pick up cool perks on our";16.0;1688.0;['https://blog.openai.com/first-retro-contest-retrospective/', 'https://arxiv.org/abs/1804.03720', 'https://pixabay.com/photo-933427/', 'https://opengameart.org/content/nes-shooter-music-5-tracks-3-jingles'];[];[];0.672;0.791;[];OpenAI's Gaming AI Contest: Results;;https://www.youtube.com/watch?v=2FHHuRTkr_Y;34572.0;31.0
2015-10-17;2021-02-01;"Researchers at Harvard, Columbia University and MIT got interested in exploring the sounds that different metal objects emit when struck, opening up the possibility of computationally designing musical instruments such as a glockenspiel. The output of the algorithm is the blueprint of the instrument that can be 3D printed. The sound quality of these instruments is remarkably close to professionally manufactured instruments. The paper ""Computational Design of Metallophone Contact Sounds"" is available below. It also contains a comparison to a professionally manufactured instrument. http://people.seas.harvard.edu/~gaurav/papers/cdmcs sa 2015/ Recommended for you: Hydrographic 3D printing - https://www.youtube.com/watch?v=kLnG0...";0.0;206.0;['http://people.seas.harvard.edu/~gaurav/papers/cdmcs_sa_2015/'];[];['recommend'];0.551;0.724;['Recommender'];3D Printing a Glockenspiel;Computational Design of Metallophone Contact Sounds is available below. It also contains a comparison to a professionally manufactured instrument. http://people.seas.harvard.edu/~gaurav/papers/cdmcs_sa_2015/ Recommended for you: Hydrographic 3D printing - https://www.youtube.com/watch?v=kLnG0... Subscribe if you would like to see more of these! - http://www.youtube.com/subscriptionc... The thumbnail background is taken from the original paper. Splash screen/thumbnail design: Felcia Fehr - http://felicia.hu Kroly Zsolnai-Fehr's links: Patreon  https://www.patreon.com/TwoMinutePapers Facebook  https://www.facebook.com/TwoMinutePapers/ Twitter  https://twitter.com/karolyzsolnai Web  https://cg.tuwien.ac.at/~zsolnai/;https://www.youtube.com/watch?v=2kOCTf8jIik;5277.0;94.0
2017-05-14;2021-02-01;"The paper ""DeepLoco: Dynamic Locomotion Skills Using Hierarchical Deep Reinforcement Learning"" is available here: http://www.cs.ubc.ca/~van/papers/2017-TOG-deepLoco/index.html Two Minute Papers Merch: US: http://twominutepapers.com/ EU/Worldwide: https://shop.spreadshirt.net/TwoMinutePapers/";6.0;602.0;['http://www.cs.ubc.ca/~van/papers/2017-TOG-deepLoco/index.html', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-1505714/'];[];['reinforcement learning'];0.617;0.757;['RL'];Digital Creatures Learn to Navigate in 3D;DeepLoco: Dynamic Locomotion Skills Using Hierarchical Deep Reinforcement Learning;https://www.youtube.com/watch?v=2vnLBb18MuQ;12390.0;23.0
2017-10-07;2021-02-01;"The paper ""Game Engine Learning from Video"" is available here: https://www.cc.gatech.edu/~riedl/pubs/ijcai17.pdf Our";35.0;1669.0;['https://www.cc.gatech.edu/~riedl/pubs/ijcai17.pdf', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-1558063/'];[];[];0.67;0.805;[];AI Learns To Recreate Computer Games;Game Engine Learning from Video;https://www.youtube.com/watch?v=2VyhmbEjs9A;53415.0;12.0
2017-07-27;2021-02-01;"The paper ""Interactive High-Quality Green-Screen Keying via Color Unmixing"" is available here: http://people.inf.ethz.ch/aksoyy/keying/ Two Minute Papers Merch: US: http://twominutepapers.com/ EU/Worldwide: https://shop.spreadshirt.net/TwoMinut...";6.0;512.0;[];[];[];0.607;0.76;[];Interactive Green-Screen Keying;Interactive High-Quality Green-Screen Keying via Color Unmixing;https://www.youtube.com/watch?v=343n8xwozJI;13533.0;21.0
2018-02-19;2021-02-01;"The paper ""Learning to Prune Filters in Convolutional Neural Networks"" is available here: https://arxiv.org/pdf/1801.07365.pdf";5.0;943.0;[];[];['neural network', 'filter', 'convolutional neural network'];0.642;0.78;['NN', 'CNN'];Pruning Makes Faster and Smaller Neural Networks;Learning to Prune Filters in Convolutional Neural Networks;https://www.youtube.com/watch?v=3yOZxmlBG3Y;24168.0;14.0
2017-06-08;2021-02-01;"The paper ""Multi-species simulation of porous sand and water mixtures"" is available here: http://web.cs.ucla.edu/~cffjiang/research/wetsand/wetsand siggraph17.pdf Two Minute Papers Merch: US: http://twominutepapers.com/ EU/Worldwide: https://shop.spreadshirt.net/TwoMinutePapers/ If you're looking for some additional amusement: 1. An even slower motion version of the main scene: https://twitter.com/karolyzsolnai/st... 2. Watch the citation (""Source: [...]"") at the bottom left throughout the video.";6.0;673.0;['http://web.cs.ucla.edu/~cffjiang/research/wetsand/wetsand_siggraph17.pdf', 'https://twitter.com/karoly_zsolnai/status/872497135287140353', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-192988/'];[];[];0.623;0.778;[];Simulating Wet Sand;Multi-species simulation of porous sand and water mixtures;https://www.youtube.com/watch?v=4Df_BluxwkU;22570.0;54.0
2016-03-02;2021-02-01;"I get a lot of messages from you Fellow Scholars that you would like to get started in machine learning and are looking for materials. Below you find a ton of resources to get you started! The AI Revolution: The Road to Superintelligence on Wait But Why: http://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html http://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html Superintelligence by Nick Bostrom: https://en.wikipedia.org/wiki/Superintelligence: Paths, Dangers, Strategies Courses: Welch Labs - https://www.youtube.com/playlist?list... Andrew Ng on Coursera - https://class.coursera.org/ml-005/lecture Andrew Ng (YouTube playlist) - https://www.youtube.com/playlist?list... Nando de Freitas (UBC) - https://www.youtube.com/playlist?list... Nando de Freitas (Oxford) - https://www.youtube.com/playlist?list... Nando de Freitas (more) - https://www.youtube.com/playlist?list... https://www.youtube.com/watch?v=PlhFW... One more at Caltech - https://work.caltech.edu/telecourse.html Andrej Karpathy - https://www.youtube.com/playlist?list... UC Berkeley - https://www.youtube.com/channel/UCshmLD2MsyqAKBx8ctivb5Q/videos Geoffrey Hinton - https://www.coursera.org/course/neuralnets Machine Learning specialization at Coursera - https://www.coursera.org/specializations/machine-learning MIT - http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-034-artificial-intelligence-fall-2010/lecture-videos/ Mathematicalmonk's course: https://www.youtube.com/watch?v=yDLKJ... ""Pattern Recognition and Machine Learning"" by Christoper Bishop: http://research.microsoft.com/en-us/um/people/cmbishop/prml/ ""Algorithms for Reinforcement Learning"" by Csaba Szepesvri: http://www.ualberta.ca/~szepesva/papers/RLAlgsInMDPs.pdf A great talk on deep learning libraries: https://www.youtube.com/watch?v=Vf-O... Two great sources to check for new papers: http://gitxiv.com/top http://www.arxiv-sanity.com/top Recent machine learning papers on the arXiv: http://arxiv.org/list/stat.ML/recent The Machine Learning Reddit: http://www.reddit.com/r/MachineLearning/ One more great post on how to get started with machine learning: https://www.quora.com/How-do-I-get-started-in-machine-learning-both-theory-and-programming/answer/Sebastian-Raschka-1 A great blog post on how to get started with Keras: http://swanintelligence.com/first-steps-with-neural-nets-in-keras.html A website with lots of intuitive articles on deep learning: http://neuralnetworksanddeeplearning.com/. A free book on deep learning by Ian Goodfellow, Yoshua Bengio and Aaron Courville: http://www.deeplearningbook.org/ WE'D LIKE TO THANK OUR GENEROUS SUPPORTERS WHO MAKE TWO MINUTE PAPERS POSSIBLE: Sunil Kim, Vinay S.";44.0;6340.0;['http://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html', 'http://waitbutwhy.com/2015/01/artificial-intelligence-revolution-2.html', 'https://en.wikipedia.org/wiki/Superintelligence:_Paths,_Dangers,_Strategies', 'https://class.coursera.org/ml-005/lecture', 'https://work.caltech.edu/telecourse.html', 'https://www.youtube.com/channel/UCshmLD2MsyqAKBx8ctivb5Q/videos', 'https://www.coursera.org/course/neuralnets', 'https://www.coursera.org/specializations/machine-learning', 'http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-034-artificial-intelligence-fall-2010/lecture-videos/', 'http://research.microsoft.com/en-us/um/people/cmbishop/prml/', 'http://www.ualberta.ca/~szepesva/papers/RLAlgsInMDPs.pdf', 'http://gitxiv.com/top', 'http://www.arxiv-sanity.com/top', 'http://arxiv.org/list/stat.ML/recent', 'http://www.reddit.com/r/MachineLearning/', 'https://www.quora.com/How-do-I-get-started-in-machine-learning-both-theory-and-programming/answer/Sebastian-Raschka-1', 'http://swanintelligence.com/first-steps-with-neural-nets-in-keras.html', 'http://neuralnetworksanddeeplearning.com/', 'http://www.deeplearningbook.org/', 'https://flic.kr/p/sDTYmm'];['AI', 'DL', 'RL', 'NER', 'ML'];['deep learning', 'reinforcement learning', 'machine learning', 'recogn'];0.731;0.831;['AI', 'DL', 'RL', 'NER', 'ML'];How To Get Started With Machine Learning?;;https://www.youtube.com/watch?v=4h0uC9FPVMQ;141492.0;240.0
2016-11-19;2021-02-01;"The Ishikawa Watanabe Laboratory, the University of Tokyo laboratory has all rights to the materials shown in the video. The paper ""Learning to Simplify: Fully Convolutional Networks for Rough Sketch Cleanup"" and its online demo is available here: http://hi.cs.waseda.ac.jp/~esimo/en/research/sketch/ http://hi.cs.waseda.ac.jp:8081/ Recommended for you: Rocking Out With Convolutions - https://www.youtube.com/watch?v=JKYQO... Separable Subsurface Scattering - https://www.youtube.com/watch?v=72iA... WaveNet by Google DeepMind - https://www.youtube.com/watch?v=CqFIV...";30.0;4045.0;['http://hi.cs.waseda.ac.jp/~esimo/en/research/sketch/', 'http://hi.cs.waseda.ac.jp:8081/', 'https://en.wikipedia.org/wiki/Vector_graphics', 'https://en.wikipedia.org/wiki/Image_tracing', 'https://en.wikipedia.org/wiki/Image_resolution', 'https://pixabay.com/photo-1281718/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/'];[];['recommend'];0.712;0.827;['Recommender'];Deep Learning Program Simplifies Your Drawings;Learning to Simplify: Fully Convolutional Networks for Rough Sketch Cleanup and its online demo;https://www.youtube.com/watch?v=4MfG9CDufPA;120756.0;60.0
2016-04-10;2021-02-01;"The Dunning-Kruger effect describes a phenomenon where incompetent people assess their skills way higher than it is. We will talk about this phenomenon, its connection to impostor syndrome, and most importantly, why we should not use this knowledge to condemn others but to improve ourselves. The paper ""Unskilled and Unaware of It: How Difficulties in Recognizing One's Own Incompetence Lead to Inflated Self-Assessments"" is available here. It is a really easy and enjoyable read, make sure you give it a shot! http://www.nottingham.ac.uk/~ntzcl1/literature/metacognition/kruger.pdf Recommended for you: What Is Impostor Syndrome? - https://www.youtube.com/watch?v=YPpIW...";9.0;363.0;['http://www.nottingham.ac.uk/~ntzcl1/literature/metacognition/kruger.pdf', 'https://flic.kr/p/rjdQyY'];[];['recogn', 'recommend'];0.586;0.753;['Recommender'];The Dunning-Kruger Effect;Unskilled and Unaware of It: How Difficulties in Recognizing One's Own Incompetence Lead to Inflated Self-Assessments;https://www.youtube.com/watch?v=4Y7RIAgOpn0;11246.0;91.0
2016-09-30;2021-02-01;"In this episode, we shall talk about auxetic materials. Auxetic materials are materials that when stretched, thicken perpendicular to the direction we're stretching them. In other words, instead of thinning, they get fatter when stretched. The paper ""Beyond Developable: Computational Design and Fabrication with Auxetic Materials"" is available here: http://lgg.epfl.ch/publications/2016/BeyondDevelopable/index.php The tendon paper, ""Negative Poissons ratios in tendons: An unexpected mechanical response"" is available here: http://www.sciencedirect.com/science/article/pii/S1742706115002871 Our previous episode about optimization is available here: https://www.youtube.com/watch?v=1ypV5...";53.0;2407.0;['http://lgg.epfl.ch/publications/2016/BeyondDevelopable/index.php', 'http://www.sciencedirect.com/science/article/pii/S1742706115002871', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/'];[];[];0.688;0.817;[];3D Printing Auxetic Materials;Beyond Developable: Computational Design and Fabrication with Auxetic Materials;https://www.youtube.com/watch?v=5-xMV3sT3Tw;81128.0;75.0
2016-05-08;2021-02-01;"A few quite exciting applications of deep learning in cancer research have appeared recently. This new algorithm can recognize cancer cells by looking at blood samples without introducing any intrusive chemicals in the process. Amazing results ahead. :) The paper ""Deep Learning in Label-free Cell Classification"" is available here: http://www.nature.com/articles/srep21471 The link from Healthline: http://www.healthline.com/health/cancer/ovarian-cancer-facts-statistics-infographic#10 Recommended for you: Two+ Minute Papers - Overfitting and Regularization For Deep Learning - https://www.youtube.com/watch?v=6aF9s...";3.0;235.0;['http://www.nature.com/articles/srep21471', 'http://www.healthline.com/health/cancer/ovarian-cancer-facts-statistics-infographic#10', 'https://flic.kr/p/9ATvC1'];[];['fit', 'deep learning', 'classif', 'label', 'recogn', 'recommend'];0.559;0.743;['Classification', 'Recommender', 'DL'];Deep Learning and Cancer Research;Deep Learning in Label-free Cell Classification;https://www.youtube.com/watch?v=5PSWr2ovBvU;8606.0;70.0
2017-05-28;2021-02-01;"The paper ""Interactive Design and Stability Analysis of Decorative Joinery for Furniture"" is available here: https://jiaxianyao.github.io/joinery/ Note: SketchUp is no longer owned by Google and is now called SketchUp 3D. Two Minute Papers Merch: US: http://twominutepapers.com/ EU/Worldwide: https://shop.spreadshirt.net/TwoMinutePapers/";7.0;427.0;['https://jiaxianyao.github.io/joinery/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/'];[];[];0.596;0.747;[];Designing Decorative Joinery for Furniture;Interactive Design and Stability Analysis of Decorative Joinery for Furniture;https://www.youtube.com/watch?v=5vpklJw7uL0;9615.0;38.0
2015-07-28;2021-02-01;Creating detailed fluid and smoke simulations in Blender and other modeling software is a slow and laborious process that requires a ton of time and resources. Wavelet Turbulence is a technique that helps achieving similar effects orders of magnitude faster. It is also much lighter on memory and is now widely used in the industry, so it's definitely not an accident that Theodore Kim won an Academy Award (a technical Oscar, if you will) for this SIGGRAPH publication. It is implemented in Blender and is available for everyone free of charge, so make sure to try it out! In Two Minute Papers, I attempt to bring the most awesome research discoveries to everyone a couple minutes at a time. Here is a tutorial and a Blender download link to get you started: http://blender.org/ https://www.youtube.com/watch?v=iV43x... Kim et al.'s Wavelet Turbulence paper is available here: http://www.cs.cornell.edu/~tedkim/wturb/ Disclaimer: I was not part of this research project, I am merely providing commentary on this work.;3.0;224.0;['http://blender.org/', 'http://www.cs.cornell.edu/~tedkim/wturb/'];[];['model'];0.555;0.747;[];Fluid Simulations with Blender and Wavelet Turbulence;;https://www.youtube.com/watch?v=5xLSbj5SsSE;9481.0;161.0
2015-12-10;2021-02-01;"In this episode, we discuss what makes an event random, and how incredible it is what Bell's theorem (or inequality) has to say about truly random events. Note: ""local"" means that information from the hidden variable doesn't travel faster than light. The paper ""On the Einstein Podolsky Rosen Paradox"" is available here: http://www.drchinese.com/David/BellC... http://homepages.physik.uni-muenchen.de/~vondelft/Lehre/09qm/lec21-22-BellInequalities/Bell1964.pdf.";2.0;124.0;['http://www.drchinese.com/David/Bell_Compact.pdf', 'http://homepages.physik.uni-muenchen.de/~vondelft/Lehre/09qm/lec21-22-BellInequalities/Bell1964.pdf', 'https://flic.kr/p/8M11b6'];[];[];0.514;0.72;[];Randomness and Bell's Inequality [Audio only];On the Einstein Podolsky Rosen Paradox;https://www.youtube.com/watch?v=674DL39dOOQ;4830.0;54.0
2016-03-30;2021-02-01;"In this episode, we discuss the bane of many machine learning algorithms - overfitting. It is also explained why it is an undesirable way to learn and how to combat it via L1 and L2 regularization. The paper ""Regression Shrinkage and Selection via the Lasso"" is available here: http://statweb.stanford.edu/~tibs/lasso/lasso.pdf Andrej Karpathy's excellent lecture notes on neural networks and regularization: http://cs231n.github.io/neural-networks-1/ The neural network demo is available here: http://cs.stanford.edu/people/karpathy/convnetjs/demo/classify2d.html A playlist with out neural network and deep learning-related videos: https://www.youtube.com/playlist?list...";6.0;296.0;['http://statweb.stanford.edu/~tibs/lasso/lasso.pdf', 'http://cs231n.github.io/neural-networks-1/', 'http://cs.stanford.edu/people/karpathy/convnetjs/demo/classify2d.html', 'https://flic.kr/p/5dkbNV'];[];['neural network', 'fit', 'machine learning', 'deep learning', 'classif', 'regression'];0.573;0.746;['NN', 'DL', 'Classification', 'Regression', 'ML'];Overfitting and Regularization For Deep Learning;Regression Shrinkage and Selection via the Lasso;https://www.youtube.com/watch?v=6aF9sJrzxaM;9220.0;79.0
2017-07-30;2021-02-01;"The paper ""Animating Elastic Rods with Sound"" is available here: https://www.cs.cornell.edu/projects/rodsound/ Watch the original video with the sound samples here: https://www.youtube.com/watch?v=ePySS...";10.0;552.0;['https://www.cs.cornell.edu/projects/rodsound/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-1681565/'];[];[];0.611;0.762;[];Animating Elastic Rods With Sound;Animating Elastic Rods with Sound;https://www.youtube.com/watch?v=6c2T2cykE_A;14187.0;21.0
2017-11-26;2021-02-01;"The paper ""Deep Image Matting"" and a (seemingly) unofficial implementation by someone else is available here: https://sites.google.com/view/deepimagematting https://github.com/Joker316701882/Deep-Image-Matting Two Minute Papers Merch: US: http://twominutepapers.com/ EU/Worldwide: https://shop.spreadshirt.net/TwoMinutePapers/";13.0;892.0;['https://sites.google.com/view/deepimagematting', 'https://github.com/Joker316701882/Deep-Image-Matting', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://flic.kr/p/95VjEC'];[];[];0.638;0.78;[];Image Matting With Deep Neural Networks;Deep Image Matting and a (seemingly) unofficial implementation by someone else;https://www.youtube.com/watch?v=6DVng5JVuhI;23933.0;26.0
2017-12-06;2021-02-01;"The paper ""Hierarchical Representations for Efficient Architecture Search"" is available here: https://arxiv.org/pdf/1711.00436.pdf Genetic algorithm (+ Mona Lisa problem) implementation: 1. https://users.cg.tuwien.ac.at/zsolnai/gfx/mona lisa parallel genetic algorithm/ 2. https://users.cg.tuwien.ac.at/zsolnai/gfx/mona lisa parallel genetic algorithm/ Andrej Karpathy's online demo: http://cs.stanford.edu/people/karpathy/convnetjs/demo/classify2d.html Overfitting and Regularization For Deep Learning - https://www.youtube.com/watch?v=6aF9s... Training Deep Neural Networks With Dropout - https://www.youtube.com/watch?v=LhhEv... How Do Genetic Algorithms Work? - https://www.youtube.com/watch?v=ziMHa...";38.0;2099.0;['https://arxiv.org/pdf/1711.00436.pdf', 'https://users.cg.tuwien.ac.at/zsolnai/gfx/mona_lisa_parallel_genetic_algorithm/', 'https://users.cg.tuwien.ac.at/zsolnai/gfx/knapsack_genetic/', 'http://cs.stanford.edu/people/karpathy/convnetjs/demo/classify2d.html', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-2692456/'];[];['neural network', 'fit', 'train', 'deep learning', 'classif'];0.682;0.807;['Classification', 'NN', 'DL'];This Neural Network Optimizes Itself;Hierarchical Representations for Efficient Architecture Search;https://www.youtube.com/watch?v=6JZNEb5uDu4;57140.0;59.0
2016-07-05;2021-02-01;"The paper ""Connected Fermat Spirals for Layered Fabrication"" is available here: http://irc.cs.sdu.edu.cn/html/2016/2016 0519/222.html The ThatsMaths article on sunflowers + paper ""Fibonacci patterns: common or rare?"" is available here: https://thatsmaths.com/2014/06/05/sunflowers-and-fibonacci-models-of-efficiency/ http://www.sciencedirect.com/science/article/pii/S2210983813001314 Another nice application of Hilbert curves for spatial indexing (thanks for the link TheJonManley!): http://blog.notdot.net/2009/11/Damn-Cool-Algorithms-Spatial-indexing-with-Quadtrees-and-Hilbert-Curves";3.0;237.0;['http://irc.cs.sdu.edu.cn/html/2016/2016_0519/222.html', 'https://thatsmaths.com/2014/06/05/sunflowers-and-fibonacci-models-of-efficiency/', 'http://www.sciencedirect.com/science/article/pii/S2210983813001314', 'http://blog.notdot.net/2009/11/Damn-Cool-Algorithms-Spatial-indexing-with-Quadtrees-and-Hilbert-Curves', 'https://experiment.com/', 'https://flic.kr/p/5bXvB9'];[];['layer', 'model'];0.559;0.731;[];Fermat Spirals for Layered 3D Printing;Connected Fermat Spirals for Layered Fabrication;https://www.youtube.com/watch?v=6rNcAVr-U4s;6284.0;45.0
2016-05-15;2021-02-01;"Separable Subsurface Scattering is a novel technique to add real-time subsurface light transport calculations for computer games and other real-time applications. The paper ""Separable Subsurface Scattering"" and its implementation is available here: https://users.cg.tuwien.ac.at/zsolnai/gfx/separable-subsurface-scattering-with-activision-blizzard/ http://www.iryoku.com/separable-sss/ Recommended for you: Ray Tracing / Subsurface Scattering @ Function 2015 - https://www.youtube.com/watch?v=qyDUv... Separable Subsurface Scattering Unofficial Talk - https://www.youtube.com/watch?v=mU-5C... Separable Subsurface Scattering Implementation in Blender (thank you Lubos Lenco!): http://www.blendernation.com/2016/05/02/separable-subsurface-scattering-game-engine-cycles/ http://luboslenco.com/notes/ssss/";10.0;996.0;['https://users.cg.tuwien.ac.at/zsolnai/gfx/separable-subsurface-scattering-with-activision-blizzard/', 'http://www.iryoku.com/separable-sss/', 'http://www.blendernation.com/2016/05/02/separable-subsurface-scattering-game-engine-cycles/', 'http://luboslenco.com/notes/ssss/', 'https://flic.kr/p/fGie2L', 'https://flic.kr/p/8wXFiC'];[];['recommend'];0.644;0.797;['Recommender'];Separable Subsurface Scattering;Separable Subsurface Scattering and its implementation;https://www.youtube.com/watch?v=72_iAlYwl0c;40923.0;66.0
2017-01-11;2021-02-01;"The paper ""An Iterative Image Registration Technique with an Application to Stereo Vision"" is available here: http://cseweb.ucsd.edu/classes/sp02/cse252/lucaskanade81.pdf Our earlier episode on extrapolation: https://www.youtube.com/watch?v=AHl2J...";13.0;601.0;['http://cseweb.ucsd.edu/classes/sp02/cse252/lucaskanade81.pdf', 'https://pixabay.com/photo-1032741/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/'];[];[];0.616;0.776;[];Amazing Slow Motion Videos With Optical Flow;An Iterative Image Registration Technique with an Application to Stereo Vision;https://www.youtube.com/watch?v=7aLda2E0Yyg;21255.0;23.0
2016-11-27;2021-02-01;"The paper ""Acoustic Voxels: Computational Optimization of Modular Acoustic Filters"" is available here: http://www.cs.columbia.edu/cg/lego/";47.0;1943.0;[];[];['filter'];0.678;0.808;[];3D Printing Acoustic Filters;Acoustic Voxels: Computational Optimization of Modular Acoustic Filters;https://www.youtube.com/watch?v=7JbN9vXxGYE;60874.0;14.0
2017-07-16;2021-02-01;"The paper ""Deep Opacity Maps"" is available here: http://www.cemyuksel.com/research/deepopacity/ Unofficial implementation: http://prideout.net/blog/?p=69 Recommended for you: The Dunning-Kruger Effect - https://www.youtube.com/watch?v=4Y7RI... Are We Living In a Computer Simulation? - https://www.youtube.com/watch?v=ATN9o... Two Minute Papers Merch: US: http://twominutepapers.com/ EU/Worldwide: https://shop.spreadshirt.net/TwoMinutePapers/";14.0;1033.0;['http://www.cemyuksel.com/research/deepopacity/', 'http://prideout.net/blog/?p=69', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-1853957/'];[];['recommend'];0.646;0.793;['Recommender'];Real-Time Hair Rendering With Deep Opacity Maps;Deep Opacity Maps;https://www.youtube.com/watch?v=7x2UvvD48Fw;36856.0;37.0
2017-03-15;2021-02-01;"The paper ""Stable and Controllable Neural Texture Synthesis and Style Transfer Using Histogram Losses"" is available here: https://arxiv.org/abs/1701.08893 Texture synthesis survey: http://www-sop.inria.fr/reves/Basilic...";3.0;570.0;[];[];['loss'];0.614;0.764;[];Stable Neural Style Transfer;Stable and Controllable Neural Texture Synthesis and Style Transfer Using Histogram Losses;https://www.youtube.com/watch?v=8u3Hkbev2Gg;14981.0;22.0
2017-04-23;2021-02-01;"The paper ""Semantic Scene Completion from a Single Depth Image"" is available here: http://sscnet.cs.princeton.edu/ Recommended for you: How Does Deep Learning Work? - https://www.youtube.com/watch?v=He4t7... Artificial Neural Networks and Deep Learning - https://www.youtube.com/watch?v=rCWTO...";1.0;466.0;['http://sscnet.cs.princeton.edu/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-2225414/'];[];['neural network', 'deep learning', 'artificial neural network', 'recommend'];0.602;0.757;['Recommender', 'NN', 'DL', 'ANN'];Semantic Scene Completion From One Depth Image;Semantic Scene Completion from a Single Depth Image;https://www.youtube.com/watch?v=8YWgar0uCF8;12388.0;32.0
2017-06-17;2021-02-01;"The paper ""Parallel Multiscale Autoregressive Density Estimation"" is available here: https://arxiv.org/pdf/1703.03664.pdf Our";57.0;2392.0;[];[];[];0.688;0.824;[];DeepMind's AI Creates Images From Your Sentences;Parallel Multiscale Autoregressive Density Estimation;https://www.youtube.com/watch?v=9bcbh2hC7Hw;107143.0;12.0
2017-10-19;2021-02-01;"The paper ""Large Pose 3D Face Reconstruction from a Single Image via Direct Volumetric CNN Regression"" is available here: http://aaronsplace.co.uk/papers/jackson2017recon/ Online demo: http://cvl-demos.cs.nott.ac.uk/vrn/ Source code: https://github.com/AaronJackson/vrn";11.0;1139.0;['http://aaronsplace.co.uk/papers/jackson2017recon/', 'http://cvl-demos.cs.nott.ac.uk/vrn/', 'https://github.com/AaronJackson/vrn', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-1836445/'];['NN', 'CNN'];['regression'];0.652;0.786;['NN', 'Regression', 'CNN'];AI Learns 3D Face Reconstruction;Large Pose 3D Face Reconstruction from a Single Image via Direct Volumetric CNN Regression;https://www.youtube.com/watch?v=9BOdng9MpzU;29150.0;26.0
2018-06-19;2021-02-01;"The paper ""Curiosity-driven Exploration by Self-supervised Prediction"" and its source code is available here: https://pathak22.github.io/noreward-rl/ Pick up cool perks on our";26.0;1962.0;['https://pathak22.github.io/noreward-rl/', 'https://flic.kr/p/M843Kp'];[];['reward', 'predict'];0.679;0.795;[];Curiosity-Driven AI: How Effective Is It?;Curiosity-driven Exploration by Self-supervised Prediction and its source code;https://www.youtube.com/watch?v=9S2g7iixB9c;38395.0;21.0
2017-10-30;2021-02-01;"The AlphaGo Zero paper ""Mastering the Game of Go without Human Knowledge"" is available here: https://deepmind.com/blog/alphago-zero-learning-scratch/ https://deepmind.com/documents/119/agz unformatted nature.pdf Our";154.0;6096.0;['https://deepmind.com/blog/alphago-zero-learning-scratch/', 'https://deepmind.com/documents/119/agz_unformatted_nature.pdf', 'https://flic.kr/p/7nX4kK', 'https://flic.kr/p/dDeQU9', 'https://flic.kr/p/4c5RaR', 'https://www.goratings.org/en/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://flic.kr/p/skJBM1'];[];[];0.728;0.844;[];New DeepMind AI Beats AlphaGo 100-0;;https://www.youtube.com/watch?v=9xlSy9F5WtE;238966.0;20.0
2016-03-15;2021-02-01;"This time around, Google DeepMind embarked on a journey to write an algorithm that plays Go. Go is an ancient chinese board game where the opposing players try to capture each other's stones on the board. Behind the veil of this deceptively simple ruleset, lies an enormous layer of depth and complexity. As scientists like to say, the search space of this problem is significantly larger than that of chess. So large, that one often has to rely on human intuition to find a suitable next move, therefore it is not surprising that playing Go on a high level is, or maybe was widely believed to be intractable for machines. The result is Google DeepMind's AlphaGo, the deep learning technique that defeated a professional player and world champion, Lee Sedol. What it also important to note is that the techniques used in this algorithm are general, and can be used for a large number of different tasks. By this, I mean not AlphaGo specifically, but the Monte Carlo Tree Search, the value network and deep neural networks. The paper ""Mastering the Game of Go with Deep Neural Networks and Tree Search"" is available here: https://storage.googleapis.com/deepmind-data/assets/papers/deepmind-mastering-go.pdf http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html A great Go analysis video by Brady Daniels. Make sure to check it out and subscribe if you like what you see there! https://www.youtube.com/watch?v=dOQsY... The mentioned post on the Go reddit: https://www.reddit.com/r/baduk/comments/49y17z/the true strength of alphago/ Some clarification on what part of the algorithm is specific to Go and how: https://news.ycombinator.com/item?id=11280744 Go board image credits (all CC BY 2.0): Renato Ganoza - https://flic.kr/p/7nX4kK Jaro Larnos - https://flic.kr/p/dDeQU9 Luis de Bethencourt - https://flic.kr/p/4c5RaR";9.0;377.0;['https://storage.googleapis.com/deepmind-data/assets/papers/deepmind-mastering-go.pdf', 'http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html', 'https://www.reddit.com/r/baduk/comments/49y17z/the_true_strength_of_alphago/', 'https://news.ycombinator.com/item?id=11280744', 'https://flic.kr/p/7nX4kK', 'https://flic.kr/p/dDeQU9', 'https://flic.kr/p/4c5RaR'];[];['layer', 'deep learning', 'neural network'];0.588;0.762;['NN', 'DL'];How DeepMind's AlphaGo Defeated Lee Sedol;Mastering the Game of Go with Deep Neural Networks and Tree Search;https://www.youtube.com/watch?v=a-ovvd_ZrmA;14426.0;268.0
2016-08-03;2021-02-01;What is peer review and how is it done? How can we check the validity of a paper? And more importantly, how can we be sure that the peer review process is fair and consistent? We'll talk about these things and how the NIPS experiment addresses them. The NIPS experiment: http://blog.mrtz.org/2014/12/15/the-nips-experiment.html http://www.kdnuggets.com/2016/05/embrace-random-acceptance-borderline-papers.html The showcased earlier episode video: Artistic Manipulation of Caustics - https://www.youtube.com/watch?v=K-0KJ... A New Publishing Model in Computer Science by Yann LeCun: http://yann.lecun.com/ex/pamphlets/publishing-models.html;1.0;147.0;['http://blog.mrtz.org/2014/12/15/the-nips-experiment.html', 'http://www.kdnuggets.com/2016/05/embrace-random-acceptance-borderline-papers.html', 'http://yann.lecun.com/ex/pamphlets/publishing-models.html', 'https://experiment.com/', 'https://flic.kr/p/8HRJoc', 'http://www.flaticon.com/free-icon/blind-man-silhouette_8711'];[];['model'];0.527;0.705;[];Peer Review and the NeurIPS Experiment;;https://www.youtube.com/watch?v=a1z6GXj8QK8;3438.0;74.0
2016-07-20;2021-02-01;"The Two Minute Papers subreddit is available here: https://www.reddit.com/r/twominutepapers/ By using a convolutional neural networks (a powerful deep learning technique), it is now possible to build an application that takes a rough sketch as an input, and fetches photorealistic images from a database. The paper ""The Sketchy Database: Learning to Retrieve Badly Drawn Bunnies"" and the online demo is available here: http://sketchy.eye.gatech.edu/ The paper ""Signature verification using a Siamese time delay neural network"" is available here: https://scholar.google.hu/scholar?cluster=4400768003729787411&hl=en&as sdt=0,5 The paper ""Learning Fine-grained Image Similarity with Deep Ranking"" is available here: https://arxiv.org/abs/1404.4661 Our deep learning-related videos are available here: https://www.youtube.com/playlist?list...";12.0;403.0;['http://sketchy.eye.gatech.edu/', 'https://scholar.google.hu/scholar?cluster=4400768003729787411&hl=en&as_sdt=0,5', 'https://arxiv.org/abs/1404.4661', 'https://experiment.com/'];[];['neural network', 'deep learning', 'convolutional neural network', 'rank'];0.592;0.767;['CNN', 'NN', 'DL'];Photorealistic Images from Drawings;The Sketchy Database: Learning to Retrieve Badly Drawn Bunnies and the online demo;https://www.youtube.com/watch?v=a3sgFQjEfp4;16564.0;99.0
2015-08-22;2021-02-01;"There is something inherently exciting about watching breaking glass and other objects. Researchers in computer graphics also like to have some fun and write simulation programs to smash together a variety of virtual objects in slow motion. However, despite being beautiful, they are physically not correct as many effects are neglected, such as simulating plasticity, bending stiffness, stretching energies and many others. Pfaff et al.'s paper ""Adaptive Tearing and Cracking of Thin Sheets"" addresses this issue by creating an adaptive simulator that uses more computational resources only around regions where cracks are likely to happen. This new technique enables the simulation of tearing for a variety of materials like cork, foils, metals, vinyl and it also yields physically correct results for glass. The algorithm also lets artists influence the outcome to be in line with their artistic visions. Pfaff et al.'s research paper ""Adaptive Tearing and Cracking of Thin Sheets"" is available here: http://graphics.berkeley.edu/papers/Pfaff-ATC-2014-07/ Disclaimer: I was not part of this research project, I am merely providing commentary on this work. In Two Minute Papers, I attempt to bring the most awesome research discoveries to everyone a couple minutes at a time. The shattered glass image from the thumbnail was created by Andrew Magill. Music: ""Jolly Old St Nicholas"" by E's Jammy Jams";2.0;429.0;['http://graphics.berkeley.edu/papers/Pfaff-ATC-2014-07/'];[];[];0.597;0.747;[];Simulating Breaking Glass;;https://www.youtube.com/watch?v=A7Gut679I-o;9611.0;213.0
2017-04-19;2021-02-01;Two Minute Papers on;7.0;1377.0;[];[];[];0.662;0.793;[];Real-Time Modeling and Animation of Climbing Plants;Interactive Modeling and Authoring of Climbing Plants;https://www.youtube.com/watch?v=aAsejHZC5EE;36017.0;4.0
2016-04-14;2021-02-01;For the third time, we present another round of incredible deep learning applications! 1. Geolocation - http://arxiv.org/abs/1602.05314 2. Super-resolution - http://arxiv.org/pdf/1511.04491v1.pdf 3. Neural Network visualizer - http://experiments.mostafa.io/public/ffbpann/ 4. Recurrent neural network for sentence completion: http://www.cs.toronto.edu/~ilya/fourth.cgi 5. Human-in-the-loop and Doctor-in-the-loop: http://link.springer.com/article/10.1007/s40708-016-0036-4 6. Emoji suggestions for images - https://emojini.curalate.com/ 7. MNIST handwritten numbers in HD - http://blog.otoro.net/2016/04/01/generating-large-images-from-latent-vectors/ 8. Deep Learning solution to the Netflix prize -https://karthkk.wordpress.com/2016/03/22/deep-learning-solution-for-netflix-prize/ 9. Curating works of art - http://cs231n.stanford.edu/reports2016/210 Report.pdf 10. More robust neural networks against adversarial examples - http://cs231n.stanford.edu/reports2016/210 Report.pdf The Keras library: http://keras.io/ https://github.com/fchollet/keras Recommended for you: Two Minute Papers Machine Learning Playlist - https://www.youtube.com/playlist?list...;12.0;1361.0;['http://arxiv.org/abs/1602.05314', 'http://arxiv.org/pdf/1511.04491v1.pdf', 'http://experiments.mostafa.io/public/ffbpann/', 'http://www.cs.toronto.edu/~ilya/fourth.cgi', 'http://link.springer.com/article/10.1007/s40708-016-0036-4', 'https://emojini.curalate.com/', 'http://blog.otoro.net/2016/04/01/generating-large-images-from-latent-vectors/', 'https://karthkk.wordpress.com/2016/03/22/deep-learning-solution-for-netflix-prize/', 'http://cs231n.stanford.edu/reports2016/210_Report.pdf', 'http://cs231n.stanford.edu/reports2016/103_Report.pdf', 'http://keras.io/', 'https://github.com/fchollet/keras', 'https://flic.kr/p/sdUQ7'];[];['neural network', 'machine learning', 'recurrent neural network', 'deep learning', 'recommend'];0.661;0.809;['Recommender', 'RNN', 'NN', 'DL', 'ML'];10 Even Cooler Deep Learning Applications;;https://www.youtube.com/watch?v=aKSILzbAqJs;62788.0;99.0
2016-11-23;2021-02-01;"The paper ""Inverse-Foley Animation: Synchronizing rigid-body motions to sound"" is available here: http://www.cs.cornell.edu/projects/So... Recommended for you: Sound Synthesis for Fluids With Bubbles - https://www.youtube.com/watch?v=kwqme... Synthesizing Sound From Collisions - https://www.youtube.com/watch?v=rskdL... Visually Indicated Sounds - https://www.youtube.com/watch?v=flOev... What Do Virtual Objects Sound Like? - https://www.youtube.com/watch?v=ZaFqv...";31.0;3253.0;[];[];['recommend'];0.702;0.809;['Recommender'];Synchronizing Animations To Sound;Inverse-Foley Animation: Synchronizing rigid-body motions to sound;https://www.youtube.com/watch?v=aMo7pkkaZ9o;62218.0;43.0
2017-09-24;2021-02-01;"The paper ""Optimizing the Latent Space of Generative Networks"" is available here: https://arxiv.org/pdf/1707.05776.pdf Khan Academy's video on the Nash equilibrium: https://www.khanacademy.org/economics-finance-domain/microeconomics/nash-equilibrium-tutorial/nash-eq-tutorial/v/prisoners-dilemma-and-nash-equilibrium Earlier episodes showcased in the video: Image Editing with Generative Adversarial Networks - https://www.youtube.com/watch?v=pqkpI... AI Learns to Synthesize Pictures of Animals - https://www.youtube.com/watch?v=D4C1d... AI Makes 3D Models From Photos - https://www.youtube.com/watch?v=HO1LY... Font paper: http://vecg.cs.ucl.ac.uk/Projects/projects fonts/projects fonts.html";11.0;1079.0;['https://arxiv.org/pdf/1707.05776.pdf', 'https://www.khanacademy.org/economics-finance-domain/microeconomics/nash-equilibrium-tutorial/nash-eq-tutorial/v/prisoners-dilemma-and-nash-equilibrium', 'http://vecg.cs.ucl.ac.uk/Projects/projects_fonts/projects_fonts.html', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-2589641/'];['AI'];['model', 'generative adversarial network'];0.649;0.787;['AI', 'GAN'];Latent Space Human Face Synthesis;Optimizing the Latent Space of Generative Networks;https://www.youtube.com/watch?v=aR6M0MQBo2w;30483.0;57.0
2015-12-31;2021-02-01;"In machine learning, we usually have a set of problems for which we are looking for solutions. For instance, ""here is an image, please tell me what is seen on it"". Or, ""here is a computer game, please beat level three"". One problem, one solution. In this case, we are not looking for one solution, we are looking for a computer program, an algorithm, that can solve any number of problems of the same kind. It can also learn how to rotate images of different cars around to obtain a frontal pose. This technique can learn from someone how to sort a set of 20 numbers and generalize its knowledge to much longer sequences. The paper ""Neural Programmer-Interpreters"" is available here: http://www-personal.umich.edu/~reedscot/iclr project.html The thumbnail image was created by Iwan Gabovitch (CC BY 2.0) - https://flic.kr/p/paxzB9";2.0;346.0;['http://www-personal.umich.edu/~reedscot/iclr_project.html', 'https://flic.kr/p/paxzB9'];[];['machine learning'];0.584;0.756;['ML'];Neural Programmer-Interpreters Learn To Write Programs;Neural Programmer-Interpreters;https://www.youtube.com/watch?v=B70tT4WMyJk;12202.0;136.0
2017-03-22;2021-02-01;"The paper ""Shape2Vec: semantic-based descriptors for 3D shapes, sketches and images"" is available here: http://www.cl.cam.ac.uk/research/rainbow/projects/shape2vec/ Code (coming soon according to the authors): https://github.com/ftasse/Shape2Vec";4.0;402.0;['http://www.cl.cam.ac.uk/research/rainbow/projects/shape2vec/', 'https://github.com/ftasse/Shape2Vec', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-1828007/'];[];[];0.593;0.755;[];Shape2vec: Understanding 3D Shapes With AI;Shape2Vec: semantic-based descriptors for 3D shapes, sketches and images;https://www.youtube.com/watch?v=bB54Wz4kq0E;11709.0;23.0
2018-02-14;2021-02-01;"The paper ""Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions"" is available here: https://google.github.io/tacotron/pub... https://arxiv.org/abs/1712.05884 Our";16.0;2246.0;[];[];['predict'];0.685;0.806;[];Google's Text Reader AI: Almost Perfect;Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions;https://www.youtube.com/watch?v=bdM9c2OFYuw;56237.0;18.0
2017-09-07;2021-02-01;"The paper ""Hierarchical Surface Prediction for 3D Object Reconstruction"" is available here: https://arxiv.org/abs/1704.00710";18.0;1041.0;[];[];['predict'];0.646;0.8;[];AI Creates 3D Models From Images;Hierarchical Surface Prediction for 3D Object Reconstruction;https://www.youtube.com/watch?v=BjwhMDhbqAs;46380.0;13.0
2016-09-16;2021-02-01;"This tongue in cheek work is about identifying matrix ranks from images, plugging in a convolutional neural network where it is absolutely inaproppriate to use. The paper ""Visually Identifying Rank"" is available here: http://www.oneweirdkerneltrick.com/rank.pdf David Fouhey's website is available here: http://www.cs.cmu.edu/~dfouhey/ The machine learning calculator is available here: http://armlessjohn404.github.io/calcuMLator/ The paper ""Separable Subsurface Scattering"" is available here: https://users.cg.tuwien.ac.at/zsolnai/gfx/separable-subsurface-scattering-with-activision-blizzard/";6.0;233.0;['http://www.oneweirdkerneltrick.com/rank.pdf', 'http://www.cs.cmu.edu/~dfouhey/', 'http://armlessjohn404.github.io/calcuMLator/', 'https://users.cg.tuwien.ac.at/zsolnai/gfx/separable-subsurface-scattering-with-activision-blizzard/', 'https://experiment.com/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-356024/'];['ML'];['neural network', 'machine learning', 'convolutional neural network', 'rank'];0.557;0.742;['ML', 'NN', 'CNN'];Estimating Matrix Rank With Neural Networks;Visually Identifying Rank;https://www.youtube.com/watch?v=bLFISzfQCDQ;8300.0;58.0
2017-03-08;2021-02-01;"The paper ""How2Sketch: Generating Easy-To-Follow Tutorials for Sketching 3D Objects"" is available here: http://geometry.cs.ucl.ac.uk/projects/2017/how2sketch/";4.0;628.0;['http://geometry.cs.ucl.ac.uk/projects/2017/how2sketch/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-1582108/'];[];[];0.619;0.767;[];Automatic Creation of Sketch Tutorials;How2Sketch: Generating Easy-To-Follow Tutorials for Sketching 3D Objects;https://www.youtube.com/watch?v=brs1qCDzRdk;16313.0;14.0
2016-01-05;2021-02-01;"Machine learning provides us an incredible set of tools. If you have a difficult problem at hand, you don't need to hand craft an algorithm for it. It finds out by itself what is important about the problem and tries to solve it on its own. In this video, you'll see a number of incredible applications of different machine learning techniques (neural networks, deep learning, convolutional neural networks and more). Note: the fluid simulation paper is using regression forests, which is a machine learning technique, but not strictly deep learning. There are variants of it that are though (e.g., Deep Neural Decision Forests). The paper ""Toxicity Prediction using Deep Learning"" and ""Prediction of human population responses to toxic compounds by a collaborative competition"" are available here: http://arxiv.org/pdf/1503.01445.pdf http://www.nature.com/nbt/journal/v33/n9/full/nbt.3299.html The paper ""A Comparison of Algorithms and Humans For Mitosis Detection"" is available here: http://people.idsia.ch/~juergen/deeplearningwinsMICCAIgrandchallenge.html http://people.idsia.ch/~ciresan/data/isbi2014.pdf Kaggle-related things: http://kaggle.com https://www.kaggle.com/c/dato-native http://blog.kaggle.com/2015/12/03/dato-winners-interview-1st-place-mad-professors/ The paper ""Deep AutoRegressive Networks"" is available here: http://arxiv.org/pdf/1310.8499v2.pdf https://www.youtube.com/watch?v=-yX1S... The furniture completion paper, ""Data-driven Structural Priors for Shape Completion"" is available here: http://cs.stanford.edu/~mhsung/projects/structure-completion Data-driven fluid simulations using regression forests: https://graphics.ethz.ch/~sobarbar/papers/Lad15/DatadrivenFluids.mov https://www.inf.ethz.ch/personal/ladickyl/fluid sigasia15.pdf Selfies and convolutional neural networks: http://karpathy.github.io/2015/10/25/selfie/ Multiagent Cooperation and Competition with Deep Reinforcement Learning: http://arxiv.org/abs/1511.08779 https://www.youtube.com/watch?v=Gb9Dp... https://github.com/NeuroCSUT/DeepMind-Atari-Deep-Q-Learner-2Player Kaggle automatic essay scoring contest: https://www.kaggle.com/c/asap-aes http://www.vikparuchuri.com/blog/on-the-automated-scoring-of-essays/ Great talks on Kaggle: https://www.youtube.com/watch?v=9Zag7... https://www.youtube.com/watch?v=OKOlO... https://www.youtube.com/watch?v=R9Qxu... The thumbnail image was created by Barn Images - https://flic.kr/p/xxBc94";19.0;1523.0;['http://arxiv.org/pdf/1503.01445.pdf', 'http://www.nature.com/nbt/journal/v33/n9/full/nbt.3299.html', 'http://people.idsia.ch/~juergen/deeplearningwinsMICCAIgrandchallenge.html', 'http://people.idsia.ch/~ciresan/data/isbi2014.pdf', 'http://kaggle.com', 'https://www.kaggle.com/c/dato-native', 'http://blog.kaggle.com/2015/12/03/dato-winners-interview-1st-place-mad-professors/', 'http://arxiv.org/pdf/1310.8499v2.pdf', 'http://cs.stanford.edu/~mhsung/projects/structure-completion', 'https://graphics.ethz.ch/~sobarbar/papers/Lad15/DatadrivenFluids.mov', 'https://www.inf.ethz.ch/personal/ladickyl/fluid_sigasia15.pdf', 'http://karpathy.github.io/2015/10/25/selfie/', 'http://arxiv.org/abs/1511.08779', 'https://github.com/NeuroCSUT/DeepMind-Atari-Deep-Q-Learner-2Player', 'https://www.kaggle.com/c/asap-aes', 'http://www.vikparuchuri.com/blog/on-the-automated-scoring-of-essays/', 'https://flic.kr/p/xxBc94'];['AI'];['neural network', 'reinforcement learning', 'predict', 'layer', 'machine learning', 'detect', 'convolutional neural network', 'deep learning', 'regression'];0.666;0.831;['AI', 'NN', 'DL', 'RL', 'CNN', 'Regression', 'ML'];9 Cool Deep Learning Applications;Toxicity Prediction using Deep Learning and Prediction of human population responses to toxic compounds by a collaborative competition are available here: http://arxiv.org/pdf/1503.01445.pdf http://www.nature.com/nbt/journal/v33/n9/full/nbt.3299.html;https://www.youtube.com/watch?v=Bui3DWs02h4;141272.0;223.0
2017-09-10;2021-02-01;"The paper ""Calipso: Physics-based Image and Video Editing through CAD Model Proxies"" is available here: https://arxiv.org/abs/1708.03748 Project page: http://mimesis.inria.fr/calipso/ Physics simulation by SOFA: http://www.sofa-framework.org Recommended for you: https://www.youtube.com/watch?v=BjwhM...";16.0;1917.0;[];[];['model', 'recommend'];0.678;0.799;['Recommender'];Physics-based Image and Video Editing;Calipso: Physics-based Image and Video Editing through CAD Model Proxies;https://www.youtube.com/watch?v=bVGubOt_jLI;43953.0;28.0
2017-08-16;2021-02-01;Some updates and clarifications follow: Update 1: we seem to have conflicting information on the training times - both 24 hours and 2 weeks was mentioned. We'll make sure to address this when the official paper appears. Update 2: more from OpenAI - https://blog.openai.com/more-on-dota-2/ Update 3: more reddit discussion on how to trick the bot into defeat: https://www.reddit.com/r/DotA2/comments/6t8qvs/openai bots were defeated atleast 50 times/ (thanks to nikre for the link) Update 4: an OpenAI employee provides more clarification on the training process - https://news.ycombinator.com/item?id=15001521 Apologies for the inaccuracies - I've watched every video and interview I could get my hands on and found quite a bit of conflicting information. I'll take this into consideration next time when something comes up without an official research paper. OpenAI's materials on their DOTA bot: https://blog.openai.com/dota-2/ Day9's DOTA learning videos are available here: https://www.youtube.com/playlist?list...;42.0;1388.0;['https://blog.openai.com/more-on-dota-2/', 'https://www.reddit.com/r/DotA2/comments/6t8qvs/openai_bots_were_defeated_atleast_50_times/', 'https://news.ycombinator.com/item?id=15001521', 'https://blog.openai.com/dota-2/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/'];['AI'];['train'];0.661;0.789;['AI'];OpenAI's Bot Beats DOTA World Champion Dendi;;https://www.youtube.com/watch?v=cLC_GHZCOVQ;31567.0;140.0
2016-09-12;2021-02-01;"Let's talk about Google DeepMind's Wavenet! This piece of work is about generating audio waveforms for Text To Speech and more. Text To Speech basically means that we have a voice reading whatever we have written down. The difference in this work, is, however that it can synthesize these samples in someone's voice provided that we have training samples of this person speaking. The paper ""WaveNet: A Generative Model for Raw Audio"" is available here: https://arxiv.org/abs/1609.03499 The blog post about this with the sound samples is available here: https://deepmind.com/blog/wavenet-generative-model-raw-audio/ The machine learning reddit thread about this paper is available here: https://www.reddit.com/r/MachineLearning/comments/51sr9t/deepmind wavenet a generative model for raw audio/?ref=search posts Recommended for you: Every Two Minute Papers episode on deep learning: https://www.youtube.com/playlist?list...";31.0;2213.0;['https://arxiv.org/abs/1609.03499', 'https://deepmind.com/blog/wavenet-generative-model-raw-audio/', 'https://www.reddit.com/r/MachineLearning/comments/51sr9t/deepmind_wavenet_a_generative_model_for_raw_audio/?ref=search_posts', 'https://experiment.com/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/hu/spektrum-hangsz%C3%ADnszab%C3%A1lyz%C3%B3-h%C3%A1tt%C3%A9r-545827/'];[];['machine learning', 'train', 'deep learning', 'model', 'recommend'];0.684;0.825;['ML', 'Recommender', 'DL'];WaveNet by Google DeepMind;WaveNet: A Generative Model for Raw Audio;https://www.youtube.com/watch?v=CqFIVCD1WWo;111355.0;121.0
2016-12-10;2021-02-01;"The paper ""Multiphase SPH Simulation for Interactive Fluids and Solids"" is available here: http://cg.cs.tsinghua.edu.cn/papers/S... http://cg.cs.tsinghua.edu.cn/research...";2.0;306.0;[];[];[];0.576;0.742;[];Multiphase Fluid Simulations;Multiphase SPH Simulation for Interactive Fluids and Solids;https://www.youtube.com/watch?v=cUWDeDRet4c;8322.0;15.0
2016-08-25;2021-02-01;"Filigrees are detailed, thin patterns typically found in jewelry, fabrics and ornaments, and as you may imagine, crafting such motifs on objects is incredibly laborious. This project is about leaving out the craftsmen from the equation by choosing a set of target filigree patterns and creating a complex shape out of them that can be easily 3D printed. The challenge lies in grouping and packing up these patterns to fill a surface evenly. Let's see what this piece of work has to say about the problem! The paper ""Synthesis of Filigrees for Digital Fabrication"" is available here: http://i.cs.hku.hk/~wkchen/projects/proj sig16.html Recommended for you: Our earlier video on optimization - https://www.youtube.com/watch?v=1ypV5...";2.0;267.0;['http://i.cs.hku.hk/~wkchen/projects/proj_sig16.html', 'https://experiment.com/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/'];[];['recommend'];0.567;0.731;['Recommender'];3D Printing With Filigree Patterns;Synthesis of Filigrees for Digital Fabrication;https://www.youtube.com/watch?v=cVZzkSaxKmY;6281.0;109.0
2018-05-10;2021-02-01;"The paper ""The Unreasonable Effectiveness of Deep Networks as a Perceptual Metric"" is available here: https://richzhang.github.io/PerceptualSimilarity/ Our";44.0;2616.0;['https://richzhang.github.io/PerceptualSimilarity/', 'https://users.cg.tuwien.ac.at/zsolnai/gfx/adaptive_metropolis/', 'https://users.cg.tuwien.ac.at/zsolnai/gfx/gaussian-material-synthesis/', 'https://pixabay.com/photo-1285294/'];[];[];0.692;0.817;[];This AI Reproduces Human Perception;The Unreasonable Effectiveness of Deep Networks as a Perceptual Metric;https://www.youtube.com/watch?v=DglrYx9F3UU;82769.0;17.0
2015-09-21;2021-02-01;"There are computer programs that can simulate the behavior of fluids, such as water, milk, honey and many others. However, creating detailed simulations takes a really long time, up to days even for a few seconds of video footage. Adaptive algorithms are a class of techniques that try to adapt at the problem that we have at hand. This adaptive method focuses computational resources to regions which are visible and have many fine details, and coarsens the simulation quality in regions that are not visible (or interesting). The resulting algorithm is much more efficient at simulating small scale turbulent details. Recommended for you - Wavelet Turbulence: https://www.youtube.com/watch?v=5xLSb... The paper ""Highly Adaptive Liquid Simulations on Tetrahedral Meshes"" is available here: http://pub.ist.ac.at/groupwojtan/pro... Disclaimer: I was not part of this research project, I am merely providing commentary on this work. Music: ""Awakening"" by Silent Partner";15.0;2276.0;['http://pub.ist.ac.at/group_wojtan/projects/2013_Ando_HALSoTM/index.html'];[];['recommend'];0.686;0.811;['Recommender'];Adaptive Fluid Simulations;Highly Adaptive Liquid Simulations on Tetrahedral Meshes;https://www.youtube.com/watch?v=dH1s49-lrBk;65779.0;142.0
2017-01-04;2021-02-01;"The paper ""Interactive Indirect Illumination Using Voxel Cone Tracing"" is available here: https://research.nvidia.com/publication/interactive-indirect-illumination-using-voxel-cone-tracing Implementations (without highlighting a particular one): https://goo.gl/AZeWAU Our post on";54.0;3222.0;['https://research.nvidia.com/publication/interactive-indirect-illumination-using-voxel-cone-tracing', 'https://goo.gl/AZeWAU', 'https://www.patreon.com/posts/improvements-for-7607896', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-1872196/'];[];[];0.702;0.831;[];Stunning Video Game Graphics With Voxel Cone Tracing (VXGI);Interactive Indirect Illumination Using Voxel Cone Tracing;https://www.youtube.com/watch?v=dQSzmngTbtw;141244.0;23.0
2017-11-05;2021-02-01;"The paper ""Unsupervised Image-to-Image Translation Networks"" and its source code is available here: https://arxiv.org/pdf/1703.00848.pdf https://github.com/mingyuliutw/UNIT";10.0;2227.0;['https://arxiv.org/pdf/1703.00848.pdf', 'https://github.com/mingyuliutw/UNIT', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://flic.kr/p/UASi2i'];[];[];0.685;0.809;[];Video Game Graphics To Reality And Back;Unsupervised Image-to-Image Translation Networks and its source code;https://www.youtube.com/watch?v=dqxqbvyOnMY;61407.0;15.0
2017-09-27;2021-02-01;"The paper ""Hindsight Experience Replay"" is available here: https://arxiv.org/pdf/1707.01495.pdf Our";16.0;1036.0;['https://arxiv.org/pdf/1707.01495.pdf', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-1193318/'];[];[];0.646;0.779;[];Hindsight Experience Replay;Hindsight Experience Replay;https://www.youtube.com/watch?v=Dvd1jQe3pq0;23287.0;10.0
2018-02-04;2021-02-01;"The paper ""Better Exploration with Parameter Noise"" and its source code is available here: https://arxiv.org/abs/1706.01905 https://github.com/openai/baselines The write-up and our";11.0;824.0;['https://arxiv.org/abs/1706.01905', 'https://github.com/openai/baselines', 'https://www.patreon.com/posts/technical-for-16738692', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-2560006/'];[];[];0.634;0.777;[];Reinforcement Learning With Noise (OpenAI);Better Exploration with Parameter Noise and its source code;https://www.youtube.com/watch?v=DW1AuOC9TQc;22380.0;20.0
2018-03-17;2021-02-01;"The paper ""DensePose: Dense Human Pose Estimation In The Wild"" is available here: https://arxiv.org/abs/1802.00434 http://densepose.org/ Our";14.0;1267.0;['https://arxiv.org/abs/1802.00434', 'http://densepose.org/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-3178198/'];[];[];0.657;0.787;[];AI Learns Human Pose Estimation From Videos;DensePose: Dense Human Pose Estimation In The Wild;https://www.youtube.com/watch?v=dxOHmvTaCN4;29851.0;16.0
2016-12-04;2021-02-01;"The paper ""Interactive Sound Propagation with Bidirectional Path Tracing"" is available here: http://gaps-zju.org/bst/ Veach's paper on Multiple Importance Sampling: http://www.cs.jhu.edu/~misha/ReadingSeminar/Papers/Veach95.pdf http://dl.acm.org/citation.cfm?id=218498 I am also holding a full course on light transport simulations at the Technical University of Vienna. There is plenty of discussion on path tracing and bidirectional path tracing therein: https://www.youtube.com/playlist?list...";13.0;751.0;['http://gaps-zju.org/bst/', 'http://www.cs.jhu.edu/~misha/ReadingSeminar/Papers/Veach95.pdf', 'http://dl.acm.org/citation.cfm?id=218498', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://commons.wikimedia.org/wiki/File:Dubrovnik,_palazzo_sponza,_cortile_02.JPG'];[];['propagation'];0.629;0.777;[];Sound Propagation With Bidirectional Path Tracing;Interactive Sound Propagation with Bidirectional Path Tracing;https://www.youtube.com/watch?v=DzsZ2qMtEUE;22323.0;52.0
2015-11-07;2021-02-01;"This technique is a combination of two powerful machine learning algorithms: - convolutional neural networks are excellent at image classification, i.e., finding out what is seen on an input image, - recurrent neural networks that are capable of processing a sequence of inputs and outputs, therefore it can create sentences of what is seen on the image. Combining these two techniques makes it possible for a computer to describe in a sentence what is seen on an input image. The paper ""Deep Visual-Semantic Alignments for Generating Image Descriptions"" is available here: http://cs.stanford.edu/people/karpathy/deepimagesent/ A gallery with more results with the same algorithm: http://cs.stanford.edu/people/karpathy/deepimagesent/ You can train your own convolutional neural network here: http://cs.stanford.edu/people/karpathy/deepimagesent/ The source code for the project is now available here: https://github.com/karpathy/neuraltalk2";4.0;508.0;['http://cs.stanford.edu/people/karpathy/deepimagesent/', 'http://cs.stanford.edu/people/karpathy/deepimagesent/generationdemo/', 'http://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html', 'https://github.com/karpathy/neuraltalk2', 'https://flic.kr/p/qrRciQ'];[];['neural network', 'machine learning', 'convolutional neural network', 'recurrent neural network', 'train', 'classif', 'image classification'];0.607;0.781;['RNN', 'NN', 'Classification', 'CNN', 'ML'];Recurrent Neural Network Writes Sentences About Images;Deep Visual-Semantic Alignments for Generating Image Descriptions;https://www.youtube.com/watch?v=e-WB4lfg30M;24981.0;123.0
2017-07-23;2021-02-01;"The paper ""Light Field Video Capture Using a Learning-Based Hybrid Imaging System"" and its implementation is available here: https://arxiv.org/abs/1705.02997 https://github.com/junyanz/light-field-video Recommended for you: Amazing Slow Motion Videos With Optical Flow - https://www.youtube.com/watch?v=7aLda... Two Minute Papers Merch: US: http://twominutepapers.com/ EU/Worldwide: https://shop.spreadshirt.net/TwoMinutePapers/";10.0;1033.0;['https://arxiv.org/abs/1705.02997', 'https://github.com/junyanz/light-field-video', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-272263/'];[];['recommend'];0.646;0.78;['Recommender'];Refocusing Videos With Neural Networks;Light Field Video Capture Using a Learning-Based Hybrid Imaging System and its implementation;https://www.youtube.com/watch?v=EGnbAgbRIh4;24128.0;40.0
2018-06-06;2021-02-01;"The paper ""HeadOn: Real-time Reenactment of Human Portrait Videos"" is available here: http://niessnerlab.org/projects/thies2018headon.html More on Apple's Memoji: https://www.youtube.com/watch?v=CjqER... Our";31.0;1673.0;['http://niessnerlab.org/projects/thies2018headon.html', 'https://pixabay.com/photo-1867320/'];[];[];0.671;0.797;[];This Technique Impersonates People;HeadOn: Real-time Reenactment of Human Portrait Videos;https://www.youtube.com/watch?v=EQX1wsL2TSs;41437.0;19.0
2015-10-14;2021-02-01;"Metropolis light transport is an advanced photorealistic rendering technique that is remarkably effective at finding the brighter regions of a scene and building many light paths that target these regions. The resulting algorithm is more efficient than traditional random path building algorithms, such as path tracing. The paper ""Metropolis Light Transport"" by Veach and Guibas is available here: https://graphics.stanford.edu/papers/metro/ I held a course on photorealistic rendering at the Technical University of Vienna. Here you can learn how the physics of light works and to write programs like this: https://www.youtube.com/playlist?list... Recommended for you: Manipulating Photorealistic Renderings - https://www.youtube.com/watch?v=L7MOe... Ray Tracing, Subsurface Scattering @ Function 2015 - https://www.youtube.com/watch?v=qyDUv... A more elaborate discussion on Metropolis Light Transport - https://www.youtube.com/watch?v=Zl36H... Eric Veach's Sci-tech award speech: https://www.youtube.com/watch?v=e3ss... Scene credits: Italian Still Life - Bhavin Solanki - http://www.blendswap.com/blends/view/67815 Spheres - Vlad Miller (SATtva) - http://www.luxrender.net/wiki/Show-off pack Music: ""Bet On It"" by Silent Partner. A higher resolution version of the sphere scene comparison is available here: https://cg.tuwien.ac.at/~zsolnai/gfx/adaptive metropolis/ The image from fxguide is available here: http://www.fxguide.com/featured/the-state-of-rendering-part-2/";1.0;623.0;['https://graphics.stanford.edu/papers/metro/', 'http://www.blendswap.com/blends/view/67815', 'http://www.luxrender.net/wiki/Show-off_pack', 'https://cg.tuwien.ac.at/~zsolnai/gfx/adaptive_metropolis/', 'http://www.fxguide.com/featured/the-state-of-rendering-part-2/'];[];['recommend'];0.619;0.775;['Recommender'];Metropolis Light Transport;Metropolis Light Transport by Veach and Guibas;https://www.youtube.com/watch?v=f0Uzit_-h3M;21125.0;169.0
2016-12-01;2021-02-01;"The paper ""Dispersion Kernels for Water Wave Simulation"" is available here: http://www.gmrv.es/Publications/2016/... Recommended for you: Rocking Out With Convolutions - https://www.youtube.com/watch?v=JKYQO... Separable Subsurface Scattering - https://www.youtube.com/watch?v=72iA...";3.0;290.0;[];[];['recommend'];0.572;0.735;['Recommender'];Water Wave Simulation with Dispersion Kernels;Dispersion Kernels for Water Wave Simulation;https://www.youtube.com/watch?v=FeMSEaHR8aw;7039.0;26.0
2017-06-10;2021-02-01;"The paper ""pix2code: Generating Code from a Graphical User Interface Screenshot"" is available here: https://arxiv.org/abs/1705.07962 https://github.com/tonybeltramelli/pix2code Recommended for you: Recurrent Neural Network Writes Music and Shakespeare Novels - https://www.youtube.com/watch?v=Jkkjy... Two Minute Papers Merch: US: http://twominutepapers.com/ EU/Worldwide: https://shop.spreadshirt.net/TwoMinutePapers/";119.0;3089.0;['https://arxiv.org/abs/1705.07962', 'https://github.com/tonybeltramelli/pix2code', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-583839/'];[];['neural network', 'recommend', 'recurrent neural network'];0.699;0.83;['Recommender', 'NN', 'RNN'];AI Learns To Create User Interfaces (pix2code);pix2code: Generating Code from a Graphical User Interface Screenshot;https://www.youtube.com/watch?v=Fevg4aowNyc;134425.0;37.0
2018-05-15;2021-02-01;"The paper ""Deep Painterly Harmonization"" and its source code is available here: https://arxiv.org/abs/1804.03189 https://github.com/luanfujun/deep-painterly-harmonization Pick up cool perks on";8.0;2014.0;['https://arxiv.org/abs/1804.03189', 'https://github.com/luanfujun/deep-painterly-harmonization', 'https://pixabay.com/photo-3129429/'];[];[];0.68;0.79;[];AI Learns Painterly Harmonization;Deep Painterly Harmonization and its source code;https://www.youtube.com/watch?v=fklY2nH7AJo;32569.0;19.0
2016-10-29;2021-02-01;"We have had plenty of episodes about fluid simulations, so how about some tasty soft body dynamics for today? Soft body dynamics basically means computing what happens when we smash together different deformable objects. Examples include folding sheets, playing around with noodles, or torturing armadillos. I think this is a nice and representative showcase of the immense joys of computer graphics research! Clarification: the 15 ms per frame execution time is a nice ballpark number, but it depends on the scene. The paper ""Vivace: a Practical Gauss-Seidel Method for Stable Soft Body Dynamics"" is available here: http://pellacini.di.uniroma1.it/publications/vivace16/vivace16.html";6.0;553.0;['http://pellacini.di.uniroma1.it/publications/vivace16/vivace16.html', 'https://pixabay.com/photo-1747663/', 'https://commons.wikimedia.org/wiki/File:Complete_coloring_clebsch_graph.svg', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/'];[];[];0.612;0.762;[];Real-Time Soft Body Dynamics for Video Games;Vivace: a Practical Gauss-Seidel Method for Stable Soft Body Dynamics;https://www.youtube.com/watch?v=fl-7e8yBUic;14434.0;97.0
2016-07-17;2021-02-01;"The Scholarly Store is available here: https://shop.spreadshirt.net/TwoMinutePapers Using the power of deep learning, it is now possible to create a technique that looks at a silent video and synthesize appropriate sound effects for it. The usage is at the moment, limited to hitting these objects with a drumstick. Note: The authors seem to lean on a database of sounds, i.e., the synthesis does not happen from scratch, but they are not merely fetching the database entry for a given sound, but performing example-based synthesis (Section 5.2 in the paper below). In the video and the paper, they both use the words ""synthesized sound"" and ""predicted sound"", and it may be a bit unclear what degree of synthesis qualifies as a ""synthesized sound"". I think this is definitely worthy of further scrutiny. The paper ""Visually Indicated Sounds"" is available here: https://arxiv.org/abs/1512.08512 Recommended for you: What Do Virtual Objects Sound Like? - https://www.youtube.com/watch?v=ZaFqv... Synthesizing Sound From Collisions - https://www.youtube.com/watch?v=rskdL... Reconstructing Sound From Vibrations - https://www.youtube.com/watch?v=2i1hr... Our deep learning-related videos are available here (if you are looking for convolutional neural networks, recurrent neural networks): https://www.youtube.com/playlist?list...";2.0;248.0;['https://arxiv.org/abs/1512.08512', 'https://experiment.com/', 'https://flic.kr/p/9x93qE'];[];['neural network', 'predict', 'convolutional neural network', 'recurrent neural network', 'deep learning', 'recommend'];0.562;0.734;['Recommender', 'RNN', 'DL', 'NN', 'CNN'];Visually Indicated Sounds;Visually Indicated Sounds;https://www.youtube.com/watch?v=flOevlA9RyQ;6805.0;182.0
2018-01-30;2021-02-01;"The paper ""Objects that Sound"" is available here: https://arxiv.org/abs/1712.06651 https://www.youtube.com/watch?v=TFyoh... https://www.youtube.com/watch?v=xqus... Our";11.0;853.0;['https://arxiv.org/abs/1712.06651', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-756326/'];[];[];0.636;0.773;[];DeepMind's AI Learns Object Sounds;Objects that Sound;https://www.youtube.com/watch?v=FMEk8cHF-OA;19691.0;12.0
2018-01-21;2021-02-01;"The paper ""Autonomous Reconstruction of Unknown Indoor Scenes Guided by Time-varying Tensor Fields"" and its source code is available here: http://vcc.szu.edu.cn/research/2017/tfnav/";8.0;947.0;['http://vcc.szu.edu.cn/research/2017/tfnav/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-2732939/'];[];[];0.642;0.772;[];This Autonomous Robot Models Your House Interior;Autonomous Reconstruction of Unknown Indoor Scenes Guided by Time-varying Tensor Fields and its source code;https://www.youtube.com/watch?v=fTBeNAu18_s;19053.0;21.0
2016-08-08;2021-02-01;"The 2016 Rio Olympic Games is right around the corner, so it is the perfect time to talk a bit about how we can use science to predict the results. Daniel Johnson, a professor of microeconomics at the Colorado College created a simple prediction model, that, over the past 5 Olympic Games, was able to achieve 94% agreement between the predicted and actual medal counts per nation. What is even more amazing is that the model doesn't even take into consideration the athletic abilities of any of these contenders. The paper ""A Tale of Two Seasons: Participation and Medal Counts at the Summer and Winter Olympic Games"" is available here: https://www.researchgate.net/profile/Daniel Johnson7/publication/4920482 A Tale of Two Seasons Participation and Medal Counts at the Summer and Winter Olympic Games/links/0c9605229d43e35dbf000000.pdf A media article about this on Forbes: http://www.forbes.com/2010/01/19/olympic-medal-predictions-business-sports-medals.html The Olympics subreddit is available here: https://www.reddit.com/r/olympics/ From an earlier episode: Two Minute Papers - Narrow Band Liquid Simulations - https://www.youtube.com/watch?v=nfPBT...";0.0;109.0;['https://www.researchgate.net/profile/Daniel_Johnson7/publication/4920482_A_Tale_of_Two_Seasons_Participation_and_Medal_Counts_at_the_Summer_and_Winter_Olympic_Games/links/0c9605229d43e35dbf000000.pdf', 'http://www.forbes.com/2010/01/19/olympic-medal-predictions-business-sports-medals.html', 'https://www.reddit.com/r/olympics/', 'https://experiment.com/', 'https://flic.kr/p/efKqca'];[];['model', 'predict'];0.506;0.699;[];The Science of Medal Predictions (2016 Rio Olympics Edition);A Tale of Two Seasons: Participation and Medal Counts at the Summer and Winter Olympic Games;https://www.youtube.com/watch?v=gHMY40kEXzs;2972.0;157.0
2017-10-01;2021-02-01;"The paper ""Position-Normal Distributions for Efficient Rendering of Specular Microstructure"" is available here: http://people.eecs.berkeley.edu/~ling... http://people.eecs.berkeley.edu/~lingqi/ Vienna Rendering course: https://users.cg.tuwien.ac.at/zsolnai... https://www.youtube.com/playlist?list...";9.0;723.0;[];[];[];0.627;0.765;[];Light Transport on Specular Microstructure;Position-Normal Distributions for Efficient Rendering of Specular Microstructure;https://www.youtube.com/watch?v=GNx8rgNcw5c;15412.0;20.0
2018-05-06;2021-02-01;"The paper ""World Models"" is available here: https://arxiv.org/abs/1803.10122 https://worldmodels.github.io/ Support the series and pick up cool perks on our";16.0;2255.0;[];[];['model'];0.686;0.796;[];This AI Learns From Its Dreams;World Models;https://www.youtube.com/watch?v=gvjCu7zszbQ;39829.0;19.0
2018-02-22;2021-02-01;"The paper ""A Neural Parametric Singing Synthesizer"" is available here: http://www.dtic.upf.edu/~mblaauw/NPSS/ Our";13.0;1600.0;['http://www.dtic.upf.edu/~mblaauw/NPSS/', 'https://goo.gl/z6zxuT', 'https://open.spotify.com/album/0ZKglE5xlIqsWmtQHn9WxZ', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://flic.kr/p/GAhDRa'];[];[];0.669;0.796;[];This AI Sings;A Neural Parametric Singing Synthesizer;https://www.youtube.com/watch?v=HANeLG0l2GA;39765.0;12.0
2016-08-14;2021-02-01;There are some minor changes coming to Two Minute Papers, and I am trying my very best to make it as enjoyable as possible to you, so I would really like to hear your opinion on an issue. The earlier episode showcased in the video: Schrdinger's Smoke - https://www.youtube.com/watch?v=heY2g...;1.0;135.0;['https://experiment.com/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://flic.kr/p/84QwGn'];[];[];0.521;0.702;[];On the Complexity of Two Minute Papers;;https://www.youtube.com/watch?v=heB2tD0-r-c;3213.0;49.0
2016-06-05;2021-02-01;"Today we will talk about Eulerian and Lagrangian smoke and fluid simulations and how this excellent technique can incorporate a variant of Schrdinger's equation and make an excellent fluid simulator out of it. :) The paper ""Schrdinger's Smoke"" and its implementation is available here: http://multires.caltech.edu/pubs/SchrodingersSmoke.pdf http://multires.caltech.edu/pubs/SchrodingersSmoke.pdf The publisher's version is expected to show up here soon: http://www.multires.caltech.edu/pubs/pubs.htm The Short Science website is available here: http://www.shortscience.org/";6.0;1189.0;['http://multires.caltech.edu/pubs/SchrodingersSmoke.pdf', 'http://multires.caltech.edu/pubs/SchrodingersSmokeCode.zip', 'http://www.multires.caltech.edu/pubs/pubs.htm', 'http://www.shortscience.org/'];[];[];0.654;0.788;[];Schrdinger's Smoke;Schrdinger's Smoke and its implementation;https://www.youtube.com/watch?v=heY2gfXSHBo;30567.0;65.0
2016-06-19;2021-02-01;"During our journeys in deep learning, we have seen techniques that can summarize photographs in entire sentences that actually make sense. This time, we are going to turn this process around and ask a deep learning system to ""hallucinate"", i.e., generate images according to sentences that we add as an input. The results are nothing short of insane! The paper ""Generative Adversarial Text to Image Synthesis"" is available here: http://arxiv.org/abs/1605.05396 Recommended for you: Recurrent Neural Network Writes Sentences About Images - https://www.youtube.com/watch?v=e-WB4... Deep Learning related Two Minute Papers episodes - https://www.youtube.com/playlist?list...";6.0;458.0;['http://arxiv.org/abs/1605.05396', 'https://experiment.com/', 'https://flic.kr/p/GDm4Jd'];[];['neural network', 'deep learning', 'recommend', 'recurrent neural network'];0.6;0.777;['RNN', 'Recommender', 'NN', 'DL'];Hallucinating Images With Deep Learning;Generative Adversarial Text to Image Synthesis;https://www.youtube.com/watch?v=hnT-P3aALVE;22210.0;91.0
2017-01-25;2021-02-01;"The paper ""Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling"" and its source code is available here: http://3dgan.csail.mit.edu/ https://arxiv.org/pdf/1610.07584v2.pdf More about generative adversarial networks (and some explanations): Image Editing with Generative Adversarial Networks - https://www.youtube.com/watch?v=pqkpI... Image Synthesis From Text With Deep Learning - https://www.youtube.com/watch?v=rAbhy...";8.0;1486.0;[];[];['deep learning', 'model', 'generative adversarial network'];0.665;0.81;['GAN', 'DL'];AI Makes 3D Models From Photos;Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling and its source code;https://www.youtube.com/watch?v=HO1LYJb818Q;65115.0;48.0
2015-10-03;2021-02-01;"Machine learning techniques such as deep learning artificial neural networks had proven to be extremely useful for a variety of tasks that were previously deemed very difficult, or even impossible to solve. In this work, a deep learning technique is used to learn how different light source positions affect a scene and create (""guess"") new photographs with unknown light source positions. The results are absolutely stunning. The promised links for artificial neural networks follow below. The paper ""Image Based Relighting Using Neural Networks"" is available here: http://research.microsoft.com/en-us/um/people/yuedong/project/neuralibr/neuralibr.htm Disclaimer: I was not part of this research project, I am merely providing commentary on this work. Recommended for you: Artificial Neural Networks and Deep Learning - https://www.youtube.com/watch?v=rCWTO... Deep Neural Network Learns Van Gogh's Art - https://www.youtube.com/watch?v=-R9bJ... Music: ""The Place Inside"" by Silent Partner";5.0;864.0;['http://research.microsoft.com/en-us/um/people/yuedong/project/neuralibr/neuralibr.htm'];[];['neural network', 'machine learning', 'artificial neural network', 'deep learning', 'recommend'];0.637;0.789;['Recommender', 'NN', 'DL', 'ANN', 'ML'];Creating Photographs Using Deep Learning;Image Based Relighting Using Neural Networks;https://www.youtube.com/watch?v=HOLoPgTzV6g;31953.0;131.0
2016-03-13;2021-02-01;In this episode, we present another round of incredible deep learning applications! 1. Colorization - http://tinyclouds.org/colorize/ 2. RNN Music on Bob Sturm's YouTube channel - https://www.youtube.com/watch?v=RaO4H... 3. Flow Machines by Sony - https://www.youtube.com/watch?v=buXqN... 4. RNN Passwords - https://github.com/gehaxelt/RNN-Passwords 5. Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding - http://arxiv.org/abs/1510.00149 6. Right Whale Kaggle Competition - http://felixlaumon.github.io/2015/01/08/kaggle-right-whale.html 7. Improving YouTube video thumbnails - http://youtube-eng.blogspot.hu/2015/10/improving-youtube-video-thumbnails-with 8.html 8. Celebrity super-resolution: https://github.com/mikesj-public/dcgan-autoencoder 9. Convolutional Neural Network visualization - http://scs.ryerson.ca/~aharley/vis/conv/ + Paper: http://scs.ryerson.ca/~aharley/vis/harley vis isvc15.pdf 10. DarkNet RNN writes in the style of George RR Martin - http://pjreddie.com/darknet/rnns-in-darknet/;27.0;1509.0;['http://tinyclouds.org/colorize/', 'https://github.com/gehaxelt/RNN-Passwords', 'http://arxiv.org/abs/1510.00149', 'http://felixlaumon.github.io/2015/01/08/kaggle-right-whale.html', 'http://youtube-eng.blogspot.hu/2015/10/improving-youtube-video-thumbnails-with_8.html', 'https://github.com/mikesj-public/dcgan-autoencoder', 'http://scs.ryerson.ca/~aharley/vis/conv/', 'http://scs.ryerson.ca/~aharley/vis/harley_vis_isvc15.pdf', 'http://pjreddie.com/darknet/rnns-in-darknet/', 'https://flic.kr/p/deHtEb'];['RNN', 'NN'];['neural network', 'autoencoder', 'convolutional neural network', 'train', 'deep learning'];0.666;0.822;['DL', 'RNN', 'NN', 'CNN'];10 More Cool Deep Learning Applications;;https://www.youtube.com/watch?v=hPKJBXkyTKM;100816.0;98.0
2017-08-19;2021-02-01;"The paper ""Spatiotemporal Variance-Guided Filtering: Real-Time Reconstruction for Path-Traced Global Illumination"" is available here: http://cg.ivd.kit.edu/svgf.php";8.0;1884.0;[];[];['filter'];0.677;0.808;[];Real-Time Noise Filtering For Light Simulations;Spatiotemporal Variance-Guided Filtering: Real-Time Reconstruction for Path-Traced Global Illumination;https://www.youtube.com/watch?v=HSmm_vEVs10;59633.0;15.0
2017-05-03;2021-02-01;"The paper ""Deep Photo Style Transfer"" is and its source code is available here: https://arxiv.org/pdf/1703.07511.pdf https://github.com/luanfujun/deep-photo-styletransfer One more different implementation: https://github.com/martinbenson/deep-photo-styletransfer Two Minute Papers Merch: US: http://twominutepapers.com/ EU/Worldwide: https://shop.spreadshirt.net/TwoMinutePapers/ Distill: http://distill.pub/ Distill article on research debt: http://distill.pub/2017/research-debt/ Recommended for you: How Do Neural Networks See The World? - https://www.youtube.com/watch?v=hBobY...";7.0;649.0;['https://arxiv.org/pdf/1703.07511.pdf', 'https://github.com/luanfujun/deep-photo-styletransfer', 'https://github.com/martinbenson/deep-photo-styletransfer', 'http://distill.pub/', 'http://distill.pub/2017/research-debt/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-1598418/'];[];['neural network', 'recommend'];0.621;0.77;['Recommender', 'NN'];Deep Photo Style Transfer;Deep Photo Style Transfer is and its source code;https://www.youtube.com/watch?v=HTUxsrO-P_8;17865.0;49.0
2017-07-12;2021-02-01;"The paper ""Inside Fluids: Clebsch Maps for Visualization and Processing"" and its source code are available here: http://multires.caltech.edu/pubs/Clebsch.pdf http://multires.caltech.edu/pubs/Clebsch.pdf Recommended for you: Schrdinger's Smoke - https://www.youtube.com/watch?v=heY2g... Two Minute Papers Merch: US: http://twominutepapers.com/ EU/Worldwide: https://shop.spreadshirt.net/TwoMinutePapers/";7.0;704.0;['http://multires.caltech.edu/pubs/Clebsch.pdf', 'http://multires.caltech.edu/pubs/ClebschCodes.zip', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-2427263/'];[];['recommend'];0.626;0.769;['Recommender'];Visualizing Fluid Flow With Clebsch Maps;Inside Fluids: Clebsch Maps for Visualization and Processing and its source code are available here: http://multires.caltech.edu/pubs/Clebsch.pdf http://multires.caltech.edu/pubs/Clebsch.pdf Recommended for you: Schrdinger's Smoke - https://www.youtube.com/watch?v=heY2g... Two Minute Papers Merch: US: http://twominutepapers.com/ EU/Worldwide: https://shop.spreadshirt.net/TwoMinutePapers/ WE WOULD LIKE TO THANK OUR GENEROUS PATREON SUPPORTERS WHO MAKE TWO MINUTE PAPERS POSSIBLE: Andrew Melnychuk, Christian Lawson, Dave Rushton-Smith, Dennis Abts, e, Esa Turkulainen, Kaben Gabriel Nanlohy, Michael Albrecht, Michael Orenstein, Sunil Kim, Torsten Reil, VR Wizard. https://www.patreon.com/TwoMinutePapers Music: Antarctica by Audionautix is licensed under a Creative Commons Attribution license (https://creativecommons.org/licenses/by/4.0/) Artist: http://audionautix.com/ Thumbnail background image credit: https://pixabay.com/photo-2427263/ Splash screen/thumbnail design: Felcia Fehr - http://felicia.hu Kroly Zsolnai-Fehr's links: Facebook  https://www.facebook.com/TwoMinutePapers/ Twitter  https://twitter.com/karolyzsolnai Web  https://cg.tuwien.ac.at/~zsolnai/;https://www.youtube.com/watch?v=HUFh8cEDeII;17525.0;34.0
2016-08-29;2021-02-01;"We have talked about fluid and cloth simulations earlier, but we never really set foot in the domain of hair simulations in the series. To obtain some footage of virtual hair movement, simulating the dynamics of hundreds of thousands of hair strands is clearly too time consuming and would be a flippant attempt to do so. In this episode, we discuss a technique to faithfully simulate 150 thousand hair strands by using only 400 guide hairs. The paper ""Adaptive Skinning for Interactive Hair-Solid Simulation"" is available here: http://gaps-zju.org/mlchai/resources/chai2016adaptive.pdf http://gaps-zju.org/mlchai/ Two Minute Papers offers great perks to supporters on";3.0;467.0;['http://gaps-zju.org/mlchai/resources/chai2016adaptive.pdf', 'http://gaps-zju.org/mlchai/', 'https://experiment.com/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://flic.kr/p/dayCjn'];[];[];0.602;0.76;[];Interactive Hair-Solid Simulations;Adaptive Skinning for Interactive Hair-Solid Simulation;https://www.youtube.com/watch?v=HvHZXPd0Bjs;13415.0;98.0
2018-03-01;2021-02-01;"The paper ""Parallel WaveNet: Fast High-Fidelity Speech Synthesis"" is available here: https://arxiv.org/abs/1711.10433 Our";19.0;1888.0;[];[];[];0.677;0.799;[];DeepMind's WaveNet, 1000 Times Faster;Parallel WaveNet: Fast High-Fidelity Speech Synthesis;https://www.youtube.com/watch?v=hzpxXZJQNFg;44409.0;13.0
2016-01-31;2021-02-01;"This time around, Google DeepMind embarked on a journey to write an algorithm that plays Go. Go is an ancient chinese board game where the opposing players try to capture each other's stones on the board. Behind the veil of this deceptively simple ruleset, lies an enormous layer of depth and complexity. As scientists like to say, the search space of this problem is significantly larger than that of chess. So large, that one often has to rely on human intuition to find a suitable next move, therefore it is not surprising that playing Go on a high level is, or maybe was widely believed to be intractable for machines. The result is Google DeepMind's AlphaGo, the deep learning technique that defeated a professional player and European champion, Fan Hui. The paper ""Mastering the Game of Go with Deep Neural Networks and Tree Search"" is available here: https://storage.googleapis.com/deepmind-data/assets/papers/deepmind-mastering-go.pdf http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html Wired's coverage of AlphaGo: http://www.wired.com/2016/01/in-a-huge-breakthrough-googles-ai-beats-a-top-player-at-the-game-of-go/ Video coverage from DeepMind and Nature: https://www.youtube.com/watch?v=g-dKX... https://www.youtube.com/watch?v=SUbqy... Myungwan Kim analysis: https://www.youtube.com/watch?v=NHRHU... Photo credits: Watson - AP Photo/Jeopardy Productions, Inc. Fan Hui match photo - Google DeepMind - https://www.youtube.com/watch?v=SUbqy... Go board image credits (all CC BY 2.0): Renato Ganoza - https://flic.kr/p/7nX4kK Jaro Larnos (changes were applied, mostly recoloring) - https://flic.kr/p/dDeQU9 Luis de Bethencourt - https://flic.kr/p/4c5RaR Detailed analysis of the games against Fan Hui and some more speculation: https://www.reddit.com/r/MachineLearning/comments/43fl90/synopsis of top go professionals analysis of/";10.0;332.0;['https://storage.googleapis.com/deepmind-data/assets/papers/deepmind-mastering-go.pdf', 'http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html', 'http://www.wired.com/2016/01/in-a-huge-breakthrough-googles-ai-beats-a-top-player-at-the-game-of-go/', 'https://flic.kr/p/7nX4kK', 'https://flic.kr/p/dDeQU9', 'https://flic.kr/p/4c5RaR', 'https://www.reddit.com/r/MachineLearning/comments/43fl90/synopsis_of_top_go_professionals_analysis_of/'];[];['layer', 'deep learning', 'neural network'];0.58;0.784;['NN', 'DL'];How DeepMind Conquered Go With Deep Learning (AlphaGo);Mastering the Game of Go with Deep Neural Networks and Tree Search;https://www.youtube.com/watch?v=IFmj5M5Q5jg;27028.0;228.0
2015-11-22;2021-02-01;"Google DeepMind implemented an artificial intelligence program using deep reinforcement learning that plays Atari games and improves itself to a superhuman level. The technique is called deep Q-learning, it uses a combination of deep neural networks and reinforcement learning, and it is capable of playing many Atari games as good or better than humans. After presenting their initial results with the algorithm, Google almost immediately acquired the company for several hundred million dollars, hence the name Google DeepMind. I am sure that this is one of the biggest triumphs of deep learning, especially given the fact that now the first few successful experiments for 3D games are out there! The Nature paper ""Human-level control through deep reinforcement learning"" is available here: http://www.nature.com/nature/journal/v518/n7540/full/nature14236.html http://www.cs.swarthmore.edu/~meeden/cs63/s15/nature15b.pdf The code is available here: https://sites.google.com/a/deepmind.com/dqn/ Ilya Kuzovkin's fork with visualization: https://github.com/kuz/DeepMind-Atari-Deep-Q-Learner This configuration file will run Ilya Kuzovkin's version with less than 1GB of VRAM: http://cg.tuwien.ac.at/~zsolnai/wp/wp-content/uploads/2015/03/run gpu Recommended for you: Artificial Neural Networks and Deep Learning - https://www.youtube.com/watch?v=rCWTO... Recurrent Neural Network Writes Sentences About Images - https://www.youtube.com/watch?v=e-WB4... Deep Neural Network Learns Van Gogh's Art - https://www.youtube.com/watch?v=-R9bJ... Terrain Traversal with Reinforcement Learning - https://www.youtube.com/watch?v=yjHP...";17.0;755.0;['http://www.nature.com/nature/journal/v518/n7540/full/nature14236.html', 'http://www.cs.swarthmore.edu/~meeden/cs63/s15/nature15b.pdf', 'https://sites.google.com/a/deepmind.com/dqn/', 'https://github.com/kuz/DeepMind-Atari-Deep-Q-Learner', 'http://cg.tuwien.ac.at/~zsolnai/wp/wp-content/uploads/2015/03/run_gpu', 'https://flic.kr/p/76foMV'];[];['neural network', 'reinforcement learning', 'artificial intelligence', 'artificial neural network', 'recurrent neural network', 'deep learning', 'recommend'];0.629;0.8;['AI', 'RNN', 'NN', 'DL', 'ANN', 'Recommender', 'RL'];Google DeepMind's Deep Q-Learning & Superhuman Atari Gameplays;;https://www.youtube.com/watch?v=Ih8EfvOzBOY;45396.0;187.0
2016-01-12;2021-02-01;"This episode covers a paper from Disney Research on how to design 3D printable robots. In order to get a robot from A to B, one has to specify scientific attributes like trajectories and angular velocities. But people don't think in angular velocities, they think in intuitive actions, like moving forward, sideways, or even the style of a desired movement. Specifying these things instead would be much more useful, but also, scientifically quite challenging. One can specify the design of the robot, for instance, different shapes, motor positions, and joints can be added, and the technique finds out a physically plausible way for them to walk and move around. The paper ""Interactive Design of 3D Printable Robotic Creatures"" is available here: https://www.disneyresearch.com/publication/interactive-design-of-3d-printable-robotic-creatures/ Recommended for you: - Hydrographic Printing (in 3D) https://www.youtube.com/watch?v=kLnG0... - 3D Printing a Glockenspiel https://www.youtube.com/watch?v=2kOCT...";2.0;420.0;['https://www.disneyresearch.com/publication/interactive-design-of-3d-printable-robotic-creatures/'];[];['recommend'];0.596;0.753;['Recommender'];Designing 3D Printable Robotic Creatures;Interactive Design of 3D Printable Robotic Creatures;https://www.youtube.com/watch?v=ImIaoKsjgUE;11277.0;137.0
2017-01-08;2021-02-01;"The paper ""Accelerating Eulerian Fluid Simulation With Convolutional Networks"" and its source code is available here: http://cims.nyu.edu/~schlacht/CNNFluids.htm https://users.cg.tuwien.ac.at/zsolnai/accelerating-eulerian-fluid-simulation-convolutional-networks/ https://github.com/google/FluidNet The mentioned previous work has used an SPH-based Lagrangian simulation, performed the regression with regression forests, and the process also has included a fair amount of feature engineering. It is an excellent piece of work by the name ""Data-driven Fluid Simulations using Regression Forests"" and is a highly recommended read: https://www.inf.ethz.ch/personal/ladickyl/fluid sigasia15.pdf https://www.youtube.com/watch?v=kGB7W... Video credits: Surface-Only Liquids - https://www.youtube.com/watch?v=-rfM... Schrdinger's Smoke - https://www.youtube.com/watch?v=heY2g... Thumbnail image background credit: https://pixabay.com/photo-889131/";117.0;5584.0;['http://cims.nyu.edu/~schlacht/CNNFluids.htm', 'https://users.cg.tuwien.ac.at/zsolnai/accelerating-eulerian-fluid-simulation-convolutional-networks/', 'https://github.com/google/FluidNet', 'https://www.inf.ethz.ch/personal/ladickyl/fluid_sigasia15.pdf', 'https://pixabay.com/photo-889131/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/'];['NN', 'CNN'];['regression', 'recommend'];0.725;0.84;['NN', 'Recommender', 'Regression', 'CNN'];Neural Network Learns The Physics of Fluids and Smoke;Accelerating Eulerian Fluid Simulation With Convolutional Networks and its source code;https://www.youtube.com/watch?v=iOWamCtnwTc;203239.0;87.0
2016-06-26;2021-02-01;"The paper ""Fitting Procedural Yarn Models for Realistic Cloth Rendering"" is available here: https://shuangz.com/publications.htm http://www.cs.cornell.edu/~kb/publications/SIG16ProceduralYarn.pdf Video credits (in order): Bandyte - https://www.youtube.com/watch?v=e4Bhd... TheJamsh - https://www.youtube.com/watch?v=oSYjg... Gamasutra - http://www.gamasutra.com/blogs/AAdonaac/20150903/252889/Procedural Dungeon Generation Algorithm.php";5.0;616.0;['https://shuangz.com/publications.htm', 'http://www.cs.cornell.edu/~kb/publications/SIG16ProceduralYarn.pdf', 'http://www.gamasutra.com/blogs/AAdonaac/20150903/252889/Procedural_Dungeon_Generation_Algorithm.php', 'https://experiment.com/', 'https://flic.kr/p/gqShF5'];[];['model', 'fit'];0.618;0.771;[];Procedural Yarn Models for Cloth Rendering;Fitting Procedural Yarn Models for Realistic Cloth Rendering;https://www.youtube.com/watch?v=iTRnr6p7iYo;18437.0;31.0
2015-11-06;2021-02-01;You can now be a part of Two Minute Papers on;1.0;138.0;[];[];[];0.522;0.759;[];Be a Part of Two Minute Papers on Patreon!;;https://www.youtube.com/watch?v=iuJwmM2-JWM;13240.0;11.0
2018-03-03;2021-02-01;"The paper ""Why Should I Trust You? - Explaining the Predictions of Any Classifier"" and its implementation is available here: http://www.kdd.org/kdd2016/papers/files/rfp0573-ribeiroA.pdf https://github.com/marcotcr/lime Our";3.0;941.0;['http://www.kdd.org/kdd2016/papers/files/rfp0573-ribeiroA.pdf', 'https://github.com/marcotcr/lime', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-563428/'];[];['classif', 'predict'];0.642;0.769;['Classification'];Why Should We Trust An AI?;Why Should I Trust You? - Explaining the Predictions of Any Classifier and its implementation;https://www.youtube.com/watch?v=izZofvgaIig;17626.0;23.0
2016-12-14;2021-02-01;"The paper ""FlexMolds: Automatic Design of Flexible Shells for Molding"" is available here: http://vcg.isti.cnr.it/Publications/2016/MPBC16/";3.0;176.0;['http://vcg.isti.cnr.it/Publications/2016/MPBC16/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/'];[];[];0.539;0.724;[];3D Printing Flexible Shells For Molding;FlexMolds: Automatic Design of Flexible Shells for Molding;https://www.youtube.com/watch?v=j7XWCCvBrwU;5373.0;14.0
2016-02-03;2021-02-01;"Artificial neural networks are computer programs that try to approximate what the human brain does to solve problems like recognizing objects in images. In this piece of work, the authors analyze the properties of these neural networks and try to unveil what exactly makes them think that a paper towel is a paper towel, and, building on this knowledge, try to fool these programs. Carefully crafted adversarial examples can be used to fool deep neural network reliably. The paper ""Intriguing properties of neural networks"" is available here: http://arxiv.org/abs/1312.6199 The paper ""Explaining and Harnessing Adversarial Examples"" is available here: http://arxiv.org/abs/1412.6572 Image credits: Thumbnail image - https://www.flickr.com/photos/healthblog/8384110298 (CC BY-SA 2.0) Shower cap - Code Words / Julia Evans - https://codewords.recurse.com/issues/five/why-do-neural-networks-think-a-panda-is-a-vulture MNIST - hxhl95 Andrej Karpathy's online convolutional neural network: http://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html";9.0;309.0;['http://arxiv.org/abs/1312.6199', 'http://arxiv.org/abs/1412.6572', 'https://www.flickr.com/photos/healthblog/8384110298', 'https://codewords.recurse.com/issues/five/why-do-neural-networks-think-a-panda-is-a-vulture', 'http://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html'];[];['convolutional neural network', 'neural network', 'artificial neural network', 'recogn'];0.575;0.762;['NN', 'CNN', 'ANN'];Breaking Deep Learning Systems With Adversarial Examples;Intriguing properties of neural networks;https://www.youtube.com/watch?v=j9FLOinaG94;14311.0;128.0
2017-05-24;2021-02-01;"The paper ""Lighting Grid Hierarchy for Self-illuminating Explosions"" is available here: http://www.cemyuksel.com/research/lgh/ Rendering course at the Technical University of Vienna: https://users.cg.tuwien.ac.at/zsolnai... https://www.youtube.com/playlist?list... Our light transport-related episodes: https://www.youtube.com/playlist?list... Two Minute Papers Merch: US: http://twominutepapers.com/ EU/Worldwide: https://shop.spreadshirt.net/TwoMinut... If you don't mind, make sure to send us a picture of yourself with a piece of merch!";2.0;851.0;[];[];[];0.636;0.771;[];Self-Illuminating Explosions;Lighting Grid Hierarchy for Self-illuminating Explosions;https://www.youtube.com/watch?v=jDxsGW5KUP0;18724.0;53.0
2015-10-23;2021-02-01;"Artificial neural networks are powerful machine learning techniques that can learn to recognize images or paint in the style of Van Gogh. Recurrent neural networks offer a more general model that can learn input sequences and create output sequences. The resulting technique (Long Short-Term Memory in these examples) can write novels in the style of Tolstoy, Shakespeare, or write their own music. Andrej Karpathy's original article is available here: http://karpathy.github.io/2015/05/21/rnn-effectiveness/ Source code: https://github.com/karpathy/char-rnn The paper ""Long Short-Term Memory"" by Sepp Hochreiter and Jrgen Schmidhuber is available here: http://www.bioinf.jku.at/publications/older/2604.pdf http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97 lstm.pdf Continuing ""Let It Go"" from Disney with a recurrent neural network: https://ericye16.com/music-rnn/ Recommended for you: Artificial Neural Networks and Deep Learning - https://www.youtube.com/watch?v=rCWTO... Deep Neural Network Learns Van Gogh's Art - https://www.youtube.com/watch?v=-R9bJ... Creating Photographs Using Deep Learning - https://www.youtube.com/watch?v=HOLoP... A great write-up on how LSTMs work: http://colah.github.io/posts/2015-08-Understanding-LSTMs/ More applications of Long Short-Term Memory: http://googleresearch.blogspot.co.uk/2015/09/google-voice-search-faster-and-more.html http://googleresearch.blogspot.co.at/2015/08/the-neural-networks-behind-google-voice.html";5.0;808.0;['http://karpathy.github.io/2015/05/21/rnn-effectiveness/', 'https://github.com/karpathy/char-rnn', 'http://www.bioinf.jku.at/publications/older/2604.pdf', 'http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf', 'https://ericye16.com/music-rnn/', 'http://colah.github.io/posts/2015-08-Understanding-LSTMs/', 'http://googleresearch.blogspot.co.uk/2015/09/google-voice-search-faster-and-more.html', 'http://googleresearch.blogspot.co.at/2015/08/the-neural-networks-behind-google-voice.html', 'https://www.flickr.com/photos/naturegeak/5819184201/'];[];['neural network', 'machine learning', 'artificial neural network', 'recurrent neural network', 'recommend', 'deep learning', 'recogn', 'model', 'lstm'];0.633;0.79;['LSTM', 'RNN', 'NN', 'Recommender', 'ANN', 'DL', 'ML'];Recurrent Neural Network Writes Music and Shakespeare Novels;Long Short-Term Memory by Sepp Hochreiter and Jrgen Schmidhuber;https://www.youtube.com/watch?v=Jkkjy7dVdaY;32932.0;145.0
2016-04-04;2021-02-01;This technique uses deep learning to create beautiful paintings from terribly drawn sketches. The results look so great that many people called this work out to be an April Fools' day joke! The paper 'Semantic Style Transfer and Turning Two-Bit Doodles into Fine Artwork' and its implementation is available here: https://github.com/alexjc/neural-doodle http://arxiv.org/pdf/1603.01768v1.pdf A playlist with out neural network and deep learning-related videos: https://www.youtube.com/playlist?list...;5.0;977.0;['https://github.com/alexjc/neural-doodle', 'http://arxiv.org/pdf/1603.01768v1.pdf', 'https://creativecommons.org/licenses/by/4.0/', 'http://chriszabriskie.com/uvp/', 'http://chriszabriskie.com/'];[];['neural network', 'deep learning'];0.644;0.791;['NN', 'DL'];From Doodles To Paintings With Deep Learning;'Semantic Style Transfer and Turning Two-Bit Doodles into Fine Artwork' and its implementation;https://www.youtube.com/watch?v=jMZqxfTls-0;34549.0;63.0
2017-03-01;2021-02-01;"The paper ""Real-time Fiber-level Cloth Rendering"" is available here: http://www.cs.utah.edu/~kwu/rtfr.html";2.0;761.0;[];[];[];0.63;0.771;[];Real-Time Fiber-Level Cloth Rendering;Real-time Fiber-level Cloth Rendering;https://www.youtube.com/watch?v=JzOc_NNY_zY;18464.0;10.0
2016-02-21;2021-02-01;"A caustic is a beautiful phenomenon in nature where curved surfaces reflect or refract light, thereby concentrating it to a relatively small area. Since we, humans are pretty bad at estimating how exactly caustics should look like, one can manipulate them to be more in line with their artistic vision. The paper ""Stylized Caustics: Progressive Rendering of Animated Caustics"" is available here: http://vc.cs.ovgu.de/files/publications/2016/Guenther 2016 EGb.pdf CynicatPro's channel is available here: https://www.youtube.com/user/CynicatPro/videos Recommended for you: Manipulating Photorealistic Renderings - https://www.youtube.com/watch?v=L7MOe... Ray Tracing / Subsurface Scattering @ Function 2015 - https://www.youtube.com/watch?v=qyDUv... Metropolis Light Transport - https://www.youtube.com/watch?v=f0Uzi... The background of the thumbnail image was created by woodleywonderworks (CC BY 2.0) - https://flic.kr/p/2tKhPY";4.0;187.0;['http://vc.cs.ovgu.de/files/publications/2016/Guenther_2016_EGb.pdf', 'https://www.youtube.com/user/CynicatPro/videos', 'https://flic.kr/p/2tKhPY'];[];['recommend'];0.543;0.732;['Recommender'];Artistic Manipulation of Caustics;Stylized Caustics: Progressive Rendering of Animated Caustics;https://www.youtube.com/watch?v=K-0KJtk07YU;6462.0;109.0
2018-07-08;2021-02-01;"The paper ""Towards Virtual Reality Infinite Walking: Dynamic Saccadic Redirection "" is available here: http://research.nvidia.com/publication/2018-08 Towards-Virtual-Reality Pick up cool perks on our";87.0;3374.0;['http://research.nvidia.com/publication/2018-08_Towards-Virtual-Reality', 'https://pixabay.com/photo-2561233/'];[];[];0.703;0.822;[];Infinite Walking in Virtual Reality;Towards Virtual Reality Infinite Walking: Dynamic Saccadic Redirection;https://www.youtube.com/watch?v=KEdrBMZx53w;97912.0;22.0
2017-02-19;2021-02-01;"The paper ""IM2CAD"" is available here: http://homes.cs.washington.edu/~izadinia/im2cad.html LSUN Challenge datasets: http://lsun.cs.princeton.edu/2016/ More related papers are available here: http://www.cs.toronto.edu/~fidler/projects/rent3D.html http://web.engr.illinois.edu/~slazebni/publications/iccv15 informative.pdf http://ieeexplore.ieee.org/document/6619238/?reload=true";9.0;664.0;['http://homes.cs.washington.edu/~izadinia/im2cad.html', 'http://lsun.cs.princeton.edu/2016/', 'http://www.cs.toronto.edu/~fidler/projects/rent3D.html', 'http://web.engr.illinois.edu/~slazebni/publications/iccv15_informative.pdf', 'http://ieeexplore.ieee.org/document/6619238/?reload=true', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-389254/'];[];[];0.622;0.774;[];AI Builds 3D Models From Images With a Twist;IM2CAD;https://www.youtube.com/watch?v=kf-KViOuktc;19958.0;21.0
2017-10-22;2021-02-01;"The paper ""Learning with Opponent-Learning Awareness"" is available here: https://arxiv.org/abs/1709.04326 Our";16.0;898.0;[];[];[];0.639;0.769;[];Learning to Model Other Minds (OpenAI);Learning with Opponent-Learning Awareness;https://www.youtube.com/watch?v=kfJMUeQO0S0;17629.0;11.0
2016-01-24;2021-02-01;"In this series, we have studied fluid simulations extensively. But we haven't talked about one important quantity that describes a fluid, and this quantity is none other than viscosity. Viscosity means the resistance of a fluid against deformation. The large viscosity of honey makes it highly resistant to deformation, and this is responsible for its famous and beautiful coiling effect. Water, however, does not have a lot of objections against deformations, making it so easy to pour it into a glass. With this piece of work, it is possible to efficiently simulate the motion of fluids, and it supports the simulation of a large range of viscosities. The paper ""An Implicit Viscosity Formulation for SPH Fluids"" is available here: http://cg.informatik.uni-freiburg.de/publications/2015 SIGGRAPH viscousSPH.pdf Recommended for you: Painting with Fluid Simulations - https://www.youtube.com/watch?v=1aVSb... Modeling Colliding and Merging Fluids - https://www.youtube.com/watch?v=uj8b5... Adaptive Fluid Simulations - https://www.youtube.com/watch?v=dH1s4... Video source: Smarter Every Day - https://www.youtube.com/watch?v=zz5lG... The thumbnail image was created by Dino Giordano (CC BY 2.0) - https://flic.kr/p/4p9z4w";1.0;297.0;['http://cg.informatik.uni-freiburg.de/publications/2015_SIGGRAPH_viscousSPH.pdf', 'https://flic.kr/p/4p9z4w'];[];['model', 'recommend'];0.574;0.766;['Recommender'];Simulating Viscosity and Melting Fluids;An Implicit Viscosity Formulation for SPH Fluids;https://www.youtube.com/watch?v=KgIrnR2O8KQ;15949.0;163.0
2018-05-26;2021-02-01;"The paper ""Non-stationary Texture Synthesis by Adversarial Expansion"" and its source code is available here: http://vcc.szu.edu.cn/research/2018/TexSyn https://github.com/jessemelpolio/non-stationary texture syn Errata: please note that the image at the start of the video is of a wrong paper. Apologies! Pick up cool perks on our";7.0;1395.0;['http://vcc.szu.edu.cn/research/2018/TexSyn', 'https://github.com/jessemelpolio/non-stationary_texture_syn', 'https://pixabay.com/photo-3013486/', 'https://commons.wikimedia.org/wiki/File:In-game-view-doom.png'];[];[];0.662;0.782;[];AI-Based Large-Scale Texture Synthesis;Non-stationary Texture Synthesis by Adversarial Expansion and its source code;https://www.youtube.com/watch?v=KL6U6iasUxs;25984.0;43.0
2015-08-31;2021-02-01;"3D printing is a technique to create digital objects in real life. This technology is mostly focused on reproducing the digital geometry itself - colored patterns (textures) still remains a challenge, and we only have very rudimentary technology to do that. Hydrographic printing on 3D surfaces is a really simple technique: you place a film in water, use a chemical activator spray on it, and shove the object in the water. However, since these objects start stretching the film, the technique is not very accurate, and it only helps you putting repetitive patterns on these objects. Computational Hydrographic Printing is a technique that simulates all of these physical forces that are exerted on the film when your desired object is immersed into the water. Then, it creates a new image map taking all of these distortions into account, and this image you can print with your home inkjet printer. The results will be really accurate, close to indistinguishable from the digitally designed object. The paper ""Computational Hydrographic Printing"" is available here: http://www.cs.columbia.edu/~cxz/publications/hydrographics.pdf Disclaimer: I was not part of this research project, I am merely providing commentary on this work. The splash screen background was taken from ""Computational Hydrographic Printing"" by Zheng et al. Splash screen/thumbnail design: Felcia Fehr - http://felicia.hu Flickr: Wonderlane Link: https://flic.kr/p/atCLXr Music: Soul Groove by Audionautix - it is licensed under a Creative Commons Attribution license (https://creativecommons.org/licenses/by/4.0/) Artist: http://audionautix.com/";2.0;348.0;['http://www.cs.columbia.edu/~cxz/publications/hydrographics.pdf', 'https://flic.kr/p/atCLXr', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/'];[];[];0.584;0.751;[];Hydrographic Printing;Computational Hydrographic Printing;https://www.youtube.com/watch?v=kLnG073NYtw;10613.0;232.0
2016-01-09;2021-02-01;"Creating geometry for a computer game or a movie is a very long and arduous task. For instance, if we would like to populate a virtual city with buildings, it would cost a ton of time and money and of course, we would need quite a few artists. This piece of work solves this problem in a very elegant and convenient way: it learns the preference of the user, then creates and recommends a set of solutions that are expected to be desirable. The weapon of choice to accomplish this was Gaussian Process Regression. The paper ""Interactive Design of Probability Density Functions for Shape Grammars"" is available here: http://lgg.epfl.ch/publications/2015/proman/index.php The thumbnail image was created by See-ming Lee (nice name, btw!) (CC BY 2.0) - https://flic.kr/p/oewqwn";2.0;211.0;['http://lgg.epfl.ch/publications/2015/proman/index.php', 'https://flic.kr/p/oewqwn'];[];['regression', 'recommend'];0.552;0.74;['Recommender', 'Regression'];Designing Cities and Furnitures With Machine Learning;Interactive Design of Probability Density Functions for Shape Grammars;https://www.youtube.com/watch?v=kMa_B3wLxAM;7915.0;125.0
2015-09-08;2021-02-01;"In this episode, we are going to talk about computer animation, animating bipeds in particular. If we have the geometry of a creature, we need to specify the bones, the muscle routings and the muscle activations to make them able to walk. Depending on the body proportions and types, it may require quite a bit of trial and error to build muscle layouts so the creature doesn't collapse. Making them walk is even more difficult! This piece of work not only makes it happen for a variety of bipedal creatures, but the results are robust for a variety of target walking speeds, uneven terrain and other, unpleasant difficulties. The paper ""Flexible Muscle-Based Locomotion for Bipedal Creatures"" is available here: http://www.goatstream.com/research/papers/SA2013/ Disclaimer: I was not part of this research project, I am merely providing commentary on this work. Music: ""Daisy Dukes"" by Silent Partner";7.0;1109.0;['http://www.goatstream.com/research/papers/SA2013/'];[];[];0.65;0.8;[];Digital Creatures Learn To Walk;Flexible Muscle-Based Locomotion for Bipedal Creatures;https://www.youtube.com/watch?v=kQ2bqz3HPJE;45396.0;143.0
2016-09-01;2021-02-01;"Earlier, we have talked quite a bit about a fantastic new tool that we called artistic style transfer. This means that we have an input photograph that we'd like to modify, and another image from which we'd like to extract the artistic style. This way, we can, for instance, change our photo to look in the style of famous artists. Today, we're going to talk about a flamboyant little technique that is able to perform artistic style transfer in a way that preserves the illumination of the scene. The paper ""StyLit: Illumination-Guided Example-Based Stylization of 3D Renderings"" is available here: http://dcgi.fel.cvut.cz/home/sykorad/stylit Recommended for you: Artistic Style Transfer For Videos - https://www.youtube.com/watch?v=Uxax5... Deep Neural Network Learns Van Gogh's Art - https://www.youtube.com/watch?v=-R9bJ... Neural Material Synthesis (this contains discussions on diffuse and specular materials)- https://www.youtube.com/watch?v=XpwW3...";8.0;688.0;['http://dcgi.fel.cvut.cz/home/sykorad/stylit', 'https://experiment.com/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://flic.kr/p/nWXd5H'];[];['neural network', 'recommend'];0.624;0.762;['Recommender', 'NN'];StyLit, Illumination-Guided Artistic Style Transfer;StyLit: Illumination-Guided Example-Based Stylization of 3D Renderings;https://www.youtube.com/watch?v=ksCSL6Ql0Yg;14331.0;132.0
2016-10-04;2021-02-01;"In this work, the authors created a simulator, that shows us not only the motion of a piece of fluid, but the physics of bubbles within as well. This sounds great, but there are two huge problems: one, there are a lot of them, and two, they can undergo all kinds of deformations and topology changes. The paper ""Toward Animating Water with Complex Acoustic Bubbles"" is available here: http://www.cs.cornell.edu/projects/So... Recommended for you: All previous episodes on fluid simulations (and more!) - https://www.youtube.com/playlist?list...";2.0;325.0;[];[];['recommend'];0.58;0.738;['Recommender'];Sound Synthesis for Fluids With Bubbles;Toward Animating Water with Complex Acoustic Bubbles;https://www.youtube.com/watch?v=kwqme8mEgz4;7642.0;82.0
2015-09-11;2021-02-01;"Photorealistic rendering (also called global illumination) enables us to see how digital objects would look like in real life. It is an amazingly powerful tool in the hands of a professional artist, who can create breathtaking images or animations with. However, for the longest time, artists didn't use it in the movie industry because it did not offer a great artistic freedom - after all, it works according to the laws of physics, which are exact. This piece of work enables us to apply artistic edits to photorealistic renderings easily and intuitively. I believe this one has the potential to single-handedly change the landscape of photorealistic rendering on a production scale. VFX tricks with photorealistic rendering in Game of Thrones: https://www.youtube.com/watch?v=C56t6... https://www.youtube.com/watch?v=YJDsl... The paper ""Path-Space Manipulation of Physically-Based Light Transport"" is available here: https://cg.ivd.kit.edu/english/PSMPBLT.php Disclaimer: I was not part of this research project, I am merely providing commentary on this work. I held a course on photorealistic rendering at the Technical University of Vienna. Here you can learn how the physics of light works and to write programs like this: https://www.youtube.com/playlist?list... Lightrig: http://lightrig.de/ Function 2015 demoparty: http://2015.function.hu/ Scene credits: Last Light - J the Ninja (Jason Clarke) - also used as the thumbnail background Italian Style Still Life - Bhavin Solanki Interior scene - EnzoR Klein Bottle - BravoZulu Audi R8 - barryangus SL65 ""Black edition"" - zuzzi Music: ""Do It Right"" by Jingle Punks The thumbnail background was created by Jason Clarke. Splash screen/thumbnail design: Felcia Fehr - http://felicia.hu";0.0;184.0;['https://cg.ivd.kit.edu/english/PSMPBLT.php', 'http://lightrig.de/', 'http://2015.function.hu/'];[];[];0.543;0.734;[];Manipulating Photorealistic Renderings;Path-Space Manipulation of Physically-Based Light Transport;https://www.youtube.com/watch?v=L7MOeQw47BM;6846.0;250.0
2018-07-16;2021-02-01;"The paper ""Example-based Turbulence Style Transfer"" is available here: http://nishitalab.org/user/syuhei/TurbuStyleTrans/turbu styletrans.html Pick up cool perks on our";7.0;1022.0;['http://nishitalab.org/user/syuhei/TurbuStyleTrans/turbu_styletrans.html', 'https://pixabay.com/photo-984175/'];[];[];0.646;0.783;[];Style Transfer...For Smoke and Fluids!;Example-based Turbulence Style Transfer;https://www.youtube.com/watch?v=lCoR-4OlIZI;26266.0;17.0
2017-11-15;2021-02-01;"The paper ""Neural Task Programming: Learning to Generalize Across Hierarchical Tasks"" is available here: https://stanfordvl.github.io/ntp/";15.0;1026.0;[];[];[];0.646;0.777;[];Generalizing AI With Neural Task Programming;Neural Task Programming: Learning to Generalize Across Hierarchical Tasks;https://www.youtube.com/watch?v=Lcxz6dtYjI4;22008.0;15.0
2017-07-03;2021-02-01;"The paper ""VoCo: Text-based Insertion and Replacement in Audio Narration"" is available here: http://gfx.cs.princeton.edu/pubs/Jin... Two Minute Papers Merch: US: http://twominutepapers.com/ EU/Worldwide: https://shop.spreadshirt.net/TwoMinut...";9.0;592.0;[];[];[];0.615;0.763;[];Text-based Editing of Audio Narration;VoCo: Text-based Insertion and Replacement in Audio Narration;https://www.youtube.com/watch?v=ldO7RD3s4_s;14748.0;22.0
2017-04-12;2021-02-01;"The paper ""On-the-Fly Print: Incremental Printing While Modeling"" is available here: http://www.huaishu.me/projects/on-the... http://www.cs.cornell.edu/projects/wi...";3.0;293.0;[];[];['model'];0.573;0.747;[];On-the-Fly 3D Printing While Modeling;On-the-Fly Print: Incremental Printing While Modeling;https://www.youtube.com/watch?v=lf3ViWEeKqc;9605.0;13.0
2016-05-01;2021-02-01;"In this episode, we discuss the bane of many machine learning algorithms - overfitting. It is also explained why it is an undesirable way to learn and how to combat it via dropout. The paper ""Dropout: A Simple Way to Prevent Neural Networks from Overtting"" is available here: https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf Andrej Karpathy's autoencoder is available here: http://cs.stanford.edu/people/karpathy/convnetjs/demo/autoencoder.html Recommended for you: Overfitting and Regularization For Deep Learning - https://www.youtube.com/watch?v=6aF9s... Decision Trees and Boosting, XGBoost -https://www.youtube.com/watch?v=0Xc9L... A full playlist with machine learning and deep learning-related Two Minute Papers videos - https://www.youtube.com/playlist?list...";2.0;279.0;['https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf', 'http://cs.stanford.edu/people/karpathy/convnetjs/demo/autoencoder.html', 'https://flic.kr/p/ejXPXt'];['ML'];['neural network', 'fit', 'autoencoder', 'machine learning', 'decision tree', 'deep learning', 'recommend'];0.57;0.744;['Recommender', 'NN', 'DL', 'Decision Tree', 'ML'];Training Deep Neural Networks With Dropout;Dropout: A Simple Way to Prevent Neural Networks from Overtting;https://www.youtube.com/watch?v=LhhEv1dMpKE;8761.0;88.0
2017-02-16;2021-02-01;"The paper ""Discovery of complex behaviors through contact-invariant optimization"" is available here: http://homes.cs.washington.edu/~todor... http://homes.cs.washington.edu/~todor... Our earlier episode on optimization: https://www.youtube.com/watch?v=1ypV5... Our technical write-up on our video rendering pipeline changes is available here: https://www.patreon.com/posts/improve...";6.0;1341.0;[];[];[];0.66;0.777;[];Digital Creatures Learn to Cooperate;Discovery of complex behaviors through contact-invariant optimization;https://www.youtube.com/watch?v=LmYKfU5O_NA;21889.0;33.0
2015-10-07;2021-02-01;"This time, we are going to set foot in cloth simulations that are widely used in the motion picture industry. Adaptive algorithms are a class of techniques that try to adapt at the problem that we have at hand. This adaptive method focuses computational resources to regions which are likely to have fine details (wrinkles) and coarsens the simulation quality in regions that are at rest. This substantially reduces the computation time we need for the cloth simulation step. The paper ""Adaptive Anisotropic Remeshing for Cloth Simulation"" by Narain et al. is available here: http://graphics.berkeley.edu/papers/Narain-AAR-2012-11/ Recommended for you - Adaptive Fluid Simulations: https://www.youtube.com/watch?v=dH1s4... The YouTube channel of Sardi Pax with lots of useful Blender tutorials is available here: https://www.youtube.com/user/srf123 Here are some Blender (and cloth simulation) tutorials to get you started: https://www.youtube.com/watch?v=lZe3t... https://www.youtube.com/watch?v=k4czh... https://www.youtube.com/watch?v=gARJx... http://blender.org/ The background of the thumbnail image is the work of Theresa Thompson: https://flic.kr/p/5khSsE It has went through slight modifications (rotation and a monochrome transform). Splash screen/thumbnail design: Felcia Fehr - http://felicia.hu";1.0;181.0;['http://graphics.berkeley.edu/papers/Narain-AAR-2012-11/', 'https://www.youtube.com/user/srf123', 'http://blender.org/', 'https://flic.kr/p/5khSsE'];[];['recommend'];0.541;0.747;['Recommender'];Adaptive Cloth Simulations;Adaptive Anisotropic Remeshing for Cloth Simulation by Narain et al.;https://www.youtube.com/watch?v=LU3pdWTD4Rw;9444.0;166.0
2017-04-15;2021-02-01;"The paper ""Primal-Dual Optimization for Fluids"" is available here: http://www.ntoken.com/pubs.html An introduction to fluid simulations and fluid control with source code, both CPU and GPU (OpenCL): 1. https://users.cg.tuwien.ac.at/zsolnai... 2. https://users.cg.tuwien.ac.at/zsolnai... Doyub Kim's book on fluid simulations, with source code: http://doyub.com/ https://twitter.com/doyub?lang=en The first Two Minute Papers episode on Wavelet Turbulence: https://www.youtube.com/watch?v=5xLSb...";6.0;545.0;[];[];[];0.611;0.763;[];Controllable Fluid and Smoke Simulations;Primal-Dual Optimization for Fluids;https://www.youtube.com/watch?v=lxNEWuO6xQk;14722.0;51.0
2018-04-26;2021-02-01;"The paper ""Joint 3D Face Reconstruction and Dense Alignment with Position Map Regression Network"" and its source code is available here: https://arxiv.org/abs/1803.07835 https://github.com/YadiraF/PRNet Addicted? Pick up cool perks on our";8.0;1209.0;[];[];['regression'];0.655;0.791;['Regression'];AI Learns Real-Time 3D Face Reconstruction;Joint 3D Face Reconstruction and Dense Alignment with Position Map Regression Network and its source code;https://www.youtube.com/watch?v=m9XyXiL6n8w;34105.0;30.0
2018-01-14;2021-02-01;"The paper ""Conformation Constraints for Efficient Viscoelastic Fluid Simulation"" is available here: http://www.gmrv.es/Publications/2017/BGAO17/";9.0;1349.0;['http://www.gmrv.es/Publications/2017/BGAO17/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-1958464/'];[];['train'];0.66;0.781;[];Efficient Viscoelastic Fluid Simulations;Conformation Constraints for Efficient Viscoelastic Fluid Simulation;https://www.youtube.com/watch?v=MCHw6fUyLMY;24700.0;13.0
2017-10-25;2021-02-01;"The paper ""Real-time Global Illumination by Precomputed Local Reconstruction from Sparse Radiance Probes"" is available here: https://arisilvennoinen.github.io/Pub...";13.0;1544.0;[];[];[];0.667;0.79;[];Real-Time Global Illumination With Radiance Probes;Real-time Global Illumination by Precomputed Local Reconstruction from Sparse Radiance Probes;https://www.youtube.com/watch?v=mECv52eSjBo;32858.0;17.0
2016-06-08;2021-02-01;"The paper ""Let there be Color!: Joint End-to-end Learning of Global and Local Image Priors for Automatic Image Colorization with Simultaneous Classification"" and its implementation are available here: http://hi.cs.waseda.ac.jp/~iizuka/projects/colorization/en/ https://github.com/satoshiiizuka/siggraph2016 colorization The video classification paper by Karpathy et al.: http://cs.stanford.edu/people/karpathy/deepvideo/ Recommended for you: Artistic Style Transfer For Videos - https://www.youtube.com/watch?v=Uxax5... Deep Learning related Two Minute Papers videos - https://www.youtube.com/playlist?list...";4.0;572.0;['http://hi.cs.waseda.ac.jp/~iizuka/projects/colorization/en/', 'https://github.com/satoshiiizuka/siggraph2016_colorization', 'http://cs.stanford.edu/people/karpathy/deepvideo/'];[];['deep learning', 'classif', 'recommend'];0.614;0.782;['Classification', 'Recommender', 'DL'];Image Colorization With Deep Learning and Classification;Let there be Color!: Joint End-to-end Learning of Global and Local Image Priors for Automatic Image Colorization with Simultaneous Classification and its implementation are available here: http://hi.cs.waseda.ac.jp/~iizuka/projects/colorization/en/ https://github.com/satoshiiizuka/siggraph2016_colorization The video classification paper by Karpathy et al.: http://cs.stanford.edu/people/karpathy/deepvideo/ Recommended for you: Artistic Style Transfer For Videos - https://www.youtube.com/watch?v=Uxax5... Deep Learning related Two Minute Papers videos - https://www.youtube.com/playlist?list... WE WOULD LIKE TO THANK OUR GENEROUS SUPPORTERS WHO MAKE TWO MINUTE PAPERS POSSIBLE: David Jaenisch, Sunil Kim, Julian Josephs. https://www.patreon.com/TwoMinutePapers Subscribe if you would like to see more of these! - http://www.youtube.com/subscriptionc... Splash screen/thumbnail design: Felcia Fehr - http://felicia.hu Kroly Zsolnai-Fehr's links: Facebook  https://www.facebook.com/TwoMinutePapers/ Twitter  https://twitter.com/karolyzsolnai Web  https://cg.tuwien.ac.at/~zsolnai/;https://www.youtube.com/watch?v=MfaTOXxA8dM;25358.0;59.0
2015-10-30;2021-02-01;"In computer animation, animating human faces is an art itself, but transferring expressions from one human to someone else is an even more complex task. One has to take into consideration the geometry, the reflectance properties, pose, and the illumination of both faces, and make sure that mouth movements and wrinkles are transferred properly. The fact that the human eye is very keen on catching artificial changes makes the problem even more difficult. This paper describes a real-time solution to this animation problem. The paper ""Real-time Expression Transfer for Facial Reenactment"" is available here: http://graphics.stanford.edu/~niessner/thies2015realtime.html Recommended for you: ALL Two Minute Papers episodes! :) - https://www.youtube.com/playlist?list...";2.0;214.0;['http://graphics.stanford.edu/~niessner/thies2015realtime.html', 'https://flic.kr/p/9d8ApH'];[];['recommend'];0.553;0.755;['Recommender'];Real-Time Facial Expression Transfer;Real-time Expression Transfer for Facial Reenactment;https://www.youtube.com/watch?v=mkI6qfpEJmI;11773.0;106.0
2017-08-31;2021-02-01;"The paper ""Look, Listen and Learn"" is available here: https://arxiv.org/abs/1705.08168 Our";17.0;1604.0;['https://arxiv.org/abs/1705.08168', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-1838412/'];[];[];0.669;0.793;[];DeepMind's AI Learns Audio And Video Concepts By Itself;Look, Listen and Learn;https://www.youtube.com/watch?v=mL3CzZcBJZU;36483.0;11.0
2017-11-02;2021-02-01;"The paper ""Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World"" is available here: https://arxiv.org/pdf/1703.06907.pdf";17.0;850.0;[];[];['neural network'];0.635;0.776;['NN'];Transferring AI To The Real World (OpenAI);Domain Randomization for Transferring Deep Neural  Networks from Simulation to the Real World;https://www.youtube.com/watch?v=mmeoUZ_wRm4;21369.0;19.0
2017-01-21;2021-02-01;"The paper ""Awesome Typography: Statistics-Based Text Effects Transfer"" is available here: https://arxiv.org/abs/1611.09026 Recommended for you: Artistic Style Transfer For Videos - https://www.youtube.com/watch?v=Uxax5...";6.0;494.0;[];[];['recommend'];0.605;0.763;['Recommender'];Text Style Transfer;Awesome Typography: Statistics-Based Text Effects Transfer;https://www.youtube.com/watch?v=MtWtY4DdiWs;14934.0;22.0
2017-09-13;2021-02-01;"The paper ""Data-Driven Synthesis of Smoke Flows with CNN-based Feature Descriptors"" is available here: https://ge.in.tum.de/publications/2017-sig-chu/ Recommended for you: Wavelet Turbulence - https://www.youtube.com/watch?v=5xLSb... Neural Network Learns The Physics of Fluids and Smoke - https://www.youtube.com/watch?v=iOWam...";10.0;907.0;['https://ge.in.tum.de/publications/2017-sig-chu/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-2571245/'];['NN', 'CNN'];['neural network', 'recommend'];0.639;0.773;['Recommender', 'NN', 'CNN'];AI Learns To Improve Smoke Simulations;Data-Driven Synthesis of Smoke Flows with CNN-based Feature Descriptors;https://www.youtube.com/watch?v=Mu0ew2F-SSA;19853.0;33.0
2016-09-19;2021-02-01;"A realistic simulation of sounds within virtual environments dramatically improves the immersion of the user in computer games and virtual reality applications. To be able to simulate these effects, we need to compute the interaction between sound waves and the geometry and materials within the scene. Let's see how this work accomplishes it! The paper ""Adaptive Impulse Response Modeling for Interactive Sound Propagation"" is available here: http://gamma.cs.unc.edu/ADAPTIVEIR/ Recommended for you: Rocking Out With Convolutions - https://www.youtube.com/watch?v=JKYQO... All light-transport related episodes: https://www.youtube.com/playlist?list...";0.0;215.0;['http://gamma.cs.unc.edu/ADAPTIVEIR/', 'https://experiment.com/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://flic.kr/p/9YViuT'];[];['model', 'propagation', 'recommend'];0.553;0.723;['Recommender'];Sound Propagation With Adaptive Impulse Responses;Adaptive Impulse Response Modeling for Interactive Sound Propagation;https://www.youtube.com/watch?v=Mx8viOFKiIs;5232.0;81.0
2017-11-29;2021-02-01;"The paper ""Meta Learning Shared Hierarchies"" and its source code is available here: https://arxiv.org/abs/1710.09767 https://github.com/openai/mlsh A video from Robert Miles: https://www.youtube.com/watch?v=MUVbq... We have been experimenting with opening a bitcoin wallet. Let us know if it's working properly and thank you very much for your support! Bitcoin: 13hhmJnLEzwXgmgJN7RB6bWVdT7WkrFAHh";8.0;726.0;['https://arxiv.org/abs/1710.09767', 'https://github.com/openai/mlsh', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-1804496/'];[];[];0.627;0.772;[];Meta Learning Shared Hierarchies;Meta Learning Shared Hierarchies and its source code;https://www.youtube.com/watch?v=M_eaS7X-mIw;18899.0;47.0
2017-03-27;2021-02-01;"The paper ""PatchMatch: A Randomized Correspondence Algorithm for Structural Image Editing"" and part of its source code is available here: http://gfx.cs.princeton.edu/gfx/pubs/... Additional, unofficial implementations: https://github.com/ikuwow/PatchMatch https://github.com/rcrandall/PatchMatch";1.0;629.0;[];[];[];0.62;0.758;[];Structural Image Editing With PatchMatch;PatchMatch: A Randomized Correspondence Algorithm for Structural Image Editing and part of its source code;https://www.youtube.com/watch?v=n3aoc36V8LM;12692.0;26.0
2017-11-22;2021-02-01;"The paper ""Interactive Example-Based Terrain Authoring with Conditional Generative Adversarial Networks"" is available here: https://hal.archives-ouvertes.fr/hal-...";16.0;2419.0;[];[];['generative adversarial network'];0.689;0.812;['GAN'];Terrain Generation With Deep Learning;Interactive Example-Based Terrain Authoring with Conditional Generative Adversarial Networks;https://www.youtube.com/watch?v=NEscK5RCtlo;68687.0;15.0
2016-04-28;2021-02-01;"We continue our journey in the land of fluid simulations and discuss a really cool FLIP-based technique that uses both particles and grids to create very high quality footage at a much more reasonable cost than previous works. The paper ""Narrow Band FLIP for Liquid Simulations"" is available here: https://wwwcg.in.tum.de/research/research/publications/2016/narrow-band-flip-for-liquid-simulations.html Yearning for more fluids? :) A Two Minute Papers playlist of fluid and cloth simulation-related topics is available here: https://www.youtube.com/playlist?list...";7.0;637.0;['https://wwwcg.in.tum.de/research/research/publications/2016/narrow-band-flip-for-liquid-simulations.html'];[];[];0.62;0.784;[];Narrow Band Liquid Simulations;Narrow Band FLIP for Liquid Simulations;https://www.youtube.com/watch?v=nfPBT71xYVQ;27550.0;70.0
2018-04-12;2021-02-01;"The paper ""Evolutionary Generative Adversarial Networks"" is available here: https://arxiv.org/abs/1803.00657 Our";11.0;1154.0;[];[];['generative adversarial network'];0.652;0.79;['GAN'];Evolving Generative Adversarial Networks;Evolutionary Generative Adversarial Networks;https://www.youtube.com/watch?v=ni6P5KU3SDU;33525.0;11.0
2016-10-26;2021-02-01;"A tangle pattern is a beautiful, intervowen tapestry of basic stroke patterns, like dots, straight lines, and simple curves. If we look at some of these works, we see that many of these are highly structured, and maybe, we could automatically create such beautiful structures with a computer. The paper ""gTangle: a Grammar for the Procedural Generation of Tangle Patterns"" is available here: http://pellacini.di.uniroma1.it/publi... The paper ""Layer-Based Procedural Design of Facades"" is available here: https://www.cg.tuwien.ac.at/research/... https://vimeo.com/118400233";4.0;263.0;[];[];['layer'];0.566;0.732;[];Generating Tangle Patterns With Grammars;gTangle: a Grammar for the Procedural Generation of Tangle Patterns;https://www.youtube.com/watch?v=nK3giIsNAHg;6459.0;76.0
2018-06-23;2021-02-01;"The paper ""Deep Video Portraits"" is available here: http://gvv.mpi-inf.mpg.de/projects/DeepVideoPortraits/ Pick up cool perks on our";15.0;1442.0;['http://gvv.mpi-inf.mpg.de/projects/DeepVideoPortraits/', 'https://pixabay.com/photo-2119595/'];[];[];0.664;0.796;[];Better Video Impersonations with AI;Deep Video Portraits;https://www.youtube.com/watch?v=Nq2xvsVojVo;40020.0;15.0
2017-10-04;2021-02-01;"The paper ""Synthesizing Obama: Learning Lip Sync from Audio"" is available here: https://grail.cs.washington.edu/proje... Our";7.0;1181.0;[];[];[];0.654;0.791;[];Audio To Obama: AI Learns Lip Sync from Audio;Synthesizing Obama: Learning Lip Sync from Audio;https://www.youtube.com/watch?v=nsuAQcvafCs;34371.0;14.0
2017-01-17;2021-02-01;"The paper ""Generating Videos with Scene Dynamics"" and its source code, and a pre-trained network is available here: http://web.mit.edu/vondrick/tinyvideo/ Recommended for you: Image Synthesis From Text With Deep Learning - https://www.youtube.com/watch?v=rAbhy... What is an Autoencoder? - https://www.youtube.com/watch?v=Rdpbn... Hallucinating Images With Deep Learning - https://www.youtube.com/watch?v=hnT-P...";19.0;1313.0;[];[];['autoencoder', 'deep learning', 'recommend', 'train'];0.659;0.808;['Recommender', 'DL'];Deep Learning Program Hallucinates Videos;Generating Videos with Scene Dynamics and its source code, and a pre-trained network;https://www.youtube.com/watch?v=oitGRdHFNWw;60189.0;44.0
2017-05-06;2021-02-01;"The paper ""Downsampling Scattering Parameters for Rendering Anisotropic Media"" and its source code is available here: https://shuangz.com/projects/multires-sa16/ Two Minute Papers Merch: US: http://twominutepapers.com/ EU/Worldwide: https://shop.spreadshirt.net/TwoMinutePapers/";4.0;424.0;['https://shuangz.com/projects/multires-sa16/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-1747666/'];[];[];0.596;0.751;[];An Efficient Scattering Material Representation;Downsampling Scattering Parameters for Rendering Anisotropic Media and its source code;https://www.youtube.com/watch?v=oleylS5XGpg;10674.0;25.0
2017-06-28;2021-02-01;"The paper ""Efficient Yarn-based Cloth with Adaptive Contact Linearization"" is available here: https://www.cs.cornell.edu/projects/YarnCloth/ https://www.cs.cornell.edu/projects/YarnCloth/ Two Minute Papers Merch: US: http://twominutepapers.com/ EU/Worldwide: https://shop.spreadshirt.net/TwoMinutePapers/";4.0;603.0;['https://www.cs.cornell.edu/projects/YarnCloth/', 'https://www.cs.cornell.edu/projects/YarnCloth/sg10_acl.pdf', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-1142179/'];[];[];0.617;0.765;[];Efficient Yarn-based Cloth Simulations;Efficient Yarn-based Cloth with Adaptive Contact Linearization;https://www.youtube.com/watch?v=oltKUPTBz9Q;15413.0;22.0
2018-03-21;2021-02-01;"The paper ""IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures"" is available here: https://arxiv.org/abs/1802.01561 Update: Its source code is now available here: https://github.com/deepmind/scalable agent DeepMind Lab: https://arxiv.org/abs/1612.03801 Our";19.0;880.0;['https://arxiv.org/abs/1802.01561', 'https://github.com/deepmind/scalable_agent', 'https://arxiv.org/abs/1612.03801', 'https://pixabay.com/photo-1548365/'];['RL'];[];0.637;0.779;['RL'];DeepMind's AI Masters Even More Atari Games;IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures;https://www.youtube.com/watch?v=oWpp1YYcCsU;23622.0;29.0
2017-11-11;2021-02-01;"The paper ""Emergent Complexity via Multi-Agent Competition"" and its source code is available here: https://arxiv.org/abs/1710.03748 https://github.com/openai/multiagent-competition";9.0;924.0;['https://arxiv.org/abs/1710.03748', 'https://github.com/openai/multiagent-competition', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://flic.kr/p/5BaDVq'];[];[];0.64;0.771;[];AI Competitive Self-Play;Emergent Complexity via Multi-Agent Competition and its source code;https://www.youtube.com/watch?v=p831XtyLA5M;18448.0;16.0
2018-02-11;2021-02-01;"The paper ""SLAC: A Sparsely Labeled Dataset for Action Classification and Localization"" is available here: http://slac.csail.mit.edu/ https://arxiv.org/abs/1712.09374";1.0;694.0;['http://slac.csail.mit.edu/', 'https://arxiv.org/abs/1712.09374', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-3011677/'];[];['label', 'classif'];0.625;0.769;['Classification'];SLAC Dataset From MIT and Facebook;SLAC: A Sparsely Labeled Dataset for Action Classification and Localization;https://www.youtube.com/watch?v=pAiiPNg0kDE;17286.0;17.0
2016-12-17;2021-02-01;"The paper ""Crumpling Sound Synthesis"" is available here: http://www.cs.columbia.edu/cg/crumpling/";7.0;486.0;['http://www.cs.columbia.edu/cg/crumpling/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/'];[];[];0.604;0.756;[];Crumpling Sound Synthesis;Crumpling Sound Synthesis;https://www.youtube.com/watch?v=PMSV7CjBuZI;12063.0;9.0
2017-02-22;2021-02-01;"The paper ""Scene Completion Using Millions of Photographs"" is available here: http://graphics.cs.cmu.edu/projects/s...";4.0;543.0;[];[];[];0.611;0.762;[];Learning to Fill Holes in Images;Scene Completion Using Millions of Photographs;https://www.youtube.com/watch?v=psOPu3TldgY;14253.0;12.0
2018-03-06;2021-02-01;"The paper ""Building Blocks of Interpretability"" is available here: https://distill.pub/2018/building-blo... Our";9.0;1378.0;[];[];[];0.662;0.782;[];Building Blocks of AI Interpretability;Building Blocks of Interpretability;https://www.youtube.com/watch?v=pVgC-7QTr40;25378.0;11.0
2017-08-27;2021-02-01;"The paper ""An Efficient and Practical Near and Far Field Fur Reflectance Model"" is available here: https://people.eecs.berkeley.edu/~lingqi/publications/paper fur2.pdf https://people.eecs.berkeley.edu/~lingqi/publications/paper fur2.pdf The free Rendering course is available on YouTube here: https://www.youtube.com/playlist?list...";6.0;731.0;['https://people.eecs.berkeley.edu/~lingqi/publications/paper_fur2.pdf', 'https://people.eecs.berkeley.edu/~lingqi/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-1238238/'];[];['model'];0.628;0.771;[];Photorealistic Fur With Multi-Scale Rendering;An Efficient and Practical Near and Far Field Fur Reflectance Model;https://www.youtube.com/watch?v=qKhSZmS6aWw;18740.0;30.0
2016-11-13;2021-02-01;"The paper ""Playing for Data: Ground Truth from Computer Games"" is available here: http://download.visinf.tu-darmstadt.de/data/from games/ Computer graphics / VR challenge grant at Experiment: https://experiment.com/grants/graphics-and-virtualreality Other popular datasets: - CamVid - http://mi.eng.cam.ac.uk/research/projects/VideoRec/CamVid/ - CityScapes - https://www.cityscapes-dataset.com/dataset-overview/";9.0;982.0;['http://download.visinf.tu-darmstadt.de/data/from_games/', 'https://experiment.com/grants/graphics-and-virtualreality', 'http://mi.eng.cam.ac.uk/research/projects/VideoRec/CamVid/', 'https://www.cityscapes-dataset.com/dataset-overview/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/'];[];['ground truth'];0.644;0.786;[];Computer Games Empower Deep Learning Research;Playing for Data: Ground Truth from Computer Games;https://www.youtube.com/watch?v=QkqNzrsaxYc;29520.0;35.0
2017-12-13;2021-02-01;"The paper ""CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning"" is available here: https://stanfordmlgroup.github.io/projects/chexnet/ Interesting commentary on the article, check this one out too! https://lukeoakdenrayner.wordpress.com/2017/11/18/quick-thoughts-on-chestxray14-performance-claims-and-clinical-tasks/ Our";3.0;1165.0;['https://stanfordmlgroup.github.io/projects/chexnet/', 'https://lukeoakdenrayner.wordpress.com/2017/11/18/quick-thoughts-on-chestxray14-performance-claims-and-clinical-tasks/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://flic.kr/p/bCaBTq'];[];['deep learning', 'detect'];0.653;0.782;['DL'];AI Beats Radiologists at Pneumonia Detection;CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning;https://www.youtube.com/watch?v=QmIM24JDE3A;25543.0;28.0
2017-06-21;2021-02-01;"The paper ""Robust eXtended Finite Elements for Complex Cutting of Deformables"" is available here: https://www.animation.rwth-aachen.de/publication/0551/ https://animation.rwth-aachen.de/media/papers/2017-SIGGRAPH-XFEM.pdf Two Minute Papers Merch: US: http://twominutepapers.com/ EU/Worldwide: https://shop.spreadshirt.net/TwoMinutePapers/";14.0;1220.0;['https://www.animation.rwth-aachen.de/publication/0551/', 'https://animation.rwth-aachen.de/media/papers/2017-SIGGRAPH-XFEM.pdf', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-185456/'];[];[];0.655;0.78;[];Simulating Cuts On Virtual Bodies;Robust eXtended Finite Elements for Complex Cutting of Deformables;https://www.youtube.com/watch?v=R5t74AC6I0A;24430.0;24.0
2016-12-29;2021-02-01;"The paper ""StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks"" is available here: https://arxiv.org/abs/1612.03242 Source code for this project is also available here: https://github.com/hanzhanggit/StackGAN We have a";24.0;2531.0;[];['GAN'];['generative adversarial network'];0.691;0.826;['GAN'];Image Synthesis From Text With Deep Learning;StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks;https://www.youtube.com/watch?v=rAbhypxs1qQ;114725.0;30.0
2015-08-14;2021-02-01;"Artificial neural networks provide us incredibly powerful tools in machine learning that are useful for a variety of tasks ranging from image classification to voice translation. So what is all the deep learning rage about? The media seems to be all over the newest neural network research of the DeepMind company that was recently acquired by Google. They used neural networks to create algorithms that are able to play Atari games, learn them like a human would, eventually achieving superhuman performance. Deep learning means that we use artificial neural network with multiple layers, making it even more powerful for more difficult tasks. These machine learning techniques proved to be useful for many tasks beyond image recognition: they also excel at weather predictions, breast cancer cell mitosis detection, brain image segmentation and toxicity prediction among many others. If you would like to know more about neural networks and deep learning, make sure to check out these talks from Andrew Ng: https://www.youtube.com/watch?v=n1ViN... https://www.youtube.com/watch?v=W15K9... You can also check out this gorgeous application of neural networks and reinforcement learning from Google DeepMind: http://www.wired.co.uk/news/archive/2015-02/25/google-deepmind-atari Disclaimer: I was not part of this research project, I am merely providing commentary on this work. In Two Minute Papers, I attempt to bring the most awesome research discoveries to everyone a couple minutes at a time. Music: ""Watercolors"" by John Deley and the 41 Players";3.0;339.0;['http://www.wired.co.uk/news/archive/2015-02/25/google-deepmind-atari'];[];['neural network', 'reinforcement learning', 'predict', 'layer', 'machine learning', 'detect', 'artificial neural network', 'deep learning', 'classif', 'recogn', 'image classification', 'image segmentation'];0.582;0.774;['NN', 'DL', 'ANN', 'Classification', 'Image Segmentation', 'RL', 'ML'];Artificial Neural Networks and Deep Learning;;https://www.youtube.com/watch?v=rCWTOOgVXyE;20389.0;226.0
2015-10-11;2021-02-01;"Simulating colliding bodies is an essential part of creating photorealistic video footage on a computer. However, even though we know how these collisions look like, we don't yet know how they sound like. In this piece of work, a technique is described that is capable of simulating the sound emitted by smashing deformable bodies together. The results match real-world experiments remarkably well. The paper ""Toward High-Quality Modal Contact Sound"" is available here: http://www.cs.cornell.edu/projects/Sound/mc/";2.0;248.0;['http://www.cs.cornell.edu/projects/Sound/mc/'];[];[];0.562;0.728;[];Synthesizing Sound From Collisions;Toward High-Quality Modal Contact Sound;https://www.youtube.com/watch?v=rskdLEl05KI;5931.0;73.0
2017-08-02;2021-02-01;"The paper ""Anisotropic Elastoplasticity for Cloth, Knit and Hair Frictional Contact"" is available here: http://www.math.ucla.edu/~jteran/pape... http://dl.acm.org/citation.cfm?id=307... Our";4.0;746.0;[];[];[];0.629;0.762;[];Elastoplastic Hair and Cloth Simulations;Anisotropic Elastoplasticity for Cloth, Knit and Hair Frictional Contact;https://www.youtube.com/watch?v=RygQnpQMdPI;14252.0;17.0
2018-03-31;2021-02-01;"The paper ""One pixel attack for fooling deep neural networks"" is available here: https://arxiv.org/abs/1710.08864 This seems like an unofficial implementation: https://github.com/Hyperparticle/one-... Differential evolution animation credit: https://pablormier.github.io/2017/09/... Our";75.0;3815.0;[];[];['neural network'];0.709;0.824;['NN'];One Pixel Attack Defeats Neural Networks;One pixel attack for fooling deep neural networks;https://www.youtube.com/watch?v=SA4YEAWVpbk;107729.0;27.0
2017-06-24;2021-02-01;"The paper ""A Practical Extension to Microfacet Theory for the Modeling of Varying Iridescence"" and its source code is available here: https://belcour.github.io/blog/research/2017/05/01/brdf-thin-film.html Additional reading: 1. http://www.care2.com/greenliving/amazing-iridescent-fruit-worlds-most-intense-color.html 2. https://academy.allaboutbirds.org/how-birds-make-colorful-feathers/ 3. http://www.cam.ac.uk/research/news/african-fruit-brightest-thing-in-nature-but-does-not-use-pigment-to-create-its-extraordinary-colour Two Minute Papers Merch: US: http://twominutepapers.com/ EU/Worldwide: https://shop.spreadshirt.net/TwoMinutePapers/";7.0;849.0;['https://belcour.github.io/blog/research/2017/05/01/brdf-thin-film.html', 'http://www.care2.com/greenliving/amazing-iridescent-fruit-worlds-most-intense-color.html', 'https://academy.allaboutbirds.org/how-birds-make-colorful-feathers/', 'http://www.cam.ac.uk/research/news/african-fruit-brightest-thing-in-nature-but-does-not-use-pigment-to-create-its-extraordinary-colour', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-2139279/'];[];['model'];0.636;0.774;[];Iridescent Light Simulations;A Practical Extension to Microfacet Theory for the Modeling of Varying Iridescence and its source code;https://www.youtube.com/watch?v=SauCsNkGr-E;20036.0;38.0
2016-05-11;2021-02-01;"The paper ""Real-Time Polygonal-Light Shading with Linearly Transformed Cosines"" is available here: https://eheitzresearch.wordpress.com/415-2/";8.0;526.0;['https://eheitzresearch.wordpress.com/415-2/'];[];[];0.609;0.769;[];Real-Time Shading With Area Light Sources;Real-Time Polygonal-Light Shading with Linearly Transformed Cosines;https://www.youtube.com/watch?v=SC0D7aJOySY;17474.0;13.0
2015-09-27;2021-02-01;"Building architectural elements and buildings with flying machines is a hot research topic. It is a remarkably difficult task, as many of these flying machines not only have to be controlled safely, but they also have to collaborate efficiently to succeed in building complex structures. Even something as mundane as deploying the rope has its own science. In this work from the ETH Zrich, these flying machines build quite reliable rope bridges that humans can use for traversal. The original video can be found here: http://www.idsc.ethz.ch/research-dandrea/research-projects/aerial-construction.html The paper ""Building Tensile Structures with Flying Machines"" is available here: http://flyingmachinearena.org/wp-content/publications/2013/augIROS13.pdf Disclaimer: I was not part of this research project, I am merely providing commentary on this work.";1.0;282.0;['http://www.idsc.ethz.ch/research-dandrea/research-projects/aerial-construction.html', 'http://flyingmachinearena.org/wp-content/publications/2013/augIROS13.pdf'];[];[];0.571;0.735;[];Building Bridges With Flying Machines;Building Tensile Structures with Flying Machines;https://www.youtube.com/watch?v=SmyiKmfnbhc;6954.0;115.0
2015-10-26;2021-02-01;"Photorealistic rendering (also called global illumination) enables us to see how digital objects would look like in real life. It is an amazingly powerful tool in the hands of a professional artist, who can create breathtaking images or animations with. However, images created with these technique contain a substantial amount of noise until a large number of light rays are computed. Today, we're going to talk about how to use gradients and Poisson's equation to speed up this process substantially. The paper ""Gradient-Domain Path Tracing"" is available here: https://mediatech.aalto.fi/publications/graphics/GPT/ The paper ""Gradient-Domain Metropolis Light Transport"" is available here: https://mediatech.aalto.fi/publications/graphics/GPT/ I held a course on photorealistic rendering at the Technical University of Vienna. Here you can learn how the physics of light works and to write programs like this: https://www.youtube.com/playlist?list... Recommended for you: Metropolis Light Transport - https://www.youtube.com/watch?v=f0Uzi... Manipulating Photorealistic Renderings - https://www.youtube.com/watch?v=L7MOe... A talk on ray tracing - https://www.youtube.com/watch?v=qyDUv... The Moon's elevation map is provided by NASA and is available here (license: CC BY 2.0) - https://flic.kr/p/aFqE3n Music: ""Infinite Perspective"" by Kevin MacLeod is licensed under a Creative Commons Attribution license (https://creativecommons.org/licenses/by/4.0/) Source: http://incompetech.com/music/royalty-free/index.html?isrc=USUAN1500024 Artist: http://incompetech.com/";2.0;461.0;['https://mediatech.aalto.fi/publications/graphics/GPT/', 'https://mediatech.aalto.fi/publications/graphics/GMLT/', 'https://flic.kr/p/aFqE3n', 'https://creativecommons.org/licenses/by/4.0/', 'http://incompetech.com/music/royalty-free/index.html?isrc=USUAN1500024', 'http://incompetech.com/'];[];['recommend'];0.601;0.753;['Recommender'];Gradients, Poisson's Equation and Light Transport;Gradient-Domain Path Tracing;https://www.youtube.com/watch?v=sSnDTPjfBYU;11271.0;186.0
2017-08-23;2021-02-01;"The paper ""StarCraft II: A New Challenge for Reinforcement Learning"" and its source code is available here: https://arxiv.org/abs/1708.04782 https://github.com/Blizzard/s2client-...";59.0;2872.0;[];[];['reinforcement learning'];0.696;0.827;['RL'];DeepMind Publishes StarCraft II Learning Environment;StarCraft II: A New Challenge for Reinforcement Learning and its source code;https://www.youtube.com/watch?v=St5lxIxYGkI;118415.0;19.0
2018-06-12;2021-02-01;"The paper ""Neural Best-Buddies: Sparse Cross-Domain Correspondence"" is available here: https://arxiv.org/abs/1805.04140 Pick up cool perks on our";21.0;1334.0;['https://arxiv.org/abs/1805.04140', 'https://pixabay.com/photo-1580869/'];[];[];0.659;0.786;[];Neural Image Stitching And Morphing;Neural Best-Buddies: Sparse Cross-Domain Correspondence;https://www.youtube.com/watch?v=SWW0nVQNm2w;29523.0;17.0
2016-11-06;2021-02-01;The Two Minute Papers Data project: https://www.reddit.com/r/twominutepapers/comments/58qa8p/github repository for video data/ https://www.reddit.com/r/twominutepapers/comments/58qa8p/github repository for video data/ A nice writeup about the Starcraft 2 panel az Blizzcon: https://www.reddit.com/r/starcraft/comments/5bb6y0/notes from the ai panel/ Recommended for you: StyLit, Illumination-Guided Artistic Style Transfer - https://www.youtube.com/watch?v=ksCSL... Real-Time Shading With Area Light Sources - https://www.youtube.com/watch?v=SC0D7...;4.0;164.0;['https://www.reddit.com/r/starcraft/comments/5bb6y0/notes_from_the_ai_panel/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://flic.kr/p/J5Ys9N'];[];['recommend'];0.533;0.689;['Recommender'];Building a Community Around Two Minute Papers;;https://www.youtube.com/watch?v=sWZQxB2es88;2414.0;49.0
2016-12-07;2021-02-01;"The paper ""Expediting Precomputation for Reduced Deformable Simulation "" is available here: http://www.cs.columbia.edu/cg/fastpre...";1.0;312.0;[];[];[];0.577;0.743;[];Precomputed Deformation Simulations;Expediting Precomputation for Reduced Deformable Simulation;https://www.youtube.com/watch?v=tB0AVkPDDJU;8612.0;13.0
2017-09-17;2021-02-01;"The paper ""Perceptual Evaluation of Liquid Simulation Methods"" is available here: https://ge.in.tum.de/publications/2017-sig-um/";13.0;815.0;['https://ge.in.tum.de/publications/2017-sig-um/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-2753740/'];[];[];0.633;0.781;[];What is The Best Way To Simulate Liquids?;Perceptual Evaluation of Liquid Simulation Methods;https://www.youtube.com/watch?v=TItYXBoJ1sc;25104.0;12.0
2015-08-08;2021-02-01;"What is femto-photography? To be able to capture how waves of light propagate in space, one would need to build a camera that is able to take one trillion frames per second. At first, this sounds impossible, but researchers at MIT and the University of Zaragoza have managed to crack this nut: in their newest work they published to SIGGRAPH that they call femto-photography, we can observe how a mirror lights up with its image as light propagates from the light source to the camera. All this in slow motion! The paper ""Femto-Photography: Capturing and Visualizing the Propagation of Light"" is available here: http://dspace.mit.edu/openaccess-disseminate/1721.1/82039 http://giga.cps.unizar.es/~diegog/ficheros/pdf papers/femto.pdf Disclaimer: I was not part of this research project, I am merely providing commentary on this work.";4.0;270.0;['http://dspace.mit.edu/openaccess-disseminate/1721.1/82039', 'http://giga.cps.unizar.es/~diegog/ficheros/pdf_papers/femto.pdf'];[];['propagation'];0.567;0.771;[];Capturing Waves of Light With Femto-photography;Femto-Photography: Capturing and Visualizing the Propagation of Light;https://www.youtube.com/watch?v=TRNUTN01SEg;18566.0;123.0
2017-07-19;2021-02-01;"The paper ""Phace: Physics-based Face Modeling and Animation"" is available here: http://lgg.epfl.ch/publications/2017/... Our";9.0;649.0;[];[];['model'];0.621;0.771;[];Phace: Physics-based Face Modeling and Animation;Phace: Physics-based Face Modeling and Animation;https://www.youtube.com/watch?v=twWHwVaBfM8;18552.0;13.0
2017-10-15;2021-02-01;"The paper ""Video Frame Interpolation via Adaptive Separable Convolution"" and its source code is available here: https://arxiv.org/abs/1708.01692 https://github.com/sniklaus/pytorch-s... Two Minute Papers subreddit: https://www.reddit.com/r/twominutepap... Recommended for you: 1. Separable Subsurface Scattering (with convolutions) - https://www.youtube.com/watch?v=72iA... 2. https://users.cg.tuwien.ac.at/zsolnai... 3. Rocking Out With Convolutions - https://www.youtube.com/watch?v=JKYQO...";9.0;1638.0;[];[];['recommend'];0.67;0.793;['Recommender'];AI Learns Video Frame Interpolation;Video Frame Interpolation via Adaptive Separable Convolution and its source code;https://www.youtube.com/watch?v=T_g6S3f0Z5I;36304.0;43.0
2016-02-10;2021-02-01;"The faithful simulation of human skin is incredibly important both in computer games, the movie industry, and also in medical sciences. The appearance of our face is strongly determined by the underlying structure of our skin. Human skin changes significantly with age. Scientists at the University of Zaragoza came up with a really cool, fully-fledged biophysically-based model that opens up the possibility of simply specifying intuitive parameters like age, gender, skin type, and get, after some processing, a much lighter skin representation ready to generate photorealistic rendered results in real time. The paper ""A Biophysically-Based Model of the Optical Properties of Skin Aging"" is available here: http://giga.cps.unizar.es/~ajarabo/pubs/skinAgingEG15/ The thumbnail image was taken from this work.";0.0;148.0;['http://giga.cps.unizar.es/~ajarabo/pubs/skinAgingEG15/'];[];['model'];0.528;0.724;[];Biophysical Skin Aging Simulations;A Biophysically-Based Model of the Optical Properties of Skin Aging;https://www.youtube.com/watch?v=u3C4zkxNtok;5299.0;115.0
2017-03-05;2021-02-01;"Online demo of pix2pix (try drawing there!): https://affinelayer.com/pixsrv/ The paper ""Image-to-Image Translation with Conditional Adversarial Nets"" and its source code is available here: https://phillipi.github.io/pix2pix/ Twitter: https://twitter.com/search?vertical=d... More amusing results: http://www.neogaf.com/forum/showthrea... http://thechive.com/2017/02/22/this-d... Recommended for you: Image Editing with Generative Adversarial Networks - https://www.youtube.com/watch?v=pqkpI...";160.0;6276.0;[];[];['layer', 'pix2pix', 'recommend', 'generative adversarial network'];0.73;0.849;['GAN', 'Recommender', 'Pix2Pix'];AI Makes Stunning Photos From Your Drawings (pix2pix);Image-to-Image Translation with Conditional Adversarial Nets and its source code;https://www.youtube.com/watch?v=u7kQ5lNfUfg;291672.0;42.0
2017-04-30;2021-02-01;"The paper ""Photorealistic Facial Texture Inference Using Deep Neural Networks"" is available here: http://www.hao-li.com/HaoLi/HaoLi-... http://arxiv.org/pdf/1612.00523v1.pdf Two Minute Papers Merch: US: http://twominutepapers.com/ EU/Worldwide: https://shop.spreadshirt.net/TwoMinutePapers/ Earlier episode on texture synthesis: https://www.youtube.com/watch?v=8u3Hk... PatchMatch: https://www.youtube.com/watch?v=n3aoc...";123.0;2821.0;['http://www.hao-li.com/Hao_Li/Hao_Li_-_publications.html', 'http://arxiv.org/pdf/1612.00523v1.pdf', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-1961529/'];[];['neural network'];0.694;0.831;['NN'];AI Creates 3D Models From Faces;Photorealistic Facial Texture Inference Using Deep Neural Networks;https://www.youtube.com/watch?v=u9UUWqVquXo;143185.0;31.0
2017-04-05;2021-02-01;"The paper ""Rent3D: Floor-Plan Priors for Monocular Layout Estimation"" is available here: http://www.cs.toronto.edu/~fidler/projects/rent3D.html http://www.cs.toronto.edu/~urtasun/publications/liu etal cvpr15.pdf Followup paper - HouseCraft: http://www.cs.toronto.edu/housecraft/ https://github.com/chuhang/HouseCraft";7.0;723.0;['http://www.cs.toronto.edu/~fidler/projects/rent3D.html', 'http://www.cs.toronto.edu/~urtasun/publications/liu_etal_cvpr15.pdf', 'http://www.cs.toronto.edu/housecraft/', 'https://github.com/chuhang/HouseCraft', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-354233/'];[];[];0.627;0.771;[];Instant 3D Floorplans From Your Photos;Rent3D: Floor-Plan Priors for Monocular Layout Estimation;https://www.youtube.com/watch?v=UBORpapdAfU;18268.0;22.0
2017-03-29;2021-02-01;"The paper ""Stitch Meshes for Modeling Knitted Clothing with Yarn-level Detail"" is available here: http://www.cs.cornell.edu/projects/stitchmeshes/ http://www.cemyuksel.com/research/stitchmeshes/";3.0;503.0;['http://www.cs.cornell.edu/projects/stitchmeshes/', 'http://www.cemyuksel.com/research/stitchmeshes/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-2042186/'];[];['model'];0.606;0.758;[];Modeling Knitted Clothing;Stitch Meshes for Modeling Knitted Clothing with Yarn-level Detail;https://www.youtube.com/watch?v=UEPbzj-ekAI;12732.0;16.0
2015-08-25;2021-02-01;"Building time lapse videos from community photographs is an incredibly difficult and laborious task: these photos were taken at a different part of the year, from different times of the day, with different viewpoints and cameras. A good algorithm should try to equalize these images and bring them to a common denominator to get rid of the commonly seen flickering effect. Researchers at the University of Washington and Google nailed this regularization in their newest work that they showcased at SIGGRAPH 2015. Check out the video for the details! Photograph credits in the video: Flickr user dration, Zack Lee, Nadav Tobias, Juan Jesus Oro and Klaus Wikirchen. In the original paper, photographs from the following Flickr users were reproduced under Creative Commons license: Aliento Ms All, jirihnidek, mcxurxo, elka cz, Daikrieg, Free the image, Cebete and ToastyKen. The paper ""Time-lapse Mining from Internet Photos"" is available here: http://grail.cs.washington.edu/projects/timelapse/ Disclaimer: I was not part of this research project, I am merely providing commentary on this work. Thumbnail background by Davidw: https://www.flickr.com/photos/davidw/2297191644/ https://creativecommons.org/licenses/by/2.0/";0.0;156.0;['http://grail.cs.washington.edu/projects/timelapse/', 'https://www.flickr.com/photos/davidw/2297191644/', 'https://creativecommons.org/licenses/by/2.0/'];[];[];0.532;0.708;[];Time Lapse Videos From Community Photos;Time-lapse Mining from Internet Photos;https://www.youtube.com/watch?v=UePDRN94C8c;3684.0;171.0
2016-02-24;2021-02-01;"Artificial neural networks were inspired by the human brain and simulate how neurons behave when they are shown a sensory input (e.g., images, sounds, etc). They are known to be excellent tools for image recognition, any many other problems beyond that - they also excel at weather predictions, breast cancer cell mitosis detection, brain image segmentation and toxicity prediction among many others. Deep learning means that we use an artificial neural network with multiple layers, making it even more powerful for more difficult tasks. This time they have been shown to be apt at reproducing the artistic style of many famous painters, such as Vincent Van Gogh and Pablo Picasso among many others. All the user needs to do is provide an input photograph and a target image from which the artistic style will be learned. The paper ""Combining Markov Random Fields and Convolutional Neural Networks for Image Synthesis"" is available here: http://arxiv.org/pdf/1601.04589v1.pdf Previous work - the paper ""A Neural Algorithm of Artistic Style"" is available here http://arxiv.org/pdf/1508.06576v2.pdf";0.0;591.0;['http://arxiv.org/pdf/1601.04589v1.pdf', 'http://arxiv.org/pdf/1508.06576v2.pdf', 'http://deepart.io/', 'https://deepforger.com/', 'https://twitter.com/deepforger'];[];['neural network', 'neuron', 'predict', 'layer', 'detect', 'convolutional neural network', 'artificial neural network', 'deep learning', 'recogn', 'image segmentation'];0.616;0.781;['NN', 'DL', 'Image Segmentation', 'ANN', 'CNN'];Deep Learning Program Learns to Paint;Combining Markov Random Fields and Convolutional Neural Networks for Image Synthesis;https://www.youtube.com/watch?v=UGAzi1QBVEg;24986.0;168.0
2018-02-25;2021-02-01;"The paper ""A Hyperbolic Geometric Flow for Evolving Films and Foams"" is available here: https://sadashigeishida.bitbucket.io/... Recommended for you: 1. Reddit discussion on bubble thickness measurements - https://www.reddit.com/r/askscience/c... 2. An early episode on bubbles - https://www.youtube.com/watch?v=uj8b5...";6.0;880.0;[];[];['recommend'];0.638;0.773;['Recommender'];Bubble Collision Simulations in Milliseconds;A Hyperbolic Geometric Flow for Evolving Films and Foams;https://www.youtube.com/watch?v=uGhyOBSzdTs;19410.0;35.0
2017-06-05;2021-02-01;"The paper ""Perspective-aware Manipulation of Portrait Photos"" and its demo is available here: http://gfx.cs.princeton.edu/pubs/Fried 2016 PMO/index.php http://faces.cs.princeton.edu/ Two Minute Papers Merch: US: http://twominutepapers.com/ EU/Worldwide: https://shop.spreadshirt.net/TwoMinutePapers/";3.0;733.0;['http://gfx.cs.princeton.edu/pubs/Fried_2016_PMO/index.php', 'http://faces.cs.princeton.edu/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-465563/'];[];[];0.628;0.771;[];Algorithmic Beautification of Selfies;Perspective-aware Manipulation of Portrait Photos and its demo;https://www.youtube.com/watch?v=UjuBLS15JqM;18655.0;25.0
2018-05-01;2021-02-01;"The paper ""Robots that can adapt like animals"" and its source code is available here: https://members.loria.fr/jbmouret/nature press.html https://members.loria.fr/code/itelim... Pick up cool perks on our";5.0;1085.0;['https://members.loria.fr/jbmouret/nature_press.html', 'https://members.loria.fr/code/ite_limbo_nature.zip'];[];[];0.649;0.79;[];This Robot Adapts Like Animals;Robots that can adapt like animals and its source code;https://www.youtube.com/watch?v=UMSNBLAfC7o;32596.0;24.0
2018-01-17;2021-02-01;"The paper ""High-Resolution Multi-Scale Neural Texture Synthesis"" and its source code is available here: https://wxs.ca/research/multiscale-neural-synthesis/ Our";8.0;1023.0;['https://wxs.ca/research/multiscale-neural-synthesis/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-2929203/'];[];[];0.646;0.772;[];High-Resolution Neural Texture Synthesis;High-Resolution Multi-Scale Neural Texture Synthesis and its source code;https://www.youtube.com/watch?v=Uo6hFVRsjpA;18851.0;16.0
2018-01-27;2021-02-01;"The paper ""Building Machines That Learn and Think Like People"" is available here: https://arxiv.org/abs/1604.00289 DeepMind's commentary article: https://arxiv.org/ftp/arxiv/papers/1711/1711.08378.pdf One-time payment links are available below. Thank you very much for your generous support! PayPal: https://www.paypal.me/TwoMinutePapers Bitcoin: 13hhmJnLEzwXgmgJN7RB6bWVdT7WkrFAHh Ethereum: 0x002BB163DfE89B7aD0712846F1a1E53ba6136b5A";23.0;978.0;['https://arxiv.org/abs/1604.00289', 'https://arxiv.org/ftp/arxiv/papers/1711/1711.08378.pdf', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-2981726/'];[];[];0.643;0.781;[];Building Machines That Learn and Think Like People;Building Machines That Learn and Think Like People;https://www.youtube.com/watch?v=uOiOhVgR3VA;24912.0;38.0
2018-03-15;2021-02-01;"The paper ""Avatar Digitization From a Single Image For Real-Time Rendering"" is available here: http://www.hao-li.com/publications/papers/siggraphAsia2017ADFSIFRTR.pdf http://www.hao-li.com/HaoLi/HaoLi-... Demo for iOS: http://pinscreen.com/ Our";13.0;1414.0;['http://www.hao-li.com/publications/papers/siggraphAsia2017ADFSIFRTR.pdf', 'http://www.hao-li.com/Hao_Li/Hao_Li_-_publications.html', 'http://pinscreen.com/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/'];[];[];0.663;0.792;[];AI-Based Animoji Without The iPhone X;Avatar Digitization From a Single Image For Real-Time Rendering;https://www.youtube.com/watch?v=UPcR7S8ue1A;35163.0;21.0
2016-05-22;2021-02-01;"Artificial neural networks were inspired by the human brain and simulate how neurons behave when they are shown a sensory input (e.g., images, sounds, etc). They are known to be excellent tools for image recognition, any many other problems beyond that - they also excel at weather predictions, breast cancer cell mitosis detection, brain image segmentation and toxicity prediction among many others. Deep learning means that we use an artificial neural network with multiple layers, making it even more powerful for more difficult tasks. This time they have been shown to be apt at reproducing the artistic style of many famous painters, such as Vincent Van Gogh and Pablo Picasso among many others. All the user needs to do is provide an input photograph and a target image from which the artistic style will be learned. And now, onto the next frontier: transferring artistic style to videos! The paper ""Artistic style transfer for videos"" is available here: http://arxiv.org/abs/1604.08610 The implementation of this technique is also available: https://github.com/manuelruder/artistic-videos Recommended for you: Deep Neural Network Learns Van Gogh's Art - https://www.youtube.com/watch?v=-R9bJ... Deep Learning Program Learns to Paint - https://www.youtube.com/watch?v=UGAzi... From Doodles To Paintings With Deep Learning - https://www.youtube.com/watch?v=jMZqx... Sintel Movie copyright: Blender Foundation https://durian.blender.org/sharing/";1.0;1012.0;['http://arxiv.org/abs/1604.08610', 'https://github.com/manuelruder/artistic-videos', 'https://durian.blender.org/sharing/'];[];['neural network', 'neuron', 'predict', 'layer', 'detect', 'artificial neural network', 'deep learning', 'recogn', 'recommend', 'image segmentation'];0.646;0.8;['Recommender', 'NN', 'Image Segmentation', 'DL', 'ANN'];Artistic Style Transfer For Videos;Artistic style transfer for videos;https://www.youtube.com/watch?v=Uxax5EKg0zA;45470.0;202.0
2017-12-09;2021-02-01;"The paper ""Universal Style Transfer via Feature Transforms"" and its source code is available here: https://arxiv.org/abs/1705.08086 https://github.com/Yijunmaverick/Univ... Recommended for you: https://www.youtube.com/watch?v=Rdpbn... - What is an Autoencoder?";10.0;1687.0;[];[];['autoencoder', 'recommend'];0.672;0.793;['Recommender'];Universal Neural Style Transfer;Universal Style Transfer via Feature Transforms and its source code;https://www.youtube.com/watch?v=v1oWke0Qf1E;35960.0;26.0
2017-02-05;2021-02-01;OpenAI Universe + blog post: https://openai.com/blog/universe/ https://universe.openai.com/ Also, make sure to check out Google DeepMind's lab: https://github.com/deepmind/lab https://deepmind.com/blog/open-sourcing-deepmind-lab/ For the record: no, I am not an Edge user. :) Terrain learning footage credit: http://www.cs.ubc.ca/~van/papers/2016-TOG-deepRL/;15.0;814.0;['https://openai.com/blog/universe/', 'https://universe.openai.com/', 'https://github.com/deepmind/lab', 'https://deepmind.com/blog/open-sourcing-deepmind-lab/', 'http://www.cs.ubc.ca/~van/papers/2016-TOG-deepRL/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-821568/'];['RL', 'AI'];[];0.633;0.781;['RL', 'AI'];Game AI Development With OpenAI Universe;;https://www.youtube.com/watch?v=vaFhLAbPi8w;24670.0;34.0
2018-03-27;2021-02-01;"The paper ""Learning by Playing - Solving Sparse Reward Tasks from Scratch"" is available here: https://arxiv.org/abs/1802.10567 Our";8.0;1091.0;[];[];['reward'];0.649;0.782;[];DeepMind's AI Learns Complex Behaviors From Scratch;Learning by Playing - Solving Sparse Reward Tasks from Scratch;https://www.youtube.com/watch?v=veWkBsK0nwU;25779.0;17.0
2017-08-06;2021-02-01;"The paper ""Visual Attribute Transfer through Deep Image Analogy"" and its source code is available here: https://arxiv.org/pdf/1705.01088.pdf https://github.com/msracver/Deep-Image-Analogy";9.0;1288.0;['https://arxiv.org/pdf/1705.01088.pdf', 'https://github.com/msracver/Deep-Image-Analogy', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-1895653/'];[];[];0.658;0.787;[];AI Learns Semantic Style Transfer;Visual Attribute Transfer through Deep Image Analogy and its source code;https://www.youtube.com/watch?v=vmkqFRyNUWo;29676.0;18.0
2017-11-18;2021-02-01;"The paper ""Progressive Growing of GANs for Improved Quality, Stability, and Variation"" and its source code is available here: http://research.nvidia.com/publication/2017-10 Progressive-Growing-of Our";31.0;2180.0;['http://research.nvidia.com/publication/2017-10_Progressive-Growing-of', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-2911332/'];['GAN'];[];0.684;0.813;['GAN'];NVIDIA's AI Dreams Up Imaginary Celebrities;Progressive Growing of GANs for Improved Quality, Stability, and Variation and its source code;https://www.youtube.com/watch?v=VrgYtFhVGmg;71672.0;22.0
2017-07-06;2021-02-01;"The paper ""A simple neural network module for relational reasoning"" is available here: https://arxiv.org/abs/1706.01427 Details on our";66.0;3334.0;[];[];['neural network'];0.703;0.822;['NN'];DeepMind's AI Learns Superhuman Relational Reasoning;A simple neural network module for relational reasoning;https://www.youtube.com/watch?v=vzg5Qe0pTKk;98647.0;17.0
2016-10-09;2021-02-01;"Better Explained tutorials: https://betterexplained.com/articles/an-interactive-guide-to-the-fourier-transform/ https://betterexplained.com/cheatsheet/ Today, our main question is whether we can reproduce the effect of subsurface scattering with 3D printed materials. The input would be a real material, and the output would be an arbitrary shaped 3d printed material with similar scattering properties. Something that looks similar. The paper ""Physical Reproduction of Materials with Specified Subsurface Scattering"" is available here: http://people.csail.mit.edu/wojciech/PRO/index.html Recommended for you: Separable Subsurface Scattering (more on diffusion profiles therein) - https://www.youtube.com/watch?v=72iA...";6.0;290.0;['https://betterexplained.com/articles/an-interactive-guide-to-the-fourier-transform/', 'https://betterexplained.com/cheatsheet/', 'http://people.csail.mit.edu/wojciech/PRO/index.html', 'https://flic.kr/p/6mPh2m', 'https://flic.kr/p/fGie2L', 'http://research.edm.uhasselt.be/thaber/subsurface.php', 'http://www.cs.virginia.edu/~rw2p/cs647/project.htm', 'https://flic.kr/p/83CZc1', 'https://flic.kr/p/E4WLJQ', 'https://flic.kr/p/b9xtJa', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/'];[];['recommend'];0.572;0.752;['Recommender'];3D Printing Materials With Subsurface Scattering;Physical Reproduction of Materials with Specified Subsurface Scattering;https://www.youtube.com/watch?v=w2D5JR83pFI;10800.0;76.0
2016-05-19;2021-02-01;"In this piece of work, a combination of deep learning and reinforcement learning is presented which has proven to be useful in solving many extremely difficult tasks. Google DeepMind built a system that can play Atari games at a superhuman level using this technique that is also referred to as Deep Q-Learning. This time, it was used to teach digital creatures to walk and overcome challenging terrain arrangements. The paper ""Terrain-Adaptive Locomotion Skills Using Deep Reinforcement Learning "" is available here: http://www.cs.ubc.ca/~van/papers/2016-TOG-deepRL/index.html The implementation of the paper is also available here: https://github.com/xbpeng/DeepTerrainRL OpenAI's Gym project: https://gym.openai.com/";4.0;694.0;['http://www.cs.ubc.ca/~van/papers/2016-TOG-deepRL/index.html', 'https://github.com/xbpeng/DeepTerrainRL', 'https://gym.openai.com/', 'https://flic.kr/p/o7z8o1'];['RL', 'AI'];['deep learning', 'reinforcement learning'];0.625;0.78;['RL', 'AI', 'DL'];Deep Reinforcement Terrain Learning;Terrain-Adaptive Locomotion Skills Using Deep Reinforcement Learning;https://www.youtube.com/watch?v=wBrwN4dS-DA;24532.0;96.0
2018-02-07;2021-02-01;"The paper ""DeepMind Control Suite"" and its source code is available here: https://arxiv.org/pdf/1801.00690v1.pdf https://github.com/deepmind/dmcontrol";4.0;744.0;[];[];[];0.629;0.772;[];DeepMind Control Suite;DeepMind Control Suite and its source code;https://www.youtube.com/watch?v=WhaRsrlaXLk;18880.0;14.0
2017-06-14;2021-02-01;"The paper ""Stylized Keyframe Animation of Fluid Simulations"" is available here: http://gfx.cs.princeton.edu/pubs/Browning 2014 SKA/index.php Two Minute Papers Merch: US: http://twominutepapers.com/ EU/Worldwide: https://shop.spreadshirt.net/TwoMinutePapers/";9.0;490.0;['http://gfx.cs.princeton.edu/pubs/Browning_2014_SKA/index.php', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-1330662/'];[];[];0.604;0.755;[];Style Transfer For Fluid Simulations;Stylized Keyframe Animation of Fluid Simulations;https://www.youtube.com/watch?v=wlAgyf_e-hA;11724.0;22.0
2017-05-17;2021-02-01;"The paper ""Phase-Functioned Neural Networks for Character Control"" is available here: http://theorangeduck.com/page/phase-functioned-neural-networks-character-control Two Minute Papers Merch: US: http://twominutepapers.com/ EU/Worldwide: https://shop.spreadshirt.net/TwoMinutePapers/";6.0;1103.0;['http://theorangeduck.com/page/phase-functioned-neural-networks-character-control', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-1835354/'];[];['neural network'];0.65;0.78;['NN'];Real-Time Character Control With Phase-Functioned Neural Networks;Phase-Functioned Neural Networks for Character Control;https://www.youtube.com/watch?v=wlndIQHtiFw;23905.0;20.0
2017-02-01;2021-02-01;"The paper ""RAISR: Rapid and Accurate Image Super Resolution"" is available here: https://arxiv.org/abs/1606.01299 Additional supplementary materials: https://drive.google.com/file/d/0BzCe... Blog posts: https://research.googleblog.com/2016/... https://www.blog.google/products/goog...";31.0;2345.0;[];['AI'];[];0.687;0.818;['AI'];Enhance! Super Resolution From Google;RAISR: Rapid and Accurate Image Super Resolution;https://www.youtube.com/watch?v=WovbLx8C0yA;84129.0;21.0
2017-10-11;2021-02-01;"The paper ""Deep Reinforcement Learning from Human Preferences"" is available here: https://arxiv.org/pdf/1706.03741.pdf Our";28.0;690.0;['https://arxiv.org/pdf/1706.03741.pdf', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-2386034/'];[];['reinforcement learning'];0.623;0.769;['RL'];Deep Learning From Human Preferences;Deep Reinforcement Learning from Human Preferences;https://www.youtube.com/watch?v=WT0WtoYz2jE;17633.0;13.0
2017-04-02;2021-02-01;"The paper ""Learning Detail Transfer based on Geometric Features"" is available here: http://www.chongyangma.com/publicatio... The story of our recent software and hardware overhaul: https://www.patreon.com/posts/softwar...";6.0;392.0;[];[];[];0.591;0.751;[];Geometric Detail Transfer;Learning Detail Transfer based on Geometric Features;https://www.youtube.com/watch?v=wz9cUncBdxw;10575.0;23.0
2017-02-13;2021-02-01;"The paper ""Importance Sampling Techniques for Path Tracing in Participating Media"" is available here: https://www.solidangle.com/research/e... Implementation in 2k (binary + video without code): https://users.cg.tuwien.ac.at/zsolnai... Solid Angle (Arnold renderer) webpage + Oscar award headline: https://www.solidangle.com/ https://www.solidangle.com/news/2017-...";10.0;708.0;[];[];[];0.626;0.773;[];How Do Hollywood Movies Render Smoke?;Importance Sampling Techniques for Path Tracing in Participating Media;https://www.youtube.com/watch?v=XbuEYcFfl6s;19845.0;35.0
2018-04-22;2021-02-01;"The paper ""Toward Multimodal Image-to-Image Translation"" and its source code is available here: https://junyanz.github.io/BicycleGAN/ Our";10.0;1297.0;['https://junyanz.github.io/BicycleGAN/', 'https://pixabay.com/photo-2985977/'];['GAN'];[];0.658;0.79;['GAN'];AI Photo Translation;Toward Multimodal Image-to-Image Translation and its source code;https://www.youtube.com/watch?v=XcxzKLrCpyk;32560.0;15.0
2017-07-09;2021-02-01;"The paper ""The ""something something"" video database for learning and evaluating visual common sense"" is available here: https://arxiv.org/abs/1706.04261 Source for the video results: https://medium.com/@raghavgoyal14/7383596f58df Recommended for you: Recurrent Neural Network Writes Sentences About Images - https://www.youtube.com/watch?v=e-WB4... Two Minute Papers Merch: US: http://twominutepapers.com/ EU/Worldwide: https://shop.spreadshirt.net/TwoMinutePapers/";26.0;625.0;['https://arxiv.org/abs/1706.04261', 'https://medium.com/@raghavgoyal14/7383596f58df', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-569070/'];[];['neural network', 'recommend', 'recurrent neural network'];0.617;0.777;['Recommender', 'NN', 'RNN'];AI Learns Visual Common Sense With New Dataset;The something something video database for learning and evaluating visual common sense;https://www.youtube.com/watch?v=XgB3Xg5st2U;21804.0;44.0
2018-01-01;2021-02-01;"The paper ""High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs"" and its source code is available here: https://tcwang0509.github.io/pix2pixHD/ Openings at our Institute. Make sure to mention to the contact person that you found this through Two Minute Papers! https://www.cg.tuwien.ac.at/jobs/3dspatialization/";8.0;1694.0;['https://tcwang0509.github.io/pix2pixHD/', 'https://www.cg.tuwien.ac.at/jobs/3dspatialization/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-1721451/'];['GAN'];['pix2pix'];0.672;0.793;['GAN', 'Pix2Pix'];AI Learns Semantic Image Manipulation;High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs and its source code;https://www.youtube.com/watch?v=XhH2Cc4thJw;36149.0;40.0
2016-09-06;2021-02-01;"This time, we are going to talk about hair modeling - obtaining hair geometry information from a photograph. This geometry information we can use in our movies and computer games. We can also run simulations on them and see how they look on a digital character. This is a remarkably difficult problem and you'll see a great solution to it in this episode. The paper ""AutoHair: Fully Automatic Hair Modeling from A Single Image"" is available here: http://gaps-zju.org/mlchai/resources/chai2016autohair.pdf http://gaps-zju.org/mlchai/";3.0;445.0;['http://gaps-zju.org/mlchai/resources/chai2016autohair.pdf', 'http://gaps-zju.org/mlchai/', 'https://experiment.com/', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://flic.kr/p/oye7FJ'];[];['model'];0.599;0.76;[];Automatic Hair Modeling from One Image;AutoHair: Fully Automatic Hair Modeling from A Single Image;https://www.youtube.com/watch?v=XmM1tF7AxdA;13433.0;79.0
2017-08-09;2021-02-01;"The paper ""Imagination-Augmented Agents for Deep Reinforcement Learning"" is available here: https://arxiv.org/abs/1707.06203 Out";51.0;3282.0;['https://arxiv.org/abs/1707.06203', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-767781/'];[];['reinforcement learning'];0.702;0.818;['RL'];DeepMind's AI Learns Imagination-Based Planning;Imagination-Augmented Agents for Deep Reinforcement Learning;https://www.youtube.com/watch?v=xp-YOPcjkFw;86893.0;13.0
2016-08-17;2021-02-01;"We are going to talk about techniques that create physically based material models from photographs that we can use in our light simulation programs. In an earlier work, two photographs are required for high-quality reconstruction. It seems that working from only one photograph doesn't seem possible at all. However, with the power of deep learning... The paper ""Two-Shot SVBRDF Capture for Stationary Materials"" is available here: https://mediatech.aalto.fi/publications/graphics/TwoShotSVBRDF/ The paper ""Reflectance Modeling by Neural Texture Synthesis"" is available here: https://mediatech.aalto.fi/publications/graphics/TwoShotSVBRDF/ NVIDIA has implemented the two-shot model! Have a look: https://twitter.com/karolyzsolnai/st... Our earlier episode on Gradient Domain Light Transport is available here: https://www.youtube.com/watch?v=sSnDT... The light transport course at the Technical University of Vienna is available here: https://www.youtube.com/playlist?list...";6.0;629.0;['https://mediatech.aalto.fi/publications/graphics/TwoShotSVBRDF/', 'https://mediatech.aalto.fi/publications/graphics/NeuralSVBRDF/', 'https://twitter.com/karoly_zsolnai/status/839570124017438726', 'https://experiment.com/', 'https://flic.kr/p/7pNLqB', 'https://flic.kr/p/b2GMJ', 'https://flic.kr/p/7j3dUX', 'https://flic.kr/p/Gdg3JC', 'https://flic.kr/p/rAbED', 'http://collagefactory.blogspot.hu/2010/04/brdf-for-diffuseglossyspecular.html', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/'];[];['deep learning', 'model'];0.619;0.768;['DL'];Neural Material Synthesis;Two-Shot SVBRDF Capture for Stationary Materials;https://www.youtube.com/watch?v=XpwW3glj2T8;16878.0;115.0
2017-01-29;2021-02-01;"The paper ""A scalable Schur-complement fluids solver for heterogeneous compute platforms"" is available here: http://graphics.cs.wisc.edu/Papers/20...";6.0;941.0;[];[];[];0.642;0.785;[];Large-Scale Fluid Simulations On Your Graphics Card;A scalable Schur-complement fluids solver for heterogeneous compute platforms;https://www.youtube.com/watch?v=Yd4blFeRTEw;28255.0;15.0
2017-12-17;2021-02-01;"The paper ""Interactive Reconstruction of Monte Carlo Image Sequences using a Recurrent Denoising Autoencoder"" is available here: http://research.nvidia.com/publicatio... The paper with the notoriously difficult ""Spheres"" scene: https://users.cg.tuwien.ac.at/zsolnai...";18.0;2278.0;[];[];['autoencoder'];0.686;0.808;[];AI Learns Noise Filtering For Photorealistic Videos;Interactive Reconstruction of Monte Carlo Image Sequences using a Recurrent Denoising Autoencoder;https://www.youtube.com/watch?v=YjjTPV2pXY0;60943.0;27.0
2018-06-30;2021-02-01;"The paper ""Efficient Rendering of Layered Materials using an Atomic Decomposition with Statistical Operators"" is available here: https://belcour.github.io/blog/resear... My course on photorealistic rendering at the Technical University of Vienna: https://www.youtube.com/playlist?list... Pick up cool perks on our";9.0;1255.0;[];[];['layer'];0.657;0.779;[];Beautiful Layered Materials, Instantly;Efficient Rendering of Layered Materials using an Atomic Decomposition with Statistical Operators;https://www.youtube.com/watch?v=YTup-cvELK0;23281.0;36.0
2017-03-19;2021-02-01;"The paper ""Space-Time Video Completion"" is available here: http://www.wisdom.weizmann.ac.il/~vis... Unofficial implementation: http://www2.mta.ac.il/~tal/ImageCompl... Disclaimer: as the website mentioned the source code, I incorrectly assumed that it also contains that. Unfortunately, this is not the case. Please have a look at this followup paper with source code, hopefully this will be of help - http://perso.telecom-paristech.fr/~go... In the meantime, if you find an implementation of this technique, please let me know and I'll add a link to it here.";3.0;633.0;[];[];[];0.62;0.759;[];Space-Time Video Completion;Space-Time Video Completion;https://www.youtube.com/watch?v=YWK-bnyXvbg;13252.0;76.0
2016-06-22;2021-02-01;"The paper ""Model Compression"" is available here: https://www.cs.cornell.edu/~caruana/compression.kdd06.pdf There is also a talk on it here: http://research.microsoft.com/apps/video/default.aspx?id=103668&r=1 Discussions on this issue: 1. https://www.linkedin.com/pulse/computer-vision-research-my-deep-depression-nikos-paragios 2. https://www.reddit.com/r/MachineLearning/comments/4lq701/yann lecuns letter to cvpr chair after bad/ Recommended for you: Neural Programmer Interpreters - https://www.youtube.com/watch?v=B70tT...";2.0;275.0;['https://www.cs.cornell.edu/~caruana/compression.kdd06.pdf', 'http://research.microsoft.com/apps/video/default.aspx?id=103668&r=1', 'https://www.linkedin.com/pulse/computer-vision-research-my-deep-depression-nikos-paragios', 'https://www.reddit.com/r/MachineLearning/comments/4lq701/yann_lecuns_letter_to_cvpr_chair_after_bad/', 'https://experiment.com/', 'https://flic.kr/p/nVUaB'];[];['model', 'recommend'];0.569;0.74;['Recommender'];What Can We Learn From Deep Learning Programs?;Model Compression;https://www.youtube.com/watch?v=ZBWTD2aNb_o;8045.0;40.0
2017-05-31;2021-02-01;"The paper ""Variational Stokes: A Unified Pressure-Viscosity Solver for Accurate Viscous Liquids"" is available here: https://cs.uwaterloo.ca/~elariono/sto... Recommended for you: Simulating Viscosity and Melting Fluids - https://www.youtube.com/watch?v=KgIrn... Two Minute Papers Merch: US: http://twominutepapers.com/ EU/Worldwide: https://shop.spreadshirt.net/TwoMinut...";5.0;1021.0;[];[];['recommend'];0.646;0.791;['Recommender'];Simulating Honey Coiling;Variational Stokes: A Unified Pressure-Viscosity Solver for Accurate Viscous Liquids;https://www.youtube.com/watch?v=ZEjUqZU1hNQ;33879.0;34.0
2016-07-31;2021-02-01;"This piece of work is about synthesizing believable footstep animations for virtual characters. The paper ""Task-based Locomotion"" is available here: http://www.cs.ubc.ca/~van/papers/2016-TOG-taskBasedLocomotion/index.html";2.0;373.0;['http://www.cs.ubc.ca/~van/papers/2016-TOG-taskBasedLocomotion/index.html', 'https://experiment.com/'];[];[];0.588;0.741;[];Task-based Animation of Virtual Characters;Task-based Locomotion;https://www.youtube.com/watch?v=ZHoNpxUHewQ;8094.0;21.0
2018-01-06;2021-02-01;"The paper ""Distilling a Neural Network Into a Soft Decision Tree"" is available here: https://arxiv.org/pdf/1711.09784.pdf Decision Trees and Boosting, XGBoost: https://www.youtube.com/watch?v=0Xc9L...";17.0;1197.0;[];[];['neural network', 'decision tree'];0.654;0.787;['NN', 'Decision Tree'];Distilling Neural Networks;Distilling a Neural Network Into a Soft Decision Tree;https://www.youtube.com/watch?v=zjaz2mC1KhM;30189.0;21.0
2016-07-25;2021-02-01;"This piece of work enables us to walk around in a room with a camera, and create a complete 3D computer model from the video footage. Note that the title says ""2D"", but since RGB-D cameras are relatively new, they are both referred to as 2D and 3D (I've heard 2.5D as well before). We went with the 2D for now and I hope it won't raise any confusion! :) The paper ""BundleFusion: Real-time Globally Consistent 3D Reconstruction using Online Surface Re-integration"" is available here: http://graphics.stanford.edu/projects/bundlefusion/";6.0;366.0;['http://graphics.stanford.edu/projects/bundlefusion/', 'https://experiment.com/', 'http://www.blendswap.com/blends/view/74382'];[];['model'];0.587;0.754;[];Bundlefusion: 3D Scenes from 2D Videos;BundleFusion: Real-time Globally Consistent 3D Reconstruction using Online Surface Re-integration;https://www.youtube.com/watch?v=zLzhsyeAie4;11521.0;86.0
2016-03-20;2021-02-01;"This piece of work tries to estimate depth information from an input photogaph. This means that it looks at the photo and tries to tell how far away parts of the image are from the camera, and the final goal is that we provide a photograph for which the depth information is completely unknown and we ask the algorithm to provide it for us. The paper ""3-D Depth Reconstruction from a Single Still Image"" is available here: http://www.cs.cornell.edu/~asaxena/learningdepth/saxena ijcv07 learningdepth.pdf The source of the shown video at the end: https://www.youtube.com/watch?v=GWWIn...";5.0;330.0;['http://www.cs.cornell.edu/~asaxena/learningdepth/saxena_ijcv07_learningdepth.pdf', 'https://flic.kr/p/pZj8KD'];[];[];0.58;0.769;[];3D Depth From a Single Photograph;3-D Depth Reconstruction from a Single Still Image;https://www.youtube.com/watch?v=ZolWxY4f9wc;17460.0;90.0
2017-09-04;2021-02-01;"The paper ""Audio-Driven Facial Animation by Joint End-to-End Learning of Pose and Emotion"" is available here: http://research.nvidia.com/publication/2017-07 Audio-Driven-Facial-Animation Our";132.0;7747.0;['http://research.nvidia.com/publication/2017-07_Audio-Driven-Facial-Animation', 'https://www.patreon.com/posts/14199475', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-2308464/'];[];[];0.738;0.843;[];AI Creates Facial Animation From Audio;Audio-Driven Facial Animation by Joint End-to-End Learning of Pose and Emotion;https://www.youtube.com/watch?v=ZtP3gl_2kBM;229506.0;19.0
2017-02-26;2021-02-01;"The paper ""Recovering Shape and Spatially-Varying Surface Reflectance under Unknown Illumination"" is available here: http://www.cs.wm.edu/~ppeers/showPublication.php?id=Xia:2016:RSS";3.0;601.0;['http://www.cs.wm.edu/~ppeers/showPublication.php?id=Xia:2016:RSS', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://www.flickr.com/photos/8143264@N08/4946656511/'];[];[];0.617;0.749;[];Shape and Material from Video;Recovering Shape and Spatially-Varying Surface Reflectance under Unknown Illumination;https://www.youtube.com/watch?v=ZUa5sNVSjGw;10056.0;15.0
2018-01-10;2021-02-01;"The paper ""Deep Image Prior"" and its source code is available here: https://dmitryulyanov.github.io/deep... Our";10.0;1223.0;[];[];[];0.655;0.786;[];Deep Image Prior;Deep Image Prior and its source code;https://www.youtube.com/watch?v=_BPJFFkxSbw;29396.0;14.0
2017-08-13;2021-02-01;"The paper ""Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks"" is available here: https://arxiv.org/pdf/1702.01135.pdf Out";12.0;986.0;['https://arxiv.org/pdf/1702.01135.pdf', 'https://creativecommons.org/licenses/by/4.0/', 'http://audionautix.com/', 'https://pixabay.com/photo-2072618/'];[];['neural network', 'relu'];0.644;0.768;['ReLu', 'NN'];Verifying Mission-Critical AI Programs;Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks;https://www.youtube.com/watch?v=_DN2rzHkpZE;16910.0;17.0
2016-01-17;2021-02-01;"What are caustics? A caustic is a beautiful phenomenon in nature where curved surfaces reflect or refract light, thereby concentrating it to a relatively small area. This technique makes it possible to essentially imagine any kind of caustic pattern, for instance, this brain pattern, and it will create the model that will cast caustics that look exactly like that. It also works with sunlight, and you can also choose different colors for your caustics. The authors found their simulations to be in good agreement with reality, therefore the desired caustic patterns can be fabricated faithfully. The paper ""High-contrast Computational Caustic Design"" is available here: http://chateaunoir.net/caustics.html The full Rendering course at the TU Wien is available here: https://www.youtube.com/playlist?list... More results from this project are available here: http://rayform.ch/";0.0;233.0;['http://chateaunoir.net/caustics.html', 'http://rayform.ch/', 'https://en.wikipedia.org/wiki/Caustic_(optics', 'https://www.flickr.com/photos/fdecomite/2486275725', 'https://flic.kr/p/pamCiP', 'https://flic.kr/p/nD7Ex', 'https://flic.kr/p/iJUi3', 'https://flic.kr/p/8DvPiz'];[];['model'];0.559;0.719;[];3D Printing Objects With Caustics;High-contrast Computational Caustic Design;https://www.youtube.com/watch?v=_r-eIKkyAco;4779.0;126.0
2015-11-18;2021-02-01;"Reinforcement learning is a technique that can learn how to play computer games, or any kind of activity that requires a sequence of actions. In this case, we would like a digital dog to run, and leap over and onto obstacles by choosing the optimal next action. It is quite difficult as there are a lot of body parts to control in harmony. And what is really amazing is that if it has learned everything properly, it will come up with exactly the same movements as we'd expect animals to do in real life! In this technique, dogs were used to demonstrate that reinforcement learning works well in this context, but it's worth noting that it also works with bipeds. The paper ""Dynamic Terrain Traversal Skills Using Reinforcement Learning "" is available here: http://www.cs.ubc.ca/~van/papers/2015-TOG-terrainRL/ Recommended for you: Digital Creatures Learn To Walk - https://www.youtube.com/watch?v=kQ2bq...";0.0;229.0;['http://www.cs.ubc.ca/~van/papers/2015-TOG-terrainRL/', 'https://flic.kr/p/wXfFt1'];['RL'];['reinforcement learning', 'recommend'];0.558;0.748;['RL', 'Recommender'];Terrain Traversal with Reinforcement Learning;Dynamic Terrain Traversal Skills Using Reinforcement Learning;https://www.youtube.com/watch?v=_yjHPu1aYCY;9834.0;144.0
2016-03-02;2021-02-01;Two Minute Papers is a series where the most recent and awesome scientific works are discussed in a simple and enjoyable way, two minutes at a time. Give it a try! A full playlist with every episode is available here: https://www.youtube.com/playlist?list...;2.0;442.0;['https://flic.kr/p/7GGgdx'];[];[];0.599;0.819;[];Awesome Research For Everyone! - Two Minute Papers Channel Trailer;;https://www.youtube.com/watch?v=_ZLXKt4L-AA;88495.0;41.0
