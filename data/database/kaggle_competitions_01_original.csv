date;description;license;link;ml_detected;ml_libs;ml_slugs;ml_terms;reference;score_views;score_votes;scraped_at;sources;tags;title;type;views;votes;score_private;score_public
2019-01-11 10:49:10;Hybrid solution update using multiple sources. Here is my quick & dirty test kernel using hybrid clear/crypted training set and partial decryption results. As you can see, the improvement is not impressive... Many Thanks to:  Flal for kernel :Cipher #1 & Cipher #2 Full Solutions (https://www.kaggle.com/leflal/cipher-1-cipher-2-full-solutions) ARES for kernel: Classification - TFIDF + Logistic (https://www.kaggle.com/ananthu017/classification-tfidf-logistic) kaggleuser58 for kernel: 1 char decryption in level 1, 2 and 3 gives 98.85% (https://www.kaggle.com/kaggleuser58/1-char-decryption-in-level-1-2-and-3-gives-98-85);Apache 2.0;https://www.kaggle.com/a45632/classification-tfidf-svm-2-0;1.0;['sklearn'];['ai', 'ml'];['filter', 'train', 'model', 'predict', 'classification'];https://www.kaggle.com/c/20-newsgroups-ciphertext-challenge;0.615;0.268;2020-12-12 16:01:56;20 Newsgroups Ciphertext Challenge;['gpu, beginner, nlp'];Classification - TFIDF + SVM - 2.0;Python notebook;582.0;7;;
2018-12-24 16:27:39;This is an attempt to solve difficulty 3. It builds on the tools provided by this awesome kernel to solve difficulty 1.  https://www.kaggle.com/rturley/a-first-crack-tools-and-first-cipher-solution;Apache 2.0;https://www.kaggle.com/amansohane/level-3-with-partial-deciphering-0-94-level-3;1.0;['sklearn'];['ai', 'dl', 'gan', 'rl', 'ml', 'nn', 'ann'];['train', 'classification', 'predict'];https://www.kaggle.com/c/20-newsgroups-ciphertext-challenge;0.593;0.268;2020-12-12 16:01:56;20 Newsgroups Ciphertext Challenge;[];Level 3 with partial deciphering;Python notebook;399.0;7;;
2019-01-04 08:43:54;"What is Attention? Attention is simply a vector, often the outputs of dense layer using softmax function. Before Attention mechanism, translation relies on reading a complete sentence and compress all information into a fixed-length vector, as you can image, a sentence with hundreds of words represented by several words will surely lead to information loss, inadequate translation, etc.  Attention Architecture with Idea Behind it. The basic idea: each time the model predicts an output word, it only uses parts of an input where the most relevant information is concentrated instead of an entire sentence. In other words, it only pays attention to some input words. Let’s investigate how this is implemented.    Encoder works as usual, and thedifference is only on the decoder’s part. As you can see from a picture, the decoder’s hidden state is computed with a context vector, the previous output and the previous hidden state. But now we use not a single context vector c, but a separate context vector c_i for each target word. These context vectors are computed as a weighted sum of annotations generated by the encoder. In Bahdanau’s paper, they use a Bidirectional LSTM, so these annotations are concatenations of hidden states in forward and backward directions. The weight of each annotation is computed by an alignment model which scores how well the inputs and the output match. An alignment model is a feedforward neural network, for instance. In general, it can be any other model as well. As a result, the alphas — the weights of hidden states when computing a context vector — show how important a given annotation is in deciding the next state and generating the output word. These are the attention scores.  Why Attention? The core of Probabilistic Language Model is to assign a probability to a sentence by Markov Assumption. Due to the nature of sentences that consist of different numbers of words, RNN is naturally introduced to model the conditional probability among words.   Vanilla RNN (the classic one) often gets trapped when modeling:  Structure Dilemma: in real world, the length of outputs and inputs can be totally different, while Vanilla RNN can only handle fixed-length problem which is difficult for the alignment. Consider an EN-FR translation examples: “he doesn’t like apples” → “Il n’aime pas les pommes”. Mathematical Nature: it suffers from Gradient Vanishing/Exploding which means it is hard to train when sentences are long enough (maybe at most 4 words). Translation often requires arbitrary input length and out put length, to deal with the deficits above, encoder-decoder model is adopted and basic RNN cell is changed to GRU or LSTM cell, hyperbolic tangent activation is replaced by ReLU. We use GRU cell here.    Embedding layer maps discrete words into dense vectors for computational efficiency. Then embedded word vectors are fed into encoder, aka GRU cells sequentially. What happened during encoding? Information flows from left to right and each word vector is learned according to not only current input but also all previous words. When the sentence is completely read, encoder generates an output and a hidden state at timestep 4 for further processing. For encoding part, decoder (GRUs as well) grabs the hidden state from encoder, trained by teacher forcing (a mode that previous cell’s output as current input), then generate translation words sequentially.  It seems amazing as this model can be applied to N-to-M sequence, yet there still is one main deficit left unsolved: is one hidden state really enough?   How does attention work?  Similar to the basic encoder-decoder architecture, this fancy mechanism plug a context vector into the gap between encoder and decoder. According to the schematic above, blue represents encoder and red represents decoder; and we could see that context vector takes all cells’ outputs as input to compute the probability distribution of source language words for each single word decoder wants to generate. By utilizing this mechanism, it is possible for decoder to capture somewhat global information rather than solely to infer based on one hidden state. And to build context vector is fairly simple. For a fixed target word, first, we loop over all encoders’ states to compare target and source states to generate scores for each state in encoders. Then we could use softmax to normalize all scores, which generates the probability distribution conditioned on target states. At last, the weights are introduced to make context vector easy to train. That’s it. Math is shown below:   To understand the seemingly complicated math, we need to keep three key points in mind:  During decoding,context vectors are computed for every output word. So we will have a 2D matrix whose size is # of target words multiplied by # of source words. Equation (1) demonstrates how to compute a single value given one target word and a set of source word. Once context vector is computed, attention vector could be computed by context vector, target word, and attention function f. We need attention mechanism to be trainable. According to equation (4), both styles offer the trainable weights (W in Luong’s, W1 and W2 in Bahdanau’s). Thus, different styles may result in different performance.  Attention ScoringInputs to the scoring functionLet's start by looking at the inputs we'll give to the scoring function. We will assume we're in the first step in the decoging phase. The first input to the scoring function is the hidden state of decoder (assuming a toy RNN with three hidden nodes -- not usable in real life, but easier to illustrate):";Apache 2.0;https://www.kaggle.com/ashishpatel26/attension-layer-basic-for-nlp;1.0;['pattern'];['ner', 'ai', 'dl', 'rl', 'nn', 'rnn', 'ann'];['gru', 'generation', 'train', 'model', 'neural network', 'machine translation', 'layer', 'loss', 'lstm', 'predict', 'relu', 'hidden layer'];https://www.kaggle.com/c/20-newsgroups-ciphertext-challenge;0.726;0.464;2020-12-12 16:01:56;multiple data sources;[];Attension Layer Basic For NLP;Python notebook;5631.0;63;;
2018-12-27 10:13:57;"Beginner to Intermediate Natural Language Processing Guide Table of Contents  0.0 Setup 0.1 Python & Anaconda 0.2 Libraries 0.3 Other   1.0 Background 1.1 What is NLP? 1.2 Why is NLP Important? 1.3 Why is NLP a ""hard"" problem? 1.4 Glossary   2.0 Sentiment Analysis 2.1 Preparing the Data 2.1.1 Training Data 2.1.2 Test Data   2.2 Building a Classifier 2.3 Classification 2.4 Accuracy   3.0 Regular Expressions 3.1 Simplest Form 3.2 Case Sensitivity 3.3 Disjunctions  3.4 Ranges  3.5 Exclusions  3.6 Question Marks  3.7 Kleene Star  3.8 Wildcards  3.9 Kleene+    4.0 Word Tagging and Models 4.1 NLTK Parts of Speech Tagger 4.1.1 Ambiguity   4.2 Unigram Models 4.3 Bigram Models   5.0 Normalizing Text 5.1 Stemming 5.1.1 What is Stemming? 5.1.2 Types of Stemmers   5.2 Lemmatization 5.2.1 What is Lemmatization? 5.2.2 WordNetLemmatizer?     6.0 Final Words 6.1 Resources";Apache 2.0;https://www.kaggle.com/ashishpatel26/beginner-to-intermediate-nlp-tutorial;1.0;['vocabulary', 'nltk', 'sklearn', 'spacy', 'pattern'];['ner', 'ai', 'dl', 'gan', 'rl', 'nlp', 'nn', 'ann'];['unlabeled', 'recognition', 'natural language processing', 'logistic regression', 'predict', 'sentiment analysis', 'machine learning', 'training data', 'train', 'classification', 'labeled', 'model', 'loss', 'understanding', 'named entity recognition', 'test data', 'regression', 'artificial intelligence', 'fitting', 'label', 'random forest', 'natural language'];https://www.kaggle.com/c/20-newsgroups-ciphertext-challenge;0.73;0.427;2020-12-12 16:01:56;multiple data sources;['beginner, nlp, india, +2 morelanguages, spaCy'];Beginner to Intermediate NLP Tutorial;Python notebook;6237.0;40;;
2018-12-19 14:42:40;This a fork of @opanichev 's great kernel: https://www.kaggle.com/opanichev/lightgbm-and-simple-features. Instead of using difficulty as a feature, we'll train a model for each of them.;Apache 2.0;https://www.kaggle.com/ashishpatel26/stratified-kfold-hyperparameter-tuning;1.0;['pattern', 'lightgbm', 'sklearn'];['ai', 'rl', 'ml', 'gbm'];['predict', 'train', 'model', 'label', 'loss'];https://www.kaggle.com/c/20-newsgroups-ciphertext-challenge;0.627;0.302;2020-12-12 16:01:56;20 Newsgroups Ciphertext Challenge;['gpu, nlp'];Stratified KFold + Hyperparameter Tuning;Python notebook;714.0;10;0.36946;0.36946
2018-12-16 09:47:01;code borrowed from https://www.kaggle.com/jazivxt/enigma-layers-template , thanks!;Apache 2.0;https://www.kaggle.com/interneuron/difficulty-1-deciphering-wip;1.0;['sklearn'];['ner', 'ai', 'gan', 'rl', 'nn'];['train', 'understanding', 'model', 'layer'];https://www.kaggle.com/c/20-newsgroups-ciphertext-challenge;0.623;0.319;2020-12-12 16:01:56;20 Newsgroups Ciphertext Challenge;[];Difficulty #1 deciphering wip;Python notebook;672.0;12;;
2019-01-09 22:08:28;"This kernel shows how to get 98.85% ciphertexts matched with the plaintext without any decryption. The only thing we need to know is which character for each difficulty corresponds to the plaintext space character. The most frequent character for each of difficulty 1, 2 and 3 is easily found and used as space.  ""1"" is space for difficulty 1 and ""8"" is space for difficulty 2 and 3.";Apache 2.0;https://www.kaggle.com/kaggleuser58/1-char-decryption-in-level-1-2-and-3-gives-98-85;1.0;['pattern', 'sklearn'];['ai', 'rl'];['classification'];https://www.kaggle.com/c/20-newsgroups-ciphertext-challenge;0.591;0.253;2020-12-12 16:01:56;multiple data sources;[];1 char decryption in level 1, 2 and 3 gives 98.85%;Python notebook;385.0;6;;
2018-12-19 12:16:26;SummaryThe title of this kernel is quite bold and, as all bold affirmations it is not completely true but, it is a good clickbait, isn't it? :-) I think we only need to identify the white space character. There are some interesting kernels trying to decrypt all the texts but, at least for the case of difficulty 1 (and maybe 2), it wouldn't be strictly neccessary. If we knew how the white space is encrypted we could tokenize properly (to models like Bag of Words the real words doesn't matter: if chars substitution has been applied it should work the same) I have tried to know what are the most probable encripted white space character using brute force: my assumption is that, the same model (Logistic Regression) should perform better if we tokenize using the right character.;Apache 2.0;https://www.kaggle.com/lbronchal/don-t-waste-your-time-decrypting-the-texts;1.0;['pattern', 'vocabulary', 'sklearn'];['ner', 'ai', 'rl', 'cv', 'ml'];['filter', 'regression', 'train', 'model', 'label', 'logistic regression', 'predict', 'classification'];https://www.kaggle.com/c/20-newsgroups-ciphertext-challenge;0.644;0.281;2020-12-12 16:01:56;20 Newsgroups Ciphertext Challenge;['classification, nlp'];Don't waste your time decrypting the texts;Python notebook;971.0;8;;
2018-12-20 01:28:46;This is a quite fast solution working only on the encrypted text, without the use of brute force. It is possible to get this way 0.48+ LB  As it is shown in this kernel, it would be also possible to identify the delimiters used (at least for difficulty 1 and 2), even without decryting the full text. With that knowledge it would be possible to get even a better result without seeing the plain texts or using brute force.;Apache 2.0;https://www.kaggle.com/lbronchal/without-breaking-ciphers-0-48-lb;1.0;['sklearn'];['ai', 'nn', 'ml', 'cv'];['regression', 'train', 'model', 'loss', 'label', 'predict', 'classification'];https://www.kaggle.com/c/20-newsgroups-ciphertext-challenge;0.635;0.319;2020-12-12 16:01:56;20 Newsgroups Ciphertext Challenge;['nlp, multiclass classification'];Without breaking ciphers: [0.48+ LB];Python notebook;833.0;12;0.48622;0.48622
2019-01-02 15:02:15;This kernel provides targets for the competition test set using exact matchings with plain-text chunks, for cipher #1, #2 & #3. It outputs two dataframes as pickles:  test_123.pkl which contains as target for cipher #1, #2 & #3 the list of all possible targets from decrypted ciphertext exact matchin (see https://www.kaggle.com/leflal/you-cannot-avoid-multiple-targets) test_sub.pkl which contains one target for cipher #1, #2 & #3 (chosen among the above list of possible targets), ready for submission  If you use the output pickle in your work, be it to cross-check your model or enhance your submission,  or if you simply appreciate this contribution,  please upvote this kernel, thanks and have a nice 2019.;Apache 2.0;https://www.kaggle.com/leflal/cipher-1-2-3-exact-matching-targets;1.0;['sklearn'];['ai', 'nn', 'ann'];['train', 'model'];https://www.kaggle.com/c/20-newsgroups-ciphertext-challenge;0.601;0.292;2020-12-12 16:01:56;multiple data sources;[];Cipher #1, #2 & #3 Exact Matching Targets;Python notebook;455.0;9;;
2018-12-23 20:45:40;This kernel focuses on the cryptanalysis of the ciphers.  It contains a full manual cryptanalysis of cipher #1 before we move on to an automated one (cipher1_map.csv). It contains also the results of a full cryptanalysis of cipher #2 (cipher2_map.csv)  The sole purpose of the manual cryptanalysis illustrated on cipher #1 are:  To give an idea of what's doable manually on cipher #1 (spoiler alert: a lot) To demonstrate how tedious and time-consuming this manual analysis can be To illustrate the needs and requirements for automated cryptanalysis tools  (spoiler alert: fuzzywuzzy)  There is already a very nice automated kernel that has been published: https://www.kaggle.com/rturley/a-first-crack-tools-and-first-cipher-solution Here is the cryptanalysis plan we will follow:  Take advantage of the existing knowledge on the issue at hand, here we know that: The plaintexts corresponding to our ciphertexts are part of the 20 newsgroups dataset The cipher #1 is a substitution cipher: it is a simple table wich maps a plaintext character to a ciphertext character     Analyze the most frequent characters in the ciphertexts and compare them to the plaintexts ones.  Our hope is to be able to match a few usual suspects that pop out statistically in English like e or t.  And more importantly to identify words separators (the space or newline characters) which would allow us to move on to the next step   Analyze the most frequent words in the ciphertexts and compare them to the plaintexts ones. If we have partially decoded words that we can recognize then we can increase of knowledge of the cipher map   Complete the cryptanalysis by specifically looking for less frequent characters and matching plaintexts and ciphertexts pairs  In short: Characters > Words > Messages;Apache 2.0;https://www.kaggle.com/leflal/cipher-1-cipher-2-full-solutions;1.0;['pattern', 'caffe', 'sklearn'];['ner', 'ai', 'nlu', 'dl', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'test data', 'train', 'model', 'understanding', 'epoch', 'layer', 'label', 'predict', 'rank', 'recommend', 'relu'];https://www.kaggle.com/c/20-newsgroups-ciphertext-challenge;0.672;0.327;2020-12-12 16:01:56;multiple data sources;[];Cipher #1 & Cipher #2 Full Solutions;Python notebook;1685.0;13;;
2019-01-02 11:47:54;"Cipher #3 SolutionTo help kagglers move forward on the cryptanalysis of cipher #3, this kernel wishes to provide material for a known-plaintext attack (KPA) as suggested by EtienneW (https://www.kaggle.com/c/20-newsgroups-ciphertext-challenge/discussion/75407), that is to say matching cipher&plaintext (aka cribs) pairs. We provide the matched cipher&plaintext pairs in output of this kernel in a pickle (df_crib.pkl) And for those who's rather take the elevator than climbing the stairs, this kernel also provides the decryption of cipher #3 train & test sets in pickles (train_3.pkl & test_3.pkl). If you find this material & hints useful, please upvote. Spoiler hint if you are in a hurry: focus only on the alphabetic characters once cipher #2 has been applied to the matching plaintext of a cipher # text (see section 3.1) This kernels proceeds as follows:  It loads and pre-processes all the data for the task at hand: The plain-text set from scikit-learn The competition's train & test set from kaggle The cipher #2 map from another kernel (https://www.kaggle.com/leflal/cipher-1-cipher-2-full-solutions)   It provides several angles to ""understand"" cipher #3: Matching ciphertexts and plaintexts which begin with ""From:"" Matching frequent words across ciphertexts (Subject:, Organization, Lines:) Matching ciphertexts and plaintexts by length of words sequence   It provides the decryption of cipher #3 train & test sets  Hopefully this will help you move past the brick wall. See you on cipher #4 and all the best for 2019.";Apache 2.0;https://www.kaggle.com/leflal/cipher-3-solution;1.0;['sklearn'];['ner', 'ai', 'gan', 'cv', 'rl', 'nn', 'ml'];['train', 'filter'];https://www.kaggle.com/c/20-newsgroups-ciphertext-challenge;0.629;0.311;2020-12-12 16:01:56;multiple data sources;[];Cipher#3 Solution;Python notebook;738.0;11;;
2018-12-18 08:11:27;Let us see if we can break simple ciphers with repeated appearing words and phrase! (SPOILER: cipher 1 is quite easy);Apache 2.0;https://www.kaggle.com/mithrillion/enigma-was-gimped-by-weather-reports;1.0;['pattern', 'sklearn', 'nltk'];['ner', 'ai', 'gan', 'cv', 'rl', 'nn'];['train', 'model', 'neuron'];https://www.kaggle.com/c/20-newsgroups-ciphertext-challenge;0.629;0.319;2020-12-12 16:01:56;20 Newsgroups Ciphertext Challenge;[];Enigma was Gimped by Weather Reports...;Python notebook;739.0;12;;
2019-01-16 08:08:25;"A First Crack: Tools, Tips & 3 Cipher SolutionsTo get started on this Kaggle competition, we will need some tools for cracking simple ciphers. This kernel explores the data, creates some helpful functionality for all ciphers, and applies them to cracking the first three ciphers.  Loading the Source Data (Important!) Utility Functions Characteristics of Plaintext Data Length of the newsgroup documents (before being split into 300 char strings) Distribution of ASCII characters in plaintext Dictionary of most common words in the plaintext source   Cracking Cipher#1 Matching the observed character frequencies Optimizing the decryption with word frequency similarity (or ngrams) Finding actual plaintext in the source and fine-tuning   Cracking Cipher #2 Cracking Cipher #3 Make Predictions  In working on this, many thanks is due to:  Practical Cryptography for a summary of classic ciphers The scikit-learn tutorial for text data using the same ""20 Newgroups"" dataset   Hope you found this public kernel to be helpful!";Apache 2.0;https://www.kaggle.com/rturley/a-first-crack-tools-tips-3-cipher-solutions;1.0;['pattern', 'vocabulary', 'sklearn'];['ner', 'ai', 'gan', 'rl', 'ml', 'nn', 'ann'];['training data', 'test data', 'train', 'fitting', 'label', 'predict', 'understanding'];https://www.kaggle.com/c/20-newsgroups-ciphertext-challenge;0.709;0.458;2020-12-12 16:01:56;20 Newsgroups Ciphertext Challenge;['data visualization, exploratory data analysis, puzzles'];A First Crack: Tools, Tips & 3 Cipher Solutions;Python notebook;3790.0;58;0.79648;0.79648
2018-12-17 12:20:53;This a fork of @opanichev 's great kernel: https://www.kaggle.com/opanichev/lightgbm-and-simple-features. Instead of using difficulty as a feature, we'll train a model for each of them.;Apache 2.0;https://www.kaggle.com/suicaokhoailang/one-model-for-each-difficulty-0-3691-lb;1.0;['pattern', 'lightgbm', 'sklearn'];['ai', 'rl', 'ml', 'gbm'];['predict', 'train', 'model', 'label', 'loss'];https://www.kaggle.com/c/20-newsgroups-ciphertext-challenge;0.675;0.357;2020-12-12 16:01:56;20 Newsgroups Ciphertext Challenge;['gpu'];One model for each difficulty.;Python notebook;1784.0;18;0.36914;0.36914
2019-10-29 16:27:40;Please check out Guido's excellent kernel here. In this kernel i show how to perform inference on test set using the trained model. I just added RaDAM optimzer and got some better score. You can find the BEV of the test set here. Updates: Corrected yaw calculation Used category height information;Apache 2.0;https://www.kaggle.com/asimandia/lyft3d-inference-kernel;1.0;['pytorch'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ann'];['image segmentation', 'activation function', 'filter', 'test data', 'train', 'model', 'neural network', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'recommend', 'u-net', 'convolutional neural network'];https://www.kaggle.com/c/3d-object-detection-for-autonomous-vehicles;0.692;0.423;2020-12-12 16:08:03;multiple data sources;['gpu'];lyft3d inference kernel;Python notebook;2595.0;38;0.040;0.040
2019-11-11 08:54:38;Level 5 Kaggle Reference ModelAuthor: Guido Zuidhof - gzuidhof@lyft.com  In this Kernel we provide a (near) end-to-end example solution for the Lyft Level 5 Kaggle competition. We train a U-Net fully convolutional neural network to predict whether a car or other object is present for every pixel in a birds eye view of the world centered on the car. We can then threshold this probability map and fit boxes around each of the detections. You can expect to train the model in a couple of hours on a modern GPU, with inference times under 30ms per image. OutlineA. Creating an index and splitting into train and validation scenes Loading the dataset Creating a dataframe with one scene per row. Splitting all data into a train and validation set by car  B. Creating input and targets We produce top-down images and targets Running this on all of the data in parallel  C. Training a network to segment objects Defining datasets / dataloaders Defining the network architecture (U-net) Training the model  D. Inference and postprocessing Predicting our validation set. Thresholding the probability map. Performing a morphological closing operation to filter out tiny objects (presuming they are false positives) Loading the ground truth backprojecting our predicted boxes into world space  E. Visualizing the results (not included in this kernel)x. Creating top down visualizations of the ground truth and predictions using the nuScenes SDK. x. (Optional) Creating a GIF of a scene. F. Evaluationx. Computing mAP.;Apache 2.0;https://www.kaggle.com/asimandia/reference-model;1.0;['pytorch', 'opencv-python', 'pillow'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['image segmentation', 'activation function', 'filter', 'train', 'model', 'neural network', 'epoch', 'layer', 'loss', 'label', 'predict', 'rank', 'relu', 'u-net', 'convolutional neural network', 'ground truth'];https://www.kaggle.com/c/3d-object-detection-for-autonomous-vehicles;0.652;0.362;2020-12-12 16:08:03;Lyft 3D Object Detection for Autonomous Vehicles;['gpu'];Reference Model;Python notebook;1136.0;19;;
2019-09-15 02:43:59;YOLOv3 Keras API Image Object DetectionIn this notebook I want to implement simple object detection with Keras of some JPEG images in our training set. I use a pretrained (MSCOCO dataset) YOLOv3 model. This kernel is mainly based on https://machinelearningmastery.com/how-to-perform-object-detection-with-yolov3-in-keras and adapted for Lyft 3D Object Detection for Autonomous Driving challenge. I highly advise you to read to throught the blog for deeper understanding, and giving the original blogger the props. Please note that the model hasn't been fine tuned, or trained myself. The following implementation should serve the purpose of facilitating to get started with the current challenge. I don't know how relevant object detection with images is, in a 3D object detection challenge, as the LiDAR data is not regarded. If this Kernel helped you in any way, give it an upvote (such that I can increasy my online self-esteem...)$;Apache 2.0;https://www.kaggle.com/fanconic/yolov3-keras-image-object-detection;1.0;['tensorflow', 'keras'];['ner', 'ai', 'nn', 'rl'];['filter', 'object detection', 'train', 'recognition', 'model', 'neural network', 'layer', 'label', 'predict', 'relu', 'understanding'];https://www.kaggle.com/c/3d-object-detection-for-autonomous-vehicles;0.739;0.375;2020-12-12 16:08:03;multiple data sources;[];YOLOv3 Keras - Image Object Detection;Python notebook;7714.0;22;;
2019-09-17 02:27:48;Level 5 Kaggle Reference ModelAuthor: Guido Zuidhof - gzuidhof@lyft.com  In this Kernel we provide a (near) end-to-end example solution for the Lyft Level 5 Kaggle competition. We train a U-Net fully convolutional neural network to predict whether a car or other object is present for every pixel in a birds eye view of the world centered on the car. We can then threshold this probability map and fit boxes around each of the detections. You can expect to train the model in a couple of hours on a modern GPU, with inference times under 30ms per image. OutlineA. Creating an index and splitting into train and validation scenes Loading the dataset Creating a dataframe with one scene per row. Splitting all data into a train and validation set by car  B. Creating input and targets We produce top-down images and targets Running this on all of the data in parallel  C. Training a network to segment objects Defining datasets / dataloaders Defining the network architecture (U-net) Training the model  D. Inference and postprocessing Predicting our validation set. Thresholding the probability map. Performing a morphological closing operation to filter out tiny objects (presuming they are false positives) Loading the ground truth backprojecting our predicted boxes into world space  E. Visualizing the results (not included in this kernel)x. Creating top down visualizations of the ground truth and predictions using the nuScenes SDK. x. (Optional) Creating a GIF of a scene. F. Evaluationx. Computing mAP.;Apache 2.0;https://www.kaggle.com/gzuidhof/reference-model;1.0;['pytorch', 'opencv-python', 'pillow'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['image segmentation', 'activation function', 'filter', 'train', 'model', 'neural network', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'u-net', 'convolutional neural network', 'ground truth'];https://www.kaggle.com/c/3d-object-detection-for-autonomous-vehicles;0.758;0.527;2020-12-12 16:08:01;Lyft 3D Object Detection for Autonomous Vehicles;['gpu'];Reference Model;Python notebook;12864.0;147;;
2019-09-13 10:43:37;Lyft 3D Object Detection for Autonomous Vehicles   Self-driving technology presents a rare opportunity to improve the quality of life in many of our communities. Avoidable collisions, single-occupant commuters, and vehicle emissions are choking cities, while infrastructure strains under rapid urban growth. Autonomous vehicles are expected to redefine transportation and unlock a myriad of societal, environmental, and economic benefits. You can apply your data analysis skills in this competition to advance the state of self-driving technology.  This dataset aims to democratize access to such data, and foster innovation in higher-level autonomy functions for everyone, everywhere. By conducting a competition, we hope to encourage the research community to focus on hard problems in this space—namely, 3D object detection over semantic maps. In this competition, you will build and optimize algorithms based on a large-scale dataset. This dataset features the raw sensor camera inputs as perceived by a fleet of multiple, high-end, autonomous vehicles in a restricted geographic area. References Lyft: Quick EDA and creating useful files by @xhlulu Official Devkit for the public 2019 Lyft Level 5 AV Dataset by @iglovikov;Apache 2.0;https://www.kaggle.com/jesucristo/starter-devkit-lyft3d;1.0;['opencv-python', 'pillow'];['ner', 'ai', 'cv', 'rl', 'ml', 'nn', 'ann'];['train', 'loss', 'object detection', 'predict'];https://www.kaggle.com/c/3d-object-detection-for-autonomous-vehicles;0.718;0.479;2020-12-12 16:08:03;Lyft 3D Object Detection for Autonomous Vehicles;['exploratory data analysis, image data, automobiles and vehicles'];Starter Devkit Lyft3D;Python notebook;4589.0;76;;
2019-10-02 02:00:44;Please check out Guido's excellent kernel here. In this kernel i show how to perform inference on test set using the trained model. You can find the BEV of the test set here. Updates: Corrected yaw calculation Used category height information;Apache 2.0;https://www.kaggle.com/meaninglesslives/lyft3d-inference-kernel;1.0;['pytorch'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ann'];['image segmentation', 'activation function', 'filter', 'test data', 'train', 'model', 'neural network', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'recommend', 'u-net', 'convolutional neural network'];https://www.kaggle.com/c/3d-object-detection-for-autonomous-vehicles;0.743;0.5;2020-12-12 16:08:01;multiple data sources;['gpu'];lyft3d inference kernel;Python notebook;8611.0;101;0.035;0.034
2019-11-01 14:45:17;Updates 1 I have added code that does model prediction visualization by putting it in camera frame. I found this to be more intuitive than visualizing it in lidar frame. I hope you find it useful.  If you check out the reference model in lyft devkit, you will find that they are using map masks for training UNET. The map masks are first extracted around the corresponding ego region and used as 3 additional channels. This seems to be give some improvement in lb score. In this notebook i do inference using such a trained trained model. I have extracted the ego centered maps and made a train and test dataset. You can find it here. It takes a long time to compute on test set, so i am sharing it here :-D Updates 2I have added code that shows how you can easily ensemble your models. Here, I use same models at different epochs of training. Even such a simple approach gives a slight boost. To get a bigger boost, you can try training models with different architectures. Good Luck !;Apache 2.0;https://www.kaggle.com/meaninglesslives/lyft3d-inference-prediction-visualization;1.0;['pytorch'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['image segmentation', 'activation function', 'filter', 'test data', 'train', 'model', 'neural network', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'u-net', 'convolutional neural network'];https://www.kaggle.com/c/3d-object-detection-for-autonomous-vehicles;0.743;0.494;2020-12-12 16:08:01;multiple data sources;['gpu'];lyft3d inference + Prediction Visualization;Python notebook;8664.0;93;0.044;0.044
2020-02-22 09:16:39;Table of Contents Introduction Download some useful packages Import packages Load json files from dataset Data example Define generator Define metrics Define loss function Configure parameters Create train and validation generators Create callbacks Load pre-trained model Train 3D U-Net model Visualize some results of validation set Conclusion;Apache 2.0;https://www.kaggle.com/phunghieu/getting-started-with-3d-semantic-segmentation;1.0;['tensorflow', 'skimage', 'keras'];['ner', 'ai', 'dl', 'rl', 'nn', 'ann'];['filter', 'training data', 'train', 'model', 'neural network', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'u-net'];https://www.kaggle.com/c/3d-object-detection-for-autonomous-vehicles;0.708;0.425;2020-12-12 16:08:03;Lyft 3D Object Detection for Autonomous Vehicles;['gpu, deep learning, neural networks, +1 moreautomobiles and vehicles'];Getting started with 3D Semantic Segmentation;Python notebook;3657.0;39;;
2019-09-14 22:11:39;This code shows how to get points from .bin files in Dataset to train your own neural network.;Apache 2.0;https://www.kaggle.com/stalkermustang/getting-data-for-nn-dataset;1.0;['pytorch'];['ai', 'nn', 'ann', 'cv'];['train', 'label', 'filter', 'neural network'];https://www.kaggle.com/c/3d-object-detection-for-autonomous-vehicles;0.663;0.403;2020-12-12 16:08:03;Lyft 3D Object Detection for Autonomous Vehicles;[];Getting data for NN dataset;Python notebook;1412.0;30;;
2020-05-09 04:33:55;In this approach we use Bag of decision trees. Features: Surrouding cells for a given cell. Data Augmentation  Background color is detected using custom logic. Custom logic is written to find the colors which need to be excempted from augmentation. All the colors which are present in all the input of training exmaples are marked for excemption. Color which is not present in input but present in output are excepted.   For rest of colors all permutations are used to augment.  Model Bag of decision trees are used since, single decision tree have some randomness factor which may give incorrect result. Result Training: Solved 41/400;Apache 2.0;https://www.kaggle.com/adityaork/decision-tree-smart-data-augmentation;1.0;['sklearn'];['ner', 'ai'];['predict', 'train', 'model', 'loss', 'decision tree'];https://www.kaggle.com/c/abstraction-and-reasoning-challenge;0.72;0.484;2020-12-12 16:09:12;Abstraction and Reasoning Challenge;[];Decision tree + Smart data augmentation;Python notebook;4839.0;81;0.980;0.980
2020-02-19 08:54:27;How to solve this task with cellular automata ?;Apache 2.0;https://www.kaggle.com/arsenynerinovsky/cellular-automata-as-a-language-for-reasoning;1.0;['pattern'];['ner', 'ai', 'dl', 'gan', 'rl', 'nn', 'ml'];['train', 'neural network', 'generation'];https://www.kaggle.com/c/abstraction-and-reasoning-challenge;0.782;0.599;2020-12-12 16:09:11;multiple data sources;[];Cellular Automata as a Language for Reasoning ;Python notebook;25926.0;442;;
2020-04-21 19:40:08;Done!--All training tasks tagged. In the following (hidden) cells I create a dataframe to encode task tags and properties in a way that could possibly generalize to further tasks. The classification is far from perfect and depends largely on my ability to describe task resolution in a DSL-ish and transferrable way, so any help and corrections are greatly appreciated. All my gratitude to boliu0 for making this bearable. The dataframe can be imported from the outputs of this kernel. In my other notebook I multiply the number of tasks in the training set, while preserving tags.  Contents  The tagging itself EDA Other Features Can We Predict Tags? Interactive Widget (Edit Mode only);Apache 2.0;https://www.kaggle.com/davidbnn92/task-tagging;1.0;['pattern', 'sklearn'];['ner', 'ai', 'cv', 'nn', 'ml'];['train', 'model', 'label', 'predict', 'rank', 'classification'];https://www.kaggle.com/c/abstraction-and-reasoning-challenge;0.709;0.497;2020-12-12 16:09:12;Abstraction and Reasoning Challenge;['data visualization, exploratory data analysis, feature engineering'];Task Tagging;Python notebook;3791.0;96;;
2020-02-06 00:15:18;Abstraction and Reasoning Starter NotebookThis notebook will get you started on on the basics of this competition;Apache 2.0;https://www.kaggle.com/inversion/abstraction-and-reasoning-starter-notebook;1.0;['pattern'];['ner', 'ai', 'dl'];['train', 'predict'];https://www.kaggle.com/c/abstraction-and-reasoning-challenge;0.744;0.533;2020-12-12 16:09:11;Abstraction and Reasoning Challenge;[];Abstraction and Reasoning Starter Notebook;Python notebook;8742.0;160;1.000;1.000
2020-03-21 05:46:54;In this notebook i show how to use decision trees for ARC Challenge.;Apache 2.0;https://www.kaggle.com/meaninglesslives/using-decision-trees-for-arc;1.0;['xgboost'];['ner', 'ai', 'dl', 'rl'];['train', 'fitting', 'model', 'neural network', 'predict', 'decision tree', 'supervised learning'];https://www.kaggle.com/c/abstraction-and-reasoning-challenge;0.73;0.514;2020-12-12 16:09:11;Abstraction and Reasoning Challenge;[];Using Decision Trees for ARC;Python notebook;6184.0;121;0.990;0.990
2020-03-29 00:13:45;"In this work I'm gonna design & implement a functional-style DSL based on simple image manipulation like movement, flipping, connected region extraction, color separation, etc. It's called ""naive"" because it's intuitive and straightforward. If you like this kernel please upvote. It encorages me to produce more quality content!";Apache 2.0;https://www.kaggle.com/nanoix9/a-naive-image-manipulation-dsl;1.0;['pattern'];['ner', 'ai', 'nn', 'ann'];['train', 'label', 'filter'];https://www.kaggle.com/c/abstraction-and-reasoning-challenge;0.668;0.435;2020-12-12 16:09:12;Abstraction and Reasoning Challenge;[];A Naive Image Manipulation DSL;Python notebook;1552.0;44;;
2020-02-26 22:57:20;Patch images with Tiles and Symmetry;Apache 2.0;https://www.kaggle.com/paulorzp/28-tasks-tiles-and-symmetry;1.0;['skimage'];['ai', 'dl'];['train', 'label', 'filter'];https://www.kaggle.com/c/abstraction-and-reasoning-challenge;0.704;0.464;2020-12-12 16:09:12;Abstraction and Reasoning Challenge;[];+28 tasks (Tiles and Symmetry) ;Python notebook;3336.0;63;;
2020-03-19 05:20:30;AutoEncoder for Abstraction and Reasoning (Keras) I have tried to solve it with autoencoder with Keras. But it is not that looks useful yet. Please give me some advice and vote. updates v3? add cutout augmentation   v4 CAE to VAE (and no data augmentation)   v5~6 submission error correction   v7 Dropout   v8 knn;Apache 2.0;https://www.kaggle.com/seriousran/variational-autoencoder-abstraction-and-reasoning;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cv', 'nn', 'ml'];['autoencoder', 'predict', 'train', 'model', 'epoch', 'layer', 'vgg', 'lstm', 'loss', 'relu', 'resnet'];https://www.kaggle.com/c/abstraction-and-reasoning-challenge;0.68;0.423;2020-12-12 16:09:12;Abstraction and Reasoning Challenge;[];Variational AutoEncoder Abstraction and Reasoning;Python notebook;2010.0;38;1.000;1.000
2020-02-16 01:51:15;**Solving tasks using one Conv2d(in_channels=10, out_channels=10, kernel_size=5, padding=2);Apache 2.0;https://www.kaggle.com/yakuben/basic-cnn-approach;1.0;['pytorch'];['ner', 'ai', 'nn', 'ann'];['predict', 'train', 'model', 'epoch', 'label', 'loss'];https://www.kaggle.com/c/abstraction-and-reasoning-challenge;0.717;0.483;2020-12-12 16:09:12;Abstraction and Reasoning Challenge;['beginner, data visualization'];basic CNN approach;Python notebook;4564.0;80;;
2020-03-10 22:32:28;A DSL alongside a Genetic Algorithm applied to the ARC DatasetIn this notebook, we present a minimalistic Domain Specific Language for some of the ARC tasks. We instroduce the language and how it can be used to precess the input in complex ways. We then implement an evaluation function able to run a such program against an input image. We also provide a program solution of a task as an exemple. In a second time, we implement a simple genetic algorithm (based on a multiobjective and elitist strategy) that is able to generate programs written in this DSL and demonstrate its usage against the same ARC task previously solved by hand.;Apache 2.0;https://www.kaggle.com/zenol42/dsl-and-genetic-algorithm-applied-to-arc;1.0;['tensorflow'];['ner', 'ai', 'rl', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'generation', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/abstraction-and-reasoning-challenge;0.744;0.549;2020-12-12 16:09:11;Abstraction and Reasoning Challenge;[];DSL and Genetic Algorithm applied to ARC;Python notebook;8825.0;202;;
2019-06-16 19:46:53;IntroductionIn this notebook we'll go over defining, training and testing as well as the pre-processing steps needed to feed an image into CNNs to get state of the art results. We'll be using PyTorch for this tutorial. PyTorch is a powerful deep learning framework which is rising in popularity, and it is thoroughly at home in Python which makes it really easy to learn and use. This tutorial won’t assume much in regards to prior knowledge of PyTorch, but it might be helpful to checkout my previous introductory CV tutorial.  In this notebook, we'll train a CNN to classify images based on whether they have a columnar cactus or not. We'll use the Aerial Cactus Dataset from this currently running Kaggle competition. For more information about the dataset visit this page. I picked this competition because I felt it is the best place for beginners to practice their new found skills with CNNs as MNIST is just way too simple to bring CNNs into play, a regular Multi-layer perceptron may well do the job. So, this is a perfect beginners competition as someone rightly said in the discussion forums. If you like this kernel or wish to fork it please give it an UPVOTE to show your appreciation.;Apache 2.0;https://www.kaggle.com/abhinand05/in-depth-guide-to-convolutional-neural-networks;1.0;['pytorch', 'pattern'];['ner', 'ai', 'cnn', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'predict', 'relu', 'training data', 'train', 'epoch', 'activation function', 'propagation', 'model', 'neural network', 'layer', 'loss', 'hidden layer', 'understanding', 'test data', 'fitting', 'output layer', 'deep learning', 'label', 'convolutional neural network'];https://www.kaggle.com/c/aerial-cactus-identification;0.717;0.463;2020-12-12 16:10:46;Aerial Cactus Identification;['beginner, exploratory data analysis, deep learning, +1 morecnn'];In-Depth Guide to Convolutional Neural Networks;Python notebook;4474.0;62;0.9981;0.9981
2019-06-08 16:57:01;Arial Cactus Identification with PyTorch and VGG16;Apache 2.0;https://www.kaggle.com/aleksandradeis/arial-cactus-identification-with-pytorch-and-vgg16;1.0;['pytorch'];['ner', 'ai', 'nn'];['training data', 'test data', 'train', 'model', 'epoch', 'deep learning', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'classification', 'labeled'];https://www.kaggle.com/c/aerial-cactus-identification;0.629;0.346;2020-12-12 16:10:46;Aerial Cactus Identification;['deep learning, transfer learning'];Arial Cactus Identification with PyTorch and VGG16;Python notebook;743.0;16;0.9741;0.9741
2019-06-06 17:40:34;In this kernel, we use efficientnet to complete the binary classification task. This kernel is especially helpful if you are making an introduction to computer vision and deep learning in general. In order to solve this challenge, the steps I take are the following:  Specify where the training and test folders are Visualize a few images to know what data we're dealing with Use Keras's ImageDataGenerator to augment the training data. If you haven't used this library before, or are new to data augmentation, take a look at this link: http://keras.io/preprocessing/image/ We use a pre-trained model called EfficientNet. You don't need to know how this works. We just feed the data to the model we obtain online, and it gives us a good accuracy. We finally make our predictions on the test images in the test zip file and format the submission.csv file to hold our own submissions!;Apache 2.0;https://www.kaggle.com/arjunrao2000/beginners-guide-efficientnet-with-keras;1.0;['tensorflow', 'keras'];['ner', 'ai', 'dl', 'cv', 'nn', 'ml'];['training data', 'train', 'model', 'epoch', 'deep learning', 'layer', 'relu', 'loss', 'label', 'predict', 'computer vision', 'classification'];https://www.kaggle.com/c/aerial-cactus-identification;0.747;0.39;2020-12-12 16:10:46;Aerial Cactus Identification;['gpu, beginner'];Beginners Guide - EfficientNet With Keras ;Python notebook;9553.0;26;0.9996;0.9996
2019-04-10 21:28:50;General information Researchers in Mexico have created the VIGIA project, aiming to build a system for autonomous surveillance of protected areas. One of the first steps is being able to recognize the vegetation in the area. In this competition we are trying to identify whether there is a cactus in the image. In this kernel I use kekas (https://github.com/belskikh/kekas) as a wrapper for Pytorch. Most of the code is taken from my other kernel: https://www.kaggle.com/artgor/cancer-detection-with-kekas;Apache 2.0;https://www.kaggle.com/artgor/detecting-cactus-with-kekas;1.0;['pytorch', 'albumentations', 'sklearn'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ann'];['test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict'];https://www.kaggle.com/c/aerial-cactus-identification;0.737;0.465;2020-12-12 16:10:46;Aerial Cactus Identification;['beginner, deep learning, classification'];Detecting cactus with kekas;Python notebook;7322.0;64;0.9998;0.9998
2019-06-04 23:05:03;Simple example of transfer learning from pretrained model using Keras and Efficientnet (https://pypi.org/project/efficientnet/).;Apache 2.0;https://www.kaggle.com/ateplyuk/keras-starter-efficientnet;1.0;['tensorflow', 'keras'];['dl', 'ai', 'nn', 'cv'];['predict', 'train', 'model', 'epoch', 'layer', 'loss', 'relu'];https://www.kaggle.com/c/aerial-cactus-identification;0.779;0.446;2020-12-12 16:10:46;Aerial Cactus Identification;['gpu'];Keras Starter (EfficientNet);Python notebook;23351.0;50;0.9875;0.9875
2019-06-16 10:30:41;Example of using EfficientNet model in PyTorch.;Apache 2.0;https://www.kaggle.com/ateplyuk/pytorch-efficientnet;1.0;['pytorch'];['ai', 'nn'];['filter', 'train', 'model', 'epoch', 'loss', 'label', 'predict'];https://www.kaggle.com/c/aerial-cactus-identification;0.746;0.456;2020-12-12 16:10:46;Aerial Cactus Identification;['gpu'];PyTorch EfficientNet;Python notebook;9205.0;57;0.9018;0.9018
2019-06-13 13:21:47;Easy example of using CNN in PyTorch;Apache 2.0;https://www.kaggle.com/ateplyuk/starter-pytorch;1.0;['pytorch'];['ai', 'nn', 'cnn', 'ann'];['filter', 'train', 'model', 'epoch', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/aerial-cactus-identification;0.67;0.371;2020-12-12 16:10:46;Aerial Cactus Identification;['gpu'];Starter_PyTorch;Python notebook;1628.0;21;0.9430;0.9430
2019-05-24 06:29:00;Aerial Cactus Prediction using fast.ai & ResNet-34IntroductionTo assess the impact of climate change on Earth's flora and fauna, it is vital to quantify how human activities such as logging, mining, and agriculture are impacting our protected natural areas. Researchers in Mexico have created the VIGIA project, which aims to build a system for autonomous surveillance of protected areas. A first step in such an effort is the ability to recognize the vegetation inside the protected areas. In this competition, you are tasked with creation of an algorithm that can identify a specific type of cactus in aerial imagery. The original version of this data can be found here, with full details in López-Jiménez's master thesis: Efren López-Jiménez, Sistema embebido para la supervisión inteligente de terrenos con vehı́culos aéreos no tripulados. Master Thesis, Instituto Politécnico Nacional, 2018. DOI: 10.13140/RG.2.2.19455.46246.  In this kernel I will attempt to identify a specific type of cactus in aerial imagery using fast.ai and a ImageNet pre-trained ResNet-34. I will explain my process throughout the kernel, which should allow anyone familiar with the fast.ai library to follow along. Why train a smaller model and not a larger model such as DenseNet-161? While I could train a DenseNet-161 model using the fast.ai defaults and match the top results in this competition, a smaller model that can match the accuracy of a larger model is more flexible. It could more easily be deployed as part of a smartphone app, for example. Plus training a smaller model requires different approaches and hyperparameter tuning.;Apache 2.0;https://www.kaggle.com/benjaminwarner/aerial-cactus-prediction-using-fast-ai-resnet-34;1.0;['pytorch'];['ner', 'ai', 'cnn', 'rl', 'nn', 'ml'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'recommend', 'resnet', 'classification'];https://www.kaggle.com/c/aerial-cactus-identification;0.692;0.362;2020-12-12 16:10:46;multiple data sources;['gpu, beginner'];Aerial Cactus Prediction using fast.ai & ResNet-34;Python notebook;2564.0;19;0.9999;0.9999
2019-03-15 14:28:02;EDA (Exploratory Data Analysis). The purpose of EDA is:  Look at the data Understand the distribution of two classes (hasn't cactus / has cactus) Look at some features of the image (distribution of RGB channels, average brightness, etc.);Apache 2.0;https://www.kaggle.com/bonhart/simple-cnn-on-pytorch-for-beginers;1.0;['pytorch', 'keras', 'sklearn'];['ner', 'ai', 'cnn', 'cv', 'nn', 'ann'];['test data', 'train', 'model', 'neural network', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'convolutional neural network'];https://www.kaggle.com/c/aerial-cactus-identification;0.693;0.393;2020-12-12 16:10:46;Aerial Cactus Identification;['gpu, beginner, exploratory data analysis'];SImple CNN on PyTorch for beginers;Python notebook;2620.0;27;;
2019-05-01 00:28:23;The goal of this kernel is to create a simple Convolution Neural Network that will allow to differentiate images that contains cacti from images that do not. While better results closer to 100% accuracy could be designed using layers from pre-trained models such as VGG16, we want to stick with a fairly simple CNN architecture and see how far we can go, and whether pre-trained layers are even needed.;Apache 2.0;https://www.kaggle.com/frlemarchand/simple-cnn-using-keras;1.0;['tensorflow', 'keras'];['ner', 'ai', 'dl', 'cnn', 'rl', 'nn'];['test data', 'train', 'model', 'neural network', 'epoch', 'deep learning', 'layer', 'vgg', 'loss', 'predict', 'relu', 'convolutional neural network'];https://www.kaggle.com/c/aerial-cactus-identification;0.706;0.387;2020-12-12 16:10:46;Aerial Cactus Identification;['gpu, deep learning, cnn'];Simple CNN using Keras;Python notebook;3513.0;25;1.0000;1.0000
2019-07-03 15:52:50;Guide to different CNN Architectures using keras:In this tutorial i am going to explain 5 different CNN architectures which are commonly used.1. VGG16/192. GoogLeNet/Inception3. Xception4. Mobile net5. ResnetNote: I am not going to train model on longer epochs my solely aim is to illustrate how different architectures works.If you want to get better accuracy and performance of the model please make deeper models and run for many epochs and tune the hyperparameters and also i commented some code blocks as they are taking longer time to run if you want to run them uncomment them.;Apache 2.0;https://www.kaggle.com/ratan123/in-depth-guide-to-different-cnn-architectures;1.0;['tensorflow', 'keras'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'nn', 'ann'];['filter', 'recognition', 'vgg', 'predict', 'relu', 'train', 'epoch', 'alexnet', 'activation function', 'classification', 'image classification', 'model', 'neural network', 'layer', 'loss', 'hidden layer', 'understanding', 'resnet', 'fitting', 'deep learning', 'label', 'convolutional neural network'];https://www.kaggle.com/c/aerial-cactus-identification;0.688;0.478;2020-12-12 16:10:46;Aerial Cactus Identification;['gpu'];In-Depth Guide To Different CNN Architectures ;Python notebook;2341.0;75;;
2019-03-23 09:44:17;IntroductionIn this short notebook I wanted to experiment with PCA and neural network implemented with Keras library. Also I would like to ilustrate how PCA decomposition works on data from this dataset. Most important thing, I would like hopefully to get some feedback to improve this method or find completely different approach. Thanks to other authors for publishing their notebooks, I reused some parts of the code when I was looking for fiding nice solutions for problems I had on a way.;Apache 2.0;https://www.kaggle.com/rohandx1996/pca-mlp-vs-pca-cnn-focal-loss-resnet50-vs-vgg16;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'ml', 'nn', 'ann'];['activation function', 'image classification', 'test data', 'object detection', 'train', 'model', 'output layer', 'neural network', 'epoch', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'resnet', 'classification', 'hidden layer'];https://www.kaggle.com/c/aerial-cactus-identification;0.652;0.352;2020-12-12 16:10:46;Aerial Cactus Identification;['beginner, deep learning, cnn, +1 morepca'];PCA-MLP VS PCA-CNN , Focal Loss resnet50 vs Vgg16;Python notebook;1138.0;17;;
2017-10-07 17:27:57;Predicting Destinations with the Airbnb Dataset This notebook demonstrates the entire process of building a predictive model to suggest the first destination of new Airbnb Users. All the processes involved, such as data wrangling, exploratory data analysis, inferential statistics and machine learning have been divided into main sections and the reader is strongly advised to read it sequentially, from top to bottom.;Apache 2.0;https://www.kaggle.com/rounakbanik/airbnb-new-user-bookings;1.0;['sklearn'];['ai', 'dl', 'cv', 'rl', 'nn', 'ann'];['machine learning', 'training data', 'regression', 'test data', 'train', 'random forest', 'model', 'loss', 'label', 'logistic regression', 'gradient boosting', 'predict', 'recommend', 'classification'];https://www.kaggle.com/c/airbnb-recruiting-new-user-bookings;0.733;0.371;2020-12-12 16:26:37;Airbnb New User Bookings;[];Airbnb New User Bookings;Python notebook;6582.0;21;;
2016-03-08 11:38:21;Airbnb New User Bookings CompetitionAuthor: Sandro Vega Pons (sv.pons@gmail.com) The main 3 points of this notebook are:  Source code of the ensemble techniques I used in my solution. Example of how to use them in a 3-layer learning architecture. Analysis of the performance of the methods on problems with different number of classes.  Comparison with stack generalization based on LogisticRegression (sklearn implementation) and GradientBoosting (XGBoost implementation).;Apache 2.0;https://www.kaggle.com/svpons/three-level-classification-architecture;1.0;['xgboost', 'sklearn'];['ner', 'ai', 'gbm', 'cv', 'rl', 'nn', 'ml'];['regression', 'generation', 'train', 'model', 'layer', 'loss', 'label', 'gradient boosting', 'predict', 'classification'];https://www.kaggle.com/c/airbnb-recruiting-new-user-bookings;0.768;0.408;2020-12-12 16:26:37;Airbnb New User Bookings;[];three_level_classification_architecture;Python notebook;16760.0;32;;
2018-08-03 23:29:58;Look at a sample of the training images.;Apache 2.0;https://www.kaggle.com/ezietsman/airbus-eda;1.0;['skimage'];['ai', 'nn', 'rl'];['train', 'label'];https://www.kaggle.com/c/airbus-ship-detection;0.742;0.49;2020-12-12 16:28:05;Airbus Ship Detection Challenge;[];Airbus EDA;Python notebook;8472.0;88;;
2018-11-15 01:28:26;Mask-RCNN Starter Model for the Airbus Ship Detection Challenge with transfer learning  Using pre-trained COCO weights trained on http://cocodataset.org as in https://github.com/matterport/Mask_RCNN/tree/master/samples/balloon We get some amazing performance training only within the 6hrs kaggle kernel limit.;Apache 2.0;https://www.kaggle.com/hmendonca/airbus-mask-rcnn-and-coco-transfer-learning;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ai', 'cnn', 'cv', 'rl', 'nn', 'ann'];['filter', 'training data', 'test data', 'train', 'model', 'epoch', 'validation data', 'layer', 'loss', 'label', 'predict', 'resnet', 'ground truth'];https://www.kaggle.com/c/airbus-ship-detection;0.778;0.486;2020-12-12 16:28:05;multiple data sources;['gpu, deep learning, cnn, +1 moreneural networks'];Airbus Mask-RCNN and COCO transfer learning;Python notebook;22809.0;84;0.81095;0.66036
2018-11-08 04:12:27;We combine here the 2 best public models: The U-Net segmentation from: https://www.kaggle.com/hmendonca/u-net-model-with-submission and reduce the false positives with the classification CNN: https://www.kaggle.com/kmader/transfer-learning-for-boat-or-no-boat (Thanks Kevin!);Apache 2.0;https://www.kaggle.com/hmendonca/classification-and-segmentation-fp;1.0;['tensorflow', 'skimage', 'keras'];['ai', 'nn', 'cnn', 'rl'];['train', 'model', 'label', 'predict', 'classification', 'u-net'];https://www.kaggle.com/c/airbus-ship-detection;0.746;0.458;2020-12-12 16:28:05;multiple data sources;['deep learning, cnn, ensembling'];Classification and Segmentation (-FP);Python notebook;9243.0;58;;
2018-10-02 20:16:12;OverviewWe try here to improve another public U-Net model: https://www.kaggle.com/kmader/baseline-u-net-model-part-1 which shows how to extract the segmentation map for the ships, augment the images and train a simple DNN model to detect them. A few additional tweaks like balancing the ship-count out a little better have also been done. We are using a different loss function (closer to the competition scoring) and also fix and improve some visualisation functions and the submission itself.;Apache 2.0;https://www.kaggle.com/hmendonca/u-net-model-with-submission;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'rl', 'nn', 'ann'];['filter', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'u-net', 'predict', 'relu', 'labeled', 'ground truth'];https://www.kaggle.com/c/airbus-ship-detection;0.779;0.519;2020-12-12 16:28:05;Airbus Ship Detection Challenge;['gpu, cnn, neural networks'];U-Net Model with submission;Python notebook;23653.0;131;;
2018-08-26 17:35:11;OverviewResnet34 is commonly used as an encoder for U-net and SSD, boosting the model performance and training time since you do not need to train the model from scratch. However, in particular cases it makes sense to do fine-tuning of Resnet34 model before using it as a decoder for object localization or image segmentation. In this competition the size of ship masks is much smaller than the size of images that leads to quite unbalanced training with ~1 positive pixel per 1000 negative ones. If images with no ships are used, instead of ~1:1000 you will end up with ~1:10000 unbalance, which is quite tough. Moreover, the training time is ~4 times longer since you need to process more images in each epoch. So, it is reasonable to drop empty images and focus only on ones with ships. Meanwhile, since the current dataset is quite different from ImageNet, the empty images are quite helpful in fine-tuning your encoder on a pseudo task - ship detection. Moreover, when the training of your U-net or SSD model is completed, you can run the model on images without ships, add false positives (~4000 in my case) as negative example to you training set, and train the model for several additional epochs. Finally, a good model focused on a single task, ship detection, can boost the final score when you stack up it with U-net or SSD. If you predict a ship for an empty image you will get automatically zero score for it, and since PLB has ~85% of empty images, prediction of empty images is quite important. In this notebook I want to share how to pretrain Resnet34 (or higher end models) on a ship detection task. After training of the head layers of the model on 256x256 rescaled images for one epoch the accuracy has reached 93.7%. The following fine-tuning of entire model for 2 more epochs with learning rate annealing boosted the accuracy to ~97%. If the training is continued for several epochs with a new data set composed of images of 384x384 resolution, the accuracy could be boosted to ~98%. Unfortunately, continuing training the model on full resolution, 768x768, images leaded to reduction of the accuracy that is likely attributed to insufficient model capacity.;Apache 2.0;https://www.kaggle.com/iafoss/fine-tuning-resnet34-on-ship-detection;1.0;['pytorch', 'sklearn'];['ner', 'ai', 'dl', 'cv', 'ml', 'nn', 'ann'];['image segmentation', 'predict', 'train', 'fitting', 'model', 'epoch', 'layer', 'loss', 'recommend', 'resnet', 'u-net'];https://www.kaggle.com/c/airbus-ship-detection;0.772;0.507;2020-12-12 16:28:05;Airbus Ship Detection Challenge;['deep learning, classification, cnn, +2 moreneural networks, binary classification'];Fine-tuning ResNet34 on ship detection;Python notebook;18898.0;110;;
2018-10-30 01:38:41;2. Understanding and plotting rle bounding boxesAirbus Ship Detection Challenge - A quick overview for computer vision noobs  Hi, and welcome! This is the second kernel of the series Airbus Ship Detection Challenge - A quick overview for computer vision noobs. In this short kernel we will explain the run-length encoded bounding boxes, translate the rle code into a list of pixels with pure python and plot that list of pixels as a mask on top of the pictures with matplotlib. The full series consist of the following notebooks:  Loading and visualizing the images Understanding and plotting rle bounding boxes Basic exploratory analysis Exploring public models 1.0 submission: submitting the test file  This is an ongoing project, so expect more notebooks to be added to the series soon. Actually, we are currently working on the following ones:  Understanding and exploiting the data leak A quick overview of image segmentation domain Jumping into Pytorch Understanding U-net Proposing a simple improvement to U-net model;Apache 2.0;https://www.kaggle.com/julian3833/2-understanding-and-plotting-rle-bounding-boxes;1.0;['pytorch'];['ai', 'nn', 'rl'];['image segmentation', 'train', 'model', 'computer vision', 'understanding', 'u-net'];https://www.kaggle.com/c/airbus-ship-detection;0.72;0.44;2020-12-12 16:28:05;Airbus Ship Detection Challenge;['beginner'];2 - Understanding and plotting rle bounding boxes;Python notebook;4840.0;47;;
2018-09-12 16:58:25;4. Exploring public modelsAirbus Ship Detection Challenge - A quick overview for computer vision noobs  Hi, and welcome! This is the fourth kernel of the series Airbus Ship Detection Challenge - A quick overview for computer vision noobs. This short kernel has two goals: first, to do a quick research of the currently trending public models and, second, to analyze the main approaches those models take. The full series consist of the following notebooks:  Loading and visualizing the images Understanding and plotting rle bounding boxes  Basic exploratory analysis Exploring public models 1.0 submission: submitting the test file  This is an ongoing project, so expect more notebooks to be added to the series soon. Actually, we are currently working on the following ones:  Understanding and exploiting the data leak A quick overview of image segmentation domain Jumping into Pytorch Understanding U-net Proposing a simple improvement to U-net model;Apache 2.0;https://www.kaggle.com/julian3833/4-exploring-public-models;1.0;['pytorch', 'keras', 'skimage'];['ner', 'ai', 'gan', 'rl', 'nn', 'ann'];['image segmentation', 'object detection', 'train', 'model', 'deep learning', 'layer', 'computer vision', 'loss', 'label', 'predict', 'rank', 'understanding', 'resnet', 'classification', 'u-net'];https://www.kaggle.com/c/airbus-ship-detection;0.706;0.411;2020-12-12 16:28:05;Airbus Ship Detection Challenge;['gpu, beginner'];4 - Exploring public models;Python notebook;3483.0;33;;
2018-10-19 11:51:39;OverviewThe notebook shows how to extract the segmentation map for the ships, augment the images and train a simple DNN model to detect them. A few additional tweaks like balancing the ship-count out a little better have been done.;Apache 2.0;https://www.kaggle.com/kmader/baseline-u-net-model-part-1;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'rl', 'nn', 'ann'];['filter', 'test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'u-net', 'predict', 'relu', 'labeled'];https://www.kaggle.com/c/airbus-ship-detection;0.801;0.569;2020-12-12 16:28:05;Airbus Ship Detection Challenge;['gpu, cnn'];Baseline U-Net Model (Part 1);Python notebook;47010.0;274;;
2018-10-19 15:21:02;OverviewSince making all the predictions takes a long time and quite a bit of memory, we make a seperate kernel for just the submission, where we read the test data and apply the model. The model is built and trained in the kernel at https://www.kaggle.com/kmader/baseline-u-net-model-part-1;Apache 2.0;https://www.kaggle.com/kmader/from-trained-u-net-to-submission-part-2;1.0;['tensorflow', 'skimage', 'keras'];['ner', 'ai', 'dl', 'rl', 'nn', 'ann'];['test data', 'train', 'model', 'layer', 'label', 'predict', 'u-net'];https://www.kaggle.com/c/airbus-ship-detection;0.739;0.447;2020-12-12 16:28:05;multiple data sources;['gpu'];From Trained U-Net to Submission (Part 2);Python notebook;7793.0;51;;
2018-10-19 12:05:06;OverviewRather than trying to segment, we start off by making a model that simply tries to identify if any boat shows up in the image.  For this model we can see roughly how it performs in the compititon by guessing the whole image (as an RLE) if any boat shows up (not a very smart startegy, but might provide some interesting results). BeyondThe model could also be useful as a quick way (low resolution images) to screen through lots of images to see if they are likely to have a boat and if they are then run a much more expensive full-resolution U-Net on that sample;Apache 2.0;https://www.kaggle.com/kmader/transfer-learning-for-boat-or-no-boat;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'rl', 'nn', 'ann'];['predict', 'test data', 'train', 'model', 'epoch', 'layer', 'vgg', 'loss', 'relu', 'resnet', 'u-net'];https://www.kaggle.com/c/airbus-ship-detection;0.764;0.507;2020-12-12 16:28:05;Airbus Ship Detection Challenge;['gpu, image data, transfer learning'];Transfer Learning for Boat or No-Boat;Python notebook;15067.0;110;0.74459;0.51751
2018-11-06 11:14:28;V18: bug fix (calculation of F2 score);Apache 2.0;https://www.kaggle.com/kotarojp/first-step-for-submission-u-net-tta;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'rl', 'cv', 'nn'];['train', 'model', 'epoch', 'validation data', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/airbus-ship-detection;0.72;0.429;2020-12-12 16:28:05;Airbus Ship Detection Challenge;['gpu, beginner'];First Step for Submission(U-net, TTA);Python notebook;4792.0;41;;
2018-08-26 23:25:48;Data preparetion. Spet by step Simple Dataset Splitting data into train and validation part Using augmentation for images Adding mask;Apache 2.0;https://www.kaggle.com/leighplt/pytorch-tutorial-dataset-data-preparetion-stage;1.0;['albumentations'];['ai', 'nn', 'ann', 'rl'];['train', 'filter'];https://www.kaggle.com/c/airbus-ship-detection;0.775;0.44;2020-12-12 16:28:05;Airbus Ship Detection Challenge;['beginner, deep learning'];PyTorch Tutorial: Dataset. Data preparetion stage.;Python notebook;20965.0;47;;
2018-10-16 09:11:45;Current competition metric implies segmenation task. However one valid approach could incorporate object detection. In this direcrion and borrowing stuff from Kevin's excellent kernel https://www.kaggle.com/kmader/baseline-u-net-model-part-1, we attempt to extract bounding boxes information from binary rle-encoded masks.;Apache 2.0;https://www.kaggle.com/voglinio/from-masks-to-bounding-boxes;1.0;['skimage'];['ai', 'rl', 'nn', 'cv'];['object detection', 'train', 'model', 'label', 'u-net'];https://www.kaggle.com/c/airbus-ship-detection;0.779;0.5;2020-12-12 16:28:05;Airbus Ship Detection Challenge;[];From masks to bounding boxes;Python notebook;23665.0;100;;
2018-08-06 07:10:39;OverviewInitial data-load code and submit code take from this awesome kernel https://www.kaggle.com/kmader/baseline-u-net-model-part-1;Apache 2.0;https://www.kaggle.com/windsurfer/baseline-u-net-on-pytorch;1.0;['pytorch', 'skimage', 'sklearn'];['ai', 'rl', 'cv', 'nn', 'ann'];['predict', 'train', 'model', 'epoch', 'validation data', 'label', 'loss', 'relu', 'u-net'];https://www.kaggle.com/c/airbus-ship-detection;0.748;0.449;2020-12-12 16:28:05;Airbus Ship Detection Challenge;['gpu'];Baseline U-Net on PyTorch;Python notebook;9762.0;52;;
2020-07-03 16:22:38;❄Alaska2❄ Competiton: EDA and Understanding1. Competition Outline Steganography is the method of hiding secret data in any image/audio/video. In a nutshell, the main motive of steganography is to hide the intended information within any image/audio/video that doesn’t appear to be secret just by looking at 1.1 Description Current Methods : Produce unreliable results, raising false alarms Data : images acquired with ~ 50 different cameras and processed in different fashions  1.2 Evaluation submissions are evaluated on the weighted AUC each region of the ROC curve is weighted according to these chosen parameters: tpr_thresholds = [0.0, 0.4, 1.0] weights = [2, 1]     1.3 Sumbission fileFor each Id (image) in the test set, you must provide a score that indicates how likely this image contains hidden data: the higher the score, the more it is assumed that image contains secret data. 1.4 DataFiles  Cover/ contains 75k unaltered images meant for use in training. JMiPOD/ contains 75k examples of the JMiPOD algorithm applied to the cover images. JUNIWARD/ contains 75k examples of the JUNIWARD algorithm applied to the cover images. UERD/ contains 75k examples of the UERD algorithm applied to the cover images. Test/ contains 5k test set images. These are the images for which you are predicting. sample_submission.csv contains an example submission in the correct format.;Apache 2.0;https://www.kaggle.com/andradaolteanu/alaska2-competition-multiclass-pytorch-effnetb2;1.0;['pytorch', 'albumentations', 'sklearn', 'pillow'];['ner', 'ai', 'dl', 'cnn', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'understanding', 'resnet', 'classification'];https://www.kaggle.com/c/alaska2-image-steganalysis;0.728;0.532;2020-12-12 16:29:23;multiple data sources;['gpu, deep learning, classification, +1 moreneural networks'];❄ALASKA2 Competition: Multiclass PyTorch EffNetB2;Python notebook;5820.0;157;;
2020-04-29 23:28:53;An implementation of the competition metricThis kernel is a clean-up of Max Jeblick's evaluation metric implementation into an easy to use function: https://www.kaggle.com/maxjeblick/alaska2-efficientnet-on-tpus-competition-metric See the evaluation page for more info about the metric! EDIT: Changed to reflect the update in evaluation metric of the competition!;Apache 2.0;https://www.kaggle.com/anokas/weighted-auc-metric-updated;0.8;['sklearn'];[];['model', 'label'];https://www.kaggle.com/c/alaska2-image-steganalysis;0.713;0.488;2020-12-12 16:29:24;ALASKA2 Image Steganalysis;[];Weighted AUC Metric (Updated);Python notebook;4072.0;86;;
2020-07-12 16:13:21;This is a fork of Alex Shonenkov kernel with TTA added[Train + Inference] GPU Baseline;Apache 2.0;https://www.kaggle.com/demesgal/train-inference-gpu-baseline-tta;1.0;['pytorch', 'albumentations', 'skimage', 'sklearn'];['ai', 'dl', 'gan', 'cv', 'nlp', 'nn', 'ann'];['filter', 'train', 'model', 'epoch', 'layer', 'label', 'loss'];https://www.kaggle.com/c/alaska2-image-steganalysis;0.705;0.447;2020-12-12 16:29:24;multiple data sources;['gpu'];[Train + Inference] GPU Baseline TTA;Python notebook;3460.0;51;0.906;0.922
2020-07-03 21:13:23;About this kernelMost of this notebook is blatantly stolen from https://www.kaggle.com/xhlulu/alaska2-efficientnet-on-tpus I've uploaded some tfrecord datasets. All permutations of the same cover image should be separated into each tfrecord file. So two tfrecord files should never have any image that matches the cover. This should make validation better, because you don't want the model to see the cover in train and then the stega image in validation. The main contribution here is the 6 alaska datasets that have been turned into TFRecords and a cache trick. Because TPUs have limited ram, if you decode the JPEG and then cache it, you will run out of ram because you are caching an uncompressed JPEG, which is massive. Instead, cache the JPEG binary and decode it. TPUs have alot of CPU cores for that job and your main bottleneck is usually file access. Also, the tfrecords stream better than 300k images as separate files. Tweak it yourself and experiment!;Apache 2.0;https://www.kaggle.com/hooong/tpu-on-all-300k-images-without-crashing;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'dl', 'gan', 'cv', 'nn', 'ann'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict'];https://www.kaggle.com/c/alaska2-image-steganalysis;0.672;0.408;2020-12-12 16:29:24;multiple data sources;[];TPU On All 300k Images Without Crashing;Python notebook;1684.0;32;;
2020-05-09 03:43:50;Acknowledgements Built-upon https://www.kaggle.com/xhlulu/alaska2-efficientnet-on-tpus by @xhlulu Added backbone EfficientNetB7 and blend with EfficientNetB3 Experimented with number of epochs and modified LR scheduling;Apache 2.0;https://www.kaggle.com/khoongweihao/alaska2-blending-efficientnets-on-tpus;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'gan', 'nn', 'ann'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict'];https://www.kaggle.com/c/alaska2-image-steganalysis;0.68;0.431;2020-12-12 16:29:24;ALASKA2 Image Steganalysis;['tpu, deep learning, ensembling'];ALASKA2: Blending EfficientNets on TPUs;Python notebook;2009.0;42;0.764;0.747
2020-05-23 11:48:42;OverviewThis notebook provides a baseline stacking framework with TPU and GPU models. I did not include my best weights here as there is no free lunch in this world. An important point to note is that the TPU weights are trained with TensorFlow wheres the GPU ones are with PyTorch! The stacking methods shown here are:  mean median min-max mean min-max median pushout-median  My public GPU and TPU weights for EfficientNetb0 to b7 can be found here:https://www.kaggle.com/khoongweihao/alaska2-efficientnet-trained-model-weights. The weights will be updated periodically to reflect my progress in the competition.;Apache 2.0;https://www.kaggle.com/khoongweihao/alaska2-stacking-gpu-tpu-models-a-starter-kit;1.0;['pytorch', 'albumentations', 'tensorflow', 'sklearn'];['ner', 'ai', 'dl', 'cnn', 'gan', 'cv', 'rl', 'nn', 'ann'];['neuron', 'train', 'model', 'epoch', 'layer', 'label', 'classification'];https://www.kaggle.com/c/alaska2-image-steganalysis;0.691;0.437;2020-12-12 16:29:24;multiple data sources;['gpu'];ALASKA2 Stacking GPU & TPU Models - A Starter Kit;Python notebook;2511.0;45;0.871;0.893
2020-06-12 01:52:46;In my previous kernel, I trained a multiclass CNN based classifier. I was curious to understand what the CNN is learning, since detecting if hidden message is present or not seems to be impossible visually. So, in this kernel, I try to do a Grad-Cam visualization to understand which parts the CNN is focussing on. Inspired by Remi's earlier work, I also plot the RGB difference and DCT difference for easier comparison.;Apache 2.0;https://www.kaggle.com/meaninglesslives/alaska2-analyzing-model-predictions;1.0;['pytorch', 'albumentations', 'sklearn'];['ner', 'ai', 'cnn', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['neuron', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'classification'];https://www.kaggle.com/c/alaska2-image-steganalysis;0.661;0.416;2020-12-12 16:29:24;multiple data sources;['gpu'];Alaska2 Analyzing Model Predictions ;Python notebook;1355.0;35;;
2020-06-08 13:46:04;In this kernel i build a CNN based multiclass classifier that given an input image predicts which category the image belongs to namely, (No Hidden Message, JMiPOD, JUNIWARD or UERD). The main highlights of the kernel:  Approach the problem as multiclass classification instead of binary class. Proper split for train and validation set and use competition metric proposed here  to get good estimate of model performance on public lb. Illustrate the use of proper augmentation strategy to improve model performance. Using imagenet pretrained EfficientNet B0 as model backbone for the classifier. One Possible way to convert multiclass probabilities to binary. Use test time augmentation to improve lb score.  I have added some comments at each block which further clarifies some of the above mentioned points. Updates: v3:   New way of converting multiclass probabilities to binary (basically take sum of probabilities of JMiPOD, JUNIWARD and UERD). Trained for 5 more epochs.  v4:   Based on some of the discussion, I decided to increase the number of classes. So, now i train a CNN classifier that separates images into one of the following categories [Normal, JMiPOD_75, JMiPOD_90, JMiPOD_95, JUNIWARD_75, JUNIWARD_90, JUNIWARD_95,UERD_75, UERD_90, UERD_95]. v5:    Train for more epochs. v6:    Train for more epochs. Reduced learning rate every 2 epochs by 0.5.   Added CoarseDropout and Cutout. It seems to improve performance.;Apache 2.0;https://www.kaggle.com/meaninglesslives/alaska2-cnn-multiclass-classifier;1.0;['pytorch', 'albumentations', 'sklearn'];['ai', 'cnn', 'gan', 'cv', 'nn', 'ann'];['neuron', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'classification'];https://www.kaggle.com/c/alaska2-image-steganalysis;0.752;0.521;2020-12-12 16:29:24;multiple data sources;['gpu, deep learning, classification'];Alaska2 CNN Multiclass Classifier;Python notebook;10935.0;135;0.882;0.888
2020-05-15 10:28:59;thanks to @abhishek brother and @xhlulu as i borrowed a lot of code from them.have been learning a lot from them since last 1+ year.;Apache 2.0;https://www.kaggle.com/mobassir/pytorch-tpu-transfer-learning-baseline;1.0;['sklearn', 'pytorch', 'albumentations', 'spacy', 'skimage'];['ai', 'dl', 'gan', 'cv', 'rl', 'nlp', 'nn'];['filter', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'rank', 'understanding', 'resnet', 'classification'];https://www.kaggle.com/c/alaska2-image-steganalysis;0.715;0.478;2020-12-12 16:29:24;multiple data sources;['tpu'];Pytorch TPU Transfer Learning Baseline;Python notebook;4345.0;75;;
2020-04-28 01:22:00;IntroductionAs mentioned here, SRNet is a top NN for steganalysis. I would like to check the out-of-box performance of SRNet on this dataset. You can find the model and pretrained weight here. If you like it, please upvote the notebook and the dataset.;Apache 2.0;https://www.kaggle.com/naivelamb/alaska2-srnet-baseline-inference;1.0;['pytorch', 'albumentations'];['ai', 'gan', 'cv', 'nn', 'ann'];['train', 'model', 'label', 'predict'];https://www.kaggle.com/c/alaska2-image-steganalysis;0.703;0.455;2020-12-12 16:29:24;multiple data sources;[];ALASKA2: SRNet baseline inference;Python notebook;3246.0;56;0.590;0.549
2020-05-04 12:14:45;The goal of this notebook is to reproduce the architecture described in http://www.ws.binghamton.edu/fridrich/Research/SRNet.pdf;Apache 2.0;https://www.kaggle.com/pednt9/alaska2-srnet-in-keras;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'gan', 'nn', 'ann'];['filter', 'regression', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/alaska2-image-steganalysis;0.693;0.427;2020-12-12 16:29:24;ALASKA2 Image Steganalysis;['gpu, cnn, neural networks'];ALASKA2 – SRNet in Keras;Python notebook;2598.0;40;0.581;0.619
2020-06-01 14:02:11;Alaska2 Baseline PyTorchHi everyone! My name is Alex Shonenkov, I am DL/NLP/CV/TS research engineer. Especially I am in Love with NLP & DL. I would like to share with you my starter pipeline for solving this competition :);Apache 2.0;https://www.kaggle.com/shonenkov/train-inference-gpu-baseline;1.0;['pytorch', 'albumentations', 'skimage', 'sklearn'];['ai', 'dl', 'gan', 'cv', 'nlp', 'nn', 'ann'];['filter', 'train', 'model', 'epoch', 'layer', 'label', 'loss'];https://www.kaggle.com/c/alaska2-image-steganalysis;0.768;0.577;2020-12-12 16:29:23;multiple data sources;['gpu'];[Train + Inference] GPU Baseline;Python notebook;17192.0;311;0.904;0.921
2020-05-02 23:13:29;About this notebookThis notebook presents a Knaive model and is a supporting notebook to the my main notebook here, which presents complete detialed explanation and dicussions abobut this competitiom: https://www.kaggle.com/tanulsingh077/steganalysis-complete-understanding-and-model ---> Original author (TANUL SINGH) To understand how I came up with this idea and how everything works please refer above If you like my effort and contribution please show token of gratitude by upvoting my kernels Basic IdeaYesterday Kaggle launched the steganalysis competition. I found it very interesting as I have never heard of something like this. It instilled the spy fantasies within me. From yesterday I have been reading research papers on approaching this problem using deep learning but before I tried SRNET I want to do something of own. After a lot of thinking I came up with this :-  In this we are suppose to predict whether the test images are hiding some information or not but we dont have labels for the train images we just clean images and same images encoded using different algos, the main point is creating labels then we can approach this as regression problem . I thought Since in steganography in images, any technique involves changes in pixel values, a very knaive way to get labels would be to flatten the RGB images(both encoded and normal) into a vector and then find cosine dissimilarity between the two vectors, since the encoded value contains a hidden information its vector will differ from the main vector and hence we will have a non zero value of cosine dissimilarity. Then we Label the images as: Cover_images as 0 , JMIPOD images as similarity between cover and JMIPOD images , JUNIWARD images as similarity between cover and JUNIWARD images, UERD images as similarity between cover and UERD images After creating our labels , we will stack all the images and labels in a datafame and then approach this as simple regression problem  Update : One flaw that I found in the above approach was that labels to be predicted should be between zero and one, whereas our regression problem predicts values of any range and values can also be negative , so I passed out cosine dissmilarity through sigmoid function to get a probability between zero and one;Apache 2.0;https://www.kaggle.com/tanulsingh077/steganalysis-a-knaive-approach;1.0;['tensorflow', 'skimage', 'keras'];['ai', 'gan'];['regression', 'train', 'model', 'epoch', 'deep learning', 'layer', 'loss', 'label', 'predict', 'relu', 'understanding'];https://www.kaggle.com/c/alaska2-image-steganalysis;0.693;0.452;2020-12-12 16:29:24;ALASKA2 Image Steganalysis;['gpu, feature engineering'];Steganalysis : A Knaive approach;Python notebook;2610.0;54;0.614;0.556
2020-05-02 21:26:24;"About this Competition""Wait!What? Another one , No man this can't be happening"", Calm down there Pal! , it's just the quarantine , It's messing with Kaggle. Kaggle is going wild with competitons releasing 4th competiton this week, but we need to support Kaggle as good community members right? I mean these are tough times 😛 . This is an interesting competition though,I mean Stegnography, now we are talking, it's time to give all those suppressed spy fantasies we have had for a long time , some air  😍 and dive right in . This competition wants us to create an efficient and reliable method to detect secret data hidden within innocuous-seeming digital images.";Apache 2.0;https://www.kaggle.com/tanulsingh077/steganalysis-complete-understanding-and-model;1.0;['pattern', 'skimage', 'pillow'];['ai', 'cnn', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['train', 'model', 'neural network', 'label', 'predict', 'understanding'];https://www.kaggle.com/c/alaska2-image-steganalysis;0.759;0.584;2020-12-12 16:29:23;multiple data sources;['exploratory data analysis, feature engineering, cnn'];Steganalysis : Complete Understanding and Model;Python notebook;13284.0;347;;
2020-04-29 02:46:49;About this kernelThis is the 3rd notebook I'm making using EfficientNet on TPUs. The full list:  https://www.kaggle.com/xhlulu/flowers-tpu-concise-efficientnet-b7 https://www.kaggle.com/xhlulu/plant-pathology-very-concise-tpu-efficientnet  If you want to dive deeper in the tf.data.Dataset way of building your input pipeline, please check out this tutorial by Martin, which I followed in order to build this kernel. References https://www.kaggle.com/mgornergoogle/getting-started-with-100-flowers-on-tpu https://codelabs.developers.google.com/codelabs/keras-flowers-data/#0;Apache 2.0;https://www.kaggle.com/xhlulu/alaska2-efficientnet-on-tpus;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'gan', 'nn', 'ann'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict'];https://www.kaggle.com/c/alaska2-image-steganalysis;0.764;0.523;2020-12-12 16:29:24;ALASKA2 Image Steganalysis;['tpu'];Alaska2: EfficientNet on TPUs;Python notebook;15231.0;138;0.754;0.791
2016-10-13 06:04:10;This is my first kernel submission on kaggle. I got the motivation from other EDA notebooks for this competition.;Apache 2.0;https://www.kaggle.com/achalshah/allstate-feature-analysis-python;1.0;['sklearn'];['ai', 'nn', 'ann'];['filter', 'machine learning', 'test data', 'train', 'model', 'label', 'loss'];https://www.kaggle.com/c/allstate-claims-severity;0.757;0.463;2020-12-12 16:36:59;Allstate Claims Severity;[];Allstate Feature Analysis - Python;Python notebook;12577.0;62;;
2016-10-11 17:50:46;Loading the dataset and create lists with the features.;Apache 2.0;https://www.kaggle.com/guyko81/just-an-easy-solution;1.0;['xgboost', 'sklearn'];['ai', 'nn', 'ml', 'cv'];['regression', 'train', 'model', 'loss', 'label', 'predict'];https://www.kaggle.com/c/allstate-claims-severity;0.747;0.447;2020-12-12 16:36:59;Allstate Claims Severity;[];Just an easy solution;Python notebook;9418.0;51;;
2016-11-26 08:54:30;Welcome to the wonderful world of Markov Chain Monte Carlo Here I present a toy example of how one can use MCMC to get a pretty good improvement over straight averaging;Apache 2.0;https://www.kaggle.com/scirpus/markov-chain-monte-carlo;1.0;['sklearn'];['ai', 'ml', 'rl'];['model', 'regression'];https://www.kaggle.com/c/allstate-claims-severity;0.753;0.46;2020-12-12 16:36:59;Allstate Claims Severity;[];Markov Chain Monte Carlo;Python notebook;11186.0;60;;
2016-10-16 16:59:31;Thank you for opening this script! I have made all efforts to document each and every step involved in the prediction process so that this notebook acts as a good starting point for new Kagglers and new machine learning enthusiasts. Please upvote this kernel so that it reaches the top of the chart and is easily locatable by new users. Your comments on how we can improve this kernel is welcome. Thanks. My other exploratory studies can be accessed here : https://www.kaggle.com/sharmasanthosh/kernels  Data statistics Shape Peek Description Skew  Transformation Correction of skew  Data Interaction Correlation Scatter plot  Data Visualization Box and density plots Grouping of one hot encoded attributes  Data Preparation One hot encoding of categorical data Test-train split  Evaluation, prediction, and analysis Linear Regression (Linear algo) Ridge Regression (Linear algo) LASSO Linear Regression (Linear algo) Elastic Net Regression (Linear algo) KNN (non-linear algo) CART (non-linear algo) SVM (Non-linear algo) Bagged Decision Trees (Bagging) Random Forest (Bagging) Extra Trees (Bagging) AdaBoost (Boosting) Stochastic Gradient Boosting (Boosting) MLP (Deep Learning) XGBoost  Make Predictions;Apache 2.0;https://www.kaggle.com/sharmasanthosh/exploratory-study-on-ml-algorithms;1.0;['xgboost', 'sklearn', 'tensorflow', 'pattern', 'keras'];['ai', 'nn', 'ml', 'cv'];['linear regression', 'filter', 'machine learning', 'regression', 'test data', 'train', 'model', 'epoch', 'deep learning', 'layer', 'loss', 'label', 'gradient boosting', 'predict', 'relu', 'decision tree', 'random forest'];https://www.kaggle.com/c/allstate-claims-severity;0.809;0.615;2020-12-12 16:36:58;Allstate Claims Severity;['model comparison'];Exploratory study on ML algorithms;Python notebook;62265.0;581;;
2020-06-26 17:35:48;1. Data preprocessing and visualisationsImporting libraries and datasets;Apache 2.0;https://www.kaggle.com/arindambaruah/amzn-access-predictions-beginner;1.0;['xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'gbm', 'cv', 'rl', 'nn', 'ann'];['machine learning', 'test data', 'regression', 'random forest', 'train', 'fitting', 'model', 'understanding', 'gradient descent', 'label', 'logistic regression', 'predict', 'decision tree', 'classification'];https://www.kaggle.com/c/amazon-employee-access-challenge;0.546;0.188;2020-12-12 16:38:00;Amazon.com - Employee Access Challenge;[];AMZN_access_predictions_beginner;Python notebook;191.0;3;0.57592;0.58096
2019-04-10 00:23:17;"Unsupervised categorical encodingsWe will start with ""unsupervised"" categorical encodings. By “unsupervised” here I mean we are not going to use information about the target in any way. One of the advantages of this approach - you can use all data you have, for example in case of Kaggle competition you can use both files, train.csv and test.csv. In first cell we load all data we need.";Apache 2.0;https://www.kaggle.com/dmitrylarko/kaggledays-sf-2-amazon-unsupervised-encoding;1.0;['catboost', 'xgboost', 'sklearn', 'lightgbm'];['ai', 'dl', 'gbm', 'cv', 'nn', 'ml'];['test data', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/amazon-employee-access-challenge;0.684;0.403;2020-12-12 16:38:00;Amazon.com - Employee Access Challenge;['feature engineering'];KaggleDays SF: 2. Amazon - Unsupervised encoding;Python notebook;2164.0;30;0.89088;0.89148
2019-04-10 00:03:21;Supervised categorical encodingsBy “supervised” here I mean we are going to use the information about target we are trying to predict in order to build our categorical embeddings.;Apache 2.0;https://www.kaggle.com/dmitrylarko/kaggledays-sf-3-amazon-supervised-encoding;1.0;['catboost', 'lightgbm', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'ml'];['train', 'model', 'predict'];https://www.kaggle.com/c/amazon-employee-access-challenge;0.683;0.405;2020-12-12 16:38:00;Amazon.com - Employee Access Challenge;['feature engineering']; KaggleDays SF: 3. Amazon - Supervised encoding;Python notebook;2109.0;31;0.89689;0.90589
2020-08-28 21:33:08;End to end solutionUsing original features and 2-nd level interactions (pairs) this solution shows a pipeline which gets you to top 20 position on private and public LB. In this solution we are building 2 datasets and train 2 models. The final submission is an averages of these 2 models.;Apache 2.0;https://www.kaggle.com/dmitrylarko/kaggledays-sf-4-amazon-end-to-end;1.0;['catboost', 'lightgbm', 'sklearn'];['cv', 'ai', 'gbm'];['train', 'model', 'label', 'predict'];https://www.kaggle.com/c/amazon-employee-access-challenge;0.686;0.39;2020-12-12 16:38:00;Amazon.com - Employee Access Challenge;['feature engineering']; KaggleDays SF: 4. Amazon - End to End;Python notebook;2264.0;26;0.91842;0.92258
2019-06-18 20:13:51;The result of the test set given is saved in the variable test_pred;Apache 2.0;https://www.kaggle.com/hoodini/amazon-employee-access-random-forest;1.0;['sklearn'];['ai'];['random forest', 'train', 'fitting', 'model', 'predict', 'classification'];https://www.kaggle.com/c/amazon-employee-access-challenge;0.624;0.152;2020-12-12 16:38:00;Amazon.com - Employee Access Challenge;[];Amazon Employee Access (Random Forest);Python notebook;677.0;2;0.50000;0.50000
2020-04-15 17:57:56;Let's define all things we need. And we will need: Frequency Encoding, Label Encoding, SVD encoding and target encoding.;Apache 2.0;https://www.kaggle.com/jagannathrk/employees-access-prediction;1.0;['catboost', 'lightgbm', 'sklearn'];['cv', 'ai', 'gbm'];['train', 'model', 'label', 'predict'];https://www.kaggle.com/c/amazon-employee-access-challenge;0.531;0.099;2020-12-12 16:38:00;Amazon.com - Employee Access Challenge;[];Employees access prediction;Python notebook;155.0;1;;
2019-05-01 16:04:56;"mlcourse.ai – Open Machine Learning Course Author: Mikhail Tribunskiy, @MITribunskiy  Tutorial  ""CatBoost overview""";Apache 2.0;https://www.kaggle.com/mitribunskiy/tutorial-catboost-overview;1.0;['catboost', 'xgboost', 'sklearn'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml'];['filter', 'machine learning', 'regression', 'train', 'fitting', 'model', 'validation data', 'loss', 'label', 'gradient boosting', 'predict', 'rank', 'decision tree', 'classification'];https://www.kaggle.com/c/amazon-employee-access-challenge;0.78;0.49;2020-12-12 16:38:00;multiple data sources;['beginner, classification, gradient boosting, +1 morecategorical data'];Tutorial: CatBoost Overview;Python notebook;24042.0;88;;
2020-03-08 23:54:01;"Catboost & Hyperopt : Amazon employees dataset Information from Kaggle When an employee at any company starts work, they first need to obtain the computer access necessary to fulfill their role. Given data about current employees and their provisioned access, models can be built that automatically determine access privileges as employees enter and leave roles within a company. These auto-access models seek to minimize the human involvement required to grant or revoke employee access.     Catboost:  Yandex, the developers of Catboost, claim that default Catboost provides ~20% logloss improvement over LightGMB & XGBoost. Tuning further improves performance of the model. I will be testing these claims. Catboost uses gradient boosted trees. Great for working on catgorical data and mixed data (with both categorical and numerical features) Data is quantized into bins. The algorithm decides bin 'borders'(We can set our own values too). This quantization supports faster integration into parallel processing workflows.  Symmetric gradient boosted trees are built, each subsequent tree improves the performance of the previous set of trees.  Categorical preprocessing steps like One-Hot-Encoding, text preprocessing steps like tokenization, Bag of Words models can be performed within the Catboost algorithm (No need for additional preprocessing.)       RESULT: One of the columns had duplicated information. After removing this column - the default algorithm gave the best loss publicised by Yandex (~0.137). A kaggle submission showed 90% AUC score. Hyperopt tuning did not improve scores.  Yandex's claims were proven. It had the best loss among the boosting models as shown in table below.       Model Logloss from default   Catboost 0.13516505504697254   Xgboost 0.1554555542790197   LightGBM 0.16383632381872779  Table of Contents Imports & Read in file Explore data Preprocessing Baseline Model Test set performance Hyperparameter tuning Model validation Other Boosting Algorithms    Description of Features:    Label Description   ACTION ACTION is 1 if the resource was approved, 0 if the resource was not   RESOURCE An ID for each resource   EMPLOYEE ID The EMPLOYEE ID of the manager of the current EMPLOYEE ID record; an employee may have only one manager at a time   ROLE_ROLLUP_1 Company role grouping category id 1 (e.g. US Engineering)   ROLE_ROLLUP_2 Company role grouping category id 2 (e.g. US Retail)   ROLE_DEPTNAME Company role department description (e.g. Retail)   ROLE_TITLE Company role business title description (e.g. Senior Engineering Retail Manager)   ROLE_FAMILY_DESC Company role family extended description (e.g. Retail Manager, Software Engineering)   ROLE_FAMILY Company role family description (e.g. Retail Manager)   ROLE_CODE Company role code; this code is unique to each role (e.g. Manager)";Apache 2.0;https://www.kaggle.com/orpitadas/amazon-catboost-shap-hyperopt-90-auc-silvermedal;1.0;['catboost', 'xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'gbm', 'cv', 'rl', 'nn'];['test data', 'regression', 'train', 'fitting', 'model', 'neural network', 'validation data', 'loss', 'label', 'predict', 'classification', 'bayesian'];https://www.kaggle.com/c/amazon-employee-access-challenge;0.603;0.099;2020-12-12 16:38:00;Amazon.com - Employee Access Challenge;['beginner, classification, gradient boosting'];Amazon_Catboost_SHAP_hyperopt_90%AUC_silvermedal;Python notebook;472.0;1;;
2020-11-23 08:00:37;Reading data set from input data;Apache 2.0;https://www.kaggle.com/pinakimishrads/catboost-multiclass-classification-amazon-data;1.0;['catboost', 'sklearn'];['ai', 'rl', 'nn', 'cv'];['test data', 'train', 'fitting', 'model', 'loss', 'label', 'predict', 'rank', 'classification'];https://www.kaggle.com/c/amazon-employee-access-challenge;0.499;0.152;2020-12-12 16:38:00;Amazon.com - Employee Access Challenge;['gpu, deep learning, multiclass classification, +1 moredata analytics'];notebook049136136f;Python notebook;99.0;2;;
2020-08-20 03:53:16;CatBoost Classifier in PythonHello friends, In our machine learning journey, all of us have to deal with categorical data at some point of time. In sklearn, we are required to convert these categories into the numerical format. In order to do this conversion, we use several pre-processing methods like “label encoding”, “one hot encoding” and others. In this kernel, we will discuss an open sourced library - CatBoost developed and contributed by Yandex. CatBoost can use categorical features directly and is scalable in nature. So, let's get started.;Apache 2.0;https://www.kaggle.com/prashant111/catboost-classifier-in-python;1.0;['xgboost', 'lightgbm', 'catboost', 'sklearn', 'h2o', 'tensorflow'];['ner', 'ai', 'dl', 'gbm', 'rl', 'nn', 'ml'];['machine learning', 'test data', 'train', 'fitting', 'model', 'deep learning', 'loss', 'label', 'gradient boosting', 'predict', 'decision tree', 'recommend'];https://www.kaggle.com/c/amazon-employee-access-challenge;0.755;0.483;2020-12-12 16:38:00;Amazon.com - Employee Access Challenge;[];CatBoost Classifier in Python;Python notebook;11746.0;80;;
2020-05-23 10:50:05;Accepts a fitted model and an evaluation dataset at input.     Prints the confusion matrix, classification_report & auc score.      Also, displays Precision-Recall curve & ROC curve.;Apache 2.0;https://www.kaggle.com/samisha31/employeeaccess;1.0;['catboost', 'xgboost', 'sklearn', 'lightgbm'];['ai', 'gbm', 'cv', 'rl', 'nn'];['test data', 'regression', 'train', 'fitting', 'model', 'neural network', 'loss', 'label', 'predict', 'classification'];https://www.kaggle.com/c/amazon-employee-access-challenge;0.506;0.0;2020-12-12 16:38:01;Amazon.com - Employee Access Challenge;[];EmployeeAccess;Python notebook;109.0;0;;
2019-12-20 08:07:14;Problem definition:The data consists of real historical data collected from 2010 & 2011.  Employees are manually allowed or denied access to resources over time. You must create an algorithm capable of learning from this historical data to predict approval/denial for an unseen set of employees.;Apache 2.0;https://www.kaggle.com/shyamsundarnaik/amazon-employee-access-challenge-using-tree-algms;1.0;['catboost', 'xgboost', 'sklearn'];['ai', 'cv'];['training data', 'test data', 'train', 'model', 'predict', 'classification', 'ground truth'];https://www.kaggle.com/c/amazon-employee-access-challenge;0.547;0.099;2020-12-12 16:38:01;multiple data sources;[];Amazon Employee Access Challenge using Tree Algms;Python notebook;195.0;1;;
2019-12-12 06:59:42;Problem Statement The data consists of real historical data collected from 2010 & 2011.  Employees are manually allowed or denied access to resources over time. We have to create an algorithm capable of learning from this historical data to predict approval/denial for an unseen set of employees.;Apache 2.0;https://www.kaggle.com/subbareddyalamuru/predicting-action-using-dt-rf-and-bagging-classfr;1.0;['catboost', 'sklearn'];['ai', 'nn', 'ann', 'cv'];['test data', 'train', 'model', 'label', 'predict', 'random forest'];https://www.kaggle.com/c/amazon-employee-access-challenge;0.559;0.188;2020-12-12 16:38:00;Amazon.com - Employee Access Challenge;[];Predicting Action using DT,RF and Bagging Classfr;Python notebook;233.0;3;;
2019-06-28 08:36:44;In this kernel, I present to you an OptimizedRounder class for Quadratic Weighted Kappa (QWK);Apache 2.0;https://www.kaggle.com/abhishek/optimizer-for-quadratic-weighted-kappa;0.8;['sklearn'];[];['loss', 'predict'];https://www.kaggle.com/c/aptos2019-blindness-detection;0.748;0.551;2020-12-12 16:39:24;APTOS 2019 Blindness Detection;[];optimizer for quadratic weighted kappa;Python notebook;9892.0;206;;
2019-06-30 16:20:56;TTA for the lazy, like me;Apache 2.0;https://www.kaggle.com/abhishek/pytorch-inference-kernel-lazy-tta;1.0;['pytorch'];['ai', 'nn'];['train', 'model', 'layer', 'relu', 'resnet'];https://www.kaggle.com/c/aptos2019-blindness-detection;0.788;0.595;2020-12-12 16:39:24;multiple data sources;['gpu'];pytorch inference kernel + lazy TTA;Python notebook;30707.0;416;0.880464;0.755951
2019-09-06 20:40:47;APTOS 2019 Blindness Detection In this Kernel, we will design a Machine learning model,which will help in identifing the eyes disease.  As this is a imaged based problem, we will use Deep Learning for model design. Diabetic retinopathy affects blood vessels in the light-sensitive tissue called the retina that lines the back of the eye. It is the most common cause of vision loss among people with diabetes and the leading cause of vision impairment and blindness among working-age adults. It don't have any earaly symtoms. As of now, Retena photography is a way to detect the stage of Blindness. Automating it with ml, will help a lot in health domain.   Import Required Libraries Loading Data  Data Visualization Train and Test dataset Data Pre-Processing Image Data Generator Model Architecture Design Keras Callback Funcations Transfer Learning Validation Accuracy & Loss Validation Accuracy Test-Time Augmentation Visualization Test Result    Design CNN from Scratch Use pre-train model for Blindness Detection Stages Of Diabetic Retinopathy  NO DR Mild Moderate  Servere Proliferative DR;Apache 2.0;https://www.kaggle.com/bharatsingh213/keras-resnet-tta;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cnn', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'training data', 'generation', 'train', 'test data', 'model', 'epoch', 'deep learning', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'resnet'];https://www.kaggle.com/c/aptos2019-blindness-detection;0.757;0.497;2020-12-12 16:39:24;multiple data sources;['beginner, exploratory data analysis, deep learning, +1 morefeature engineering'];Keras+ResNet+TTA ;Python notebook;12561.0;97;0.871031;0.703619
2019-11-17 11:53:07;Implementation of EfficientNetB5 for the APTOS 2019 competition with Keras;Apache 2.0;https://www.kaggle.com/carlolepelaars/efficientnetb5-with-keras-aptos-2019;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'nn', 'ann'];['machine learning', 'training data', 'regression', 'train', 'fitting', 'model', 'neural network', 'epoch', 'deep learning', 'layer', 'validation data', 'loss', 'label', 'predict', 'relu', 'recommend', 'convolutional neural network', 'ground truth'];https://www.kaggle.com/c/aptos2019-blindness-detection;0.779;0.558;2020-12-12 16:39:24;multiple data sources;['deep learning, neural networks, regression'];EfficientNetB5 with Keras (APTOS 2019);Python notebook;23510.0;230;;
2019-08-15 08:29:23;version2-3. Fix Nvidia apex installation Error Inference: https://www.kaggle.com/chanhu/eye-inference-num-class-1-ver3;Apache 2.0;https://www.kaggle.com/chanhu/eye-efficientnet-pytorch-lb-0-777;1.0;['pytorch', 'sklearn'];['ai', 'dl', 'cv', 'rl', 'nlp', 'nn', 'rnn'];['filter', 'train', 'model', 'epoch', 'layer', 'label', 'loss'];https://www.kaggle.com/c/aptos2019-blindness-detection;0.757;0.524;2020-12-12 16:39:24;multiple data sources;['gpu'];Eye -- EfficientNet Pytorch[LB 0.777] ;Python notebook;12643.0;140;;
2019-07-20 02:53:31;THIS KERNEL WILL RESULT IN PUBLIC LB AROUND 0.78, BUT IF YOU PLAY AROUND WITH TRANSOFORMATIONS, IMAGE_SIZE, TRAINING CYCLES IT CAN RESULT TO >0.795;Apache 2.0;https://www.kaggle.com/drhabib/starter-kernel-for-0-79;1.0;['pytorch', 'tensorflow', 'sklearn'];['ner', 'ai', 'rl', 'nn', 'ann'];['activation function', 'filter', 'train', 'model', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/aptos2019-blindness-detection;0.774;0.57;2020-12-12 16:39:24;multiple data sources;['gpu'];Starter kernel for > 0.79;Python notebook;20253.0;275;0.911409;0.783583
2019-08-21 23:35:40;"EfficientNet architecturePre-trained weights from: https://www.kaggle.com/hmendonca/efficientnet-pytorch-ignite and Ignite examples: Recently new ConvNets architectures have been proposed in ""EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"" paper. According to the paper, model's compound scaling starting from a 'good' baseline provides an network that achieves state-of-the-art on ImageNet, while being 8.4x smaller and 6.1x faster on inference than the best existing ConvNet.   This kernel borrowed some of its code from: https://www.kaggle.com/kageyama/fork-of-fastai-blindness-detection-resnet34 and https://www.kaggle.com/demonplus/fast-ai-starter-with-resnet-50 Many thanks to the authors! If you liked it, please upvote and leave questions or any feedback below (for me and other kagglers learning). Cheers!";Apache 2.0;https://www.kaggle.com/hmendonca/efficientnetb4-fastai-blindness-detection;1.0;['pytorch', 'sklearn'];['ner', 'ai', 'dl', 'cv', 'nn', 'ml'];['filter', 'train', 'model', 'neural network', 'epoch', 'layer', 'label', 'loss', 'resnet', 'classification', 'convolutional neural network'];https://www.kaggle.com/c/aptos2019-blindness-detection;0.756;0.511;2020-12-12 16:39:24;multiple data sources;['beginner, deep learning, classification, +2 morecnn, transfer learning'];EfficientNetB4 FastAI - Blindness Detection;Python notebook;12240.0;117;0.882015;0.715706
2019-07-08 09:32:38;Update: changing the batch_size from 32 to 128 when warm up the model, adding Kappa loss from this kernel: https://www.kaggle.com/christofhenkel/weighted-kappa-loss-for-keras-tensorflow;Apache 2.0;https://www.kaggle.com/mathormad/aptos-resnet50-baseline;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cv', 'rl', 'nn', 'ann'];['filter', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'resnet'];https://www.kaggle.com/c/aptos2019-blindness-detection;0.776;0.535;2020-12-12 16:39:24;multiple data sources;['gpu, classification'];[APTOS] resnet50 baseline;Python notebook;21325.0;163;;
2019-07-13 18:15:29;Credits and references : The complete code is taken from this kernel.Changed the model,added some augmentations and retrained it.Thanks to the Author of the kernel.;Apache 2.0;https://www.kaggle.com/ratan123/aptos-2019-keras-baseline;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cnn', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'resnet'];https://www.kaggle.com/c/aptos2019-blindness-detection;0.744;0.526;2020-12-12 16:39:24;multiple data sources;['beginner, deep learning, classification, +1 morehealthcare'];APTOS 2019: Keras Baseline;Python notebook;8733.0;144;0.901502;0.749141
2019-09-10 19:01:49;0. Spotting Blindness -- Real or Spurious?Above is the old title I used, in this new version I also show how to analyze robustness of our model using the great albumentation  Therefore, I decide to change the title to more appropriately reflect the techniques I used here. Please see Section 5 below for the updated material. 1. Introduction : This eye is in danger, I estimate severity level 4Do you want to understand, when the model saying the above statement, how does it know? Does the model look at the same bloody or cotton wool spots like us? Below are what CNN actually see. Does this make sense? Look at the picture below, in the first case, it seems that the model works great! It is able to identify important spots in the eye. In the second case, however, even though the model estimate the severity to be level 3, it almost entirely misses the big wool spots in the middle. It might infer that our model still doesn't grasp an important concept of 'hard exudates' well enough. (ref. https://www.eyeops.com/);Apache 2.0;https://www.kaggle.com/ratthachat/aptos-augmentation-visualize-diabetic-retinopathy;1.0;['sklearn', 'pytorch', 'albumentations', 'tensorflow', 'keras'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'nn', 'ann'];['training data', 'test data', 'train', 'fitting', 'model', 'layer', 'predict', 'relu'];https://www.kaggle.com/c/aptos2019-blindness-detection;0.832;0.51;2020-12-12 16:39:24;multiple data sources;['gpu, data visualization, cnn, +1 moreneural networks'];APTOS Augmentation& Visualize Diabetic Retinopathy;Python notebook;148482.0;116;;
2019-09-09 08:07:58;UPDATE on V9:This kernel have two important updates.  Before Version 8, I couldn't make Ben's and Cropping method work together nicely, so I emphasized on gray scale. Now, I adjust both functions and beleive that color version is better than gray scale.  Before Version 9, I found a bug that will cause an old crop function to fail in a private test set (it works fine on training and public test sets). Here, I fix that bug. However, I still cannot guarantee whether there will be any more cases on private test set that will fail the crop function. Update on V11 Now I was able to have a valid LB score with the new crop function, so if anybody still have some submission errors, that is the reason of other bugs.   update on V14. Compare to circle crop in Section 3.A2 according to @taindow : please visit his kernel : https://www.kaggle.com/taindow/pre-processing-train-and-test-images  Other minor updates. Note on estimation inconsistency and Aravind's history.;Apache 2.0;https://www.kaggle.com/ratthachat/aptos-eye-preprocessing-in-diabetic-retinopathy;1.0;['sklearn', 'opencv-python', 'tensorflow', 'keras', 'skimage'];['ner', 'ai', 'gan', 'cv', 'rl', 'nn', 'ann'];['filter', 'training data', 'test data', 'train', 'model', 'label', 'loss', 'resnet'];https://www.kaggle.com/c/aptos2019-blindness-detection;0.811;0.633;2020-12-12 16:39:24;multiple data sources;['gpu, data visualization, exploratory data analysis, +1 moredata cleaning'];APTOS : Eye Preprocessing in Diabetic Retinopathy;Python notebook;66307.0;803;;
2019-07-21 14:15:35;Summary Using only image size and pixel counts, local validation kappa can easily reach 0.70+ This does NOT generalise to the test data Simple re-sizing is not enough to combat the issue, and CNN can easily overfit Use pre-processing wisely to overcome this;Apache 2.0;https://www.kaggle.com/taindow/be-careful-what-you-train-on;1.0;['xgboost', 'sklearn'];['ner', 'ai', 'cnn', 'cv', 'rl', 'ml', 'nn', 'ann'];['predict', 'training data', 'test data', 'train', 'model', 'label', 'loss'];https://www.kaggle.com/c/aptos2019-blindness-detection;0.723;0.527;2020-12-12 16:39:24;APTOS 2019 Blindness Detection;['gpu'];Be careful what you train on ...;Python notebook;5206.0;147;0.463379;0.034041
2019-07-03 21:01:07;BEFORE YOU FORK, PLEASE SUPPORT AND UPVOTE;Apache 2.0;https://www.kaggle.com/tanlikesmath/intro-aptos-diabetic-retinopathy-eda-starter;1.0;['pytorch', 'sklearn'];['ner', 'ai', 'dl', 'cnn', 'rl', 'nn'];['regression', 'train', 'model', 'neural network', 'epoch', 'deep learning', 'layer', 'loss', 'label', 'predict', 'computer vision', 'resnet', 'classification', 'labeled'];https://www.kaggle.com/c/aptos2019-blindness-detection;0.782;0.601;2020-12-12 16:39:24;multiple data sources;['gpu, beginner, deep learning, +1 moreclassification'];Intro APTOS Diabetic Retinopathy (EDA & Starter);Python notebook;25998.0;458;0.883263;0.700638
2019-07-26 16:37:02;About this kernelIn this kernel, we will explore the complete workflow for the APTOS 2019 competition. We will go through:  Loading & Exploration: A quick overview of the dataset Resize Images: We will resize both the training and test images to 224x224, so that it matches the ImageNet format. Mixup & Data Generator: We show how to create a data generator that will perform random transformation to our datasets (flip vertically/horizontally, rotation, zooming). This will help our model generalize better to the data, since it is fairly small (only ~3000 images). Quadratic Weighted Kappa: A thorough overview of the metric used for this competition, with an intuitive example. Check it out! Model: We will use a DenseNet-121 pre-trained on ImageNet. We will finetune it using Adam for 15 epochs, and evaluate it on an unseen validation set. Training & Evaluation: We take a look at the change in loss and QWK score through the epochs.  Unused MethodsThroughout V15-V18 of this kernel, I ablated a few methods that I presented in this kernel. The highest LB score was achieved after I removed:  Mixup Optimized Threshold  I decided to keep them in the kernel if it ever becomes useful for you. Citations & Resources I had the idea of using mixup from KeepLearning's ResNet50 baseline. Since the implementation was in PyTorch, I instead used an open-sourced keras implementation. The transfer learning procedure is mostly inspired from my previous kernel for iWildCam. The workflow was however heavily modified since then. Used similar method as Abhishek to find the optimal threshold. Lex's kernel prompted me to try using Multilabel instead of multiclass classification, which slightly improved the kappa score.;Apache 2.0;https://www.kaggle.com/xhlulu/aptos-2019-densenet-keras-starter;1.0;['pytorch', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'rl', 'cv', 'ml'];['generation', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'resnet', 'classification'];https://www.kaggle.com/c/aptos2019-blindness-detection;0.789;0.581;2020-12-12 16:39:24;multiple data sources;['gpu, classification, cnn, +1 morehealthcare'];APTOS 2019: DenseNet Keras Starter;Python notebook;31769.0;331;;
2020-09-25 21:51:19;So there is 8 unique set of essay in the given training set;Apache 2.0;https://www.kaggle.com/irfanmansuri/the-havelett-foundation-automated-scoring;1.0;['xgboost', 'sklearn', 'keras', 'nltk'];['ner', 'ai', 'cv', 'nlp', 'nn', 'ml'];['machine learning', 'regression', 'train', 'model', 'layer', 'label', 'logistic regression', 'predict', 'classification'];https://www.kaggle.com/c/asap-aes;0.6;0.152;2020-12-12 16:39:36;The Hewlett Foundation: Automated Essay Scoring;[];The_Havelett_Foundation_Automated_Scoring;Python notebook;448.0;2;;
2019-11-27 14:01:16;Main Points Each section is self-explanatory :)  Using KFold + LightGBM with 3 Splits Clean Code No use of UCL data leak Minimum Feature Engineering Minimum Memory Usages;Apache 2.0;https://www.kaggle.com/aitude/ashrae-kfold-lightgbm-without-leak-1-08;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'rl'];['training data', 'test data', 'regression', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/ashrae-energy-prediction;0.762;0.559;2020-12-12 16:41:48;ASHRAE - Great Energy Predictor III;['feature engineering, data cleaning, regression, +1 moreensembling'];ASHRAE- KFold LightGBM - without leak (1.08);Python notebook;14210.0;233;;
2019-12-31 18:59:45;COMPREHENSIVE DATA EXPLORATION WITH PYTHONCrislânio Macêdo -  December, 31th, 2019 Model in ⚡🔌ASHRAE : Lgbm Simple FE: ⚡🔌ASHRAE : Lgbm Simple FE;Apache 2.0;https://www.kaggle.com/caesarlupum/ashrae-start-here-a-gentle-introduction;1.0;['statsmodels', 'lightgbm', 'sklearn', 'pattern'];['ner', 'ai', 'dl', 'gbm', 'gan', 'rl', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'test data', 'random forest', 'train', 'model', 'understanding', 'label', 'predict', 'rank', 'decision tree', 'recommend'];https://www.kaggle.com/c/ashrae-energy-prediction;0.806;0.636;2020-12-12 16:41:48;ASHRAE - Great Energy Predictor III;['beginner, data visualization, utility script, +1 moredata cleaning'];🔌⚡ASHRAE -Start Here: A GENTLE Introduction;Python notebook;55722.0;841;;
2019-10-28 14:31:14;"ASHRAE - Great Energy Predictor IIIOur aim in this competition is to predict energy consumption of buildings. There are 4 types of energy to predict:  0: electricity 1: chilledwater 2: steam 3: hotwater  Electricity and water consumption may have different behavior! So I tried to separately train & predict the model. I moved previous ASHRAE: Simple LGBM submission kernel. [Update] I published ""Optuna tutorial for hyperparameter optimization"" notebook. Please also check it :)";Apache 2.0;https://www.kaggle.com/corochann/ashrae-training-lgbm-by-meter-type;1.0;['catboost', 'xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'gbm', 'rl', 'nn', 'ml'];['training data', 'test data', 'regression', 'train', 'model', 'label', 'predict', 'decision tree'];https://www.kaggle.com/c/ashrae-energy-prediction;0.778;0.572;2020-12-12 16:41:48;multiple data sources;['feature engineering, ensembling, gradient boosting'];ASHRAE: Training LGBM by meter type;Python notebook;22607.0;287;;
2019-11-09 10:46:58;Optuna tutorial for begginers: hyperparameter optimization frameworkWhen I try building a model (XGBoost, LightGBM, CatBoost, Neural Network etc...), I always face an issue of how to tune these hyperparameters? Some people may be trying to set parameters manually to see if the score improves or not. In this tutorial, I will introduce optuna, Define-by-Run Hyperparameter Optimization Framework for automated hyperparameter tuning. UPDATE: added 6. Visualize study history to analayze the hyperparams-performance relationship section, please check!!!;Apache 2.0;https://www.kaggle.com/corochann/optuna-tutorial-for-hyperparameter-optimization;1.0;['xgboost', 'lightgbm', 'catboost', 'sklearn', 'mxnet', 'tensorflow', 'keras'];['ner', 'ai', 'gbm', 'rl', 'nn', 'ml'];['training data', 'test data', 'regression', 'train', 'model', 'neural network', 'layer', 'loss', 'label', 'predict', 'rank', 'decision tree', 'ground truth', 'bayesian'];https://www.kaggle.com/c/ashrae-energy-prediction;0.759;0.536;2020-12-12 16:41:48;multiple data sources;['beginner, gradient boosting, optimization'];Optuna tutorial for hyperparameter optimization;Python notebook;13288.0;166;;
2019-11-11 10:21:27;1. UCF (University of Central Florida) SpiderBuilding metadata is scraped from https://www.oeis.ucf.edu/buildings, and there are two extra features in the page.  EUI (kBTU/sqft): Energy per square foot per year Reference: https://www.energystar.gov/buildings/facility-owners-and-managers/existing-buildings/use-portfolio-manager/understand-metrics/what-energy LEED: (Leadership in Energy and Environmental Design) is the most widely used green building rating system in the world;Apache 2.0;https://www.kaggle.com/gunesevitan/ashrae-ucf-spider-and-eda-full-test-labels;1.0;['pattern'];['ner', 'ai', 'rl', 'ml', 'nn', 'ann'];['train', 'label', 'predict'];https://www.kaggle.com/c/ashrae-energy-prediction;0.735;0.532;2020-12-12 16:41:48;ASHRAE - Great Energy Predictor III;['beginner, data visualization, exploratory data analysis, +1 moredata cleaning'];ASHRAE - UCF Spider and EDA (Full Test Labels);Python notebook;6988.0;157;;
2019-10-18 13:30:48;I'll summarise here the insights from my brief data analyses and whatever is shared in public discussions. This is still highly under progress and will be updated when possible. Quoting Chris Balbach (our Competition Host): Consider the scenario laid out in this diagram. This competition simulates the modelling challenge presented at the end of the timeline when measured energy and weather conditions are known and the adjusted baseline energy must be calculated.   For further details, I recommend reading this paper by Clayton Miller.  We are actually using data from 2016 to predict the demand for both 2017 and 2018, which is a hard task. However, other public kernels have showed that you can give a relatively good estimate even with a very simple linear model.;Apache 2.0;https://www.kaggle.com/hmendonca/starter-eda-and-feature-selection-ashrae3;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'gbm', 'rl', 'nn', 'ann'];['training data', 'test data', 'train', 'fitting', 'model', 'label', 'predict', 'rank', 'recommend'];https://www.kaggle.com/c/ashrae-energy-prediction;0.751;0.555;2020-12-12 16:41:48;ASHRAE - Great Energy Predictor III;['data visualization, feature engineering, regression'];Starter EDA and Feature selection ASHRAE3;Python notebook;10584.0;219;1.412;1.246
2019-11-03 04:40:35;What's your CV method? I observed the oof using k-fold, and found that the increase in the number of folds increases the oof_rmse, but the public LB decreases.  LGBM parmeter(For the fold-12, n_estimators= 1000 learning_rate=0.1 was used as a limited time)   n_estimators=6000,   learning_rate=0.05,   feature_fraction=0.7,   subsample=0.4,   num_leaves=40,   metric='rmse'    All variables are the same.;Apache 2.0;https://www.kaggle.com/kimtaegwan/what-s-your-cv-method;1.0;['sklearn'];['cv', 'ner', 'ai', 'gbm'];['train', 'model', 'label', 'predict'];https://www.kaggle.com/c/ashrae-energy-prediction;0.759;0.525;2020-12-12 16:41:48;multiple data sources;[];What's your CV method?;Python notebook;13303.0;143;;
2019-10-31 22:11:42;This notebook is an implementation of @Fred Navruzov's Timestamp Alignment method to @corochann's kernel. The idea is to align the timestamp by peak air temperature, based on an assumption that the highest air temperature should appear at around 14:00. After aligning the timestamp of weather data, LB jumped from 1.12 to 1.11. Credits go to:  https://www.kaggle.com/corochann/ashrae-training-lgbm-by-meter-type https://www.kaggle.com/frednavruzov/aligning-temperature-timestamp Thanks @S D a lot for sharing his insights: https://www.kaggle.com/c/ashrae-energy-prediction/discussion/114483#latest-660023;Apache 2.0;https://www.kaggle.com/nz0722/aligned-timestamp-lgbm-by-meter-type;1.0;['catboost', 'xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'gbm', 'rl', 'ml', 'nn', 'ann'];['regression', 'train', 'model', 'label', 'predict', 'rank'];https://www.kaggle.com/c/ashrae-energy-prediction;0.753;0.532;2020-12-12 16:41:48;multiple data sources;[];Aligned Timestamp - LGBM by meter type;Python notebook;11138.0;158;;
2019-11-26 01:40:11;"Really simple cleanupIn this kernel, I provide basic routines to identify ""bad"" rows that can simply be dropped to improve overall performance. I identify four sorts of bad rows, with significant overlap:  Unjustified runs of zero readings: We identify sequences of more than 48 hours with zero readings which do not occur during the typical seasons for the designated meter type Zero readings for electical meters: There's no reason for a building to ever have zero electrical usage, so we simply throw them all away. The first 141 days of electricity for site 0: Most of these would be covered by the previous sets, but there are a few stray non-zero values that we ignore because they don't fit the overall pattern. Abnormally high readings from building 1099: These values are just absurdly high and don't fit an established pattern. Leaderboard probes show that we do indeed benefit by dropping the outliers.";Apache 2.0;https://www.kaggle.com/purist1024/ashrae-simple-data-cleanup-lb-1-08-no-leaks;1.0;['pattern', 'lightgbm', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'rl'];['filter', 'train', 'fitting', 'model', 'predict'];https://www.kaggle.com/c/ashrae-energy-prediction;0.754;0.549;2020-12-12 16:41:48;ASHRAE - Great Energy Predictor III;[];Ashrae: simple data cleanup (LB 1.08 no leaks);Python notebook;11508.0;202;1.281;1.081
2019-11-08 21:05:01;Half and HalfThis notebook is the Python implementation of this awesomely simple R code: https://www.kaggle.com/kailex/ac-dc by kxx It demonstrates splitting the data in half and using each half to build a model which performs very well on the public LB with minimal feature engineering. The discussion on the same: https://www.kaggle.com/c/ashrae-energy-prediction/discussion/115851;Apache 2.0;https://www.kaggle.com/rohanrao/ashrae-half-and-half;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'rl', 'gbm'];['training data', 'test data', 'regression', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/ashrae-energy-prediction;0.775;0.592;2020-12-12 16:41:48;ASHRAE - Great Energy Predictor III;['beginner, regression, gradient boosting'];ASHRAE: Half and Half;Python notebook;20980.0;393;1.310;1.108
2019-10-17 02:55:37;Features that are likely predictive: Buildings  primary_use square_feet year_built floor_count (may be too sparse to use)  Weather  time of day holiday weekend cloud_coverage + lags dew_temperature + lags precip_depth + lags sea_level_pressure + lags wind_direction + lags wind_speed + lags  Train  max, mean, min, std of the specific building historically number of meters number of buildings at a siteid;Apache 2.0;https://www.kaggle.com/ryches/simple-lgbm-solution;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'gbm', 'rl', 'nn'];['test data', 'regression', 'train', 'model', 'loss', 'label', 'predict'];https://www.kaggle.com/c/ashrae-energy-prediction;0.756;0.53;2020-12-12 16:41:48;ASHRAE - Great Energy Predictor III;['data visualization, feature engineering'];Simple LGBM Solution;Python notebook;12133.0;152;1.670;1.494
2019-11-29 14:23:53;All We need is Leak Validation(LV) ? if you like this kernel, please upvote original kernels. update leakdata;Apache 2.0;https://www.kaggle.com/yamsam/ashrae-leak-validation-and-more;1.0;['catboost', 'xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'gbm', 'nn', 'ml'];['train', 'model', 'label', 'predict'];https://www.kaggle.com/c/ashrae-energy-prediction;0.744;0.52;2020-12-12 16:41:48;multiple data sources;[];ASHRAE: Leak Validation and more;Python notebook;8766.0;133;;
2020-09-09 05:43:01;Submission Format The submissions should contain the predicted probability of click for each ad impression in the test set using the following format: id,click 60000000,0.384 63895816,0.5919 759281658,0.1934 895936184,0.9572;Apache 2.0;https://www.kaggle.com/kkchuchu/logisticregression-practice-0815;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'ml', 'nn', 'ann'];['regression', 'train', 'model', 'loss', 'label', 'predict'];https://www.kaggle.com/c/avazu-ctr-prediction;0.633;0.099;2020-12-12 16:42:00;Click-Through Rate Prediction;[];LogisticRegression_Practice_0815;Python notebook;799.0;1;0.43696;0.43892
2019-01-21 09:35:44;Chapter 5. Categorical Variables: Counting Eggs in the Age of Robotic ChickensThis chapter is one of the chapters of the book, Feature Engineering for Machine Learning. Since I do not have enough resource on my local machine, I have ended up creating this kernel to practice the source code of the chapter 5 while reading the book. You can also examine all the main chapters' code over the original GitHub repository of the book: https://github.com/alicezheng/feature-engineering-book;Apache 2.0;https://www.kaggle.com/ozlerhakan/counting-eggs-in-the-age-of-robotic-chickens;1.0;['sklearn'];['ner', 'ai', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'regression', 'train', 'model', 'predict', 'linear regression'];https://www.kaggle.com/c/avazu-ctr-prediction;0.738;0.292;2020-12-12 16:42:00;multiple data sources;[];Counting Eggs in the Age of Robotic Chickens;Python notebook;7461.0;9;;
2018-08-29 19:56:06;General informationThis kernel is dedicated to extensive EDA of Avito Demand Prediction Challenge competition as well as feature engineering. Only a simple model is used due to kernel memory constraint.;Apache 2.0;https://www.kaggle.com/artgor/eda-features-engineering-and-lightgbm;1.0;['lightgbm', 'sklearn', 'nltk'];['ner', 'ai', 'cnn', 'gbm', 'rl', 'nn'];['test data', 'regression', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/avito-demand-prediction;0.699;0.472;2020-12-12 16:57:27;Avito Demand Prediction Challenge;['data visualization, exploratory data analysis, feature engineering, +1 morenlp'];EDA, features engineering and lightgbm;Python notebook;2988.0;70;;
2018-05-19 23:38:03;In this kernel we will take a look at engineering aggregated features. Specifically, we will engineer 3 aggregated features using train_active.csv, test_active.csv, periods_test.csv and periods_test.csv. Those features will be:  avg_times_up_user - how often the average item of the user has been put up for sale. avg_days_up_user - the average number of days an item from the user has been put up for sale. n_user_items - the number of items the user has put up for sale.  Let's see if they help :);Apache 2.0;https://www.kaggle.com/bminixhofer/aggregated-features-lightgbm;1.0;['xgboost', 'lightgbm', 'nltk', 'catboost', 'sklearn'];['ai', 'rl', 'nn', 'gbm'];['filter', 'test data', 'regression', 'train', 'model', 'label', 'gradient boosting', 'predict', 'recommend'];https://www.kaggle.com/c/avito-demand-prediction;0.761;0.542;2020-12-12 16:57:27;Avito Demand Prediction Challenge;['beginner, feature engineering'];Aggregated features & LightGBM;Python notebook;13907.0;181;0.22673;0.22317
2018-05-24 19:46:44;Using text features to predict image_top_1This kernel aims to demonstrate that training an image_top_1 model using the text fields, might come handy for 3 things:  Train word embeddings that have more focus on visual content predict image_top_1 which are NaN use the difference of our image top 1 prediction and the actual prediction as feature (not implemented);Apache 2.0;https://www.kaggle.com/christofhenkel/text2image-top-1;1.0;['tensorflow', 'keras'];['ai', 'rl', 'nn', 'cv'];['gru', 'test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/avito-demand-prediction;0.694;0.471;2020-12-12 16:57:27;Avito Demand Prediction Challenge;['gpu'];text2image_top_1;Python notebook;2658.0;69;;
2018-04-25 18:11:16;This kernel show how to extract image features using keras and low memory use.;Apache 2.0;https://www.kaggle.com/classtag/extract-avito-image-features-via-keras-vgg16;1.0;['tensorflow', 'keras'];['ai'];['regression', 'train', 'model', 'layer', 'vgg', 'predict', 'resnet'];https://www.kaggle.com/c/avito-demand-prediction;0.731;0.481;2020-12-12 16:57:27;multiple data sources;[];Extract avito image features via keras VGG16;Python notebook;6358.0;78;;
2018-05-18 23:37:06;You can download the resulting file at the bottom of the notebook or under the code section of the Kernel.;Apache 2.0;https://www.kaggle.com/frankherfert/region-and-city-details-with-lat-lon-and-clusters;1.0;['sklearn'];['ner', 'ai', 'ml', 'rl'];['machine learning', 'train', 'model', 'clustering', 'label', 'predict', 'rank'];https://www.kaggle.com/c/avito-demand-prediction;0.704;0.468;2020-12-12 16:57:27;multiple data sources;[];Region and City Details with Lat, Lon and Clusters;Python notebook;3376.0;66;;
2018-05-15 23:58:14;The Avito challenge uses a number of files that, when we are adding features or doing train-test-splits, can consume more memory than some people have available. In this notebook, we will be looking at a few things we can do to save memory and increase the overall workflow speed from loading data to creating numerical features.;Apache 2.0;https://www.kaggle.com/frankherfert/tips-tricks-for-working-with-large-datasets;1.0;['pattern', 'xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'dl', 'gbm', 'nn'];['train', 'model', 'label', 'loss'];https://www.kaggle.com/c/avito-demand-prediction;0.768;0.497;2020-12-12 16:57:27;Avito Demand Prediction Challenge;['beginner'];Tips & Tricks for Working with Large Datasets;Python notebook;17101.0;97;;
2018-05-24 17:06:42;Kernel referenceshttps://www.kaggle.com/bminixhofer/aggregated-features-lightgbm/output Adding new features from Benjamin's great Kernel  Number of ads per user  Average number of active days of all Ad's put up per user  Average number of times all Ad's were made active per user;Apache 2.0;https://www.kaggle.com/shanth84/rnn-detailed-explanation-0-2246;1.0;['lightgbm', 'sklearn', 'tensorflow', 'vocabulary', 'keras'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'nn', 'rnn'];['gru', 'filter', 'recurrent neural network', 'training data', 'test data', 'train', 'model', 'neural network', 'epoch', 'validation data', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/avito-demand-prediction;0.733;0.486;2020-12-12 16:57:27;multiple data sources;['beginner, neural networks, rnn'];RNN_Detailed Explanation_[0.2246];Python notebook;6618.0;83;0.22855;0.22468
2018-05-14 05:54:14;Ideas for Generating Image Features and Measuring Image Quality   Avito is Russia's largest Advertisment firm. The quality of the advertisement image significantly affects the demand volume on an item. For both advertisers and Avito, it is important to use authentic high quality images. In this kernel, I have implemented some ideas which can be used to create new features related to images. These features are an indicatory factors about the Image Quality. Following is the list of feature ideas: 1. Dullness : Is the Image Very Dull ?1.1 Image Dullness Score 2. Whiteness : Is the Image Very White ?2.1 Image Whiteness Score 3. Uniformity : Is the Image too Uniform ?3.1 Average Pixel Width 4. Colors : What are the top colors used in the Image ?4.1 Dominant Color of the Image    4.2 Average Color of the Image 5. Dimensions : Is the Image too Large or too Small ?5.1 Width of the Image    5.2 Height of the Image    5.3 Size of the Image 6. Blurrness : Is the Image Too Blurry ?6.1 Width of the Image;Apache 2.0;https://www.kaggle.com/shivamb/ideas-for-image-features-and-image-quality;1.0;['skimage'];['ner', 'ai', 'cv', 'ml', 'nn', 'ann'];['recognition', 'model', 'label', 'filter'];https://www.kaggle.com/c/avito-demand-prediction;0.775;0.571;2020-12-12 16:57:27;multiple data sources;['feature engineering, image data, computer vision'];Ideas for Image Features and Image Quality;Python notebook;21041.0;281;;
2018-04-27 14:54:57;About the Competition: Avito, Russia’s largest classified advertisements website, is hosting its fourth Kaggle competition. The challenge is to predict demand for an online advertisement based on its full description (title, description, images, etc.), its context (geographically where it was posted, similar ads already posted) and historical demand for similar ads in similar contexts. About the Notebook: One more exciting competition ahead and this involves both NLP (text data in Russian) and Image data along with numerical . In this notebook, let us get into the basic data exploration using python. Thanks to Yandex Translate, I was able to get english names for the russian names and used them whenever possible. Most of the plots are in plotly and so please hover over them to see more details.;Apache 2.0;https://www.kaggle.com/sudalairajkumar/simple-exploration-baseline-notebook-avito;1.0;['lightgbm', 'sklearn'];['ai', 'dl', 'gbm', 'rl', 'nlp', 'nn'];['test data', 'regression', 'train', 'model', 'label', 'predict', 'classification'];https://www.kaggle.com/c/avito-demand-prediction;0.785;0.594;2020-12-12 16:57:26;Avito Demand Prediction Challenge;[];Simple Exploration + Baseline Notebook - Avito;Python notebook;28059.0;403;0.23367;0.22992
2018-06-09 22:43:36;[Update] Image Classification Confidence and Deal ProbabilityMost publicly shared models show that the image_top_1 feature has one of the strongest signals in predicting deal probability.  Take a look at SRK, kxx and Bojan Tunguz among many others.  However, this is a black box feature to us.  We don't know how it was built to use it as a guide for building similar features.  I took a stab at trying image based features and found one that might work as well. If you viewed this kernel before, skip to the last section below for analysis of correlation between image classification confidence and deal probability. Image QualityIn this competition, the quality of the advertisement image significantly affects the demand volume on an item.  Let's extract the dataset image features and see if we can use it to help predict demand.  I found out that the image classification confidence highly correlates with the deal probability.  However, we have to keep in mind that:  Not all advertisements have images. Advertisements with images tend to have a higher deal probability.  Some code and sections of this notebook were adapted from:  https://www.kaggle.com/classtag/lightgbm-with-mean-encode-feature-0-233 https://keras.io/applications/#classify-imagenet-classes-with-resnet50  Image Classification with Deep LearningKeras provides pre-trained deep learning models that will save us days annotating, and training our models.  We will just load one that suits our needs and use it to classify our images.  The assumption here is that the image classification accuracy score will reflect how clear it is for a human to identify it, and affect the chance of buying it. Different exploratory data analyses [1, 2, 3] in this competition show high correlation between the image_top_1 feature and our target deal_probability.  So, we are proceeding in the right direction. We will start by preparing our workspace and copying the large pretrained model files to where Keras can find them.;Apache 2.0;https://www.kaggle.com/wesamelshamy/high-correlation-feature-image-classification-conf;1.0;['tensorflow', 'lightgbm', 'keras'];['ner', 'ai', 'gbm', 'ml', 'nn', 'ann'];['image classification', 'train', 'model', 'neural network', 'deep learning', 'vgg', 'label', 'predict', 'resnet', 'classification'];https://www.kaggle.com/c/avito-demand-prediction;0.754;0.523;2020-12-12 16:57:27;multiple data sources;['classification, image data, computer vision'];High Correlation Feature Image Classification Conf;Python notebook;11585.0;138;;
2020-01-04 07:21:31;Bengali.AI albumentations data augmentation tutorialFor CNN training, data augmentation is important to improve test accuracy (generalization performance). I will show some image preprocessing to increase the data variety. albumentations library, fast image augmentation library and easy to use wrapper around other libraries, can be used for many kinds of data augmentation. I will introduce several methods, especially useful for this competition. Reference  https://github.com/albumentations-team/albumentations https://arxiv.org/abs/1809.06839;Apache 2.0;https://www.kaggle.com/corochann/bengali-albumentations-data-augmentation-tutorial;1.0;['xgboost', 'lightgbm', 'catboost', 'sklearn', 'pytorch', 'albumentations'];['ner', 'ai', 'cnn', 'gbm', 'cv', 'nn', 'ml'];['train', 'model', 'deep learning', 'label', 'predict'];https://www.kaggle.com/c/bengaliai-cv19;0.744;0.503;2020-12-12 17:09:20;multiple data sources;['beginner, image data, computer vision'];Bengali: albumentations data augmentation tutorial;Python notebook;8799.0;105;;
2020-01-04 03:44:17;Bengali.AI SEResNeXt prediction with pytorchThis is a prediction notebook of the previous Bengali.AI SEResNeXt training with pytorch kernel. You can see dataset here:  bengaliaicv19_trainedmodels  bengaliaicv19_seresnext101_32x4d bengaliaicv19feather  Please upvote both dataset and this kernel if you like it! :) Update history 2020/1/4 v8: Added models to support ensemble prediction.;Apache 2.0;https://www.kaggle.com/corochann/bengali-seresnext-prediction-with-pytorch;1.0;['caffe', 'xgboost', 'lightgbm', 'catboost', 'sklearn', 'pytorch', 'skimage'];['ner', 'ai', 'cnn', 'gbm', 'cv', 'ml', 'nn', 'ann'];['train', 'model', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'resnet'];https://www.kaggle.com/c/bengaliai-cv19;0.772;0.565;2020-12-12 17:09:20;multiple data sources;['deep learning, classification, computer vision'];Bengali: SEResNeXt prediction with pytorch;Python notebook;19006.0;256;0.9162;0.9663
2020-01-04 07:34:01;Bengali.AI SEResNeXt training with pytorchI will introduce following contents  Fast data loading with feather format Data augmentation technic with affine transformation CNN SoTA models: Use pytorch pretrainedmodels library, especially I use SEResNeXt in this notebook Training code abstraction: Use pytorch-ignite module for the trainining abstraction  Update history 2020/1/4 v2: Added albumentations augmentations introduced in Bengali: albumentations data augmentation tutorial;Apache 2.0;https://www.kaggle.com/corochann/bengali-seresnext-training-with-pytorch;1.0;['caffe', 'xgboost', 'lightgbm', 'catboost', 'sklearn', 'pytorch', 'albumentations', 'skimage'];['ner', 'ai', 'dl', 'cnn', 'gbm', 'cv', 'ml', 'nn', 'ann'];['training data', 'train', 'fitting', 'model', 'epoch', 'deep learning', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'resnet', 'classification'];https://www.kaggle.com/c/bengaliai-cv19;0.768;0.576;2020-12-12 17:09:20;multiple data sources;['beginner, data visualization, deep learning, +1 morecnn'];Bengali: SEResNeXt training with pytorch;Python notebook;17094.0;306;;
2020-02-10 05:55:59;An Implementation of Augmix Based on albumentationsHi, here is my implementation of Augmix augmentation based on albumentations. If you find it helpful please upvote me. Thanks!  Augmix: https://arxiv.org/abs/1912.02781 Official implementation: https://github.com/google-research/augmix albumentations： https://github.com/albumentations-team/albumentations Notice: I didn't normalize images in my implementation : https://github.com/google-research/augmix/blob/master/augment_and_mix.py#L25-L30;Apache 2.0;https://www.kaggle.com/haqishen/augmix-based-on-albumentations;1.0;['albumentations'];['ai', 'cv', 'rl', 'ml', 'nn', 'ann'];['train', 'label'];https://www.kaggle.com/c/bengaliai-cv19;0.717;0.5;2020-12-12 17:09:20;Bengali.AI Handwritten Grapheme Classification;[];AugMix based on albumentations;Python notebook;4546.0;101;;
2020-01-30 03:36:03;An Implementation of GridMask Based on albumentationsHi, here is my implementation of GridMask augmentation based on albumentations. If you find it helpful please upvote me. Thanks! GridMask: https://arxiv.org/abs/2001.04086  albumentations： https://github.com/albumentations-team/albumentations;Apache 2.0;https://www.kaggle.com/haqishen/gridmask;1.0;['albumentations'];['ai', 'cv'];['image classification', 'object detection', 'train', 'label', 'classification'];https://www.kaggle.com/c/bengaliai-cv19;0.732;0.54;2020-12-12 17:09:20;Bengali.AI Handwritten Grapheme Classification;[];GridMask;Python notebook;6433.0;175;;
2019-12-31 20:55:41;DescriptionGreetings, this kernel provides fast.ai starter code for Bengali.AI Handwritten Grapheme Classification competition. The task proposed in this competition is recognition of handwritten Bengali letters. In contrast to similar competitions such as mnist digit recognition or the recent Kannada MNIST, Bengali alphabet is quite complex and may include ~13,000 different grapheme variations. Fortunately, each grapheme can be decomposed into 3 parts: grapheme_root, vowel_diacritic, and consonant_diacritic (168, 11, and 7 independent classes, respectively). Therefore, the task of grapheme recognition is significantly simplified in comparison with 13k-way classification. Though, additional consideration may be required for this multitask classification, like checking if 3 independent models, or a single model one head, or a single model with 3 heads (this kernel) works the best. This kernel is mostly based on my findings in a recent Kannada MNIST toy competition. In addition to this kernel I have prepared a code for data preprocessing and generation of cropped images rescaled to 128x128. Because the data has much higher resolution than MNIST or CIFAR, the things that work there may be less applicable to this data, while ImageNet based solutions should be more suitable. So, I've choosen DenseNet121 as a starter network. In addition to this kernel I will prepare a submission kernel posted separately.;Apache 2.0;https://www.kaggle.com/iafoss/grapheme-fast-ai-starter-lb-0-964;1.0;['pytorch', 'sklearn'];['ner', 'ai', 'cv', 'nn', 'ann'];['filter', 'generation', 'train', 'recognition', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/bengaliai-cv19;0.765;0.547;2020-12-12 17:09:20;multiple data sources;['gpu, deep learning, classification'];Grapheme fast.ai starter;Python notebook;15775.0;195;;
2020-02-29 02:26:04;Update  Training again with different distributed samples (Stratify) Basic Ensebling (2 models : EfficientNet B0 + DenseNet169)  In this version, I set 70% randomness on the GridMask augmentation than AugMix.The ensemble is the basic averaging ensemble on the two models: EfficientNet B0 (LB: 95.77) and DenseNet169 (LB: 95.84). It just a quick prototype implementation. These models were trained for few epochs, and they can be greatly improved. Good Luck.  If this kernel helps you, please upvote to keep me motivated. Thank you.;Apache 2.0;https://www.kaggle.com/ipythonx/keras-grapheme-gridmask-augmix-ensemble;1.0;['sklearn', 'pillow', 'albumentations', 'tensorflow', 'keras'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'ml', 'nlp', 'nn', 'ann'];['image classification', 'filter', 'test data', 'object detection', 'train', 'fitting', 'model', 'epoch', 'deep learning', 'layer', 'relu', 'loss', 'label', 'predict', 'computer vision', 'classification'];https://www.kaggle.com/c/bengaliai-cv19;0.735;0.479;2020-12-12 17:09:20;multiple data sources;['gpu, beginner, deep learning, +1 moreclassification'];[Keras]:Grapheme GridMask+AugMix & Ensemble;Python notebook;6998.0;76;0.9114;0.9625
2020-01-22 09:10:21;Exploratory Data AnalysisExploratory data analysis (EDA) is an approach to analyzing data sets to summarize their main characteristics, often with visual methods.;Apache 2.0;https://www.kaggle.com/kaushal2896/bengali-graphemes-starter-eda-multi-output-cnn;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cnn', 'cv', 'ml', 'nn', 'ann'];['filter', 'training data', 'test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/bengaliai-cv19;0.794;0.603;2020-12-12 17:09:20;multiple data sources;['gpu'];Bengali Graphemes: Starter EDA+ Multi Output CNN;Python notebook;37914.0;474;0.8866;0.9506
2019-12-24 20:27:02;ResNet-34 PyTorch Starter Kit Updates: added result for training with 400 epochs     References (ResNet): https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py https://arxiv.org/pdf/1512.03385.pdf     Acknowledgements: Original kernels: https://www.kaggle.com/hanjoonchoe/grapheme-resnet-18-n-l-inference-lb-0-8566 and https://www.kaggle.com/hanjoonchoe/grapheme-resnet-18-naive-learning-3     Kindly upvote the kernel if you found it helpful, including the original author's!;Apache 2.0;https://www.kaggle.com/khoongweihao/resnet-34-pytorch-starter-kit;1.0;['pytorch'];['ai', 'dl', 'cnn', 'cv', 'ml', 'nn', 'ann'];['predict', 'train', 'model', 'epoch', 'label', 'loss', 'relu', 'resnet'];https://www.kaggle.com/c/bengaliai-cv19;0.736;0.515;2020-12-12 17:09:20;multiple data sources;['gpu, beginner, deep learning, +1 moreclassification'];ResNet-34 PyTorch Starter Kit;Python notebook;7199.0;124;0.8753;0.9289
2020-02-17 11:00:54;Simple step by step approach with efficientnet for Bengali AI competition . If its useful for you please upvote .;Apache 2.0;https://www.kaggle.com/phoenix9032/pytorch-efficientnet-starter-code;1.0;['pytorch', 'albumentations', 'tensorflow', 'sklearn'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'training data', 'test data', 'generation', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'activation function', 'rank', 'classification'];https://www.kaggle.com/c/bengaliai-cv19;0.747;0.505;2020-12-12 17:09:20;multiple data sources;['gpu'];Pytorch Efficientnet Starter Code ;Python notebook;9655.0;107;;
2020-02-26 07:28:50;This competition provides a lot of room for interresting experimentations. In this kernel I use a rather easy way to train a standard EfficientNet B3 model with a custom head layer and Generalized mean pool. I use only basic image preprocessing with a scaling factor. To save on training time I use a different training set on each epoch. This gives a nice boost of about 0.005 to 0.008 compared to a fixed training set when using train/test split or cross-validation. The downside is that the validation has some less value. This kernel contains the inference part where I use 3 models from the training. For the complete code to train it yourself you can download it from my github. I trained it for 80 epochs on my 1070 Ti (roughly 1,5 days). I hope you like it and if you find this kernel helpfull..then please don't forget to upvote it.;Apache 2.0;https://www.kaggle.com/rsmits/keras-efficientnet-b3-training-inference;1.0;['tensorflow', 'keras', 'pillow'];['ner', 'ai', 'cv', 'nn', 'ann'];['generation', 'train', 'model', 'input layer', 'epoch', 'layer', 'predict'];https://www.kaggle.com/c/bengaliai-cv19;0.769;0.532;2020-12-12 17:09:20;multiple data sources;['deep learning, classification, computer vision'];Keras EfficientNet B3 Training + Inference;Python notebook;17394.0;156;0.9182;0.9703
2019-09-23 18:16:47;"Forked from : https://www.kaggle.com/pulkitmehtawork1985/beating-benchmark Copies feature code over from my other kernel; https://www.kaggle.com/danofer/basic-features-geotab-intersections  V6 - try  a multitask model in addition to a model per target. Likely to have worse performance, but will be faster";Apache 2.0;https://www.kaggle.com/danofer/baseline-feature-engineering-geotab-69-5-lb;1.0;['xgboost', 'sklearn'];['dl', 'ai', 'nn', 'cv'];['test data', 'regression', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/bigquery-geotab-intersection-congestion;0.671;0.357;2020-12-12 17:10:49;BigQuery-Geotab Intersection Congestion;['feature engineering, geospatial analysis'];Baseline + Feature Engineering Geotab [69.5 LB];Python notebook;1663.0;18;68.791341;70.561742
2019-10-15 18:19:41;Acknowledgements D C Aichara:  https://www.kaggle.com/dcaichara/feature-engineering-and-lightgbm Dan Ofer: https://www.kaggle.com/danofer/baseline-feature-engineering-geotab-69-5-lb Fatih Bilgin: https://www.kaggle.com/fatihbilgin/data-visualization-and-eda-for-geotab-bigquery Leonardo Ferreira: https://www.kaggle.com/kabure/insightful-eda-modeling-lgbm-hyperopt John Miller: https://www.kaggle.com/jpmiller/eda-to-break-through-rmse-68 Bojan Tunguz: https://www.kaggle.com/tunguz/adversarial-geotab Bruno Gorresen Mello: https://www.kaggle.com/bgmello/how-one-percentile-affect-the-others;Apache 2.0;https://www.kaggle.com/gaborfodor/0-feature-extraction;1.0;['lightgbm', 'sklearn'];['ai', 'gbm'];['train', 'model', 'label'];https://www.kaggle.com/c/bigquery-geotab-intersection-congestion;0.642;0.346;2020-12-12 17:10:49;BigQuery-Geotab Intersection Congestion;[];0 Feature Extraction 🚦🚗;Python notebook;936.0;16;;
2019-09-15 23:50:29;Heads up, IntersectionId is Non-unique! (shared between cities);Apache 2.0;https://www.kaggle.com/janlauge/intersection-congestion-eda;1.0;['pattern'];['ai', 'dl'];['train', 'filter'];https://www.kaggle.com/c/bigquery-geotab-intersection-congestion;0.64;0.367;2020-12-12 17:10:49;BigQuery-Geotab Intersection Congestion;['data visualization, exploratory data analysis'];Intersection Congestion EDA;R notebook;915.0;20;;
2019-10-10 01:32:50;Welcome to my EDA KernelDescription:The dataset for this competition includes aggregate stopped vehicle information and intersection wait times. Your task is to predict congestion, based on an aggregate measure of stopping distance and waiting times, at intersections in 4 major US cities: Atlanta, Boston, Chicago & Philadelphia.;Apache 2.0;https://www.kaggle.com/kabure/insightful-eda-modeling-lgbm-hyperopt;1.0;['pattern', 'catboost', 'lightgbm', 'sklearn'];['ner', 'ai', 'gbm', 'rl', 'nn', 'ann'];['regression', 'train', 'model', 'loss', 'label', 'predict', 'understanding'];https://www.kaggle.com/c/bigquery-geotab-intersection-congestion;0.753;0.549;2020-12-12 17:10:48;BigQuery-Geotab Intersection Congestion;['beginner, data visualization, exploratory data analysis, +1 moredeep learning'];Insightful EDA + modeling LGBM hyperopt;Python notebook;11068.0;202;66.341865;69.263090
2019-09-23 20:02:39;Objective :We’ve all been there: Stuck at a traffic light, only to be given mere seconds to pass through an intersection, behind a parade of other commuters. Imagine if you could help city planners and governments anticipate traffic hot spots ahead of time and reduce the stop-and-go stress of millions of commuters like you. The task here is to predict congestion, based on an aggregate measure of stopping distance and waiting times, at intersections in 4 major US cities: Atlanta, Boston, Chicago & Philadelphia. About the dataThe data consists of aggregated trip logging metrics from commercial vehicles, such as semi-trucks. The data have been grouped by :  intersection month hour of day direction driven through the intersection whether the day was on a weekend or not  For each grouping in the test set, you need to make predictions for three different quantiles, that is, 20th, 50th, and 80th percentiles for:  The total time stopped at an intersection  The distance between the intersection and the first place a vehicle stopped while waiting.;Apache 2.0;https://www.kaggle.com/prazhant/predicting-wait-times-at-intersections;1.0;['h2o', 'xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'dl', 'automl', 'gbm', 'cv', 'rl', 'ml', 'nn', 'ann'];['test data', 'regression', 'train', 'model', 'label', 'predict', 'bayesian'];https://www.kaggle.com/c/bigquery-geotab-intersection-congestion;0.646;0.352;2020-12-12 17:10:49;BigQuery-Geotab Intersection Congestion;[];Predicting Wait times at intersections;Python notebook;1006.0;17;;
2019-09-13 18:31:45;Approach: We will make 6 predictions based on features - IntersectionId , Hour , Weekend , Month , entry & exit directions .Target variables will be TotalTimeStopped_p20 ,TotalTimeStopped_p50,TotalTimeStopped_p80,DistanceToFirstStop_p20,DistanceToFirstStop_p50,DistanceToFirstStop_p80 .;Apache 2.0;https://www.kaggle.com/pulkitmehtawork1985/beating-benchmark;1.0;['tensorflow', 'sklearn'];['ai', 'nn'];['train', 'model', 'regression', 'predict'];https://www.kaggle.com/c/bigquery-geotab-intersection-congestion;0.655;0.397;2020-12-12 17:10:49;BigQuery-Geotab Intersection Congestion;[];Beating BenchMark;Python notebook;1205.0;28;78.107406;80.210527
2019-10-17 00:38:50;ObjectivePast model link: https://www.kaggle.com/ragnar123/eda-feature-engineer-and-baseline-lgbm (need more work (feature engineering, feature selection etc...) This time, we will make the same model but, we are going to use a forward feature engineering tecnique to make the feature selection part.;Apache 2.0;https://www.kaggle.com/ragnar123/feature-engineering-and-forward-feature-selection;1.0;['xgboost', 'sklearn', 'lightgbm'];['ai', 'gbm', 'cv', 'rl', 'nn'];['filter', 'regression', 'train', 'model', 'label', 'predict', 'bayesian'];https://www.kaggle.com/c/bigquery-geotab-intersection-congestion;0.673;0.397;2020-12-12 17:10:49;BigQuery-Geotab Intersection Congestion;[];Feature engineering and forward feature selection;Python notebook;1710.0;28;62.456806;63.648879
2019-10-17 15:20:36;Google BigQueryBigQuery is a popular data warehouse solution from Google. Its serverless architecture makes it highly scalable with very little effort. The serverless architecture allows end user to purely focus on the individual functions in the code. In Google BigQuery end user does not have to worry about the underlying hardware, virtual machine, and number of nodes or instances etc. The user simply writes an SQL query and executes it. BigQuery’s execution algorithm analyzes the necessary resources needed to execute the query as fast as possible, provisions the resources, performs the query execution, and releases the resources.;Apache 2.0;https://www.kaggle.com/sanikamal/bqml-predict-wait-times;1.0;['tensorflow'];['ner', 'ai', 'dl', 'rl', 'ml'];['machine learning', 'regression', 'train', 'model', 'clustering', 'loss', 'label', 'k-means', 'logistic regression', 'predict', 'linear regression', 'classification'];https://www.kaggle.com/c/bigquery-geotab-intersection-congestion;0.647;0.327;2020-12-12 17:10:49;BigQuery-Geotab Intersection Congestion;[];BQML : Predict Wait Times;Python notebook;1037.0;13;91.382338;94.461273
2019-09-16 19:49:32;This kernel is a forked from BigQuery Machine Learning Tutorial and serves as a starting point for the BigQuery-Geotab Intersection Congestion competition.;Apache 2.0;https://www.kaggle.com/sirtorry/bigquery-ml-template-intersection-congestion;1.0;['tensorflow'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['machine learning', 'training data', 'regression', 'train', 'fitting', 'model', 'gradient descent', 'loss', 'label', 'k-means', 'clustering', 'logistic regression', 'predict', 'linear regression'];https://www.kaggle.com/c/bigquery-geotab-intersection-congestion;0.728;0.46;2020-12-12 17:10:49;BigQuery-Geotab Intersection Congestion;[];BigQuery ML Template (Intersection Congestion);Python notebook;5945.0;60;;
2019-09-14 17:36:36;Explanation This kernel is using BQML Code Train 6 model and Predict 6 model Reference : BigQuery ML Template (Intersection Congestion);Apache 2.0;https://www.kaggle.com/snugyun01/bigqueryml-starter-code;1.0;['tensorflow'];['ai', 'nn', 'ml'];['predict', 'train', 'model', 'label', 'loss'];https://www.kaggle.com/c/bigquery-geotab-intersection-congestion;0.646;0.352;2020-12-12 17:10:49;BigQuery-Geotab Intersection Congestion;[];BigQueryML Starter Code;Python notebook;1016.0;17;;
2019-09-17 15:18:15;"Adverserial validation scrip. Based entirely on features from: https://www.kaggle.com/danofer/baseline-feature-engineering-geotab-69-5-lb Which was forked from : https://www.kaggle.com/pulkitmehtawork1985/beating-benchmark Copies feature code over from Dan's other kernel; https://www.kaggle.com/danofer/basic-features-geotab-intersections  If you find this notebook useful, please upvote the obove other notebooks as well.";Apache 2.0;https://www.kaggle.com/tunguz/adversarial-geotab;1.0;['xgboost', 'sklearn', 'lightgbm'];['ai', 'rl', 'nn', 'gbm'];['train', 'model', 'label', 'filter'];https://www.kaggle.com/c/bigquery-geotab-intersection-congestion;0.627;0.334;2020-12-12 17:10:49;multiple data sources;[];Adversarial Geotab;Python notebook;721.0;14;;
2019-10-12 08:17:46;About This KernelThis verbosity tries to explain everything I could know. Once you get through the notebook, you can find this useful and straightforward. I attempted to explain things as simple as possible. We are going to learn about the data and get ideas for feature engineering and modeling.;Apache 2.0;https://www.kaggle.com/vikassingh1996/thoughtful-eda-feature-engineering-and-lightgbm;1.0;['catboost', 'xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'nn', 'ml'];['filter', 'test data', 'regression', 'train', 'model', 'label', 'predict', 'bayesian'];https://www.kaggle.com/c/bigquery-geotab-intersection-congestion;0.662;0.371;2020-12-12 17:10:49;BigQuery-Geotab Intersection Congestion;['exploratory data analysis, classification, feature engineering, +1 moredata cleaning'];Thoughtful EDA+ Feature Engineering and LightGBM;Python notebook;1370.0;21;66.302228;68.842725
2020-11-17 10:27:21;During the lockdown I published my first book titled Inspiration:Thoughts on Spirituality,Technology,Wealth,Leadership and Motivation.The preview of the book can be read from the Amazon link https://lnkd.in/gj7bMQAE Book is availabe for Rs 99 in India.Paperback Edition of the book is available on Amazon.com link https://lnkd.in/gkFYYMJToday we live in era of Sharing Economy.The biggest company like Amazon,Airbnb,Uber,Swiggy etc dont own much physical assets.But they are using software to optimize the use of the assets available.In this kernel we will be covering following topics. 1.Importing,Analysis and Vizualization of Data 2.Checking Multi Linear Regression Assumptions like -Normality -Linear Correlation -Multicollinearity -Autocorrelation -Sample Size 3.Drop Irrevalent features 4.Creating and Modifying features 5.Create Dummy Variables 6.Train Test Split 7.Fit and Score Model 8.Present the Results If you like the kernel please do vote.;Apache 2.0;https://www.kaggle.com/biphili/we-live-in-era-of-sharing-economy;1.0;['sklearn'];['ai', 'nn', 'rl'];['regression', 'train', 'fitting', 'model', 'label', 'predict', 'linear regression'];https://www.kaggle.com/c/bike-sharing-demand;0.626;0.397;2020-12-12 17:15:12;Bike Sharing Demand;[];We Live in Era Of Sharing Economy;Python notebook;698.0;28;;
2020-09-04 10:26:28;"Bike SharingOn this notebook, we will try to predict number of total rental using machine learning algorithms. Before this one, we will do feature engineering and exploratory data analysis for examine the data. Let's explore the data.  datetime - hourly date + timestamp   season -  1 = spring, 2 = summer, 3 = fall, 4 = winter  holiday - whether the day is considered a holiday workingday - whether the day is neither a weekend nor holiday weather - 1: Clear, Few clouds, Partly cloudy, Partly cloudy  2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist  3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds  4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog  temp - temperature in Celsius atemp - ""feels like"" temperature in Celsius humidity - relative humidity windspeed - wind speed casual - number of non-registered user rentals initiated registered - number of registered user rentals initiated count - number of total rentals";Apache 2.0;https://www.kaggle.com/fatmakursun/bike-sharing-feature-engineering;1.0;['sklearn'];['ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['machine learning', 'test data', 'regression', 'train', 'model', 'label', 'predict', 'decision tree', 'random forest'];https://www.kaggle.com/c/bike-sharing-demand;0.717;0.379;2020-12-12 17:15:12;Bike Sharing Demand;['data visualization, exploratory data analysis, feature engineering, +2 moredata cleaning, random forest'];Bike Sharing(Feature Engineering);Python notebook;4536.0;23;;
2018-11-21 22:20:17;"Data Fieldsdatetime: hourly date + timestamp season: 1 = spring, 2 = summer, 3 = fall, 4 = winter holiday: whether the day is considered a holiday workingday: whether the day is neither a weekend nor holiday weather: 1: Clear, Few clouds, Partly cloudy, Partly cloudy 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog temp: temperature in Celsius atemp: ""feels like"" temperature in Celsius humidity: relative humidity windspeed: wind speed casual: number of non-registered user rentals initiated registered: number of registered user rentals initiated count: number of total rentals";Apache 2.0;https://www.kaggle.com/fredkron/eda-ml-on-bike-sharing;1.0;['xgboost', 'sklearn'];['ai', 'dl', 'gbm', 'cv', 'rl', 'nn', 'ann'];['regression', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/bike-sharing-demand;0.704;0.311;2020-12-12 17:15:12;Bike Sharing Demand;[];EDA & ML on bike-sharing;Python notebook;3376.0;11;0.40231;0.40231
2019-10-07 20:49:39;I am super excited to share my first kernel with the Kaggle community. This kernel is for all the aspiring data scientists who wants to learn and review their knowledge. As I go on in this journey and learn new topics, I will incorporate them with each new updates. Going back to the topics of this kernel, I will do visualizations to explain the data, and machine learning algorithms to forecast bike rental demand  in the Capital Bikeshare program in Washington, D.C.;Apache 2.0;https://www.kaggle.com/hanifansari93/bike-sharing-demand-eda-modeling;1.0;['pattern', 'sklearn'];['ai', 'nn', 'ann', 'rl'];['machine learning', 'regression', 'train', 'model', 'label', 'predict', 'linear regression', 'random forest'];https://www.kaggle.com/c/bike-sharing-demand;0.673;0.311;2020-12-12 17:15:12;Bike Sharing Demand;[];Bike Sharing Demand: EDA + Regression;Python notebook;1722.0;11;0.46010;0.46010
2019-05-19 04:46:18;ReferenceVivek Srinivasan's EDA & Ensemble Model (Top 10 Percentile) https://www.kaggle.com/viveksrinivasan/eda-ensemble-model-top-10-percentile;Apache 2.0;https://www.kaggle.com/kwonyoung234/for-beginner;1.0;['sklearn'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'regression', 'train', 'model', 'label', 'predict', 'rank', 'linear regression', 'random forest'];https://www.kaggle.com/c/bike-sharing-demand;0.756;0.416;2020-12-12 17:15:12;Bike Sharing Demand;['beginner, data visualization, data cleaning'];데이터 전처리에 집중한 자전거 수요예측하기 (for beginner) ;Python notebook;12270.0;35;;
2017-11-16 16:11:44;We cannot think of any strong evidence to get rid of outlier data. As per Chebychev's rule, 3 std. deviations account for 99% of data. Using this approach, we filter out the rest of the data.;Apache 2.0;https://www.kaggle.com/miteshyadav/comprehensive-eda-with-xgboost-top-10-percentile;1.0;['pattern', 'xgboost', 'sklearn'];['ai', 'rl', 'cv', 'nn', 'ann'];['linear regression', 'filter', 'training data', 'regression', 'test data', 'train', 'model', 'label', 'predict', 'decision tree'];https://www.kaggle.com/c/bike-sharing-demand;0.754;0.418;2020-12-12 17:15:12;Bike Sharing Demand;[];Comprehensive EDA with XGBoost (Top 10 percentile);Python notebook;11539.0;36;;
2018-10-03 17:44:24;BIKE SHARING DEMAND [ RMSLE:: 0.3194];Apache 2.0;https://www.kaggle.com/rajmehra03/bike-sharing-demand-rmsle-0-3194;1.0;['sklearn'];['ai', 'cv', 'rl', 'nn', 'rnn', 'ann'];['filter', 'random forest', 'regression', 'train', 'model', 'predict', 'linear regression', 'classification'];https://www.kaggle.com/c/bike-sharing-demand;0.789;0.542;2020-12-12 17:15:12;Bike Sharing Demand;['beginner, exploratory data analysis, feature engineering, +1 moreregression'];BIKE SHARING DEMAND [ RMSLE:: 0.3194];Python notebook;32401.0;182;;
2017-04-23 06:54:23;This notebook explains how we can go about explore and prepare data for model building.The notebook is structured in the following way  About Dataset Data Summary Feature Engineering Missing Value Analysis Outlier Analysis Correlation Analysis Visualizing Distribution Of Data Visualizing Count Vs (Month,Season,Hour,Weekday,Usertype) Filling 0's In Windspeed Using Random Forest Linear Regression Model Regularization Models Ensemble Models;Apache 2.0;https://www.kaggle.com/viveksrinivasan/eda-ensemble-model-top-10-percentile;1.0;['pattern', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'nn', 'ann'];['filter', 'machine learning', 'regression', 'test data', 'train', 'fitting', 'model', 'label', 'logistic regression', 'predict', 'linear regression', 'random forest'];https://www.kaggle.com/c/bike-sharing-demand;0.818;0.601;2020-12-12 17:15:12;Bike Sharing Demand;[];EDA & Ensemble Model (Top 10 Percentile) ;Python notebook;86186.0;459;;
2017-01-10 17:07:33;Submissions are evaluated one the Root Mean Squared Logarithmic Error (RMSLE) so lets define it. Also we are using common mean absolute error;Apache 2.0;https://www.kaggle.com/yaroshevskiy/bike-rental-predictions-using-lr-rf-gbr;1.0;['sklearn'];['ai', 'dl', 'cv'];['filter', 'train', 'fitting', 'model', 'label', 'predict', 'random forest'];https://www.kaggle.com/c/bike-sharing-demand;0.726;0.311;2020-12-12 17:15:12;Bike Sharing Demand;[];Bike rental predictions using LR, RF, GBR;Python notebook;5537.0;11;1.04749;1.04749
2019-03-08 20:42:25;This is my training kernel from my lesson on Stepik. I changed it a little bit. the result is very bad in the competition;Apache 2.0;https://www.kaggle.com/zmey56/my-learning-kernel;1.0;['sklearn'];['ai', 'cv'];['train', 'model', 'label', 'predict'];https://www.kaggle.com/c/bioresponse;0.649;0.253;2020-12-12 17:15:59;Predicting a Biological Response;['beginner'];My learning kernel;Python notebook;1079.0;6;6.68322;6.68679
2020-08-13 10:21:00;🦉Cornell BirdSong Recognition🦉1. IntroductionFinally, some cutie cute competition involving animals, sounds, nature, earth and all that goodness 🌍💚. This is a very new different challenge for me, and not just because it's mainly based on audio files, but because the rules are a bit different than what I'm used to. When I joined, I had (still have) some very big issues in understanding not only the rules of submission, but also the data and ... what all means? So, as I go along I will try to bring some clear understanding and also point to some fruitful discussions. Ok, here we go! 🦅 Libraries 📚⬇;Apache 2.0;https://www.kaggle.com/andradaolteanu/birdcall-recognition-eda-and-audio-fe;1.0;['sklearn'];['ner', 'ai', 'dl', 'rl', 'nn', 'ann'];['filter', 'test data', 'train', 'recognition', 'understanding', 'label', 'predict', 'recommend', 'labeled'];https://www.kaggle.com/c/birdsong-recognition;0.768;0.61;2020-12-12 17:18:48;multiple data sources;['data visualization, exploratory data analysis, feature engineering, +1 moreaudio data'];🦉Birdcall Recognition: EDA and Audio FE;Python notebook;16755.0;533;;
2020-06-22 18:02:35;UpdateBug found: I intended to use the whole clip of site_3, but I found that current implementation only uses the last 5 seconds. This version (v3) fixes that.;Apache 2.0;https://www.kaggle.com/hidehisaarai1213/inference-pytorch-birdcall-resnet-baseline;1.0;['sklearn'];['ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'train', 'recognition', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'resnet', 'classification'];https://www.kaggle.com/c/birdsong-recognition;0.775;0.59;2020-12-12 17:18:49;multiple data sources;['beginner, deep learning'];[inference, PyTorch] Birdcall ResNet Baseline;Python notebook;20855.0;380;;
2020-08-13 12:05:23;"Feel free to comment any suggestions or criticism you might have. Please refer to the table of contents below for structural navigation.Upvote and share if you find the notebook useful! Thank you :)Table of contents: Intro Exploring the training data Analysis of ""Relevant Fields"" ebird location recordist   Audio Representation Waveform or PCM Spectrogram   Audio Feature Extraction Spectral Centroid Spectral Roll-off Spectral Bandwidth Spectral Flux Spectral Contrast Spectral Flatness Zero-crossing rate Autocorrelation Fundamental Frequency Tempo Estimation   Mel-Frequency Cepstral Coefficients Chromogram   References Further Readings   Introduction Bird vocalization includes both bird calls and bird songs. In non-technical use, bird songs are the bird sounds that are melodious to the human ear. The distinction between songs and calls is based upon complexity, length, and context. Songs are longer and more complex and are associated with territory and courtship and mating, while calls tend to serve such functions as alarms or keeping members of a flock in contact.  Song is usually delivered from prominent perches, although some species may sing when flying (we find such recordings in the training data).  Purpose behind calls & songs:  One of the two main functions of bird song is mate attraction. Experiments also suggest that parasites and diseases may directly affect song characteristics such as song rate, which thereby act as reliable indicators of health. Therefore, a female bird may select males based on the quality of their songs and the size of their song repertoire.    The second principal function of bird song is territory defense. Territorial birds will interact with each other using song to negotiate territory boundaries. Since song may be a reliable indicator of quality, individuals may be able to discern the quality of rivals and prevent an energetically costly fight. Song complexity is also linked to male territorial defense, with more complex songs being perceived as a greater territorial threat.  Communication through bird calls can be between individuals of the same species or even across species. Birds communicate alarm through vocalizations and movements that are specific to the threat, and bird alarms can be understood by other animal species, including other birds, in order to identify and protect against the specific threat. Many birds engage in duet calls. In some cases, the duets are so perfectly timed as to appear almost as one call(something we need to keep in mind while working on the data).";Apache 2.0;https://www.kaggle.com/navinmundhra/birdcall-starter-tablular-image-data;1.0;['pattern', 'sklearn'];['ner', 'ai', 'nlu', 'dl', 'gan', 'rl', 'ml', 'nn', 'ann'];['filter', 'training data', 'generation', 'train', 'recognition', 'deep learning', 'label', 'predict', 'understanding', 'classification', 'labeled'];https://www.kaggle.com/c/birdsong-recognition;0.678;0.47;2020-12-12 17:18:50;Cornell Birdcall Identification;['feature engineering, audio data'];Birdcall Starter: Tablular+Image data;Python notebook;1898.0;68;;
2020-07-02 13:11:13;"Improving the accuracy of soundscape analyses.ObjectiveIt is often easier to hear birds than see them. With proper sound detection and classification, researchers could automatically intuit factors about an area’s quality of life based on a changing bird population.The objective of the competition as stated on the competitions page is to identify a wide variety of bird vocalizations in soundscape recordings. However, the recordings are complex and may contain anthropogenic sounds (e.g., airplane overflights) or other bird and non-bird (e.g., chipmunk) calls in the background, with a particular labeled bird species in the foreground. Understanding the Evaluation MetricThe metric in this competition is the row-wise micro averaged F1 score.The F1 score or F measure, is a measure of a test’s accuracy. The F score is defined as the weighted harmonic mean of the test’s precision and recall.  DataFollowing files have been provided to the participants:  train_audio : Trainign data consisting of short recordings train_csv : metadata for training data test_audio : The hidden test set audio consists of approximately 150 recordings in mp3 format, each                       roughly 10 minutes long.  test_audio.csv : metadata for test set.It is important to note that only the first three rows are available for download; the full test.csv is in the hidden test set.  Exploring the Training metadataTo begin with let's explore the training metadata file to gather some information";Apache 2.0;https://www.kaggle.com/parulpandey/eda-and-audio-processing-with-python;1.0;['sklearn'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nn', 'ann'];['filter', 'training data', 'train', 'recognition', 'model', 'label', 'understanding', 'classification', 'labeled'];https://www.kaggle.com/c/birdsong-recognition;0.738;0.553;2020-12-12 17:18:49;multiple data sources;['beginner, audio data'];EDA and Audio Processing with Python;Python notebook;7507.0;214;;
2020-06-23 12:31:38;Table of Contents   Introduction  Exploratory Data Analysis  Importing Libraries Load Bird Species Dataset Bird Species Analysis Recordings by geographical location Samples by Country Samples by Date Birds Seen Pitch Sampling Rate Volume Channels Recordists Ratings Bird seen by Country   Audio Data analysis  Playing audio Visualizing audio in 2D Spectrogram analysis   Feature Extraction  Spectral Centroid Spectral Bandwidth Spectral Rolloff Zero-Crossing Rate Mel-Frequency Cepstral Coefficients(MFCCs) Chroma feature   Compare sound features;Apache 2.0;https://www.kaggle.com/pavansanagapati/birds-sounds-eda-spotify-urban-sound-eda;1.0;['vocabulary', 'sklearn', 'pillow', 'tensorflow', 'pattern', 'keras'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nn', 'ann'];['speech recognition', 'filter', 'machine learning', 'training data', 'train', 'recognition', 'model', 'understanding', 'reward', 'deep learning', 'layer', 'label', 'predict', 'relu', 'recommend', 'classification', 'labeled'];https://www.kaggle.com/c/birdsong-recognition;0.774;0.547;2020-12-12 17:18:49;multiple data sources;['deep learning, classification, cnn, +1 moreneural networks'];Birds Sounds EDA | Spotify & Urban Sound EDA;Python notebook;20090.0;196;;
2020-07-08 07:12:21;ObjectiveIn this competition the researchers from Cornell Lab of Ornithology’s Center for Conservation Bioacoustics (CBC) wants the kaggle community to help them build an AI solution to identify bird species using their bird call audio.Birds are excellent indicators of deteriorating habitat quality and environmental pollution.If successful, your work will help researchers better understand changes in habitat quality, levels of pollution, and the effectiveness of restoration efforts.;Apache 2.0;https://www.kaggle.com/shahules/bird-watch-complete-eda-fe;1.0;['sklearn'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['filter', 'train', 'recognition', 'model', 'label'];https://www.kaggle.com/c/birdsong-recognition;0.691;0.496;2020-12-12 17:18:49;Cornell Birdcall Identification;['exploratory data analysis, feature engineering, audio data'];Bird Watch : Complete EDA & FE;Python notebook;2536.0;95;;
2020-07-02 08:37:03;Competition MetricsHi everyone! I would like to share with you my metrics implementations for this competition. I think correct calculating metrics is very important! If you find any imprecision in calculating metrics, please, let me know!;Apache 2.0;https://www.kaggle.com/shonenkov/competition-metrics;1.0;['sklearn'];['dl'];['model', 'label', 'predict'];https://www.kaggle.com/c/birdsong-recognition;0.688;0.481;2020-12-12 17:18:49;Cornell Birdcall Identification;[];[Competition Metrics];Python notebook;2351.0;78;;
2020-06-05 15:42:08;All the remarks and comment are welcome. Thank you....;Apache 2.0;https://www.kaggle.com/adamamoussasamake/eda-ml-models-feedforward-neural-network;1.0;['xgboost', 'sklearn', 'tensorflow', 'pattern', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['training data', 'test data', 'regression', 'train', 'fitting', 'model', 'understanding', 'neural network', 'epoch', 'validation data', 'layer', 'loss', 'label', 'predict', 'relu', 'decision tree'];https://www.kaggle.com/c/bluebook-for-bulldozers;0.532;0.152;2020-12-12 17:19:45;multiple data sources;[];EDA, ML models, Feedforward Neural Network;Python notebook;157.0;2;;
2020-10-29 21:10:07;Escola Piloto Virtual - PEQ/COPPE/UFRJData Science e Machine Learning na Prática - Introdução e Aplicações na Indústria de ProcessosEste notebook é referente à Aula 1 do curso, que trata de técnicas de regressão utilizando modelos de florestas aleatórias.;Apache 2.0;https://www.kaggle.com/afrniomelo/epv-peq-aula-1-regress-o;1.0;['pattern', 'sklearn'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nn', 'ann'];['gru', 'machine learning', 'regression', 'train', 'model', 'layer', 'label', 'k-nearest neighbor', 'predict', 'rank'];https://www.kaggle.com/c/bluebook-for-bulldozers;0.681;0.346;2020-12-12 17:19:45;Blue Book for Bulldozers;[];EPV PEQ Aula 1 - Regressão;Python notebook;2011.0;16;;
2019-01-15 13:39:56;"This Notebook is inspired by fast.ai's Machine Learning course. I really liked the teaching methodology as its completely application oriented, in oppose to other theorotical approaches in academic course. I learnt a lot of practical things,  like how to actually work with categorical features, how to normalize continuous data, how to handle missing values in your dataset, how to make the best use of timestamps in your dataset, best practices while creating trainning, validation and test datasets, what actually random forest do (intuitionally) and realized how easy it is to tuning hyperparameters and many more things. You might have noted that I have used ""how to"" in front of almost all the things that I learnt because this is what I actually learnt: ""how to do something"", instead of plain theory. This notebook is meant for people's who want to learn all these thing but cannnot manage time to watch 1-1:30 hrs long videos (there are 7 lectures in the ML course, in total). I tried my best:  To put in as much stuff as possible. To keep it simple and intuitional. To avoid using fastai library (I personally think it requires you to learn a lot of context).  I have taken the trouble (rather, I enjoyed doing it) of going through the code and tried replicating the codes as normal python functions. So, you can see how the things are actually implemented instead of looking at some random function name, knowing what it does but not having any clue of how its implemented. Note: This notebook is not complete and exhaustive, I have not implemented everything that was covered in the course but I tried my best to make the notebook as end-to-end as possible. Note: This is pretty long notebook, you might want to bookmark it. The notebook will also have a Part-2 covering the rest of the lessons learnt.";Apache 2.0;https://www.kaggle.com/ankursingh12/lessons-learnt-from-fast-ai-lectures-part-1;1.0;['pattern', 'sklearn'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'training data', 'test data', 'train', 'fitting', 'model', 'validation data', 'predict', 'rank', 'decision tree', 'random forest'];https://www.kaggle.com/c/bluebook-for-bulldozers;0.658;0.34;2020-12-12 17:19:45;Blue Book for Bulldozers;['beginner, classification, feature engineering'];Lessons learnt from Fast.ai lectures Part - 1;Python notebook;1275.0;15;;
2019-01-15 13:06:39;This notebooks is inspired by 2nd Lecture of Fast.ai's ML course. In this notebook, we will be talking about some of the best practices (of removing features) which can save you alot of computation and at the same time increase your score. In particular:  Features importance Removing redundant features Removing temporal features  For all of these topics we will discuss the theory, code and interpretation as well. Hope you all will enjoy it. This is my second kernel, so please comment and let me know the things that you liked and things that you want me to improve. I would love you hear from you. Note: I highly recommend going through the Part-1 as this notebook is basically the continuation of it. Alot of code written here is directly taken from Part-1.;Apache 2.0;https://www.kaggle.com/ankursingh12/lessons-learnt-from-fast-ai-lectures-part-2;1.0;['pattern', 'sklearn'];['ner', 'ai', 'rl', 'ml', 'nn', 'ann'];['training data', 'train', 'model', 'label', 'predict', 'recommend', 'random forest'];https://www.kaggle.com/c/bluebook-for-bulldozers;0.605;0.268;2020-12-12 17:19:45;Blue Book for Bulldozers;['gpu, beginner, feature engineering, +1 morerandom forest'];lessons learnt from fast.ai lectures Part-2;Python notebook;486.0;7;;
2019-11-21 06:39:31;MotivationTree-based models like Random Forest and XGBoost has become very poplular to address tabular(structured) data problems and gained a lot of tractions in Kaggle competitions. It has its very deserving reasons. A lot of the notebooks for this competition is inspired by fast.ai ML course. This notebook will also try to use fast.ai, but another approach: Deep Learning.  This is a bit against industry consensous that Deep Learning is more for unstructured data like image, audio or NLP, and usually won't be very good at handling tabular data. Yet, the introduction of embedding for the categorical data changed this perspective and we'll try to use fast.ai's tabular model to tackle this competition and see how well a Deep Learning approach can do.;Apache 2.0;https://www.kaggle.com/lymenlee/blue-book-bulldozer-fast-ai-deep-learning;1.0;['pattern', 'xgboost'];['ner', 'ai', 'nlu', 'dl', 'rl', 'ml', 'nlp', 'nn', 'ann'];['training data', 'train', 'model', 'epoch', 'deep learning', 'layer', 'validation data', 'loss', 'label', 'predict', 'relu', 'random forest'];https://www.kaggle.com/c/bluebook-for-bulldozers;0.673;0.188;2020-12-12 17:19:45;Blue Book for Bulldozers;['gpu'];Blue Book Bulldozer - Fast.ai Deep Learning;Python notebook;1721.0;3;;
2018-10-16 20:46:13;This is a copy of lesson 1 notebook from fast.ai course Introduction to Machine Learning for Coders. It was modified in the data input only, so that i can run on Kaggle kernels. Source: https://github.com/fastai/fastai/blob/master/courses/ml1/lesson1-rf.ipynb Based on notebook version: bbcd4e0 Course page: http://course.fast.ai/ml.html;Apache 2.0;https://www.kaggle.com/miwojc/fast-ai-machine-learning-lesson-1;1.0;['pytorch', 'tensorflow', 'sklearn', 'pattern'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'random forest', 'train', 'fitting', 'model', 'understanding', 'neural network', 'validation data', 'deep learning', 'layer', 'gradient boosting', 'predict', 'rank', 'decision tree', 'recommend', 'natural language', 'propagation'];https://www.kaggle.com/c/bluebook-for-bulldozers;0.775;0.456;2020-12-12 17:19:45;Blue Book for Bulldozers;[];Fast.ai Machine Learning Lesson 1;Python notebook;20592.0;57;;
2018-10-28 14:48:08;This is a copy of lesson 2 notebook from fast.ai course Introduction to Machine Learning for Coders. It was modified in the data input only, so that i can run on Kaggle kernels. Source: https://github.com/fastai/fastai/blob/master/courses/ml1/lesson2-rf_interpretation.ipynb Based on notebook version: 186739f Course page: http://course.fast.ai/ml.html;Apache 2.0;https://www.kaggle.com/miwojc/fast-ai-machine-learning-lesson-2;1.0;['pattern', 'sklearn', 'mxnet'];['ner', 'ai', 'rl', 'nn', 'ml'];['machine learning', 'train', 'model', 'label', 'predict', 'random forest'];https://www.kaggle.com/c/bluebook-for-bulldozers;0.669;0.253;2020-12-12 17:19:45;multiple data sources;[];Fast.ai Machine Learning Lesson 2;Python notebook;1583.0;6;;
2020-09-16 16:03:57;Escola Piloto Virtual - PEQ/COPPE/UFRJData Science e Machine Learning na Prática - Introdução e Aplicações na Indústria de ProcessosEste notebook é referente à Aula 1 do curso, que trata de técnicas de regressão utilizando modelos de florestas aleatórias.;Apache 2.0;https://www.kaggle.com/pedrodelou/epv-peq-aula-1-regress-o-pedro-delou;1.0;['pattern', 'sklearn'];['ner', 'ai', 'gan', 'ml', 'nlp', 'nn', 'ann'];['gru', 'machine learning', 'regression', 'train', 'model', 'layer', 'label', 'k-nearest neighbor', 'predict', 'rank', 'random forest'];https://www.kaggle.com/c/bluebook-for-bulldozers;0.528;0.152;2020-12-12 17:19:45;Blue Book for Bulldozers;[];EPV PEQ Aula 1 - Regressão (Pedro Delou);Python notebook;148.0;2;;
2020-08-15 21:38:28;Predicting the Sale Price of Bulldozers using Machine LearningIn this notebook, we're going to go through an example machine learning project with the goal of predicting the sale price of bulldozers. Since we're trying to predict a number, this kind of problem is known as a regression problem. The data and evaluation metric we'll be using (root mean square log error or RMSLE) is from the Kaggle Bluebook for Bulldozers competition. The techniques used in here have been inspired and adapted from the fast.ai machine learning course. What we'll end up with To work through these topics, we'll use pandas, Matplotlib and NumPy for data anaylsis, as well as, Scikit-Learn for machine learning and modelling tasks. Tools which can be used for each step of the machine learning modelling process. We'll work through each step and by the end of the notebook, we'll have a trained machine learning model which predicts the sale price of a bulldozer given different characteristics about it. 1. Problem DefinitionFor this dataset, the problem we're trying to solve, or better, the question we're trying to answer is, How well can we predict the future sale price of a bulldozer, given its characteristics previous examples of how much similar bulldozers have been sold for?   2. DataLooking at the dataset from Kaggle, you can you it's a time series problem. This means there's a time attribute to dataset. In this case, it's historical sales data of bulldozers. Including things like, model type, size, sale date and more. There are 3 datasets: Train.csv - Historical bulldozer sales examples up to 2011 (close to 400,000 examples with 50+ different attributes, including SalePrice which is the target variable). Valid.csv - Historical bulldozer sales examples from January 1 2012 to April 30 2012 (close to 12,000 examples with the same attributes as Train.csv). Test.csv - Historical bulldozer sales examples from May 1 2012 to November 2012 (close to 12,000 examples but missing the SalePrice attribute, as this is what we'll be trying to predict).   3. EvaluationFor this problem, Kaggle has set the evaluation metric to being root mean squared log error (RMSLE). As with many regression evaluations, the goal will be to get this value as low as possible. To see how well our model is doing, we'll calculate the RMSLE and then compare our results to others on the Kaggle leaderboard. 4. FeaturesFeatures are different parts of the data. During this step, you'll want to start finding out what you can about the data. One of the most common ways to do this, is to create a data dictionary. For this dataset, Kaggle provide a data dictionary which contains information about what each attribute of the dataset means. You can download this file directly from the Kaggle competition page (account required) or view it on Google Sheets. With all of this being known, let's get started! First, we'll import the dataset and start exploring. Since we know the evaluation metric we're trying to minimise, our first goal will be building a baseline model and seeing how it stacks up against the competition.;Apache 2.0;https://www.kaggle.com/radhakrishnasp/bulldozer-price-prediction;1.0;['pattern', 'sklearn'];['ai', 'gan', 'cv', 'nn', 'ml'];['machine learning', 'test data', 'regression', 'train', 'fitting', 'model', 'validation data', 'label', 'predict', 'random forest'];https://www.kaggle.com/c/bluebook-for-bulldozers;0.479;0.152;2020-12-12 17:19:45;Blue Book for Bulldozers;['gpu'];notebook85513b724f;Python notebook;76.0;2;;
2020-07-07 20:30:41;Predicting the sales Price of Bulldozers;Apache 2.0;https://www.kaggle.com/rijuvaish/prediction-of-bulldozers-sales-price;1.0;['pattern', 'sklearn'];['ner', 'ai', 'gan', 'cv', 'nn'];['training data', 'test data', 'train', 'fitting', 'model', 'label', 'predict'];https://www.kaggle.com/c/bluebook-for-bulldozers;0.485;0.152;2020-12-12 17:19:45;Blue Book for Bulldozers;[];Prediction of bulldozers sales price;Python notebook;82.0;2;;
2018-08-25 03:20:05;Caderno de apoio para o vídeo 5 do curso de Machine Learning da Fast.aiVídeo completo da Lição 5;Apache 2.0;https://www.kaggle.com/sandrorgg/fast-ai-ml-lesson-5;1.0;['pattern', 'sklearn'];['ner', 'ai'];['machine learning', 'train', 'model', 'predict', 'random forest'];https://www.kaggle.com/c/bluebook-for-bulldozers;0.651;0.214;2020-12-12 17:19:45;multiple data sources;[];Fast.ai ML - Lesson 5;Python notebook;1115.0;4;;
2020-09-07 10:57:13;🚜 Predicting the Sale Price of Bulldozers using Machine LearningProblem DefinitionFor this dataset, the problem we're trying to solve, or better, the question we're trying to answer is, How well can we predict the future sale price of a bulldozer, given its characteristics previous examples of how much similar bulldozers have been sold for? DataLooking at the dataset from Kaggle, you can you it's a time series problem. This means there's a time attribute to dataset. In this case, it's historical sales data of bulldozers. Including things like, model type, size, sale date and more. There are 3 datasets: - Train.csv - Historical bulldozer sales examples up to 2011 (close to 400,000 examples with 50+ different attributes, including SalePrice which is the target variable). - Valid.csv - Historical bulldozer sales examples from January 1 2012 to April 30 2012 (close to 12,000 examples with the same attributes as Train.csv). - Test.csv - Historical bulldozer sales examples from May 1 2012 to November 2012 (close to 12,000 examples but missing the SalePrice attribute, as this is what we'll be trying to predict).   EvaluationFor this problem, Kaggle has set the evaluation metric to being root mean squared log error (RMSLE). As with many regression evaluations, the goal will be to get this value as low as possible. To see how well our model is doing, we'll calculate the RMSLE and then compare our results to others on the Kaggle leaderboard. FeaturesFeatures are different parts of the data. During this step, you'll want to start finding out what you can about the data. One of the most common ways to do this, is to create a data dictionary. For this dataset, Kaggle provide a data dictionary which contains information about what each attribute of the dataset means. You can download this file directly from the Kaggle competition page (account required) or view it on Google Sheets. With all of this being known, let's get started! First, we'll import the dataset and start exploring. Since we know the evaluation metric we're trying to minimise, our first goal will be building a baseline model and seeing how it stacks up against the competition.;Apache 2.0;https://www.kaggle.com/shyam21/bench-mark-blue-book-bulldozers;1.0;['pattern', 'sklearn'];['ner', 'ai', 'dl', 'gan', 'cv', 'nn', 'ml'];['machine learning', 'training data', 'regression', 'test data', 'train', 'fitting', 'model', 'label', 'predict'];https://www.kaggle.com/c/bluebook-for-bulldozers;0.521;0.281;2020-12-12 17:19:45;Blue Book for Bulldozers;['beginner, regression, time series analysis'];Bench mark blue book bulldozers;Python notebook;134.0;8;;
2018-09-11 07:09:59;Blue Book for Bulldozer - Kaggle Competition;Apache 2.0;https://www.kaggle.com/sureshsubramaniam/blue-book-for-bulldozer-kaggle-competition;1.0;['pattern', 'sklearn'];['ner', 'ai', 'rl', 'nn', 'ml'];['machine learning', 'training data', 'train', 'model', 'label', 'predict', 'random forest'];https://www.kaggle.com/c/bluebook-for-bulldozers;0.69;0.311;2020-12-12 17:19:45;multiple data sources;[];Blue Book for Bulldozer - Kaggle Competition;Python notebook;2441.0;11;;
2020-07-08 02:50:08;1. Problem definitionHow well can we predict the future sale price of a bulldozer, given its characteristics and previous examples of how much similiar bulldozers have been sold for?;Apache 2.0;https://www.kaggle.com/theeesky/blue-book-for-bulldozers-randomforest;1.0;['pattern', 'sklearn'];['ner', 'ai', 'gan', 'cv', 'nn'];['machine learning', 'training data', 'regression', 'test data', 'train', 'fitting', 'model', 'label', 'predict'];https://www.kaggle.com/c/bluebook-for-bulldozers;0.528;0.188;2020-12-12 17:19:45;Blue Book for Bulldozers;[];Blue Book for Bulldozers - RandomForest;Python notebook;149.0;3;;
2020-05-21 17:07:29;"Predicting the sale price of bulldozer using MLIn this notebook , I am going to go through with the goal of predicting the sale price of Bulldozers. 1. Problem definition :Predict the sale price of a particular piece of heavy equipment at auction based on it's usage, equipment type, and configuration. 2. DataThe data is downloaded from the Kaggle ""Blue Book for bulldozer"" competition.  https://www.kaggle.com/c/bluebook-for-bulldozers/data There are 3 main datasets:  Train.csv is the training set, which contains data through the end of 2011. Valid.csv is the validation set, which contains data from January 1, 2012 - April 30, 2012 You make predictions on this set throughout the majority of the competition. Your score on this set is used to create the public Leaderboard. Test.csv is the test set, which won't be released until the last week of the competition. It contains data from May 1, 2012 - November 2012. Your score on the test set determines your final rank for the competition.  3. EvaluationRMSLE (root mean squared log error) between the actual and predicted auction prices. 4 .Featureshttps://docs.google.com/spreadsheets/d/1epPQnzxSONR2ZwnVLg92luVi7XEJCs_KXqj3I1lmfQg/edit?usp=sharing";Apache 2.0;https://www.kaggle.com/vijitkam/buldozers-price-prediction-using-randomforest;1.0;['pattern', 'sklearn'];['ai', 'ml', 'cv'];['training data', 'train', 'fitting', 'model', 'label', 'predict', 'rank'];https://www.kaggle.com/c/bluebook-for-bulldozers;0.622;0.292;2020-12-12 17:19:45;Blue Book for Bulldozers;[];Buldozers price prediction using RandomForest;Python notebook;652.0;9;;
2020-04-07 09:02:33;In this kernel we will see how to do Feature Selection.We will be using Lasso,Ridge and Embeded technique.Regularization means adding penalty to the parameters of the machine learning model.THis helps in reducing the freedom of the model.Lasso regression has the ability to shrink the coefficinets to zero.This helps in carrying out feature selection.This Kernel is a work in process and I will be updating the kernel in coming days.If you like my work please do vote.;Apache 2.0;https://www.kaggle.com/biphili/feature-slection-lasso-ridge-linear-models;1.0;['sklearn'];['ann', 'ai', 'nn', 'ml'];['filter', 'machine learning', 'regression', 'training data', 'train', 'fitting', 'model', 'test data', 'label', 'logistic regression', 'predict', 'rank', 'classification'];https://www.kaggle.com/c/bnp-paribas-cardif-claims-management;0.613;0.357;2020-12-12 17:27:17;multiple data sources;[];Feature Slection Lasso,Ridge,Linear Models;Python notebook;557.0;18;;
2016-02-25 05:12:01;Exploring BNP Data DistributionsHopefully this will run on Kaggle servers.  You should see a lot of plots (I can only see one right now, before pressing view HTML output). If it doesn't I guess you'll have to run the code on your own machine.;Apache 2.0;https://www.kaggle.com/bobcz3/exploring-bnp-data-distributions;1.0;['sklearn'];['ai', 'ml'];['train', 'label', 'predict'];https://www.kaggle.com/c/bnp-paribas-cardif-claims-management;0.747;0.425;2020-12-12 17:27:17;BNP Paribas Cardif Claims Management;[];Exploring BNP Data Distributions;Python notebook;9524.0;39;;
2020-06-20 18:15:31;xfeat: Flexible Feature Engineering & Exploration Library using GPUs and Optuna.xfeat provides sklearn-like transformation classes for feature engineering and exploration. Unlike sklearn API, xfeat provides a dataframe-in, dataframe-out interface. xfeat supports both pandas and cuDF dataframes. By using cuDF and CuPy, xfeat can generate features 10 ~ 30 times faster than a naive pandas operation. https://github.com/pfnet-research/xfeat;Apache 2.0;https://www.kaggle.com/confirm/xfeat-cudf-lightgbm-catboost-wip;1.0;['catboost', 'xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'gbm'];['predict', 'train', 'model', 'label', 'loss'];https://www.kaggle.com/c/bnp-paribas-cardif-claims-management;0.689;0.367;2020-12-12 17:27:17;multiple data sources;['gpu'];xfeat + cuDF + LightGBM + CatBoost;Python notebook;2404.0;20;0.42977;0.43189
2020-04-07 23:07:54;For some competitions it can be helful to find patterns of NA values or outliers, and cluster observations by similar patterns. Here I'm wondering what value there is in looking at stockouts and grouping items by those patterns. In our data we have typical department store groupings - family and department. This makes sense for the most part although for this exercise, the groupings aren't always helpful. If you're planning a Sunday summer picnic for instance, you might go over to Household for a tablecloth, Hobbies for a frisbee, and Foods for a big pack of ground beef (don't judge..:). A lot of other people are doing the same thing and so maybe the store runs out of those items. Demand is event-driven in this case and crosses department lines. We don't really know if an item is out of stock or just no one bought it. I'll start with items having higher median sales and assume that a drop to 0 is due to a stockout. This is sure to be wrong in some cases.;Apache 2.0;https://www.kaggle.com/jpmiller/grouping-items-by-stockout-pattern;1.0;['pattern'];['ai', 'nn', 'ann'];['train', 'model', 'filter', 'clustering'];https://www.kaggle.com/c/bnp-paribas-cardif-claims-management;0.759;0.49;2020-12-12 17:27:17;multiple data sources;['tabular data'];Grouping Items by Stockout Pattern;Python notebook;13129.0;88;;
2020-09-22 19:04:53;A beginner's guide to Feature Selection Methods;Apache 2.0;https://www.kaggle.com/saisatish09/a-beginner-s-guide-to-feature-selection-methods;1.0;['sklearn'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['linear regression', 'filter', 'machine learning', 'regression', 'training data', 'train', 'fitting', 'model', 'test data', 'random forest', 'loss', 'label', 'logistic regression', 'predict', 'rank', 'decision tree', 'classification'];https://www.kaggle.com/c/bnp-paribas-cardif-claims-management;0.678;0.403;2020-12-12 17:27:17;multiple data sources;['beginner, data visualization, exploratory data analysis'];A beginner's guide to feature selection methods;Python notebook;1919.0;30;;
2016-09-26 06:33:48;Matthews correlation coefficientSee https://en.wikipedia.org/wiki/Matthews_correlation_coefficient Author: CPMP A fast implementation of Anokas mcc optimization code. This code takes as input probabilities, and selects the threshold that yields the best MCC score.  It is efficient enough to be used as a custom evaluation function in xgboost;Apache 2.0;https://www.kaggle.com/cpmpml/optimizing-probabilities-for-best-mcc;1.0;['xgboost', 'sklearn'];['ai', 'rl'];['train', 'label', 'predict'];https://www.kaggle.com/c/bosch-production-line-performance;0.763;0.49;2020-12-12 17:31:53;Bosch Production Line Performance;[];Optimizing probabilities for best MCC;Python notebook;14843.0;88;;
2016-10-11 22:30:47;Station combinationsWe have seen station 32 has high (4.7%) error rate. Let's investigate that failure rate with station combinations.;Apache 2.0;https://www.kaggle.com/gaborfodor/69-failure-rate;1.0;['pattern'];['ai'];['train', 'label'];https://www.kaggle.com/c/bosch-production-line-performance;0.756;0.463;2020-12-12 17:31:53;Bosch Production Line Performance;[];69% failure rate;Python notebook;12006.0;62;;
2016-09-24 22:27:24;Checking the 'train_dates.csv'  lots of columns (1157) 80%+ missing values Same stations often have same date values;Apache 2.0;https://www.kaggle.com/gaborfodor/notebookd19d11e4f2;1.0;['pattern'];['ai', 'dl'];['train', 'label'];https://www.kaggle.com/c/bosch-production-line-performance;0.782;0.521;2020-12-12 17:31:53;Bosch Production Line Performance;[];Date Exploration (6min == 0.01);Python notebook;25572.0;135;;
2016-09-16 23:17:03;Following a similar recipe to lewis' R script (https://www.kaggle.com/cartographic/bosch-production-line-performance/bish-bash-xgboost), sampling the data to select features before running on the full set in order to stay within kaggle's memory limits. Here I add in the train_date data too. Please feel free to fork and improve.;Apache 2.0;https://www.kaggle.com/joconnor/python-xgboost-starter-0-209-public-mcc;1.0;['xgboost', 'sklearn'];['ner', 'ai', 'nn', 'cv'];['train', 'model', 'test data', 'predict'];https://www.kaggle.com/c/bosch-production-line-performance;0.781;0.498;2020-12-12 17:31:53;Bosch Production Line Performance;[];Python XGBoost Starter (0.209 Public MCC);Python notebook;24725.0;98;;
2016-10-10 02:04:25;This is an attempt at visualizing the magic feature(outed by Faron) in how well it separates responses. Can be used to visualize any random feature's discriminating power.;Apache 2.0;https://www.kaggle.com/rithal/magic-feature-visualization;1.0;['xgboost'];['ai', 'rl'];['train'];https://www.kaggle.com/c/bosch-production-line-performance;0.753;0.442;2020-12-12 17:31:53;Bosch Production Line Performance;[];Magic Feature Visualization;Python notebook;11041.0;48;;
2016-09-22 20:55:33;Matthews correlation coefficientWiki: https://en.wikipedia.org/wiki/Matthews_correlation_coefficient Author: Vopani R-implementation of CPMP's fast mcc optimization originally from Anokas mcc optimization code. This code takes true values and predicted probabilities, and selects the threshold/cutoff that yields the best MCC score. It is slower than the Python implementation, maybe someone can optimize this further, before trying to use it in xgboost or elsewhere.;Apache 2.0;https://www.kaggle.com/rohanrao/r-implementation-of-mcc-optimization;1.0;['xgboost'];['ai'];['train', 'label', 'predict'];https://www.kaggle.com/c/bosch-production-line-performance;0.738;0.397;2020-12-12 17:31:53;Bosch Production Line Performance;[];R-implementation of MCC optimization;R notebook;7577.0;28;;
2019-04-06 19:53:42;As discussed in the discussion forums (https://www.kaggle.com/c/career-con-2019/discussion/87239#latest-508136) it looks as if each series is part of longer aquisition periods that have been cut up into chunks with 128 samples. This means that each series is not truely independent and there is leakage between them via the orientation data. Therefore if you have any features that use orientation, you will get a very high CV score due to this leakage in the train set. This kernel will show you how it is possible to get a CV score of 0.992 using only the orientation data.;Apache 2.0;https://www.kaggle.com/anjum48/leakage-within-the-train-dataset;1.0;['sklearn'];['ai', 'nn', 'cv'];['filter', 'test data', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/career-con-2019;0.648;0.371;2020-12-12 17:33:04;CareerCon 2019 - Help Navigate Robots;[];Leakage within the train dataset;Python notebook;1059.0;21;;
2019-04-11 04:21:53;LSTM for time-seriesIn this competition we basically have time-series, so it makes sense to solve it as such. In this kernel I build an LSTM neural net in Pytorch.;Apache 2.0;https://www.kaggle.com/artgor/basic-pytorch-lstm;1.0;['pytorch', 'sklearn'];['ai', 'rl', 'cv', 'nn', 'ml'];['gru', 'filter', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'lstm', 'predict'];https://www.kaggle.com/c/career-con-2019;0.718;0.397;2020-12-12 17:33:04;CareerCon 2019 - Help Navigate Robots;['data visualization, deep learning, classification, +1 morefeature engineering'];Basic pytorch LSTM;Python notebook;4588.0;28;0.5106;0.5607
2019-04-10 21:28:48;General informationIn this competition we have data about small mobile robot driving over different floor surfaces. We need to predict the floor type based on robot's sensor data. This kernel uses content of my previous kernel: https://www.kaggle.com/artgor/where-do-the-robots-drive Also I add bayesian optimization from this library: https://github.com/fmfn/BayesianOptimization Bayesian optimization works by constructing a posterior distribution of functions (gaussian process) that best describes the function you want to optimize. As the number of observations grows, the posterior distribution improves, and the algorithm becomes more certain of which regions in parameter space are worth exploring and which are not, as seen in the picture below.  work in progress;Apache 2.0;https://www.kaggle.com/artgor/bayesian-optimization-for-robots;1.0;['xgboost', 'lightgbm', 'catboost', 'sklearn', 'pattern'];['ner', 'ai', 'gbm', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'test data', 'regression', 'generation', 'train', 'model', 'loss', 'label', 'predict', 'understanding', 'bayesian'];https://www.kaggle.com/c/career-con-2019;0.688;0.427;2020-12-12 17:33:04;CareerCon 2019 - Help Navigate Robots;['classification, feature engineering, optimization'];bayesian optimization for robots;Python notebook;2353.0;40;0.5741;0.6175
2019-04-10 21:28:04;General informationIn this competition we have data about small mobile robot driving over different floor surfaces. We need to predict the floor type based on robot's sensor data. In this kernel I'll do EDA on the data, try FE and build a variety of models.  work in progress;Apache 2.0;https://www.kaggle.com/artgor/where-do-the-robots-drive;1.0;['xgboost', 'lightgbm', 'catboost', 'sklearn', 'pattern'];['ner', 'ai', 'gbm', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'test data', 'regression', 'generation', 'train', 'model', 'loss', 'label', 'predict', 'understanding'];https://www.kaggle.com/c/career-con-2019;0.747;0.534;2020-12-12 17:33:04;CareerCon 2019 - Help Navigate Robots;['data visualization, exploratory data analysis, classification, +1 morefeature engineering'];Where do the robots drive?;Python notebook;9547.0;161;0.5746;0.6217
2019-05-02 09:53:01;Robots need help!  Content Introduction  Prepare the data analysis  Data exploration  Check the data  Distribution of target feature - surface  Distribution of group_id  Density plots of features  Target feature - surface and group_id distribution  Features correlation    Feature engineering Model Submission  References;Apache 2.0;https://www.kaggle.com/gpreda/robots-need-help;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'gan', 'gbm', 'rl', 'nn', 'ann'];['filter', 'test data', 'train', 'model', 'loss', 'label', 'predict', 'random forest'];https://www.kaggle.com/c/career-con-2019;0.73;0.473;2020-12-12 17:33:04;CareerCon 2019 - Help Navigate Robots;['multiclass classification'];Robots need help!;Python notebook;6207.0;71;0.5859;0.6651
2019-04-17 15:23:17;Introduction:Robots are smart… by design. To fully understand and properly navigate a task, however, they need input about their environment. In this competition, you’ll help robots recognize the floor surface they’re standing on using data collected from Inertial Measurement Units (IMU sensors). About Data:CareerCon has collected IMU sensor data while driving a small mobile robot over different floor surfaces on the university premises. Objective:The task is to predict which one of the nine floor types (carpet, tiles, concrete) the robot is on using sensor data such as acceleration and velocity. Succeed and you'll help improve the navigation of robots without assistance across many different surfaces, so they won’t fall down on the job.;Apache 2.0;https://www.kaggle.com/hiralmshah/robot-sensor-eda-fe-and-prediction-improvement;1.0;['sklearn'];['ner', 'ai', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'test data', 'random forest', 'train', 'model', 'label', 'predict', 'understanding', 'classification'];https://www.kaggle.com/c/career-con-2019;0.73;0.47;2020-12-12 17:33:04;CareerCon 2019 - Help Navigate Robots;['beginner, data visualization, exploratory data analysis, +1 moreclassification'];Robot sensor EDA, FE and Prediction Improvement;Python notebook;6177.0;68;0.5973;0.6475
2019-04-07 08:47:27;This kernel is based on Theo Viel , Gabriel Preda, Nanashi and Vansh Jatana. Here I applied RandomForestClassifier,  set random_state higher and kfold to 50.;Apache 2.0;https://www.kaggle.com/hsinwenchang/randomforestclassifier;1.0;['sklearn'];['ann', 'ai', 'nn', 'ml'];['train', 'model', 'label', 'predict'];https://www.kaggle.com/c/career-con-2019;0.688;0.397;2020-12-12 17:33:04;CareerCon 2019 - Help Navigate Robots;['gpu, feature engineering, data cleaning, +1 moresignal processing'];RandomForestClassifier;Python notebook;2376.0;28;0.5746;0.7390
2020-07-25 17:02:21;hyper-parameters tuning of an machine learning model (Random Forest)Ouassim Adnane  v1=24/03/2019 v2=20/07/2020;Apache 2.0;https://www.kaggle.com/ishivinal/hyperparamters-optimization-gs-rs-boa-tpe-hb-ga;1.0;['sklearn'];['ner', 'ai', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'generation', 'train', 'artificial intelligence', 'model', 'loss', 'label', 'predict', 'random forest', 'bayesian'];https://www.kaggle.com/c/career-con-2019;0.709;0.473;2020-12-12 17:33:04;multiple data sources;['random forest, bayesian statistics'];🔔HyperParamters Optimization: GS,RS,BOA,TPE,HB,GA;Python notebook;3725.0;71;;
2019-04-19 14:48:26;CareerCon 2019 - Help Navigate RobotsTop Solutions Compilation  Robots are smart… by design. To fully understand and properly navigate a task, however, they need input about their environment. In this competition, you’ll help robots recognize the floor surface they’re standing on using data collected from Inertial Measurement Units (IMU sensors).  This is just a compilation of all the best solutions I have found, different types of analysis and posts (discussions). The purpose of this is to have in a single kernel all the relevant information/solutions of this competition, so that if in the future there is a similar competition this material can be used as baseline, and maybe the authors delete the kernel or make it private, so we would lose all that amazing information. Please comment bellow if you want me to add something, or if I missed something important... and please support the original kernels and their authors.  My best/original kernel in this competition is #1 Smart Robots. Most Complete Notebook 🤖 References #16 Solution by @ilhamfp31 Submission (Fourier, Neighbour Detection, SVM) by Thomas Rohwer Starter Code for 3rd place Solution https://www.kaggle.com/ilhamfp31/16-solution-0-76 https://www.kaggle.com/whoiskk/15-solution-private-0-77;Apache 2.0;https://www.kaggle.com/jesucristo/1-smart-robots-complete-compilation;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'rnn'];['filter', 'recurrent neural network', 'test data', 'train', 'model', 'neural network', 'epoch', 'deep learning', 'layer', 'validation data', 'loss', 'label', 'lstm', 'predict', 'relu'];https://www.kaggle.com/c/career-con-2019;0.69;0.429;2020-12-12 17:33:04;multiple data sources;[];#1 Smart Robots. Complete Compilation 🤖;Python notebook;2479.0;41;;
2019-04-12 08:44:46;CareerCon 2019 - Help Navigate RobotsRobots are smart… by design !!  Robots are smart… by design. To fully understand and properly navigate a task, however, they need input about their environment. In this competition, you’ll help robots recognize the floor surface they’re standing on using data collected from Inertial Measurement Units (IMU sensors). We’ve collected IMU sensor data while driving a small mobile robot over different floor surfaces on the university premises. The task is to predict which one of the nine floor types (carpet, tiles, concrete) the robot is on using sensor data such as acceleration and velocity. Succeed and you'll help improve the navigation of robots without assistance across many different surfaces, so they won’t fall down on the job. Its a golden chance to help humanity, by helping Robots !;Apache 2.0;https://www.kaggle.com/jesucristo/1-smart-robots-most-complete-notebook;1.0;['pattern', 'sklearn'];['ner', 'ai', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'test data', 'random forest', 'train', 'model', 'understanding', 'label', 'predict', 'recommend', 'classification'];https://www.kaggle.com/c/career-con-2019;0.776;0.568;2020-12-12 17:33:04;multiple data sources;['exploratory data analysis, classification, robotics'];#1 Smart Robots. Most Complete Notebook 🤖;Python notebook;21564.0;267;;
2019-03-24 23:15:13;IntroductionIn this competition, participants must help robots recognize the floor surface they’re standing on using data collected from IMU sensors.;Apache 2.0;https://www.kaggle.com/jsaguiar/surface-recognition-baseline;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'gbm', 'cv', 'rl', 'nn', 'ann'];['filter', 'train', 'model', 'label', 'gradient boosting', 'predict', 'classification'];https://www.kaggle.com/c/career-con-2019;0.703;0.423;2020-12-12 17:33:04;CareerCon 2019 - Help Navigate Robots;[];Surface Recognition Baseline;Python notebook;3292.0;38;0.5040;0.5096
2019-03-17 06:01:54;Robots are smart… by design !!Who make those Robots smart? Its you Machine Learning guys ! In this project, our task is to help robots recognize the floor surface they’re standing on using data collected from Inertial Measurement Units (IMU sensors). Hope you guys will learn something from this sensor data. Its kind of IOT data, as in IOT, we usually work with sensor data.. Its a golden chance to help humanity, by helping Robots !;Apache 2.0;https://www.kaggle.com/prashantkikani/help-humanity-by-helping-robots;1.0;['catboost', 'xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'gbm'];['machine learning', 'train', 'model', 'label', 'predict', 'classification', 'bayesian'];https://www.kaggle.com/c/career-con-2019;0.723;0.494;2020-12-12 17:33:04;CareerCon 2019 - Help Navigate Robots;['beginner, feature engineering'];Help Humanity by Helping Robots 🤖 !;Python notebook;5205.0;93;0.6133;0.7026
2019-04-20 16:29:21;"Deep Time Series ClassificationThe time series classification problem seems to be a great choice to apply Deep Learning models. However, even deep models cannot magically give you good results if the data wasn't propertly prepared. The CareerCon 2019 competition was all about time series classification. In one of my previous kernels, I've tried to apply LSTM model to the dataset and didn't get too impressive accuracy. Also, I was experimenting with 1-d convolutions but again without any luck. So finally, I decided to go with a more simple apporach. Nevertheless, when the competition was ended, one of the best solutions implemented by prith189 uses Deep Learning to achieve a decent result on both public and private leaderboard. In this notebook, we're going to use PyTorch to create a clone of the mentioned solution and see if we can improve it a bit using modern training techniques.  ImportsIn addition to PyTorch, we use ""standard"" Python's data science stack. Also, there are couple of additional functions from the standard library used in utils and snippets.";Apache 2.0;https://www.kaggle.com/purplejester/pytorch-deep-time-series-classification;1.0;['pytorch', 'keras', 'sklearn'];['ai', 'dl', 'rl', 'nn', 'ann'];['activation function', 'training data', 'neuron', 'train', 'model', 'epoch', 'deep learning', 'layer', 'validation data', 'loss', 'label', 'lstm', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/career-con-2019;0.756;0.371;2020-12-12 17:33:04;multiple data sources;['gpu, deep learning, classification, +1 moremulticlass classification'];[PyTorch] Deep Time Series Classification;Python notebook;12146.0;21;0.8967;0.8222
2019-03-14 13:33:11;Deep Learning StarterIn this kernel, I directly feed the data into a Recurrent Neural Network. For fancyness, I added an Attention Mechanism. Because of reproductibility issues, results are very unstable. The solution is to move to PyTorch but I wanted to produce something quickly.;Apache 2.0;https://www.kaggle.com/theoviel/deep-learning-starter;1.0;['pytorch', 'tensorflow', 'sklearn', 'keras'];['ai', 'nn', 'cv'];['recurrent neural network', 'train', 'model', 'neural network', 'epoch', 'deep learning', 'layer', 'validation data', 'loss', 'label', 'lstm', 'predict'];https://www.kaggle.com/c/career-con-2019;0.714;0.459;2020-12-12 17:33:04;CareerCon 2019 - Help Navigate Robots;['gpu, deep learning, lstm'];Deep Learning Starter;Python notebook;4205.0;59;0.5097;0.4985
2019-03-22 18:50:59;Leaderboard Distribution I have been doing this competetion for 4 days or so. The main problem that everybody is (including me hitting my head through the WALL) facing is the local cross validation is not matching the LeaderBoard. In this kernel I try to create a Validation Set which matches the leaderboard using LeaderBoard Probing done by @donkeys and @ninoko. The leaderboard distributions are given in the discussion threads :  https://www.kaggle.com/c/career-con-2019/discussion/84760 https://www.kaggle.com/c/career-con-2019/discussion/85204  A big thank you for wasting your 9 submissions for the greater GOOD. So lets get into it.;Apache 2.0;https://www.kaggle.com/whoiskk/validation-strategy-randomforest-0-71;1.0;['xgboost', 'sklearn', 'lightgbm'];['ai', 'gbm', 'cv', 'rl', 'nn', 'ann'];['filter', 'regression', 'train', 'fitting', 'model', 'label', 'predict', 'understanding'];https://www.kaggle.com/c/career-con-2019;0.658;0.397;2020-12-12 17:33:04;CareerCon 2019 - Help Navigate Robots;[];Validation Strategy;Python notebook;1279.0;28;;
2017-08-02 23:49:29;Let's prepare our data so that we can read it into our model. Since the data is super big we need a generator to read it a few at a time into memory.;Apache 2.0;https://www.kaggle.com/ecobill/u-nets-with-keras;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai'];['filter', 'train', 'model', 'epoch', 'layer', 'label', 'loss', 'relu', 'u-net'];https://www.kaggle.com/c/carvana-image-masking-challenge;0.748;0.437;2020-12-12 17:38:33;Carvana Image Masking Challenge;[];U-nets with Keras;Python notebook;9762.0;45;;
2017-09-02 02:35:35;IntroThanks to the Keras Kernel by Peter Giannakopoulos here, and Heng CherKeng Pytorch Kernel here. Both are wonderful approaches to the carvana challenge and I was very inspired from their code to make mine. Why creating another kernel then?I found Heng CherKeng kind of an experimental playground and I wanted to have a clear and straightforward code written for Pytorch that I can refer to later in time. The goal of this kernel is not to burst public/private lb score but rather to understand how Unets works using Pytorch. It has a clear and well documented code and takes the learning path approach. Of course I'll add more and more improvements to it to eventually reach the top results (on 31-08-2017 it reaches 0.987 on public LB). Anyone who's willing to help is welcome to open PRs on the github repo. I engage myself to review and merge them. Don't hesitate to upvote the kernel if you found it useful. My motivation comes from it. Here is the link to the github repository;Apache 2.0;https://www.kaggle.com/ekami66/clear-documented-a-to-z-code;0.7;['pytorch', 'keras'];['ai', 'nn', 'ann'];[];https://www.kaggle.com/c/carvana-image-masking-challenge;0.692;0.39;2020-12-12 17:38:33;Carvana Image Masking Challenge;[];Clear documented A to Z code;Python notebook;2562.0;26;;
2017-09-25 15:25:49;IntroductionThanks to Peter Giannakopoulos and Heng CherKeng for their starter kits. I collected their data augmentation methods and added a few based on the keras.preprocessing.image. Let me know if they help your learning process.;Apache 2.0;https://www.kaggle.com/gaborfodor/augmentation-methods;1.0;['tensorflow', 'keras'];['ai', 'nn', 'ann', 'cv'];['train'];https://www.kaggle.com/c/carvana-image-masking-challenge;0.744;0.475;2020-12-12 17:38:33;Carvana Image Masking Challenge;['computer vision, intermediate'];Augmentation methods;Python notebook;8794.0;72;;
2018-06-29 14:29:16;OverviewUsing a pretrained model to segmentHere is an example kernel where we use a pretrained VGG16 model as the encoder portion of a U-Net and thus can benefit from the features already created in the model and only focus on learning the specific decoding features. The strategy was used with LinkNet by one of the top placers in the competition. I wanted to see how well it worked in particular comparing it to standard or non-pretrained approaches, the code is setup now for VGG16 but can be easily adapted to other problems;Apache 2.0;https://www.kaggle.com/kmader/vgg16-u-net-on-carvana;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'rl', 'nn', 'ann'];['train', 'model', 'epoch', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'u-net'];https://www.kaggle.com/c/carvana-image-masking-challenge;0.762;0.405;2020-12-12 17:38:33;multiple data sources;['deep learning, computer vision, transfer learning'];VGG16+U-Net on Carvana;Python notebook;14360.0;31;;
2017-10-13 15:24:26;Fast benchmark: Pillow vs OpenCVBackground: when we deal with images in image-based problems and deploy a deep learning solution, it is better to have a fast image reading and transforming library. Let's compare Pillow and OpenCV python libraries on image loading and some basic transformations on source images from Carvana competition. OpenCV: C++, python-wrapper Pillow: Python, C  Intuition says that Opencv should be a little faster, let's see this by examples  This question I asked myself after reading the PyTorch documentation on image transformation. Most of transformations take as input a PIL image.;Apache 2.0;https://www.kaggle.com/vfdev5/pil-vs-opencv;1.0;['pytorch', 'pillow'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'generation', 'train', 'model', 'deep learning'];https://www.kaggle.com/c/carvana-image-masking-challenge;0.803;0.476;2020-12-12 17:38:33;Carvana Image Masking Challenge;[];PIL vs Opencv;Python notebook;51138.0;73;;
2019-08-24 01:17:35;No comments, only code. Feel free to ask questions :);Apache 2.0;https://www.kaggle.com/abhishek/entity-embeddings-to-handle-categories;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'rl'];['filter', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/cat-in-the-dat;0.729;0.489;2020-12-12 17:40:12;Categorical Feature Encoding Challenge;['gpu'];Entity embeddings to handle categories;Python notebook;5968.0;87;;
2019-12-10 19:51:12;2nd place Solution - Categorical Feature Encoding ChallengeA simple solution - Alexandre Daubas, Paris;Apache 2.0;https://www.kaggle.com/adaubas/2nd-place-solution-categorical-fe-callenge;1.0;['sklearn'];['ai', 'dl', 'gbm', 'cv', 'nn', 'ann'];['test data', 'regression', 'train', 'model', 'logistic regression', 'predict'];https://www.kaggle.com/c/cat-in-the-dat;0.706;0.476;2020-12-12 17:40:12;Categorical Feature Encoding Challenge;[];2nd place Solution - Categorical FE Callenge;Python notebook;3535.0;73;0.80282;0.80840
2019-08-29 21:01:38;General informationIn this kernel I work with data from Categorical Feature Encoding Challenge. This is a playground competition, where all features are categorical. As per data description: The data contains binary features (bin_*), nominal features (nom_*), ordinal features (ord_*) as well as (potentially cyclical) day (of the week) and month features. The string ordinal features ord_{3-5} are lexically ordered according to string.ascii_letters. In this kernel I'll write EDA and compare various categorical encoders. The code for categorical encoding is heavily based on this great medium article.;Apache 2.0;https://www.kaggle.com/artgor/exploring-categorical-encodings;1.0;['xgboost', 'lightgbm', 'catboost', 'sklearn', 'tensorflow'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'training data', 'test data', 'train', 'model', 'loss', 'label', 'predict', 'rank', 'classification', 'bayesian'];https://www.kaggle.com/c/cat-in-the-dat;0.687;0.431;2020-12-12 17:40:12;Categorical Feature Encoding Challenge;['exploratory data analysis, classification'];Exploring CATegorical encodings;Python notebook;2308.0;42;0.79477;0.80126
2020-01-21 01:56:10;Categorical Feature Encoding ChallengeCrislânio Macêdo -  Last Update in January, 20th, 2020  Github Linkedin Medium Quora Ensina.AI Hackerrank Blog Personal Page Twitter;Apache 2.0;https://www.kaggle.com/caesarlupum/cat-h2o-ai-from-linear-models-to-deep-learning;1.0;['catboost', 'xgboost', 'h2o'];['ner', 'ai', 'dl', 'automl', 'gbm', 'rl', 'nn', 'ml'];['filter', 'artificial neural network', 'logistic regression', 'predict', 'autoencoder', 'machine learning', 'training data', 'train', 'epoch', 'recommend', 'model', 'neural network', 'layer', 'rank', 'regression', 'fitting', 'validation data', 'deep learning', 'gradient boosting', 'random forest'];https://www.kaggle.com/c/cat-in-the-dat;0.63;0.4;2020-12-12 17:40:12;Categorical Feature Encoding Challenge;['categorical data'];🐱Cat - H2O.ai-From Linear Models to Deep Learning;Python notebook;750.0;29;;
2019-12-31 19:34:20;Categorical Feature Encoding Challenge WITH PYTHONCrislânio Macêdo -  December, 31th, 2019 🐱 CatComp - Simple Target Encoding :  🐱 CatComp - Simple Target Encoding;Apache 2.0;https://www.kaggle.com/caesarlupum/catcomp-simple-target-encoding;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'rl', 'ml'];['filter', 'regression', 'train', 'fitting', 'model', 'logistic regression', 'predict', 'classification'];https://www.kaggle.com/c/cat-in-the-dat;0.693;0.465;2020-12-12 17:40:12;Categorical Feature Encoding Challenge;['beginner, utility script']; 🐱 CatComp - Simple Target Encoding ;Python notebook;2634.0;64;;
2019-10-03 08:36:51;Credits to @Ants / Notebook : https://www.kaggle.com/superant/oh-my-cat;Apache 2.0;https://www.kaggle.com/cuijamm/simple-onehot-logisticregression-score-0-80801;1.0;['sklearn'];['ai', 'cv'];['train', 'model', 'regression', 'predict'];https://www.kaggle.com/c/cat-in-the-dat;0.679;0.383;2020-12-12 17:40:12;Categorical Feature Encoding Challenge;[];Simple OneHot & LogisticRegression(Score: 0.80801);Python notebook;1933.0;24;0.80246;0.80801
2020-11-09 00:40:16;Tune Hyperparameters for Classification Machine Learning AlgorithmsReference: Jason Brownlee PhD, machine learning blog Machine learning algorithms have hyperparameters that allow you to tailor the behavior of the algorithm to your specific dataset. Hyperparameters are different from parameters, which are the internal coefficients or weights for a model found by the learning algorithm. Unlike parameters, hyperparameters are specified by the practitioner when configuring the model. Typically, it is challenging to know what values to use for the hyperparameters of a given algorithm on a given dataset, therefore it is common to use random or grid search strategies for different hyperparameter values. The more hyperparameters of an algorithm that you need to tune, the slower the tuning process. Therefore, it is desirable to select a minimum subset of model hyperparameters to search or tune. Not all model hyperparameters are equally important. Some hyperparameters have an outsized effect on the behavior, and in turn, the performance of a machine learning algorithm. As a machine learning practitioner, you must know which hyperparameters to focus on to get a good result quickly. In this tutorial, you will discover those hyperparameters that are most important for some of the top machine learning algorithms. Let’s get started  Grid SearchAll you need to do in GridSearch is tell it which hyperparameters you want it to experiment with, and what values to try out, and it will evaluate all the possible combinations of hyperparameter values, using cross-validation. Randomized Searchthe grid search approach is fine when you are exploring relatevely few combinations, but when the hyperparameter search space is large, it is often preferable to use RandomizedSearchCV instead. This technique evaluates a given number of random combinations by selecting a random value for each hyperparameter at every iteration. This approach has two main benefits:  If you let the randomized search run for 1000 iterations it will explore 1000 different values for each hyperparameter. You have more control over the computing budget you want to allocate to hyperparameter search, simply by setting the number of iterations.;Apache 2.0;https://www.kaggle.com/faressayah/tune-hyperparameters-for-classification-ml-algo;1.0;['xgboost', 'sklearn'];['ner', 'ai', 'gbm', 'cv', 'nn', 'ann'];['linear regression', 'machine learning', 'random forest', 'regression', 'model', 'logistic regression', 'k-nearest neighbor', 'gradient boosting', 'predict', 'decision tree', 'classification'];https://www.kaggle.com/c/cat-in-the-dat;0.638;0.387;2020-12-12 17:40:12;multiple data sources;['gpu, classification, healthcare, +1 moregradient boosting'];🎯Tune Hyperparameters for Classification ML Algo;Python notebook;873.0;25;;
2019-08-27 21:08:16;Catboost is known as a convenient and effective tool for handling categorical features. Let's build a Catboost baseline by specifying the categorical feature indices to the model. I have also tried some cyclical and ordinal encoding methods. This is my first try on Catboost. If you have found any mistake, please write your comments below. Thank you very much. This notebook is modified from Why Not Logistic Regression?. Please upvote that notebook first.;Apache 2.0;https://www.kaggle.com/gogo827jz/catboost-baseline-with-feature-importance;1.0;['catboost', 'tensorflow', 'sklearn'];['ai', 'rl', 'dl', 'cv'];['regression', 'train', 'model', 'loss', 'label', 'logistic regression', 'predict'];https://www.kaggle.com/c/cat-in-the-dat;0.734;0.442;2020-12-12 17:40:12;Categorical Feature Encoding Challenge;['gpu'];CatBoost Baseline with Feature Importance;Python notebook;6890.0;48;0.79926;0.80486
2019-09-04 02:36:57;"Welcome to my EDA and Modeling kernel !It's a very cool opportunity to practice and learn from other kagglers about interesting feature encoding techniques and modelling; I hope you enjoy my work and bring me your feedback. If this kernel is useful for you, please don't forget to upvote the kernel NOTE: English is not my native language, so sorry for any mistake. I'm near of Grandmaster tier, so please, if you find this kernel useful don't forget to UPVOTE!!!!  =)";Apache 2.0;https://www.kaggle.com/kabure/eda-feat-engineering-encode-conquer;1.0;['pattern', 'catboost', 'xgboost', 'sklearn'];['ai', 'dl', 'gbm', 'cv', 'rl', 'nn', 'ml'];['filter', 'machine learning', 'regression', 'training data', 'train', 'fitting', 'model', 'test data', 'loss', 'label', 'logistic regression', 'predict', 'recommend', 'classification'];https://www.kaggle.com/c/cat-in-the-dat;0.749;0.58;2020-12-12 17:40:12;Categorical Feature Encoding Challenge;['beginner, data visualization, exploratory data analysis'];EDA & Feat Engineering - Encode & Conquer ;Python notebook;9998.0;326;0.77498;0.78097
2019-11-28 14:48:34;Problem Statement:- A common task in machine learning pipelines is encoding categorical variables for a given algorithm in a format that allows as much useful signal as possible to be captured. We have to handle different types of categorical data columns using multiple techniques in order to get best results.  Lets begin. Types of categorical data given to us  binary features low- and high-cardinality nominal features low- and high-cardinality ordinal features (potentially) cyclical features;Apache 2.0;https://www.kaggle.com/ruchibahl18/categorical-data-encoding-techniques;1.0;['tensorflow', 'catboost', 'xgboost', 'sklearn'];['ai', 'dl', 'cv', 'rl', 'nn', 'ann'];['machine learning', 'training data', 'regression', 'test data', 'train', 'fitting', 'model', 'random forest', 'label', 'logistic regression', 'predict', 'decision tree', 'classification', 'naive bayes'];https://www.kaggle.com/c/cat-in-the-dat;0.679;0.383;2020-12-12 17:40:12;Categorical Feature Encoding Challenge;['beginner, classification, feature engineering'];Categorical Data encoding techniques;Python notebook;1940.0;24;0.79493;0.80038
2020-08-31 07:59:31;IntroductionInspired by this article and the repo, I have created the following kernel:  Benchmarking Categorical Encoders  CategoricalEncodingBenchmark   Let's see how these methods work in this dataset. Discussion  no feature preprocessing Use KFold(5) for CV (+ more fold get better score) LR (C=0.1, solver=lbfgs)    Encoder LB Score     TE 0.78018   WOE 0.78861   LOOE 0.79382   James-Stein 0.77843   Catboost 0.79164   One-Hot(another my kernel) 0.77973    Category-Encoders Label Encoder One-Hot Encoder Sum Encoder Helmert Encoder Frequency Encoder Target Encoder M-Estimate Encoder Weight Of Evidence Encoder James-Stein Encoder Leave-one-out Encoder Catboost Encoder    Validation (Benchmark)  single LR LR with Cross Validation   Submit;Apache 2.0;https://www.kaggle.com/subinium/11-categorical-encoders-and-benchmark;1.0;['catboost', 'sklearn'];['ai', 'dl', 'rl', 'cv', 'ml'];['linear regression', 'training data', 'test data', 'regression', 'train', 'fitting', 'model', 'label', 'logistic regression', 'predict', 'recommend', 'classification'];https://www.kaggle.com/c/cat-in-the-dat;0.749;0.481;2020-12-12 17:40:12;Categorical Feature Encoding Challenge;['exploratory data analysis, data cleaning'];11 Categorical Encoders and Benchmark ;Python notebook;9946.0;78;;
2019-10-10 16:50:33;The recipe for today is just doing One-Hot most columns and Thermometer encoding of some ordinal columns. Finally, we apply plain Logistic Regression. Did anyone have success with more complex methods? Please let us know!;Apache 2.0;https://www.kaggle.com/superant/oh-my-cat;1.0;['sklearn'];['ner', 'ai', 'cv'];['regression', 'train', 'model', 'logistic regression', 'predict'];https://www.kaggle.com/c/cat-in-the-dat;0.729;0.489;2020-12-12 17:40:12;Categorical Feature Encoding Challenge;[];OH my Cat;Python notebook;6085.0;87;0.80260;0.80818
2019-11-04 06:40:09;About This KernelHello, kagglers! In this kernel, we are going to fight with categorical variables with some exciting feature encoding techniques and modeling. I hope you enjoy my work and bring me your feedback. If this kernel is useful for you, please don't forget to upvote the kernel and You may ask any question if you have, Let's get started: Vikas Singh, Happy Learning!!;Apache 2.0;https://www.kaggle.com/vikassingh1996/handling-categorical-variables-encoding-modeling;1.0;['xgboost', 'sklearn'];['ai', 'dl', 'gbm', 'cv', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'regression', 'test data', 'train', 'fitting', 'model', 'loss', 'label', 'logistic regression', 'gradient boosting', 'predict', 'classification', 'labeled'];https://www.kaggle.com/c/cat-in-the-dat;0.698;0.452;2020-12-12 17:40:12;Categorical Feature Encoding Challenge;['exploratory data analysis, classification, feature engineering, +2 moredata cleaning, categorical data'];Handling Categorical Variables:Encoding & Modeling;Python notebook;2954.0;54;;
2020-10-17 09:44:52;Welcome to the great Categorical Feature Encoding Challenge #2This notebook is a starter code for all beginners and easy to understand. I used the following notebook to improve knowledge about encoding: https://www.kaggle.com/shahules/an-overview-of-encoding-techniques Additionally there are created new features based on the relationsship between the nominal features.  It is used the XGB Classifier with a simple setting and great results.;Apache 2.0;https://www.kaggle.com/drcapa/categorical-feature-engineering-2-xgb;1.0;['xgboost', 'sklearn'];['dl', 'ner', 'ai', 'nn'];['test data', 'train', 'model', 'label', 'predict', 'labeled'];https://www.kaggle.com/c/cat-in-the-dat-ii;0.654;0.39;2020-12-12 17:42:12;Categorical Feature Encoding Challenge II;['exploratory data analysis, classification, feature engineering'];Categorical_Feature_Engineering_2_XGB;Python notebook;1177.0;26;0.77407;0.77315
2020-07-24 13:26:47;This kernel shows you how to find the best combination of three methods using a visual approach.In machine learning, mixtures of different models are often used to reduce variance. This raises the question of the best mix. Several points make the answer difficult.  The mixture can only be determined in the training data set but not in the test data set.  Finding the best mix for several models is problematic because of the dimensionality, since a maximum of three dimensions can be represented - perhaps four or more dimensions due to different colours and shapes.    In this kernel I will show you how to find a good mix with three different methods using the cat2 competition dataset.;Apache 2.0;https://www.kaggle.com/frankmollard/finding-the-optimal-weight-between-three-models;1.0;['xgboost', 'h2o'];['ai', 'dl', 'automl', 'nn', 'ml'];['machine learning', 'training data', 'test data', 'train', 'model', 'epoch', 'rectifier', 'predict', 'rank', 'naive bayes'];https://www.kaggle.com/c/cat-in-the-dat-ii;0.662;0.405;2020-12-12 17:42:12;Categorical Feature Encoding Challenge II;['neural networks, logistic regression, ensembling, +1 morenaive bayes'];Finding the optimal weight between three models ⚗️;R notebook;1387.0;31;0.77600;0.77424
2020-01-10 15:26:30;TensorFlow for tabular data (with categorical variables)This notebook applies TensorFlow / Keras tecniques for tabular data as described in:  https://github.com/lmassaron/deep_learning_for_tabular_data https://www.kaggle.com/lucamassaron/deep-learning-for-tabular-data  and as presented at various meetups and Google DevFests:  https://www.youtube.com/watch?v=nQgUt_uADSE  In particular, in the code you will find different data pipelines drafted for binary, high cardinality nominal, low cardinality nominal, ordinal, dates. The code is fully commented for you to explore and experiment, and, more important, it will be regularly updated during the competition with furthermore feature creation and more performing neural architectures.;Apache 2.0;https://www.kaggle.com/lucamassaron/categorical-feature-encoding-with-tensorflow;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'rl', 'cv', 'nn'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/cat-in-the-dat-ii;0.708;0.423;2020-12-12 17:42:12;Categorical Feature Encoding Challenge II;['gpu'];Categorical Feature Encoding with TensorFlow;Python notebook;3700.0;38;;
2020-02-09 08:13:39;IntroductionField-Aware Factorization is a powerful representation learning. Github here. This notebook demonstrates a way to use libffm binaries into a Kaggle kernel. Release Notes :  V4 : New version with Out-of-Fold V6 : fixed the encoder, previous version was kind of a regularizer :);Apache 2.0;https://www.kaggle.com/ogrellier/libffm-model;1.0;['sklearn'];['ner', 'ai', 'nn', 'cnn'];['r-cnn', 'predict', 'train', 'model', 'label', 'loss'];https://www.kaggle.com/c/cat-in-the-dat-ii;0.659;0.405;2020-12-12 17:42:12;multiple data sources;[];libffm_model;Python notebook;1307.0;31;0.78641;0.78493
2020-02-14 03:52:14;(Embeddings,Target + Keras) + (OHE,Target + Logit)Ideas:  Replace missing values with constant Add number of missing values in row as a feature Apply StandardScaler to created feature Apply Target to features that have many unique values Apply entity embedding layers for other features + Keras Apply OHE for other features + Logit Blend Logit and Keras;Apache 2.0;https://www.kaggle.com/pavelvpster/cat-in-dat-2-embeddings-target-keras;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'rl', 'dl', 'cv'];['filter', 'regression', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'logistic regression', 'predict', 'relu'];https://www.kaggle.com/c/cat-in-the-dat-ii;0.688;0.405;2020-12-12 17:42:12;multiple data sources;['deep learning, classification, logistic regression, +1 morecategorical data'];Cat in dat 2: Embeddings,Target + Keras;Python notebook;2373.0;31;0.78712;0.78586
2020-02-10 19:55:01;This kernel uses Deepfm model from deepctr package Deepfm : Deepfm using deepctr Guo H, Tang R, Ye Y, et al. Deepfm: a factorization-machine based neural network for ctr prediction[J]. arXiv preprint arXiv:1703.04247, 2017.(https://arxiv.org/abs/1703.04247);Apache 2.0;https://www.kaggle.com/siavrez/deepfm-model;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'nn', 'rl'];['activation function', 'filter', 'train', 'model', 'neural network', 'epoch', 'layer', 'loss', 'label', 'predict'];https://www.kaggle.com/c/cat-in-the-dat-ii;0.719;0.442;2020-12-12 17:42:12;Categorical Feature Encoding Challenge II;[];Deepfm model;Python notebook;4758.0;48;0.78776;0.78620
2020-02-23 02:05:14;IntroductionIt's just some minor changes to the great kernel libffm-model with predicting test data in each fold. Please Upvote the original kernel. Last part is a blend of some of best scoring public kernels with libffm predictions. Field-Aware Factorization is a powerful representation learning. Github here.;Apache 2.0;https://www.kaggle.com/siavrez/libffm-stratified-with-blend;1.0;['catboost', 'keras', 'sklearn'];['ner', 'ai', 'cnn', 'nn', 'ann'];['r-cnn', 'test data', 'train', 'model', 'loss', 'label', 'predict', 'rank'];https://www.kaggle.com/c/cat-in-the-dat-ii;0.687;0.383;2020-12-12 17:42:13;multiple data sources;[];Libffm Stratified With Blend;Python notebook;2320.0;24;0.78807;0.78668
2020-01-03 00:56:37;"The AUC of 0.63 is well beyond ""randon"", and could be pretty significant in terms of distinguishing between train and test sets. It's certainly well byond almost perfect 0.5 AUC of the fist Categorical Encoding competition. Let's take a look at what features are the most responsible for the discepancy.";Apache 2.0;https://www.kaggle.com/tunguz/adversicat-ii;1.0;['xgboost', 'sklearn', 'lightgbm'];['ai', 'rl', 'nn', 'gbm'];['train', 'model', 'label', 'filter'];https://www.kaggle.com/c/cat-in-the-dat-ii;0.623;0.379;2020-12-12 17:42:13;multiple data sources;[];Adversicat II;Python notebook;661.0;23;;
2020-01-29 16:21:49;Rapids is an open-source GPU accelerated Data Sceince and Machien Learnign library, developed adn mainatained by Nvidia. It is designed to be compatible with many existing CPU tools, such as Pandas, scikit-learn, numpy, etc. It enables massive acceleration of many data-science and machine learning tasks, oftentimes by a factor fo 100X, or even more. Rapids is still undergoing developemnt, and as of right now it's not availabel in the Kaggle Docker environment. If you are interested in installing and riunning Rapids locally on your own machine, then you shoudl refer to the followong instructions. The first successful install of a Rapids library on kaggle was done by Chris Deotte in the follwiong Digit Recognizer kernel. An improved install version that uses a Kaggle Dataset for install can be found here.  In this kerenl we'll follow that approach.;Apache 2.0;https://www.kaggle.com/tunguz/cats-ii-with-rapids-ridge-regression;1.0;['xgboost', 'lightgbm', 'sklearn', 'pillow', 'tensorflow', 'pattern', 'keras'];['ner', 'ai', 'nlu', 'dl', 'gbm', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'relu', 'predict', 'gru', 'machine learning', 'train', 'clustering', 'classification', 'labeled', 'propagation', 'model', 'layer', 'loss', 'rank', 'bayesian', 'regression', 'generation', 'fitting', 'label'];https://www.kaggle.com/c/cat-in-the-dat-ii;0.69;0.425;2020-12-12 17:42:12;multiple data sources;['gpu'];Cats II with Rapids Ridge Regression;Python notebook;2447.0;39;;
2020-02-14 16:15:26;Welcome to my kernel! This is my 'naive' approach for the Categorical Feature Encoding Challenge II and also one of my first steps in Kaggle platform. This notebook has been implemented during my day-off because of the Coronavirus spread (2019-nCoV)  And as usual, if my work can make you feel excited, help me to upvote this kernel on the right corner 💖💖  P/s: I come from Vietnam, so please ignore my English grammar mistakes through out this notebook 😊😊;Apache 2.0;https://www.kaggle.com/warkingleo2000/first-step-on-kaggle;1.0;['pattern', 'xgboost', 'sklearn'];['ner', 'ai', 'cv', 'rl', 'nn', 'rnn', 'ann'];['filter', 'test data', 'regression', 'train', 'recognition', 'model', 'label', 'logistic regression', 'predict', 'classification'];https://www.kaggle.com/c/cat-in-the-dat-ii;0.719;0.503;2020-12-12 17:42:12;Categorical Feature Encoding Challenge II;['beginner, data visualization, exploratory data analysis, +1 morefeature engineering'];👏First step on Kaggle👏;Python notebook;4748.0;105;;
2017-09-15 15:25:25;This script walks you through how to read the bson data into pandas dataframe, and shows some of the images present in the data.;Apache 2.0;https://www.kaggle.com/arathee2/read-bson-into-pandas-and-start-exploring;1.0;['skimage'];['ai', 'nn', 'ann'];['train'];https://www.kaggle.com/c/cdiscount-image-classification-challenge;0.703;0.34;2020-12-12 17:44:11;Cdiscount’s Image Classification Challenge;[];***Read bson into pandas and start exploring***;Python notebook;3267.0;15;;
2017-09-16 04:30:17;This notebook is just a (very) small improvement over most common baseline. It loads a few images from train and resize it to 8x8 pixels to generate a 64 (8 x 8) feature vector. Then, it uses KNN to find the most similar image on test set. Unfortunatelly, due to limitations on Kernel, only a few test images are classified.;Apache 2.0;https://www.kaggle.com/bguberfain/naive-keras-cdiscount;1.0;['tensorflow', 'keras'];['ner', 'ai', 'rl', 'cv', 'nn'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/cdiscount-image-classification-challenge;0.69;0.352;2020-12-12 17:44:11;Cdiscount’s Image Classification Challenge;[];Naive Keras Cdiscount;Python notebook;2450.0;17;;
2017-09-18 04:15:56;This script will create one folder per category and save all respective images on it. The pattern to each file is  ../input/train/[category]/[_id]-[index].jpg, where index is the position of image on each product.;Apache 2.0;https://www.kaggle.com/bguberfain/not-so-naive-way-to-convert-bson-to-files;1.0;['pattern'];['ai', 'nn', 'ann', 'rl'];['train'];https://www.kaggle.com/c/cdiscount-image-classification-challenge;0.713;0.447;2020-12-12 17:44:11;Cdiscount’s Image Classification Challenge;[];[Not so] Naive way to convert BSON to files;Python notebook;4106.0;51;;
2017-09-29 10:34:06;"Open tensorflow kernel with CLI download, Multi-GPU support and much moreCode @GitHub Just run a VGG-like convnet baseline while you analyze the data! Works on Linux with Python 3.5+. Features:  CLI data download Data validation with SHA256 hash Simple data visualization Train-Valid splitting Low memory footprint data streams Base VGG-like convnet Multi-GPU training with a single argument! TensorBoard training tracking  Quick startInstall tensorflow and 7z. Clone repo and install the requirements git clone https://github.com/Cognexa/cdiscount-kernel && cd cdiscount-kernel pip3 install -r requirements.txt --user Download dataset with kaggle-cli (this may take a while, 3 hours in my case) # requires >57Gb of free space KG_USER=""<YOUR KAGGLE USERNAME"" KG_PASS=""<YOUR KAGGLE PASSWORD>"" cxflow dataset download cdc Or if you have downloaded the data earlier: mkdir data # mv/cp your etracted files to data directory Validate your download and see the example data: # in the root directory (cdiscount-kernel) cxflow dataset validate cdc cxflow dataset show cdc # now see the newly created visual directory Create a random validation split with 10% of the data and start training: cxflow dataset split cdc cxflow train cdc model.n_gpus=<NUMBER OF GPUS TO USE> Observe the training with TensorBoard (note: a summary is written only after each epoch) tensorboard --logdir=log UPDATE [LB 0.65]important: update cxflow and cxflow-tensorflow with pip3 install cxflow cxflow-tensorflow --user --upgrade Main features:  XCeption net (https://arxiv.org/abs/1610.02357) Fast random data access  Resize the data to dataset.size with (this may take a few hours) cxflow dataset resize cdc/xception.yaml cxflow dataset split cdc/xception.yaml Run the training with cxflow train cdc/xception.yaml Training procedure that reached 0.65:  Train with original size, LR 0.0001, 4 middle flow repeats until stalled Fine-tune with 128x128, LR 0.0001, 0.5 dropout, 0.00001 weight decay until stalled Fine-tune as above but with LR 0.00001 (10x smaller)  Tips:  Use small images right away The final GlobalAveragePooling may be a bottleneck Net does not overfit so far, no augmentations needed  Example output: 2017-09-16 00:22:14.000262: INFO    @common         : Creating dataset 2017-09-16 00:22:14.000776: INFO    @common         :   CDCNaiveDataset created 2017-09-16 00:22:14.000777: INFO    @common         : Creating a model 2017-09-16 00:22:20.000724: INFO    @model          :   Creating TF model on 2 GPU devices 2017-09-16 00:22:21.000362: INFO    @cdc_net        : Flatten shape `(?, 8192)` 2017-09-16 00:22:21.000387: INFO    @cdc_dataset    : Loading metadata 2017-09-16 00:22:26.000826: INFO    @cdc_net        : Output shape `(?, 5270)` 2017-09-16 00:22:26.000893: INFO    @cdc_net        : Flatten shape `(?, 8192)` 2017-09-16 00:22:26.000901: INFO    @cdc_net        : Output shape `(?, 5270)` 2017-09-16 00:22:29.000351: INFO    @common         :   CDCNaiveNet created 2017-09-16 00:22:29.000354: INFO    @common         : Creating hooks 2017-09-16 00:22:29.000355: INFO    @common         :   ShowProgress created 2017-09-16 00:22:29.000355: INFO    @common         :   ComputeStats created 2017-09-16 00:22:29.000355: INFO    @common         :   LogVariables created 2017-09-16 00:22:29.000356: INFO    @common         :   LogProfile created 2017-09-16 00:22:29.000356: INFO    @common         :   SaveEvery created 2017-09-16 00:22:29.000356: INFO    @common         :   SaveBest created 2017-09-16 00:22:29.000357: INFO    @common         :   CatchSigint created 2017-09-16 00:22:29.000357: INFO    @common         :   StopAfter created 2017-09-16 00:22:30.000968: INFO    @common         :   WriteTensorBoard created 2017-09-16 00:22:30.000968: INFO    @common         : Creating main loop 2017-09-16 00:22:30.000968: INFO    @common         : Running the main loop 2017-09-16 03:13:01.000457: INFO    @log_variables  : After epoch 1 2017-09-16 03:13:01.000457: INFO    @log_variables  :   train loss mean: 4.243194 2017-09-16 03:13:01.000457: INFO    @log_variables  :   train accuracy mean: 0.320435 2017-09-16 03:13:01.000457: INFO    @log_variables  :   valid loss mean: 3.313541 2017-09-16 03:13:01.000457: INFO    @log_variables  :   valid accuracy mean: 0.434122 2017-09-16 03:13:03.000486: INFO    @save           : Model saved to: ./log/CDCNaiveNet_2017-09-16-00-22-14_ngz6u4_b/model_1.ckpt 2017-09-16 03:13:05.000217: INFO    @save           : Model saved to: ./log/CDCNaiveNet_2017-09-16-00-22-14_ngz6u4_b/model_best.ckpt 2017-09-16 03:13:05.000219: INFO    @log_profile    :   T read data:    1594.948686 2017-09-16 03:13:05.000219: INFO    @log_profile    :   T train:    8347.117133 2017-09-16 03:13:05.000219: INFO    @log_profile    :   T eval: 282.549242 2017-09-16 03:13:05.000219: INFO    @log_profile    :   T hooks:    8.592250 2017-09-16 03:13:05.000219: INFO    @main_loop      : Epochs done: 1 2017-09-16 06:03:17.000103: INFO    @log_variables  : After epoch 2 2017-09-16 06:03:17.000103: INFO    @log_variables  :   train loss mean: 2.952012 2017-09-16 06:03:17.000103: INFO    @log_variables  :   train accuracy mean: 0.480100 2017-09-16 06:03:17.000103: INFO    @log_variables  :   valid loss mean: 2.863293 2017-09-16 06:03:17.000104: INFO    @log_variables  :   valid accuracy mean: 0.496674 2017-09-16 06:03:18.000840: INFO    @save           : Model saved to: ./log/CDCNaiveNet_2017-09-16-00-22-14_ngz6u4_b/model_2.ckpt 2017-09-16 06:03:20.000762: INFO    @save           : Model saved to: ./log/CDCNaiveNet_2017-09-16-00-22-14_ngz6u4_b/model_best.ckpt 2017-09-16 06:03:20.000764: INFO    @log_profile    :   T read data:    1581.478134 2017-09-16 06:03:20.000764: INFO    @log_profile    :   T train:    8342.576470 2017-09-16 06:03:20.000764: INFO    @log_profile    :   T eval: 281.916230 2017-09-16 06:03:20.000764: INFO    @log_profile    :   T hooks:    8.502520 2017-09-16 06:03:20.000764: INFO    @main_loop      : Epochs done: 2  ... AboutThis kernel is written in cxflow-tensorflow, a plugin for cxflow framework. Make sure you check it out! A simple submission script will be added soon, stay tuned!";Apache 2.0;https://www.kaggle.com/blazeka/multi-gpu-tensorflow-convnet-0-65;1.0;['tensorflow'];['ai', 'dl', 'rl', 'nn', 'ml'];['train', 'model', 'epoch', 'vgg', 'loss'];https://www.kaggle.com/c/cdiscount-image-classification-challenge;0.763;0.458;2020-12-12 17:44:11;Cdiscount’s Image Classification Challenge;[];Multi-GPU tensorflow convnet [0.65];Python notebook;14593.0;58;;
2017-09-17 13:04:45;Thank you to inversion, whose code I have modified for importing BSON files. This kernel is to understand how one could structure their data to run it through Tensor Flow. I have only used the train_example.bson data and have not bothered to split the data into train/dev sets as there are only 82 images in this data. This produces very bad results but hopefully you will find it useful! PS: This is my first post.;Apache 2.0;https://www.kaggle.com/cerebrium/multi-class-logistic-regression-using-tensor-flow;1.0;['skimage', 'tensorflow', 'sklearn'];['ai', 'nn', 'ann'];['filter', 'test data', 'regression', 'train', 'model', 'layer', 'gradient descent', 'label', 'logistic regression', 'predict'];https://www.kaggle.com/c/cdiscount-image-classification-challenge;0.749;0.34;2020-12-12 17:44:11;Cdiscount’s Image Classification Challenge;[];Multi-Class Logistic Regression using Tensor Flow ;Python notebook;9938.0;15;;
2017-10-06 11:06:25;This notebook contains a generator class for Keras called BSONIterator that can read directly from the BSON data. You can use it in combination with ImageDataGenerator for doing data augmentation.;Apache 2.0;https://www.kaggle.com/humananalog/keras-generator-for-reading-directly-from-bson;1.0;['tensorflow', 'keras'];['ner', 'ai', 'ml', 'nn', 'ann'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/cdiscount-image-classification-challenge;0.769;0.537;2020-12-12 17:44:11;Cdiscount’s Image Classification Challenge;[];Keras generator for reading directly from BSON;Python notebook;17666.0;168;;
2017-09-15 20:53:21;The bson files for this competition contain a list of dictionaries, one dictionary per product. Each dictionary contains a product id (key: _id), the category id of the product (key: category_id), and between 1-4 images, stored in a list (key: imgs). Each image list contains a single dictionary per image, which uses the format: {'picture': b'...binary string...'}. The bson file can be read and processed iteratively. The following code shows how to read the data from the train_example.bson file.;Apache 2.0;https://www.kaggle.com/inversion/processing-bson-files;1.0;['skimage'];['ner', 'ai', 'nn'];['train', 'test data'];https://www.kaggle.com/c/cdiscount-image-classification-challenge;0.791;0.538;2020-12-12 17:44:11;Cdiscount’s Image Classification Challenge;[];Processing BSON Files;Python notebook;33606.0;170;;
2017-10-08 08:29:27;This notebook showcases a fast way to read data from BSON into a generator for Keras. The idea is strongly inspired from https://www.kaggle.com/humananalog/keras-generator-for-reading-directly-from-bson Since I don't have a SSD, the original Generator is ~3s per batch , I just added the feature to read chunks of file and shuffle into batch to improve speed.;Apache 2.0;https://www.kaggle.com/lamdang/fast-shuffle-bson-generator-for-keras;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'rl', 'cv'];['train', 'recommend', 'label', 'validation data'];https://www.kaggle.com/c/cdiscount-image-classification-challenge;0.655;0.362;2020-12-12 17:44:11;Cdiscount’s Image Classification Challenge;[];Fast shuffle BSON generator for Keras;Python notebook;1216.0;19;;
2017-10-12 18:15:59;Xception model for weight see: https://www.kaggle.com/c/cdiscount-image-classification-challenge/discussion/41021;Apache 2.0;https://www.kaggle.com/mihaskalic/keras-xception-model-0-68-on-pl-weights;1.0;['tensorflow', 'keras'];['ner', 'ai', 'rl'];['train', 'model', 'epoch', 'layer', 'loss', 'predict', 'classification'];https://www.kaggle.com/c/cdiscount-image-classification-challenge;0.739;0.427;2020-12-12 17:44:11;Cdiscount’s Image Classification Challenge;[];Keras Xception model [0.68++ on PL] + weights;Python notebook;7671.0;40;;
2017-11-04 10:13:46;DraftThis Kernel is still being developed;Apache 2.0;https://www.kaggle.com/sophieg/feature-extraction-dig;1.0;['skimage', 'keras', 'sklearn'];['ner', 'ai', 'gan', 'cv', 'rl', 'nn', 'ann'];['image classification', 'filter', 'regression', 'train', 'recognition', 'model', 'deep learning', 'layer', 'support vector machines', 'label', 'logistic regression', 'computer vision', 'classification'];https://www.kaggle.com/c/cdiscount-image-classification-challenge;0.691;0.327;2020-12-12 17:44:11;Cdiscount’s Image Classification Challenge;[];Feature Extraction Dig;Python notebook;2529.0;13;;
2020-12-11 22:31:51;IntroWelcome to the facial expression competition.  The data consists of 48x48 pixel grayscale images of faces. The faces have been automatically registered so that the face is more or less centered and occupies about the same amount of space in each image. The task is to categorize each face based on the emotion shown in the facial expression in to one of seven categories:   categorie emotion     0 Angry   1 Disgust   2 Fear   3 Happy   4 Sad   5 Surprise   6 Neutral    We define a simple CNN model and compare the predicted results with ge given labels. Please vote the notebook up if it helps you. Thank you.;Apache 2.0;https://www.kaggle.com/drcapa/facial-expression-eda-cnn;1.0;['keras', 'sklearn'];['ai', 'nn', 'cnn', 'ml'];['test data', 'train', 'recognition', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge;0.662;0.281;2020-12-12 17:52:11;multiple data sources;['beginner, exploratory data analysis, classification, +2 moreimage data, cnn'];Facial_Expression_EDA_CNN;Python notebook;1382.0;8;;
2020-04-30 15:50:37;Using the Facial Recognition Challenge dataset with fastaiThis is my take on lesson's one and two of the fastai course. I decided to use this library and see how well it will work out of the box on the 2013 facial recognition challenge.;Apache 2.0;https://www.kaggle.com/kaiska/facial-recognition-competition-using-fastai;1.0;['pytorch'];['ner', 'ai', 'dl', 'cnn', 'gan', 'cv', 'rl', 'nn'];['unlabeled', 'filter', 'training data', 'train', 'recognition', 'model', 'neural network', 'validation data', 'deep learning', 'layer', 'label', 'loss', 'resnet', 'classification', 'labeled'];https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge;0.641;0.152;2020-12-12 17:52:11;multiple data sources;[];Facial Recognition Competition Using FastAi;Python notebook;925.0;2;;
2020-10-24 07:51:01;Challenges in Representation Learning: Facial Expression Recognition Challengehttps://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge;Apache 2.0;https://www.kaggle.com/kilean/emotion-detection-accuracy70;1.0;['tensorflow', 'keras', 'pillow'];['ner', 'ai', 'cv', 'ml', 'nn', 'ann'];['train', 'recognition', 'model', 'epoch', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'resnet'];https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge;0.65;0.152;2020-12-12 17:52:11;Challenges in Representation Learning: Facial Expression Recognition Challenge;[];TransferLearning_OverSampling_LabelSmoothing;Python notebook;1104.0;2;;
2020-11-11 09:51:28;Using the Facial Recognition Challenge dataset with fastaiThis is my take on lesson's one and two of the fastai course. I decided to use this library and see how well it will work out of the box on the 2013 facial recognition challenge.;Apache 2.0;https://www.kaggle.com/muhammadumerbhutta/facial-recognition-competition-using-fastai;1.0;['pytorch'];['ner', 'ai', 'dl', 'cnn', 'gan', 'cv', 'rl', 'nn', 'ml'];['unlabeled', 'filter', 'training data', 'train', 'recognition', 'model', 'neural network', 'validation data', 'deep learning', 'layer', 'label', 'loss', 'resnet', 'classification', 'labeled'];https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge;0.477;0.0;2020-12-12 17:52:11;Challenges in Representation Learning: Facial Expression Recognition Challenge;[];Facial Recognition Competition Using FastAi;Python notebook;74.0;0;;
2020-11-04 17:02:24;Interesting fact, the model seems to look for clues mainly around the mouth, gives importance to the cheeks, and also a bit to the forehead. Pretty much what we do as humans !;Apache 2.0;https://www.kaggle.com/omarelmellouki/first-share;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'rl', 'ml', 'nn', 'ann'];['training data', 'test data', 'train', 'fitting', 'model', 'recognition', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'resnet', 'random forest'];https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge;0.483;0.0;2020-12-12 17:52:11;Challenges in Representation Learning: Facial Expression Recognition Challenge;['gpu, beginner, cnn, +1 morekeras'];notebookb7e99bea62;Python notebook;80.0;0;;
2019-06-26 18:22:02;General informationWe all know that feature engineering is the most important things in competitions. If you have deep domain knowledge, you can create better features! Sadly, I have little domain knowledge (last time I paid attention to chemical formulas was in school)... So I'll to create a lot of features and hope that some of them work! Important! I have realized the main problem of features in my previous kernel: I created features based on the whole train/test set, but it makes much more sense to generate features based on molecules (for example mean distance per molecules). Let's try this!  ~Thanks to the new kaggle update we can write code in kernels and import it. This is much more convenient and useful. I'm moving all the functions I can into this script: https://www.kaggle.com/artgor/artgor-utils So if you see somewhere code like artgot_utils.function_name(parameters) - it is from this script~ Important: It seems that after forking the utility script isn't copied, so I have decided to move all the functions back into the kernel. But utility kernel can't be removed from the kernel... I hope I was able to deal with it.;Apache 2.0;https://www.kaggle.com/artgor/brute-force-feature-engineering;1.0;['catboost', 'xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'ml'];['filter', 'training data', 'regression', 'test data', 'train', 'model', 'loss', 'label', 'predict', 'classification'];https://www.kaggle.com/c/champs-scalar-coupling;0.779;0.588;2020-12-12 17:53:35;multiple data sources;[];Brute force feature engineering;Python notebook;23441.0;370;;
2019-07-18 06:29:46;General informationThis kernel is created using data of Predicting Molecular Properties competition. We have information about atom couples in molecules and need to predict scalar_coupling_constant between these atoms.  In this kernel I'll do EDA and will try some approaches to modelling. ~Thanks to the new kaggle update we can write code in kernels and import it. This is much more convenient and useful. I'm moving all the functions I can into this script: https://www.kaggle.com/artgor/artgor-utils So if you see somewhere code like artgot_utils.function_name(parameters) - it is from this script~ Important: It seems that after forking the utility script isn't copied, so I have decided to move all the functions back into the kernel. But utility kernel can't be removed from the kernel... I hope I was able to deal with it.;Apache 2.0;https://www.kaggle.com/artgor/molecular-properties-eda-and-models;1.0;['catboost', 'xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'gbm', 'cv', 'rl', 'nn', 'ml'];['filter', 'training data', 'regression', 'test data', 'train', 'model', 'loss', 'label', 'gradient boosting', 'predict', 'classification'];https://www.kaggle.com/c/champs-scalar-coupling;0.803;0.623;2020-12-12 17:53:35;multiple data sources;['data visualization, exploratory data analysis, feature engineering, +1 moreregression'];Molecular Properties EDA and models;Python notebook;51264.0;666;;
2019-06-26 18:22:24;General informationThis kernel is a continuation of my previous kernels:  EDA feature engineering  In this kernel I'll try to use additional data, which is provided only for train dataset. We have several files with additional features, which have information only for train and not for test. In this kernel I'll show how to create meta-features both train and test and use them.;Apache 2.0;https://www.kaggle.com/artgor/using-meta-features-to-improve-model;1.0;['catboost', 'xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'gbm', 'cv', 'rl', 'ml'];['filter', 'training data', 'regression', 'generation', 'train', 'test data', 'model', 'loss', 'label', 'predict', 'classification'];https://www.kaggle.com/c/champs-scalar-coupling;0.766;0.565;2020-12-12 17:53:35;Predicting Molecular Properties;[];Using meta-features to improve model;Python notebook;16267.0;257;;
2019-06-26 18:23:53;"General informationIn this kernel I focus on various ML approaches:  adversarial validation for selecting stable features; comparing several validation schemes; trying several different models to find which ones are better for this competition; some approaches to feature selection and model interpretation.   Work in progress";Apache 2.0;https://www.kaggle.com/artgor/validation-feature-selection-interpretation-etc;1.0;['catboost', 'xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'gbm', 'cv', 'rl', 'nn', 'ml'];['filter', 'training data', 'regression', 'generation', 'train', 'test data', 'model', 'loss', 'label', 'predict', 'classification'];https://www.kaggle.com/c/champs-scalar-coupling;0.729;0.523;2020-12-12 17:53:35;Predicting Molecular Properties;[];Validation, feature selection, interpretation etc;Python notebook;6036.0;138;;
2019-06-17 05:16:29;Introducing Atom-Centered Symmetry Functions: Application to the prediction of Mulliken chargesGreetings everyone! One thing that you probably noticed in the Predicting Molecular Properties challenge is that the Mulliken charges are only available for the training set. And so are the dipole moments, magnetic shield tensor, potential energies, etc. Therefore, several attempts have been made to try and approximate these properties for the test set (see for instance this kernel by Alexandre). But what if we had a way to machine learn these properties and predict them for all the atoms/molecules of the test set? This would allow us to subsequently use them as input features for the prediction of the scalar coupling. It is actually possible to machine learn these properties using only the structural information contained in the structures.csv file. We do that using descriptors. You may have already heard about these descriptors (maybe because I'm mentioning them in almost all of my posts...) and it's time we took a look at them :) For this kernel I choose to focus on the Mulliken charges, but of course this can be applied to any of the properties mentioned above, however with some subtleties that I will explain. 1. What is a descriptor?The problem that we are facing is how to appropriately represent an atomic environment? In the challenge, we are provided with the cartesian positions of each atom in the molecules. While the cartesian system may seem like a simple and unequivocal descriptor of atomic configurations, it actually suffers a major drawback: the list of coordinates is ordered arbitrarily and two structures might be mapped to each other by a rotation, reflection, or translation so that two different lists of atomic coordinates can, in fact, represent the same or very similar structures. Therefore, a good representation is invariant with respect to permutational, rotational, reflectional, and translational symmetries, while retaining the faithfulness of the cartesian representation. This is what a descriptor does. It is also called the fingerprint of a molecule. During the last decade, a number of different descriptors have been established (and every month a new descriptor pops out, claiming it is superior to all the previous ones...) among which:  The symmetry functions by Behler and Parrinello: Phys. Rev. Lett. 98, 146401 (2007). The bispectrum by Bartok et al.: Phys. Rev. Lett. 104, 136403 (2010). The Coulomb matrix by Rupp et al.: Phys. Rev. Lett. 108, 058301 (2012). And others!  The descriptors can be global or local, depending on whether they represent the entire molecule (global) or the environment around each atom (local). The symmetry functions, bispectrum, and Coulomb matrix are all local descriptors: one descriptor for each atom in the molecule. Depending on the quantity that we want to predict, we will use global or local descriptors. For instance, the Mulliken charge is a local property (since there is one charge for each atom), so that it's better to use a local descriptor. On the contrary, the potential energy of the molecule is a global property, so we might instead use a global descriptor. 2. Atom-Centered Symmetry Functions (ACSF)ACSF are local descriptors that are rather easy to understand and are very powerful because they contain a lot of information on the chemical environment around each atom. They are based on a function called the cutoff function. 2.1. Understanding the cutoff functionThe cutoff function is expressed as follows: fc(Rij)={0.5[cos(πRijRc)+1]forRij≤Rc0forRij>Rc where Rij is the distance between atoms i and j, and if this distance is greater than a cutoff radius Rc, then the cutoff function becomes zero. If maths is not your cup of tea, this function might look barbaric. Let's try to understand it by plotting it for different values of Rc:;Apache 2.0;https://www.kaggle.com/borisdee/predicting-mulliken-charges-with-acsf-descriptors;1.0;['sklearn'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ann'];['filter', 'train', 'fitting', 'model', 'label', 'predict', 'understanding'];https://www.kaggle.com/c/champs-scalar-coupling;0.728;0.536;2020-12-12 17:53:35;multiple data sources;[];Predicting Mulliken Charges With ACSF Descriptors;Python notebook;5952.0;167;;
2019-08-07 07:25:35;Core IdeaDespite a lot of creeping Physics and Chemistry knowledge introduced in the description, this competition is more about Geometry and pattern matching. The hypothesis of this kernel is next:  If we have two similar sets of atoms with the same distances between them and the same types - the scalar coupling constant should be very close. More closest atoms to the pair of atoms under prediction have higher influence on scalar coupling constant then those with higher distance  So, basically, this problem could be dealt with some kind of K-Nearest Neighbor algorithm or any tree-based - e.g. LightGBM, in case we can find some representation which would describe similar configurations with similar feature sets. Each atom is described with 3 cartesian coordinates. This representation is not stable. Each coupling pair is located in a different point in space and two similar coupling sets would have very different X,Y,Z. So, instead of using coordinates let's consider next system:  Take each pair of atoms as two first core atoms Calculate the center between the pair Find all n-nearest atoms to the center (excluding first two atoms) Take two closest atoms from step 3 - they will be 3rd and 4th core atoms Calculate the distances from 4 core atoms to the rest of the atoms and to the core atoms as well  Using this representation each atom position can be described by 4 distances from the core atoms. This representation is stable to rotation and translation. And it's suitable for pattern-matching. So, we can take a sequence of atoms, describe each by 4 distances + atom type(H,O,etc) and looking up for the same pattern we can find similar configurations and detect scalar coupling constant. Here I used LightGBM, because sklearn KNN can't deal with the amount of data. My blind guess is that hand-crafted KNN can outperform LightGBM. Let's code the solution!;Apache 2.0;https://www.kaggle.com/criskiev/distance-is-all-you-need-lb-1-481;1.0;['pattern', 'catboost', 'lightgbm', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'nn', 'ml'];['regression', 'train', 'model', 'label', 'k-nearest neighbor', 'predict'];https://www.kaggle.com/c/champs-scalar-coupling;0.734;0.548;2020-12-12 17:53:35;Predicting Molecular Properties;[];Distance - is all you need. LB -1.481;Python notebook;6742.0;198;-1.47574;-1.48168
2019-08-07 10:16:25;Message Passing Neural NetworkSo, as many of you might have surmised by now the dataset for this challenge is essentially the QM9 dataset with some new values calculated for it. The first thing I though of when seeing this challenge was the Gilmer paper, as it uses the QM9 dataset. (see this talk) The major difference in this challenge is that we are asked to calulate bond properties (thus edges in a graph) as opposed to bulk properties in the paper. Here the model is laid out in a modular way so the parts can easily be replaced;Apache 2.0;https://www.kaggle.com/fnands/1-mpnn;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'nn', 'ml', 'rl'];['gru', 'train', 'model', 'output layer', 'neural network', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/champs-scalar-coupling;0.755;0.539;2020-12-12 17:53:35;multiple data sources;['gpu'];1. MPNN ;Python notebook;11926.0;173;-1.27936;-1.28163
2019-07-22 16:10:17;Predicting Molecular PropertiesVisit my script of this kernel on: https://www.kaggle.com/kabure/lightgbm-full-pipeline-model and if you like it, please upvote the kernel =) DescriptionIn this competition, you will be predicting the scalar_coupling_constant between atom pairs in molecules, given the two atom types (e.g., C and H), the coupling type (e.g., 2JHC), and any features you are able to create from the molecule structure (xyz) files. For this competition, you will not be predicting all the atom pairs in each molecule rather, you will only need to predict the pairs that are explicitly listed in the train and test files. For example, some molecules contain Fluorine (F), but you will not be predicting the scalar coupling constant for any pair that includes F. The training and test splits are by molecule, so that no molecule in the training data is found in the test data.;Apache 2.0;https://www.kaggle.com/kabure/simple-eda-lightgbm-autotuning-w-hyperopt;1.0;['pattern', 'lightgbm', 'sklearn', 'h2o'];['ner', 'ai', 'automl', 'gbm', 'rl', 'nn', 'ml'];['filter', 'training data', 'regression', 'test data', 'train', 'model', 'validation data', 'loss', 'label', 'predict', 'understanding'];https://www.kaggle.com/c/champs-scalar-coupling;0.745;0.542;2020-12-12 17:53:35;multiple data sources;['beginner, exploratory data analysis, model comparison'];Simple EDA - Lightgbm autotuning w/Hyperopt ;Python notebook;8928.0;182;-0.36852;-0.37376
2019-06-01 21:26:18;Predicting Molecular PropertiesCan you measure the magnetic interactions between a pair of atoms? In this competition, you will develop an algorithm that can predict the magnetic interaction between two atoms in a molecule (i.e., the scalar coupling constant).  NOTE : Some (but not all) of the text in this kernel was taken from the competition details. I do this to show exactly what the description and rules are for the competition alongside some exploritory code. Be sure to read the competition details yourself directly from the website here: https://www.kaggle.com/c/champs-scalar-coupling/overview/description.;Apache 2.0;https://www.kaggle.com/robikscube/exploring-molecular-properties-data;1.0;['catboost', 'lightgbm', 'sklearn'];['ner', 'ai', 'gbm', 'cv', 'rl', 'nn', 'ann'];['filter', 'machine learning', 'regression', 'training data', 'train', 'test data', 'model', 'loss', 'label', 'predict', 'classification'];https://www.kaggle.com/c/champs-scalar-coupling;0.737;0.518;2020-12-12 17:53:35;Predicting Molecular Properties;['gpu'];⚛️ Exploring Molecular Properties Data;Python notebook;7438.0;128;;
2019-05-30 04:02:27;In Atomic Distance Benchmark kernel by inversion,  I found '#(there's ways to speed this up!)'. I tried to find the faster way to calculate distance and share it.  Let's research FASTER :) From CPU times: user 7min 19s, sys: 9.25 s, total: 7min 28s  Wall time: 7min 28s  To CPU times: user 412 ms, sys: 828 ms, total: 1.24 s  Wall time: 1.23 s;Apache 2.0;https://www.kaggle.com/seriousran/just-speed-up-calculate-distance-from-benchmark;1.0;['sklearn'];['ner', 'ai'];['train', 'model', 'label'];https://www.kaggle.com/c/champs-scalar-coupling;0.734;0.539;2020-12-12 17:53:35;Predicting Molecular Properties;[];Just speed up calculate distance from Benchmark;Python notebook;6906.0;174;;
2019-07-08 01:01:23;w# Keras Multiple Output Solution Thanks to https://www.pyimagesearch.com/2018/06/04/keras-multiple-outputs-and-multiple-losses/ and https://www.kaggle.com/kmat2019/neural-network-modeling-with-multiple-outputs for the idea on approaching this problem as a multiple output problem.  Though it doesn't seem to be the favored approach for this competition, I feel that there ought to be a good neural network approach.  This kernel tries a multi-layer, dense neural network implemented in Keras.  The advantage of this approach is that it does not seem to be overfitting, which may pay off against the full dataset. Ways to improve:  I'm not a domain expert in the molecular chem field... I strongly suspect that stronger feature engineering would cause this approach to score higher.   Network architecture:  I'm putting a simpler variant forward here with some options commented out.  There are tweaks that could be made to this architecture that will improve the score.  Forcing the model to overfit to gain a better score on the leaderboard does not usually pay off in the end... More epochs.  The more epochs that can be run without overfitting, the better score could be achieved.  My observation is that even after long training epochs, the model seems to still be learning.;Apache 2.0;https://www.kaggle.com/todnewman/keras-neural-net-for-champs;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn'];['filter', 'test data', 'train', 'fitting', 'model', 'neural network', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/champs-scalar-coupling;0.77;0.566;2020-12-12 17:53:35;multiple data sources;['gpu, deep learning, neural networks'];Keras Neural Net for CHAMPS;Python notebook;18196.0;259;-1.06809;-1.07375
2019-08-17 13:30:11;IntroductionI share a simple example which employ SchNet for predicting coupling constants. I hope this kernel helps beginners of DNN and will be used as a starter kit. The core idea is same as Heng's, which employ GNN as a feature exstractor. Two feature vectors are concatenated and thrown into regression header. More details of his idea and discussions can be read in below pages.  Which graph CNN is the best (with starter kit at LB -1.469)?https://www.kaggle.com/c/champs-scalar-coupling/discussion/93972#latest-591759  Due to the limitation of Kaggle kernel, the model in not trained completely in this Kernel. You would achieve better score by continuing training procedure longer.;Apache 2.0;https://www.kaggle.com/toshik/schnet-starter-kit;1.0;['tensorflow'];['ner', 'ai', 'dl', 'cnn', 'nn', 'ml'];['filter', 'training data', 'regression', 'test data', 'train', 'fitting', 'model', 'neural network', 'epoch', 'deep learning', 'layer', 'validation data', 'loss', 'gradient boosting', 'predict', 'relu', 'resnet', 'convolutional neural network'];https://www.kaggle.com/c/champs-scalar-coupling;0.728;0.53;2020-12-12 17:53:35;Predicting Molecular Properties;['gpu'];SchNet Starter Kit;Python notebook;5922.0;153;-1.32279;-1.32705
2020-01-15 12:00:16;Introduction Data preparation Load data Normalization, Reshape and Label encoding Visualize test and train sample   Model Building Split training and valdiation set Define the model architechture Set the optimizer and annealer Data augmentation Train model   Evaluate the model Training and validation curves Visualize Prediction   Prediction and submition Predict and Submit results     1. IntroductionThis kernel is basic start in deep learning. CIFAR-10 (Canadian Institute For Advanced Research) is the type “hello world” dataset of computer vision. This dataset is a collection of images that are commonly used to train machine learning and computer vision algorithms. It is one of the most widely used datasets for machine learning research. The CIFAR-10 dataset contains 60,000 32x32 color images in 10 different classes. The 10 different classes represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. There are 6,000 images of each class. In this competition, your goal is to correctly identify different object from a dataset of tens of thousands of color images.;Apache 2.0;https://www.kaggle.com/faizanurrahmann/cifar-10-object-classification-cnn-keras;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cnn', 'gan', 'rl', 'ml', 'nn', 'ann'];['filter', 'predict', 'relu', 'machine learning', 'training data', 'train', 'epoch', 'activation function', 'classification', 'image classification', 'model', 'neural network', 'layer', 'loss', 'test data', 'fitting', 'deep learning', 'label', 'computer vision', 'convolutional neural network'];https://www.kaggle.com/c/cifar-10;0.744;0.346;2020-12-12 17:54:35;multiple data sources;['gpu'];CIFAR-10 object classification CNN-Keras;Python notebook;8772.0;16;;
2020-06-24 06:36:30;eda to check no of labels of image in test and train data;Apache 2.0;https://www.kaggle.com/karam123/cnn-and-lenet-on-cifar10;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'nn', 'cnn'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/cifar-10;0.551;0.188;2020-12-12 17:54:35;CIFAR-10 - Object Recognition in Images;['exploratory data analysis, deep learning, cnn'];cnn_and_lenet _on_cifar10;Python notebook;207.0;3;;
2020-12-07 04:30:40;ContextAny one who started their Deep learning Journey will mostly start with MNIST or CIFAR 10 as their initial problem set. MNSIT might be very easy for most of the beginers since it is a very small dataset and easy to get good accuracy, with bit of optimizations you can easily acheieve top 10% result. If you find this Kernal helpful , Please Upvote the notebook. That will enchourage me a lot. Thank you :) CIFAR 10I choose CIFAR 10 dataset to experiment my deep learning theory for the below reasons  CIFAR 10 is a bit challenging since it has 60K images, which is a lot for a begginer. The images are compressed so that they can be trained with less computational power. CIFAR 10 is very popular so that if I was struck at some point I can easily get lot of help from community. I dont need to deal with the hasle of downloading and handeling the data by writing python code. The data is readily available in keras datasets so that I can focus on the deep learning algorithm rather than the data cleaning.   KerasI choose Keras as my deep learning framework since it is begginer friendly and the learning keras is very easy. Also lots and lots of online tutorials or articles are written in Keras so its easy to get out if you are struck somewhere. In this notebook you see me using tensorflow.keras instead of keras directly. Either ways its okay, feel free to use tensorflow.keras or keras directly.;Apache 2.0;https://www.kaggle.com/kedarsai/cifar-10-88-accuracy-using-keras;1.0;['pattern', 'tensorflow', 'keras'];['ner', 'ai', 'dl', 'cnn', 'rl', 'nn', 'ml'];['filter', 'machine learning', 'training data', 'test data', 'train', 'fitting', 'model', 'input layer', 'output layer', 'neural network', 'epoch', 'deep learning', 'layer', 'label', 'loss', 'relu'];https://www.kaggle.com/c/cifar-10;0.682;0.362;2020-12-12 17:54:35;CIFAR-10 - Object Recognition in Images;['gpu, deep learning, classification, +2 morecnn, keras'];CIFAR 10 88% Accuracy using Keras;Python notebook;2075.0;19;;
2020-05-25 17:54:07;An experimentation of computer vision challenge for beginer(75% val_accuracy in 25 epochs, and 79% after 50 epochs without data augmentation).The codes of this notebook are taken on keras documentation. I am just crying to give some explaination for that code. I hope that this migth be helpful for you. Table of interest: Introduction Import and Preprocess the data 2.1 Import all required libraries 2.2 Import and preproces of data 2.3 Distribution of data.   Defining the model architecture Using ConVnets Model training Evaluate the model 5.1 Training and validations cuvre 5.2 Score trained model and prediction. 5.3 Confusion matrix. 5.4 Classification report. 5.5 Check for the predictions.   Save model and weights;Apache 2.0;https://www.kaggle.com/roblexnana/cifar10-with-cnn-for-beginer;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'training data', 'train', 'fitting', 'model', 'epoch', 'layer', 'relu', 'loss', 'label', 'predict', 'computer vision', 'classification'];https://www.kaggle.com/c/cifar-10;0.753;0.456;2020-12-12 17:54:35;CIFAR-10 - Object Recognition in Images;['gpu'];cifar10 with CNN for beginer;Python notebook;11074.0;57;;
2020-06-18 19:27:02;In this notebook I am using the Cifar10 dataset to classify various images.  I have coded the traditional LeNet model with some hyper parameter tuning for this purpose. As seen I got 71% accuracy for this model and te model performed well on images it had never seen before. It correctly classified a random image from the internet. Please find the code below;Apache 2.0;https://www.kaggle.com/vikasbhadoria/cifar10-high-accuracy-model-build-on-pytorch;1.0;['pytorch', 'tensorflow', 'keras'];['ner', 'ai', 'rl', 'nn', 'ann'];['filter', 'train', 'fitting', 'model', 'epoch', 'validation data', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/cifar-10;0.754;0.319;2020-12-12 17:54:35;CIFAR-10 - Object Recognition in Images;['cnn, transfer learning'];Cifar10 high accuracy model build on PyTorch;Python notebook;11364.0;12;;
2019-04-14 22:30:34;0. Loading the prerequisites, based on the two previous kernels;Apache 2.0;https://www.kaggle.com/group16/cracking-the-code-difficulty-3;1.0;['pattern'];['ner', 'ai', 'dl', 'rl', 'nn', 'ml'];['train', 'filter'];https://www.kaggle.com/c/ciphertext-challenge-ii;0.64;0.319;2020-12-12 17:55:04;Ciphertext Challenge II;[];Cracking the code: difficulty 3;Python notebook;902.0;12;;
2019-04-02 23:00:19;Finding the conversion pattern in difficulty 2I am able to match cipher texts in difficulty 2 ⇄ plain text, but I still can't find out the algorithm how the text is converted to cipher. Updates (ver 2): Added a new pattern for word 'people';Apache 2.0;https://www.kaggle.com/junkoda/finding-a-pattern-in-difficulty-2;1.0;['pattern'];['ner', 'ai', 'ml', 'nn', 'ann'];['train', 'label'];https://www.kaggle.com/c/ciphertext-challenge-ii;0.591;0.152;2020-12-12 17:55:04;multiple data sources;['exploratory data analysis'];Finding a pattern in difficulty 2;Python notebook;389.0;2;;
2019-08-13 17:11:12;Part I: Load datasets and just do some high-level exploration;Apache 2.0;https://www.kaggle.com/dierickx3/ctiii-level-1;1.0;['pattern'];['ner', 'ai', 'nlu', 'dl', 'gbm', 'cv', 'rl', 'ml', 'nlp', 'nn', 'ann'];['train', 'gru'];https://www.kaggle.com/c/ciphertext-challenge-iii;0.589;0.268;2020-12-12 17:56:23;Ciphertext Challenge III;[];CTIII - Level 1;Python notebook;372.0;7;0.24837;0.24837
2019-08-15 04:02:56;I definitely took some code (how to match decoded and plain strings) from https://www.kaggle.com/tarobxl/cipher-challenge-iii-level-2, and changed to improve performance (Thanks to the awesome flashtext library) Decoding itself comes from my previos Kernel: https://www.kaggle.com/elvenmonk/difficulty-1-reverse-engineering-no-ml I hope it can be useful to speedup cracking next Difficulty levels!;Apache 2.0;https://www.kaggle.com/elvenmonk/ciphertext-challenge-iii-fast-level-1;1.0;['tensorflow'];['ai', 'ml'];['train'];https://www.kaggle.com/c/ciphertext-challenge-iii;0.569;0.152;2020-12-12 17:56:23;Ciphertext Challenge III;[];Ciphertext Challenge III - Fast Level 1;Python notebook;272.0;2;;
2019-08-14 07:15:28;A bit of VisualizationsFirst let's load Competition data.;Apache 2.0;https://www.kaggle.com/elvenmonk/difficulty-1-reverse-engineering-no-ml;1.0;['pattern'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml'];['train', 'test data'];https://www.kaggle.com/c/ciphertext-challenge-iii;0.56;0.188;2020-12-12 17:56:23;Ciphertext Challenge III;[];Difficulty 1 Reverse engineering no ML;Python notebook;236.0;3;;
2019-08-29 08:36:03;Hello everyone! This is my first kernel to ciphering problems, which summaries my understanding and learning from many other kernels and discussions. If you Like the notebook and think that it helped you, please upvote.;Apache 2.0;https://www.kaggle.com/jiaofenx/ciphertext-challenge-iii-simple-eda-and-cracking;1.0;['pattern', 'tensorflow'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml'];['train', 'understanding', 'training data'];https://www.kaggle.com/c/ciphertext-challenge-iii;0.589;0.268;2020-12-12 17:56:23;Ciphertext Challenge III;['beginner'];Ciphertext Challenge III - Simple EDA and Cracking;Python notebook;374.0;7;0.49662;0.49662
2019-09-10 07:02:35;There are already several excellent explorations of the level 1 and 2 ciphers, so I'm not going to retread old ground here: instead, here's a look at levels 3 and 4 ciphers with a few hints that may help to nudge you in the right direction if you're stuck. I've deliberately not included the full solution to either cipher because I don't want to spoil the fun for people who are still working on them. Update September 9th: Now includes solutions! Thank you so much to Team Kaggle for running this competition: I started using pandas literally three weeks ago and this was a really fun way to solidify that knowledge and get some hands-on experience!;Apache 2.0;https://www.kaggle.com/nbzee1/some-hints-for-levels-3-and-4-now-with-solutions;1.0;['pattern'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'nn', 'ml'];['train', 'label', 'test data'];https://www.kaggle.com/c/ciphertext-challenge-iii;0.591;0.281;2020-12-12 17:56:23;multiple data sources;[];Some hints for levels 3 and 4 (now with solutions);Python notebook;389.0;8;;
2019-08-24 10:41:53;[Credit to https://www.kaggle.com/kaggleuser58/cipher-challenge-iii-level-1] IntroductionTime to share solution of cipher level 2 so you can look at the next level.In the previous Cipher Challenge II one of the levels was a cipher with multiple substitutions generated from a key of length 8 if I remember correct. The level 1 of this Cipher Challenge III is the same kind but with a key of length 4, so only 4 substitutions are used for each character mapping. See https://www.kaggle.com/kaggleuser58/cipher-challenge-iii-level-1 The level 2 of this Cipher Challenge III is a transposition cipher on top of level 1. See https://www.kaggle.com/c/ciphertext-challenge-iii/discussion/103969#latest-598262 The cipher The cipher only apllies to UPPERCASE and LOWERCASE letters. The key only shifts every time an UPPERCASE or LOWERCASE letter is met.  PaddingFrom Cipher Challenge II it was found that padding could be done both up front and in the end. Number of padding characters in the end was always equal to or at most 1 character more (if number of characters to pad with was odd) than the number of padding characters up front. Level 1 and level 2 - solution;Apache 2.0;https://www.kaggle.com/tarobxl/cipher-level-1-2-simple-eda-on-level-3-4;1.0;['pattern', 'tensorflow'];['ner', 'ai', 'cv', 'rl', 'nn', 'ml'];['train'];https://www.kaggle.com/c/ciphertext-challenge-iii;0.688;0.397;2020-12-12 17:56:23;Ciphertext Challenge III;[];Cipher Level 1,2 - Simple EDA on Level 3,4;Python notebook;2372.0;28;0.49674;0.49674
2019-02-02 14:22:27;Hello All ! Again back with another kaggle attempt. Taken reference from Cats and Dogs Kernel Using CNN to resolve this problem. Got a score of 0.14294. However still think rounding result might cause problem. Any suggestions welcome :);Apache 2.0;https://www.kaggle.com/ruchibahl18/starting-of-an-end-game;1.0;['tensorflow', 'keras'];['ai', 'nn', 'cnn'];['predict', 'train', 'model', 'epoch', 'layer', 'loss', 'relu'];https://www.kaggle.com/c/conway-s-reverse-game-of-life;0.656;0.214;2020-12-12 17:56:32;Conway's Reverse Game of Life;['gpu'];Starting of an end game ;Python notebook;1238.0;4;0.14366;0.14284
2020-11-29 23:21:20;"Top 10 Position with First Genetic Algorithm on GPU! 🔥How I came up with this solution?For the Kaggle Conway's Reverse Game of Life 2020 competition, I tried many approaches and I also wanted to try something new for me: Genetic Algorithm. I looked up existing Kaggle notebooks using Genetic Algorithm, but none of them were using a GPU accelerator (sorry if I am wrong and missed one). It puzzled me as the GPU is faster than the CPU. I told myself ""challenge accepted, let's make a genetic algorithm on the GPU!"". Implementing this genetic algorithm from scratch was tought but I learned a lot in the process about genetic algorithm (first purpose), but also on pytorch and how to optimize using NVIDIA Nsight. ResultsThis solution performed very well during this competition as this present notebook alone scores in the top-10 leaderboard. This new approach helped improving final solution of our team Under a Penny. I noticed the algorithm is running faster on RTX-2080 than Kaggle's P-100, probably thanks to the newer version of tensor-cores. RequirementsAll we need are :  pytorch to implement the Genetic Algorithm on GPU pandas to load and write .csv files  Implementation";Apache 2.0;https://www.kaggle.com/ebouteillon/top-10-with-first-genetic-algorithm-on-gpu;1.0;['pytorch'];['ner', 'ai', 'rl', 'cv', 'nn'];['generation', 'loss'];https://www.kaggle.com/c/conways-reverse-game-of-life-2020;0.577;0.311;2020-12-12 17:58:02;Conway's Reverse Game of Life 2020;['gpu'];Top 10 with First Genetic Algorithm on GPU! 🔥;Python notebook;307.0;11;0.05416;0.05416
2020-09-05 08:35:41;Task overview/Game RulesThe game consists of a board of cells that are either on or off. One creates an initial configuration of these on/off states and observes how it evolves. There are four simple rules to determine the next state of the game board, given the current state:  #### Overpopulation: if a living cell is surrounded by more than three living cells, it dies. #### Stasis: if a living cell is surrounded by two or three living cells, it survives. #### Underpopulation: if a living cell is surrounded by fewer than two living cells, it dies. #### Reproduction: if a dead cell is surrounded by exactly three cells, it becomes a live cell.;Apache 2.0;https://www.kaggle.com/hasnainajmal281/iterative-cnn-approach;1.0;['pytorch', 'sklearn'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'nn', 'ann'];['predict', 'train', 'model', 'neural network', 'epoch', 'loss', 'relu'];https://www.kaggle.com/c/conways-reverse-game-of-life-2020;0.629;0.327;2020-12-12 17:58:02;Conway's Reverse Game of Life 2020;['gpu'];[CRGL2020] Iterative CNN Approach;Python notebook;739.0;13;0.12742;0.12742
2020-11-27 02:58:22;Game of Life - Hashmap SolverThe theoretical state space for Reverse Game of Life is 2^(25*25) = 1.4*10^188. However there is a 5-step warmup period for the start boards, meaning many possible T=-5 start patterns will naturally die out, thus reducing the state space for practical purposes. We can also take advantage of mirror/rotate/roll/flip symeteries of the board by using geometrically invarient hash functions. This notebook attempts to solve the Reverse Game of Life problem using only dictionary lookup and geometric transforms of the test dataset. UpdateI have updated the code to use a new Geometric Invariant Hash Function function that uses concentric circles rather than lines, and is better able to detect objects seperated by whitespace. I have also written a new Image Segmentation Solver which extends the ideas in this notebook to use image segmentation techniques. This gets a suprising high score of 0.08631 which is almost matches the 0.08549 score of my Z3 Constraint Satisfaction Solver after 1000s of hours of CPU runtime.;Apache 2.0;https://www.kaggle.com/jamesmcguigan/game-of-life-hashmap-solver;1.0;['pytorch', 'pattern'];['ner', 'ai', 'dl', 'gan', 'rl', 'nn', 'ann'];['image segmentation', 'test data', 'training data', 'train', 'neural network', 'loss'];https://www.kaggle.com/c/conways-reverse-game-of-life-2020;0.617;0.311;2020-12-12 17:58:02;multiple data sources;[];Game of Life - Hashmap Solver;Python notebook;598.0;11;0.14502;0.14502
2020-11-30 23:36:29;Reverse Game of Life - Z3 Constraint SatisfactionConway's Game of Life is an example of 2D cellular automata. I have previously written an interactive playable demo of the forward version of this game:  https://life.jamesmcguigan.com/  Using the classic ruleset on a 25x25 board with wraparound, the game evolves at each timestep according to the following rules  Overpopulation: if a living cell is surrounded by more than three living cells, it dies. Stasis: if a living cell is surrounded by two or three living cells, it survives. Underpopulation: if a living cell is surrounded by fewer than two living cells, it dies. Reproduction: if a dead cell is surrounded by exactly three cells, it becomes a live cell.  Or expressed algebraicly:  living + 4-8 neighbours = dies living + 2-3 neighbours = lives living + 0-1 neighbour  = dies dead   +   3 neighbours = lives  To reverse the arrow of time:  any living cell must have had living 2-3 neighbours in the previous timestep any dead cell must have had either 0-1 or 4-8 neighbours in the previous timestep any dead cell with distance of greater than 2 from a living cell can be ignored and assumed to have 0 neighbours there are a near infinite number of self-contained patterns could have been born and died out in empty space however for the sake of the competition, ignoring them will greatly reduce the search space    Whilst there have been many proposed solutions involving CNN neural networks (when all you have is a hammer, everything looks like a nail), this is in fact a classic constraint satisfaction problem. Here are some previous examples of using the Z3 library  https://www.kaggle.com/jamesmcguigan/z3-sudoku-solver https://www.kaggle.com/jamesmcguigan/cryptarithmetic-solver;Apache 2.0;https://www.kaggle.com/jamesmcguigan/game-of-life-z3-constraint-satisfaction;1.0;['pytorch', 'pattern'];['ner', 'ai', 'dl', 'cnn', 'gan', 'rl', 'ml', 'nn', 'ann'];['image segmentation', 'training data', 'test data', 'train', 'model', 'neural network', 'layer', 'loss'];https://www.kaggle.com/c/conways-reverse-game-of-life-2020;0.716;0.437;2020-12-12 17:58:02;multiple data sources;[];Game of Life - Z3 Constraint Satisfaction;Python notebook;4423.0;45;0.08410;0.08410
2020-09-02 17:16:02;This notebook is taken from the excellent notebook by @ptyshevs, cnn_v2. That notebook was created for the previous challenge. My changes here were only what is needed to produce a result for the new challenge. A demonstration, if you will. The first part of the notebook uses cython to generate sample games. The NN is then trained on these samples. The given training set isn't used at all!;Apache 2.0;https://www.kaggle.com/jpmiller/demo-cython-generator-and-keras-cnn;1.0;['tensorflow', 'keras'];['ner', 'ai', 'cnn', 'rl', 'nn'];['filter', 'train', 'model', 'epoch', 'layer', 'loss', 'predict', 'relu'];https://www.kaggle.com/c/conways-reverse-game-of-life-2020;0.62;0.319;2020-12-12 17:58:02;Conway's Reverse Game of Life 2020;['gpu'];Demo: Cython generator and Keras CNN;Python notebook;628.0;12;0.13335;0.13335
2020-09-04 04:13:55;The Game of LifeUsing random_forest model to predict the reverse.Thanks for upvote:);Apache 2.0;https://www.kaggle.com/li325040229/the-game-of-life-reverse-with-random-forest;1.0;['xgboost', 'sklearn'];['ai', 'ml'];['predict', 'train', 'model', 'layer', 'loss'];https://www.kaggle.com/c/conways-reverse-game-of-life-2020;0.634;0.327;2020-12-12 17:58:02;multiple data sources;['gpu'];The Game of Life:reverse with Random Forest ;Python notebook;809.0;13;;
2020-12-05 04:08:07;3rd Place Solution Part: BestGuess + OptimizerMain architecture:  Hi all, thanks for the really interesting competition. I quickly want to share my solution. It is split up into 2 main blocks:  BestGuess, which is an iterative neural network approach. It predicts the start state for delta=1. Repeating it delta times for delta>1 And an Optimizer, which picks a random 3x3 reagion in the input, tries every possible combination of the 3x3 grid at once and selects randomly between the ones which produce the lowest score. It is entirely implemented on the GPU.  This approach reached a score of 0.018 before merging.;Apache 2.0;https://www.kaggle.com/markuskarmann/3rd-place-solution-part;1.0;['pattern'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['train', 'model', 'neural network', 'epoch', 'layer', 'loss', 'predict', 'relu', 'ground truth'];https://www.kaggle.com/c/conways-reverse-game-of-life-2020;0.587;0.327;2020-12-12 17:58:02;multiple data sources;['gpu, neural networks, pytorch'];3rd Place Solution Part;Python notebook;364.0;13;;
2020-09-09 14:38:57;Iterative CNN Approach with optimized thresholdsI use the great kernel of Yakubenko Oleksii for model architecture and training. Instead of setting a common threshold of y_pred = (y_pred_continuous > 0.5) for binarizing the predictions, I determine the threshold for each board individually:  Go through a set of possible thresholds [0, 0.1, ..., 1]. Binarize the board according to the threshold, i.e. y_pred = (y_pred_continuous > threshold). Make N steps y_pred_N = make_move(y_pred, N) and compute accuracy(y_pred_N, y_true_N). Note that y_true_N is the input to the neural network, i.e. the state of the game at time N. Use the threshold which maximizes the accuracy.  This kernel uses the cythonized make_board method from here  and here.;Apache 2.0;https://www.kaggle.com/maxjeblick/crgl2020-iterative-cnn-approach-with-postproces;1.0;['pytorch', 'sklearn'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'nn', 'ann'];['predict', 'train', 'model', 'neural network', 'epoch', 'loss', 'relu'];https://www.kaggle.com/c/conways-reverse-game-of-life-2020;0.628;0.346;2020-12-12 17:58:02;Conway's Reverse Game of Life 2020;['gpu'];[CRGL2020] Iterative CNN Approach with  postproces;Python notebook;735.0;16;0.12452;0.12452
2020-09-09 12:08:35;Why CNNs?the fundamental of this problem deals with surrounding blocks. Kernels in CNNs are better suited for this task as they can sense the changes in surrounding blocks. => less filters with added sense of sequences. Adding a sense of Seqence to the NetworkMaybe combine CNN+LSTM or something new;Apache 2.0;https://www.kaggle.com/parmarsuraj99/a-neural-cnn-game-of-life-with-keras;1.0;['tensorflow', 'keras'];['ner', 'ai', 'nn', 'cnn'];['filter', 'train', 'model', 'epoch', 'layer', 'loss', 'lstm', 'predict', 'relu'];https://www.kaggle.com/c/conways-reverse-game-of-life-2020;0.626;0.334;2020-12-12 17:58:02;Conway's Reverse Game of Life 2020;['gpu, beginner, deep learning, +2 morefeature engineering, keras'];A Neural CNN Game of Life with Keras;Python notebook;705.0;14;0.14689;0.14689
2020-09-08 18:43:56;Conway's Reverse Game of Life 2020;Apache 2.0;https://www.kaggle.com/rohitiscute/cnn-conway-s-reverse-game-of-life-2020;1.0;['pattern', 'keras'];['ner', 'ai', 'cnn', 'rl', 'nn'];['filter', 'generation', 'train', 'model', 'epoch', 'layer', 'loss', 'predict', 'relu'];https://www.kaggle.com/c/conways-reverse-game-of-life-2020;0.606;0.302;2020-12-12 17:58:02;Conway's Reverse Game of Life 2020;['exploratory data analysis, cnn, games'];CNN - Conway's Reverse Game of Life 2020;Python notebook;493.0;10;0.13242;0.13242
2020-09-05 05:14:56;VERSIONS V1: One Net (m1) for all delta (2 epochs) with one-step neighbors V2: One Net per (m2) delta (2 epochs) with one-step neighbors V3: One Net per (m2) delta (10 epochs) with one-step neighbors V4: One Net per (m2) delta (10 epochs) with two-step neighbors V5: One Conv Net per (c1) delta (15 epochs) with two-step neighbors;Apache 2.0;https://www.kaggle.com/ulrich07/quick-neighborhood-fe-mlp-keras;1.0;['tensorflow', 'keras'];['ner', 'ai', 'dl', 'cnn', 'rl', 'ml', 'nn', 'ann'];['predict', 'train', 'model', 'epoch', 'layer', 'loss', 'relu'];https://www.kaggle.com/c/conways-reverse-game-of-life-2020;0.657;0.393;2020-12-12 17:58:02;Conway's Reverse Game of Life 2020;['gpu, feature engineering, neural networks, +1 morekeras'];Quick Neighborhood FE + MLP Keras;Python notebook;1243.0;27;0.13346;0.13346
2020-09-03 22:51:15;Task overview/Game RulesThe game consists of a board of cells that are either on or off. One creates an initial configuration of these on/off states and observes how it evolves. There are four simple rules to determine the next state of the game board, given the current state:  #### Overpopulation: if a living cell is surrounded by more than three living cells, it dies. #### Stasis: if a living cell is surrounded by two or three living cells, it survives. #### Underpopulation: if a living cell is surrounded by fewer than two living cells, it dies. #### Reproduction: if a dead cell is surrounded by exactly three cells, it becomes a live cell.;Apache 2.0;https://www.kaggle.com/yakuben/crgl2020-iterative-cnn-approach;1.0;['pytorch', 'sklearn'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'nn', 'ann'];['predict', 'train', 'model', 'neural network', 'epoch', 'loss', 'relu'];https://www.kaggle.com/c/conways-reverse-game-of-life-2020;0.656;0.383;2020-12-12 17:58:02;Conway's Reverse Game of Life 2020;['gpu, beginner, neural networks, +1 morepytorch'];[CRGL2020] Iterative CNN Approach;Python notebook;1225.0;24;0.12853;0.12853
2018-07-24 10:14:57;0. Data Cleaning / Feature engineering;Apache 2.0;https://www.kaggle.com/ashishpatel26/catboost-approach;1.0;['catboost', 'xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'ml', 'gbm'];['predict', 'training data', 'train', 'model', 'label', 'loss'];https://www.kaggle.com/c/costa-rican-household-poverty-prediction;0.635;0.334;2020-12-12 17:59:32;Costa Rican Household Poverty Level Prediction;['gpu'];Catboost approach!!!;Python notebook;820.0;14;0.39177;0.39177
2018-07-27 09:22:46;SummaryWe train LightGBM DART model with early stopping via 5-fold cross-validation for Costa Rican Household Poverty Level Prediction. Interesting observations:  standard deviation of years of schooling and age per household are important features. early stopping and averaging of predictions over models trained during 5-fold cross-valudation improves performance drastically.;Apache 2.0;https://www.kaggle.com/ashishpatel26/feature-importance-of-lightgbm;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'rl', 'gbm'];['filter', 'train', 'fitting', 'model', 'loss', 'label', 'predict'];https://www.kaggle.com/c/costa-rican-household-poverty-prediction;0.802;0.387;2020-12-12 17:59:32;Costa Rican Household Poverty Level Prediction;['gpu'];Feature importance of LightGBM;Python notebook;48446.0;25;0.41310;0.41310
2018-08-14 13:52:35;0. Data Cleaning / Feature engineering;Apache 2.0;https://www.kaggle.com/ashishpatel26/svc-rf-lgbm-xgb;1.0;['xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'gbm', 'cv', 'rl', 'ml'];['training data', 'train', 'model', 'label', 'predict', 'bayesian'];https://www.kaggle.com/c/costa-rican-household-poverty-prediction;0.641;0.334;2020-12-12 17:59:32;multiple data sources;['gpu, random forest, xgboost, +1 moresvm'];SVC+RF+LGBM+XGB;Python notebook;931.0;14;0.43996;0.43996
2018-08-22 22:06:23;This public kernel is just intended to share my investigation on data exploratory. Since i have another private kernel to continue my work on tuning parameter and explorating more features, so this kernel is lack of visualizaton graph for now, i will try to add more explainations in upcoming commit......;Apache 2.0;https://www.kaggle.com/gaxxxx/exploratory-data-analysis-lightgbm;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'rl', 'ml'];['predict', 'train', 'model', 'label', 'loss'];https://www.kaggle.com/c/costa-rican-household-poverty-prediction;0.71;0.429;2020-12-12 17:59:32;Costa Rican Household Poverty Level Prediction;['beginner, exploratory data analysis, classification, +1 morefeature engineering'];Exploratory data analysis + LightGBM;Python notebook;3873.0;41;0.43608;0.43608
2018-07-26 21:50:29;SummaryWe train LightGBM DART model with early stopping via 5-fold cross-validation for Costa Rican Household Poverty Level Prediction. Interesting observations:  standard deviation of years of schooling and age per household are important features. early stopping and averaging of predictions over models trained during 5-fold cross-valudation improves performance drastically.;Apache 2.0;https://www.kaggle.com/ischurov/more-feature-eng-lgb-5-fold-early-stopping;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'rl', 'gbm'];['predict', 'train', 'fitting', 'model', 'loss'];https://www.kaggle.com/c/costa-rican-household-poverty-prediction;0.663;0.352;2020-12-12 17:59:32;Costa Rican Household Poverty Level Prediction;[];More feature eng + LGB + 5-fold early stopping;Python notebook;1418.0;17;;
2018-07-20 16:21:35;The data have 9557 entries, each entry has 143 columns. Most of the data are floats and integers, a few objects. Let's take a look at the objects.;Apache 2.0;https://www.kaggle.com/katacs/data-cleaning-and-random-forest;1.0;['sklearn'];['ai', 'nn', 'cv'];['predict', 'train', 'model', 'random forest', 'classification'];https://www.kaggle.com/c/costa-rican-household-poverty-prediction;0.726;0.437;2020-12-12 17:59:32;Costa Rican Household Poverty Level Prediction;[];Data cleaning and random forest;Python notebook;5556.0;45;0.40089;0.40089
2018-09-10 11:08:57;Do feature engineering to improve LightGBM predictionThis kernel closely follows https://www.kaggle.com/mlisovyi/lighgbm-hyperoptimisation-with-f1-macro, but instead of running hyperparameter optimisation it uses optimal values from that kernel and thus runs faster. Several key points:  This kernel runs training on the heads of housholds only (after extracting aggregates over households). This follows the announced scoring startegy: Note that ONLY the heads of household are used in scoring. All household members are included in test + the sample submission, but only heads of households are scored. (from the data description).  It seems to be very important to balance class frequencies. Without balancing a trained model gives ~0.39 PLB / ~0.43 local test, while adding balancing leads to ~0.42 PLB / 0.47 local test. One can do it by hand, one can achieve it by undersampling. But the simplest (and more powerful compared to undersampling) is to set class_weight='balanced' in the LightGBM model constructor in sklearn API, which will assign different weights to different classes proportional to their representation. Note that a better procedure would be to tune those weights in a CV loop instead of blindly assigning 1/n weights This kernel uses macro F1 score to early stopping in training. This is done to align with the scoring strategy. Categoricals are turned into numbers with proper mapping instead of blind label encoding.  OHE is reversed into label encoding, as it is easier to digest for a tree model. This trick would be harmful for non-tree models, so be careful. idhogar is NOT used in training. The only way it could have any info would be if there is a data leak. We are fighting with poverty here- exploiting leaks will not reduce poverty in any way :) Squared features (SQBXXX and agesq) are NOT used in training. These would be useful for a linear model, but are useless for a tree-based model and only confused it (when bagging and resampling is done) There are aggregations done within households and new features are hand-crafted. Note, that there are not so many features that can be aggregated, as most are already quoted on household level. NEW: There are geographical aggregates calculated from households NEW: Models are build and evaluated in a nested CV loop. This is done to reduce fluctuations in early-stopping criterion as well as to average over several performance estimates. A voting classifier is used to average over several LightGBM models. This allows to get better predictions by bagging/averaging.  The main goal is to do feature engineering;Apache 2.0;https://www.kaggle.com/mlisovyi/feature-engineering-lighgbm-with-f1-macro;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'train', 'fitting', 'model', 'label', 'predict', 'classification'];https://www.kaggle.com/c/costa-rican-household-poverty-prediction;0.728;0.405;2020-12-12 17:59:32;Costa Rican Household Poverty Level Prediction;[];Feature engineering + LighGBM with F1_macro;Python notebook;5907.0;31;;
2018-07-29 12:34:19;Costa Rican Poverty - Distributions and CorrelationsBy Nick Brooks, July 2018 Since most of the feature's true identities are concealed, this notebook focuses on automating the visualization of the distributions and top correlations of around 140 features.;Apache 2.0;https://www.kaggle.com/nicapotato/costa-rican-poverty-distributions-and-corr;1.0;['sklearn'];['ner', 'ai', 'rl', 'nn', 'ann'];['rank', 'label', 'train'];https://www.kaggle.com/c/costa-rican-household-poverty-prediction;0.661;0.357;2020-12-12 17:59:32;Costa Rican Household Poverty Level Prediction;['data visualization, exploratory data analysis'];Costa Rican Poverty - Distributions and Corr;Python notebook;1355.0;18;;
2018-08-03 08:08:07;Challenge The Inter-American Development Bank is asking the Kaggle community for help with income qualification for some of the world's poorest families. Are you up for the challenge?  Here's the backstory: Many social programs have a hard time making sure the right people are given enough aid. It’s especially tricky when a program focuses on the poorest segment of the population. The world’s poorest typically can’t provide the necessary income and expense records to prove that they qualify.;Apache 2.0;https://www.kaggle.com/nikitpatel/hyper-parameter-lgbm-costa-rican;1.0;['catboost', 'xgboost', 'sklearn', 'lightgbm'];['ai', 'gbm', 'cv', 'rl', 'nn'];['predict', 'test data', 'train', 'model', 'label', 'loss', 'bayesian'];https://www.kaggle.com/c/costa-rican-household-poverty-prediction;0.638;0.334;2020-12-12 17:59:32;Costa Rican Household Poverty Level Prediction;['gpu, feature engineering, data cleaning'];Hyper_Parameter_lgbm_Costa Rican;Python notebook;875.0;14;0.41825;0.41825
2018-08-08 15:26:46;Challenge The Inter-American Development Bank is asking the Kaggle community for help with income qualification for some of the world's poorest families. Are you up for the challenge?  Here's the backstory: Many social programs have a hard time making sure the right people are given enough aid. It’s especially tricky when a program focuses on the poorest segment of the population. The world’s poorest typically can’t provide the necessary income and expense records to prove that they qualify.;Apache 2.0;https://www.kaggle.com/nikitpatel/random-grid-bayes-search-cv-for-xgb;1.0;['catboost', 'xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'gbm', 'cv', 'rl', 'nn'];['filter', 'test data', 'train', 'model', 'label', 'predict', 'rank', 'classification', 'bayesian'];https://www.kaggle.com/c/costa-rican-household-poverty-prediction;0.712;0.334;2020-12-12 17:59:32;Costa Rican Household Poverty Level Prediction;['gpu, classification, feature engineering, +1 morexgboost'];Random/Grid/Bayes -Search- CV for XGB  ♻️♻️ ;Python notebook;4011.0;14;0.38769;0.38769
2018-10-30 04:24:58;Exploration Kernel - Costa Rica PovertyMany social programs have a hard time making sure the right people are given enough aid. It’s especially tricky when a program focuses on the poorest segment of the population. The world’s poorest typically can’t provide the necessary income and expense records to prove that they qualify. Beyond Costa Rica, many countries face this same problem of inaccurately assessing social need. A popular algorithm called the Proxy Means Test (or PMT) is used to verify income qualification along with family’s observable household attributes like the material of their walls and ceiling, or the assets found in the home to classify them and predict their level of need. This is an improvement but accuracy remains a problem as the region’s population grows and poverty declines. In this competition, the dataset is shared with similar attributes with an aim to improve the accuracy of household poverty prediction. In this kernel, I have performed exploration, feature engineering, and baseline model.;Apache 2.0;https://www.kaggle.com/shivamb/costa-rica-poverty-exploration-kernel;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'gbm', 'rl', 'nn'];['filter', 'test data', 'train', 'model', 'loss', 'label', 'predict'];https://www.kaggle.com/c/costa-rican-household-poverty-prediction;0.749;0.522;2020-12-12 17:59:32;Costa Rican Household Poverty Level Prediction;['beginner, data visualization, exploratory data analysis'];Costa Rica Poverty Exploration Kernel;Python notebook;10015.0;137;;
2019-05-20 08:38:53;LGMB with random split for early stoppingEdits by Eric Antoine Scuccimarra - This is a fork of  https://www.kaggle.com/mlisovyi/feature-engineering-lighgbm-with-f1-macro, by Misha Losvyi, with a few changes:  The LightGBM models have been replaced with XGBoost and the code has been updated accordingly. I am also fitting VotingClassifiers of RandomForests and ensembling the results of the XGBs with the RFs. Some additional features have been added. Some features which were previously dropped have been retained. Some of the code has been reorganized. Rather than splitting the data once and using the validation data for the LGBM early stopping, I split the data during the training so the entire training set can be trained on. I found that this works better than a k-fold split in this case.  Some additional features were taken from: https://www.kaggle.com/kuriyaman1002/reduce-features-140-84-keeping-f1-score, by Kuriyaman. Notes from Original Kernel (edited by EAS): This kernel closely follows https://www.kaggle.com/mlisovyi/lighgbm-hyperoptimisation-with-f1-macro, but instead of running hyperparameter optimisation it uses optimal values from that kernel and thus runs faster. Several key points:  This kernel runs training on the heads of housholds only (after extracting aggregates over households). This follows the announced scoring startegy: Note that ONLY the heads of household are used in scoring. All household members are included in test + the sample submission, but only heads of households are scored. (from the data description). However, at the moment it seems that evaluation depends also on non-head household members, see https://www.kaggle.com/c/costa-rican-household-poverty-prediction/discussion/61403#360115. In practise, ful prediction gives ~0.4 PLB score, while replacing all non-head entries with class 1 leads to a drop down to ~0.2 PLB score It seems to be very important to balance class frequencies. Without balancing a trained model gives ~0.39 PLB / ~0.43 local test, while adding balancing leads to ~0.42 PLB / 0.47 local test. One can do it by hand, one can achieve it by undersampling. But the simplest (and more powerful compared to undersampling) is to set class_weight='balanced' in the LightGBM model constructor in sklearn API. This kernel uses macro F1 score to early stopping in training. This is done to align with the scoring strategy. Categoricals are turned into numbers with proper mapping instead of blind label encoding.  OHE if reversed into label encoding, as it is easier to digest for a tree model. This trick would be harmful for non-tree models, so be careful. idhogar is NOT used in training. The only way it could have any info would be if there is a data leak. We are fighting with poverty here- exploiting leaks will not reduce poverty in any way :) There are aggregations done within households and new features are hand-crafted. Note, that there are not so many features that can be aggregated, as most are already quoted on household level. A voting classifier is used to average over several LightGBM models;Apache 2.0;https://www.kaggle.com/skooch/xgboost;1.0;['xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'dl', 'gbm', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'training data', 'test data', 'random forest', 'train', 'fitting', 'model', 'validation data', 'loss', 'label', 'predict', 'rank', 'decision tree', 'classification'];https://www.kaggle.com/c/costa-rican-household-poverty-prediction;0.714;0.403;2020-12-12 17:59:32;Costa Rican Household Poverty Level Prediction;[];XGBoost;Python notebook;4161.0;30;;
2018-07-24 02:45:05;OverviewThe purpose of this kernel is to take a look at the data, come up with some insights, and attempt to create a predictive model or two. This notebook is still very raw - the first few EDA sections have been decently explored/formatted, but the latter predictive sections are completely uncommented. I hope to work on those as my, very limited, time permits. PackagesFirst, let's load a few useful Python packages. This section will keep growing in subsequent versions of this EDA.;Apache 2.0;https://www.kaggle.com/tunguz/eda-model;1.0;['xgboost', 'sklearn', 'lightgbm'];['ai', 'rl', 'gbm'];['predict', 'train', 'model', 'label', 'loss'];https://www.kaggle.com/c/costa-rican-household-poverty-prediction;0.677;0.371;2020-12-12 17:59:32;Costa Rican Household Poverty Level Prediction;[];EDA + Model;Python notebook;1875.0;21;0.39328;0.39328
2018-08-19 23:17:11;"Costa Rican Household Poverty Level PredictionWelcome to another Kaggle challenge! The objective of the Costa Rican Household Poverty Level Prediction contest is to develop a machine learning model that can predict the poverty level of households using both individual and household characteristics. This ""data science for good"" project offers the opportunity to put our skills towards a task more beneficial to society than getting people to click on ads! In this notebook, we will walk through a complete machine learning solution: first, get introduced to the problem, then perform a thorough Exploratory Data Analysis of the dataset, work on feature engineering, try out multiple machine learning models, select a model, work to optimize the model, and finally, inspect the outputs of the model and draw conclusions. __While this notebook may not get us to the top of the leaderboard, it is meant to be used as a teaching tool to give you a solid foundation to build on for future machine learning projects. Kaggle projects can teach us a lot about machine learning, but several of the strategies used to get to the very top of the leaderboard are not best practices, so here we'll stick to building a very good - although not quite first place - machine learning solution. While Kaggle projects are competitions, I think they are best described as ""a machine learning education"" disguised as a contest!"" If you are looking to follow-up on this work, I have additional work including a kernel on using Automated Feature Engineering with Featuretools for this problem (with slightly higher leaderboard score). (If you enjoy my writing style and explanations, I write for Towards Data Science) Problem and Data ExplanationThe data for this competition is provided in two files: train.csv and test.csv. The training set has 9557 rows and 143 columns while the testing set has 23856 rows and 142 columns. Each row represents one individual and each column is a feature, either unique to the individual, or for the household of the individual. The training set has one additional column, Target, which represents the poverty level on a 1-4 scale and is the label for the competition. A value of 1 is the most extreme poverty. This is a supervised multi-class classification machine learning problem:  Supervised: provided with the labels for the training data Multi-class classification: Labels are discrete values with 4 classes  ObjectiveThe objective is to predict poverty on a household level. We are given data on the individual level with each individual having unique features but also information about their household. In order to create a dataset for the task, we'll have to perform some aggregations of the individual data for each household. Moreover, we have to make a prediction for every individual in the test set, but ""ONLY the heads of household are used in scoring"" which means we want to predict poverty on a household basis. Important note: while all members of a household should have the same label in the training data, there are errors where individuals in the same household have different labels. In these cases, we are told to use the label for the head of each household, which can be identified by the rows where parentesco1 == 1.0. We will cover how to correct this in the notebook (for more info take a look at the competition main discussion). The Target values represent poverty levels as follows: 1 = extreme poverty  2 = moderate poverty  3 = vulnerable households  4 = non vulnerable households   The explanations for all 143 columns can be found in the competition documentation, but a few to note are below:  Id: a unique identifier for each individual, this should not be a feature that we use!  idhogar: a unique identifier for each household. This variable is not a feature, but will be used to group individuals by household as all individuals in a household will have the same identifier. parentesco1: indicates if this person is the head of the household. Target: the label, which should be equal for all members in a household  When we make a model, we'll train on a household basis with the label for each household the poverty level of the head of household. The raw data contains a mix of both household and individual characteristics and for the individual data, we will have to find a way to aggregate this for each household. Some of the individuals belong to a household with no head of household which means that unfortunately we can't use this data for training. These issues with the data are completely typical of real-world data and hence this problem is great preparation for the datasets you'll encounter in a data science job! MetricUltimately we want to build a machine learning model that can predict the integer poverty level of a household. Our predictions will be assessed by the Macro F1 Score. You may be familiar with the standard F1 score for binary classification problems which is the harmonic mean of precision and recall: F1=21recall+1precision=2⋅precision⋅recallprecision+recallF1=21recall+1precision=2⋅precision⋅recallprecision+recall For mutli-class problems, we have to average the F1 scores for each class. The macro F1 score averages the F1 score for each class without taking into account label imbalances. Macro F1=F1 Class 1+F1 Class 2+F1 Class 3+F1 Class 44Macro F1=F1 Class 1+F1 Class 2+F1 Class 3+F1 Class 44 In other words, the number of occurrences of each label does not figure into the calculation when using macro (while it does when using the ""weighted"" score). (For more information on the differences, look at the Scikit-Learn Documention for F1 Score or this Stack Exchange question and answers. If we want to assess our performance, we can use the code: from sklearn.metrics import f1_score f1_score(y_true, y_predicted, average = 'macro`) For this problem, the labels are imbalanced, which makes it a little strange to use macro averaging for the evaluation metric, but that's a decision made by the organizers and not something we can change! In your own work, you want to be aware of label imbalances and choose a metric accordingly. RoadmapThe end objective is a machine learning model that can predict the poverty level of a household. However, before we get carried away with modeling, it's important to understand the problem and data. Also, we want to evaluate numerous models before choosing one as the ""best"" and after building a model, we want to investigate the predictions. Our roadmap is therefore as follows:  Understand the problem (we're almost there already) Exploratory Data Analysis Feature engineering to create a dataset for machine learning Compare several baseline machine learning models Try more complex machine learning models Optimize the selected model Investigate model predictions in context of problem Draw conclusions and lay out next steps   The steps laid out above are iterative meaning that while we will go through them one at a time, we might go back to an earlier step and revisit some of our decisions. In general, data science is a non-linear pracice where we are constantly evaluating our past decisions and making improvements. In particular, feature engineering, modeling, and optimization are steps that we often repeat because we never know if we got them right the first time! Getting StartedWe have a pretty good grasp of the problem, so we'll move into the Exploratory Data Analysis (EDA) and feature engineering. For the EDA we'll examine any interesting anomalies, trends, correlations, or patterns that can be used for feature engineering and for modeling. We'll make sure to investigate our data both quantitatively (with statistics) and visually (with figures). Once we have a good grasp of the data and any potentially useful relationships, we can do some feature engineering (the most important part of the machine learning pipeline) and establish a baseline model. This won't get us to the top of the leaderboard, but it will provide a strong foundation to build on! With all that info in mind (don't worry if you haven't got all the details), let's get started!";Apache 2.0;https://www.kaggle.com/willkoehrsen/a-complete-introduction-and-walkthrough;1.0;['xgboost', 'lightgbm', 'catboost', 'sklearn', 'pattern'];['ner', 'ai', 'dl', 'gbm', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'reward', 'predict', 'machine learning', 'training data', 'train', 'clustering', 'classification', 'naive bayes', 'model', 'neural network', 'layer', 'loss', 'rank', 'decision tree', 'bayesian', 'test data', 'regression', 'fitting', 'validation data', 'label', 'gradient boosting', 'random forest'];https://www.kaggle.com/c/costa-rican-household-poverty-prediction;0.8;0.578;2020-12-12 17:59:32;Costa Rican Household Poverty Level Prediction;['beginner, data visualization, exploratory data analysis, +1 moreclassification'];A Complete Introduction and Walkthrough ;Python notebook;45523.0;316;0.42736;0.42736
2018-08-29 22:46:04;Featuretools for GoodIn this notebook, we will implement automated feature engineering with Featuretools for the Costa Rican Household Poverty Challenge. The objective of this data science for good problem is to predict the poverty of households in Costa Rica. Automated Feature EngineeringAutomated feature engineering should be a default part of your data science workflow. Manual feature engineering is limited both by human creativity and time constraints but automated methods have no such constraints. At the moment, Featuretools is the only open-source Python library available for automated feature engineering. This library is extremely easy to get started with and very powerful (as the score from this kernel illustrates). For anyone new to featuretools, check out the documentation or an introductory blog post here.;Apache 2.0;https://www.kaggle.com/willkoehrsen/featuretools-for-good;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'nn'];['filter', 'machine learning', 'training data', 'train', 'fitting', 'model', 'validation data', 'label', 'gradient boosting', 'predict', 'bayesian'];https://www.kaggle.com/c/costa-rican-household-poverty-prediction;0.753;0.48;2020-12-12 17:59:32;Costa Rican Household Poverty Level Prediction;['beginner, feature engineering'];Featuretools for Good;Python notebook;11180.0;77;0.42867;0.42867
2020-04-03 00:23:03;COVID-19: Effect of temperature/humidity with visualizationThis kernel is inspired by the kernel COVID-19: Additional Statistics by @fanconic & @winterpierre91, which uses additional dataset to survey corona spread. Since it included global wheather information, I would like to focus on the relationship between wheather & corona to see if it has any effect or not. In conclusion, I could not find big relationship so far. In other words, corona's spread may not stop easily even though the global world temperature increases from April... [Note] weather information is until March 21, so this kernel investigates only until then. I might update this kernel to use daily updated wheather information if there's demand.;Apache 2.0;https://www.kaggle.com/corochann/covid-19-effect-of-temperature-humidity;1.0;['catboost', 'xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'gbm', 'rl', 'nn', 'ml'];['model'];https://www.kaggle.com/c/covid19-global-forecasting-week-1;0.726;0.429;2020-12-12 18:11:58;multiple data sources;['data visualization'];COVID-19: Effect of temperature/humidity;Python notebook;5659.0;41;;
2020-04-02 05:32:03;Introduction (Although it doesn't need any) Corona Virus Coronaviruses are zoonotic viruses (means transmitted between animals and people).   Symptoms include from fever, cough, respiratory symptoms, and breathing difficulties.  In severe cases, it can cause pneumonia, severe acute respiratory syndrome (SARS), kidney failure and even death. Coronaviruses are also asymptomatic, means a person can be a carrier for the infection but experiences no symptoms  Novel coronavirus (nCoV) A novel coronavirus (nCoV) is a new strain that has not been previously identified in humans.  COVID-19 (Corona Virus Disease 2019) Caused by a SARS-COV-2 corona virus.   First identified in Wuhan, Hubei, China. Earliest reported symptoms reported in November 2019.  First cases were linked to contact with the Huanan Seafood Wholesale Market, which sold live animals.  On 30 January the WHO declared the outbreak to be a Public Health Emergency of International Concern;Apache 2.0;https://www.kaggle.com/deepakdeepu8978/covid-19-analysis-eda-forecasting;1.0;['statsmodels'];['ner', 'ai', 'rl', 'cv'];['filter', 'training data', 'test data', 'train', 'model', 'validation data', 'label', 'predict'];https://www.kaggle.com/c/covid19-global-forecasting-week-1;0.759;0.535;2020-12-12 18:11:58;multiple data sources;['data visualization, exploratory data analysis, data cleaning, +1 morechina '];COVID-19:Analysis+EDA+Forecasting;Python notebook;13088.0;163;;
2020-03-29 15:58:54;Global Covid-19 Forecasting using a Random ForestThis is a very simple starter submission kernel using a random forest. Feature engineering and tuning will help performance. As it turns out, it is very tough to make a RF algorithm properly extrapolate. Given the decision tree structure, conditional statements which recursively split the intpu space. There are ways to get random forests to predict values that fall outside the range of values of the targets in the training set, however I haven't become privy to these techniques. Take a look at the following: https://www.statworx.com/de/blog/time-series-forecasting-with-random-forest/Nevertheless, I will leave this notebook posted as an illustration, and we can consider week 1's submission as a bit of an experiment :-);Apache 2.0;https://www.kaggle.com/dferhadi/global-forecasting-covid-19-random-forest;1.0;['sklearn'];['ai', 'nn', 'rl'];['test data', 'train', 'model', 'predict', 'decision tree', 'random forest'];https://www.kaggle.com/c/covid19-global-forecasting-week-1;0.705;0.383;2020-12-12 18:11:58;multiple data sources;[];Global Forecasting Covid-19 Random Forest;Python notebook;3429.0;24;;
2020-03-26 00:20:34;Visualization of some Additional StatisticsThis kernel is based on:  https://www.kaggle.com/jasonbenner/lets-try-xgboost-simple https://www.kaggle.com/abhinand05/covid-19-digging-a-bit-deeper;Apache 2.0;https://www.kaggle.com/fanconic/covid-19-additional-statistics;1.0;['statsmodels', 'xgboost', 'sklearn'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['test data', 'regression', 'train', 'model', 'predict', 'rank', 'decision tree', 'random forest', 'ground truth'];https://www.kaggle.com/c/covid19-global-forecasting-week-1;0.712;0.416;2020-12-12 18:11:58;multiple data sources;[];COVID-19: Additional Statistics;Python notebook;4012.0;35;2.42652;3.18379
2020-03-21 08:42:18;STATISTICAL APPROACH FOR MAKING PREDICTIONS OF CONFIRMED INFECTION AND DEATHS ON CORONA VIRUSI will be reimplementing the model proposed by researchers from TU Eindhoven in this notebook. They proposed to fit a simple sigmoid function to each of the measurements of a country:  with M the maximal number of cases, 𝛼 the number of days at which the expected number of counts is half way the maximum,and 𝛽 > 0 the growth parameter. Special caution should be taken with exponential models such as these though... I am not saying that this is the ideal approach, I am merely replicating their study !!! IMPORTANT: The public test set overlaps with the training set !!! We have to filter out data from after 11/03 in order to get an accurate public LB score;Apache 2.0;https://www.kaggle.com/group16/sigmoid-per-country-no-leakage;1.0;['sklearn'];['ai', 'rl'];['train', 'model', 'filter', 'predict'];https://www.kaggle.com/c/covid19-global-forecasting-week-1;0.708;0.427;2020-12-12 18:11:58;COVID19 Global Forecasting (Week 1);[];Sigmoid per country;Python notebook;3629.0;40;3.44644;1.36634
2020-03-26 00:06:05;INTRODUCTION:This is a very simple implementation of XGBoost for this data. One of the great features of XGBoost is that it has built in functionality to easily see the top features F score. This means we can add a lot of features to the model and then easily see what really makes a difference in prediction. This is extremely important for this challenge since it is not really about the leaderboard results, it is more about determining useful features for models. I am working on collecting publicly available datasets to continue to add in new variables (features) to see what might be useful.;Apache 2.0;https://www.kaggle.com/jasonbenner/lets-try-xgboost-simple-w-added-features;1.0;['xgboost', 'sklearn'];['ner', 'ai', 'dl', 'gan', 'rl', 'nn'];['train', 'model', 'test data', 'predict'];https://www.kaggle.com/c/covid19-global-forecasting-week-1;0.709;0.435;2020-12-12 18:11:58;multiple data sources;['covid19, xgboost'];Lets try XGBoost Simple W/Added Features;Python notebook;3739.0;44;2.65384;2.00254
2020-04-25 19:08:36;Content About the Competition Objective of the Competition About the kernel(Key Takeaways)   Importing the necessary Packages Exploratory Data Analysis Disease spread over the countries Cases Confirmed Vs Fatalities across Countries Forecasting Confirmed Cases and Fatality Rate   Survival Probability and Hazard Rate Inside Story of each Countries China Italy Iran South Korea   Observation and the big Question References Predicition;Apache 2.0;https://www.kaggle.com/pradeepmuniasamy/covid19-inside-story-of-each-countries;1.0;['pattern', 'sklearn'];['ner', 'ai', 'dl', 'rl', 'nn', 'ann'];['test data', 'regression', 'train', 'model', 'label', 'predict', 'random forest', 'ground truth'];https://www.kaggle.com/c/covid19-global-forecasting-week-1;0.736;0.486;2020-12-12 18:11:58;multiple data sources;['data visualization, exploratory data analysis, healthcare'];COVID19- Inside Story of each Countries;Python notebook;7137.0;84;;
2020-06-05 23:01:10;For LSTM model you can click on the below link:  https://www.kaggle.com/yashgoyal401/advanced-visualizations-and-predictions-with-lstm;Apache 2.0;https://www.kaggle.com/yashgoyal401/less-code-accurate-result-best-predictions;1.0;['sklearn'];['ai'];['train', 'model', 'lstm', 'predict', 'random forest'];https://www.kaggle.com/c/covid19-global-forecasting-week-1;0.669;0.379;2020-12-12 18:11:58;COVID19 Global Forecasting (Week 1);['exploratory data analysis, random forest, logistic regression, +1 moredecision tree'];Less code-Accurate Result(Best predictions);Python notebook;1579.0;23;;
2020-04-03 06:13:29;COVID19 Predictions using XGBOOST In this Project I'll be using past three months data to predict the Confirmed Cases and Fatalities for the month of April. The model used for training will be an XGBOOST model. Table of Contents Let's Explore the Data Exploratory Data Analysis(EDA) Universal growth of COVID19 over time Trend of COVID19 in top 10 affected countries Country Specific growth of COVID19 United States of America India China     Preprocessing Training and evaluating the model Prediction;Apache 2.0;https://www.kaggle.com/anshuls235/covid19-eda-predictions;1.0;['xgboost', 'sklearn'];['ner', 'ai', 'gan', 'cv', 'rl', 'nn'];['filter', 'training data', 'train', 'model', 'label', 'predict', 'understanding'];https://www.kaggle.com/c/covid19-global-forecasting-week-2;0.63;0.346;2020-12-12 18:13:38;multiple data sources;['data visualization, feature engineering, covid19'];COVID19 🦠 [EDA+Predictions];Python notebook;759.0;16;;
2020-04-02 21:36:11;This notebook shows how fatalities can be predicted as a lag of confirmed cases.  This model confirms clinical observation about duration of disease in case of fatal outcome.;Apache 2.0;https://www.kaggle.com/cpmpml/fatalities-prediction-via-linear-regression;1.0;['sklearn'];['ai', 'rl'];['training data', 'regression', 'train', 'fitting', 'model', 'validation data', 'predict', 'linear regression'];https://www.kaggle.com/c/covid19-global-forecasting-week-2;0.673;0.379;2020-12-12 18:13:38;COVID19 Global Forecasting (Week 2);[];Fatalities Prediction Via Linear Regression;Python notebook;1719.0;23;;
2020-04-01 22:40:13;"COVID-19 W2: A few charts and a simple baselineSummaryDisclaimer We still have limited data to predict or understand what will happen in the next few weeks (months). At this point I see more value in collecting data and monitoring the outbreak than trying to predict the future. Please don't kill yourself because I published a notebook Challenges The outbreak patterns vary a lot among countries Most countries have only 2 weeks data Only a handful countries managed to succesfuly slow down the outbreak Almost every country had several serious regulations in recent weeks Increasing testing capacity could have serious impact on confirmed cases  Assumptions As we are still in the early period, we will see exponential growth in the next few weeks Thanks to the panic/awareness/regulations/social distancing the exponential increase will slow down  As the process is not stationary at all I decided to use a simple heuristic approach. Maybe I will import sklearn next week. TIL Namibia's country code is NA. Now I remember I heard it in joke before, but I had to investigate a bug learn it again :) I haven't used plotly recently, I quite enjoyed the ""new"" Plotly Express interface";Apache 2.0;https://www.kaggle.com/gaborfodor/covid-19-a-few-charts-and-a-simple-baseline;1.0;['pattern', 'sklearn'];['ai', 'gan', 'rl', 'nn', 'ml'];['train', 'predict'];https://www.kaggle.com/c/covid19-global-forecasting-week-2;0.696;0.403;2020-12-12 18:13:38;multiple data sources;[];COVID-19 A few charts and a simple baseline;Python notebook;2813.0;30;0.61678;0.08250
2020-03-29 06:31:19;COVID-19 cases in US, China, Italy, UK;Apache 2.0;https://www.kaggle.com/khotijahs1/covid19-forecasting-randomforest;1.0;['sklearn'];['ai', 'rl', 'nn', 'cv'];['test data', 'train', 'model', 'label', 'predict', 'classification'];https://www.kaggle.com/c/covid19-global-forecasting-week-2;0.671;0.403;2020-12-12 18:13:38;COVID19 Global Forecasting (Week 2);[];Covid19 forecasting :  RandomForest;Python notebook;1642.0;30;2.51086;1.52567
2020-04-18 07:40:02;First up, let's see what are the top 25 cities in bangladesh?;Apache 2.0;https://www.kaggle.com/mobassir/covid-19-in-bangladesh;1.0;['catboost', 'xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'dl', 'gbm', 'gan', 'cv', 'rl', 'ml', 'nlp', 'nn', 'ann'];['rank', 'model', 'train'];https://www.kaggle.com/c/covid19-global-forecasting-week-2;0.657;0.367;2020-12-12 18:13:38;multiple data sources;[];covid-19 in bangladesh;Python notebook;1247.0;20;;
2020-04-15 17:17:13;Covid-19 Forecasting (Week 2) The covid-19 virus has created a pandemic in the early months of 2020. Kaggle has hosted a series of forecasting competitions for predict the number the spread of the virus. This is my solution for Week 2 of the series. My solution for Week 3: https://www.kaggle.com/rohanrao/covid-19-w3-lgb-mad My solution for Week 4: https://www.kaggle.com/rohanrao/covid-19-w4-lgb-mad I am compiling external datasets in the competition format here: https://www.kaggle.com/rohanrao/covid19-forecasting-metadata They are structured such that it can directly be merged with the train and test datasets on Kaggle.;Apache 2.0;https://www.kaggle.com/rohanrao/covid-19-w2-lgb-mad;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'gan', 'rl', 'nn', 'ann'];['filter', 'test data', 'regression', 'train', 'fitting', 'model', 'label', 'predict'];https://www.kaggle.com/c/covid19-global-forecasting-week-2;0.71;0.379;2020-12-12 18:13:38;multiple data sources;[];COVID-19 (W2): LGB+MAD;Python notebook;3839.0;23;;
2020-04-05 13:17:07;SEIR-HCD ModelThis is a working example of a SIER model with added compartments for HCD. The letters stand for:  Susceptible Exposed Infected Recovered Hospitalized Critical Death  I have adapted the equations from these great web apps:  http://gabgoh.github.io/COVID/index.html https://neherlab.org/covid19  NOTE: If you are looking for the SIER model, check commit 20 or earlier.;Apache 2.0;https://www.kaggle.com/anjum48/seir-hcd-model;1.0;['sklearn'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nn', 'ann'];['train', 'fitting', 'model', 'label', 'predict'];https://www.kaggle.com/c/covid19-global-forecasting-week-3;0.76;0.507;2020-12-12 18:15:06;multiple data sources;[];SEIR-HCD Model;Python notebook;13489.0;110;;
2020-04-03 00:26:23;COVID-19: Spread situation by prefecture in JapanI will zoom into Japan in this kernel, to visualize how Coronavirus spread in each prefecture in Japan. The 2 external dataset is used:  Japan COVID-19 by prefecture: Individual covid confirmed case's precise information in Japan. Data is from kaz-ogiwara/covid19  Japan Prefecture Latitude Longitude: It stores longitude, latitude information of each prefecture in Japan. Japan population by age and sex in 2020: Precise population information in Japan.  Please upvote both kernel & dataset if you find it useful :);Apache 2.0;https://www.kaggle.com/corochann/covid-19-spread-situation-by-prefecture-in-japan;1.0;['catboost', 'xgboost', 'sklearn', 'lightgbm'];['ai', 'dl', 'gbm', 'rl', 'ml', 'nn', 'ann'];['train', 'model', 'label'];https://www.kaggle.com/c/covid19-global-forecasting-week-3;0.653;0.334;2020-12-12 18:15:07;multiple data sources;['data visualization, exploratory data analysis'];COVID-19: Spread situation by prefecture in Japan;Python notebook;1153.0;14;;
2020-04-05 20:55:06;source - https://www.google.com/covid19/ OverviewCoronavirus disease (COVID-19) is an infectious disease caused by a new virus. The disease causes respiratory illness (like the flu) with symptoms such as a cough, fever, and in more severe cases, difficulty breathing. You can protect yourself by washing your hands frequently, avoiding touching your face, and avoiding close contact (1 meter or 3 feet) with people who are unwell. How it spreadsCoronavirus disease spreads primarily through contact with an infected person when they cough or sneeze. It also spreads when a person touches a surface or object that has the virus on it, then touches their eyes, nose, or mouth. symptomsPeople may be sick with the virus for 1 to 14 days before developing symptoms. The most common symptoms of coronavirus disease (COVID-19) are fever, tiredness, and dry cough. Most people (about 80%) recover from the disease without needing special treatment. PreventionsYou can protect yourself and help prevent spreading the virus to others if you: Do • Wash your hands regularly for 20 seconds, with soap and water or alcohol-based hand rub • Cover your nose and mouth with a disposable tissue or flexed elbow when you cough or sneeze • Avoid close contact (1 meter or 3 feet) with people who are unwell • Stay home and self-isolate from others in the household if you feel unwell TreatmentsThere is no specific medicine to prevent or treat coronavirus disease (COVID-19). People may need supportive care to help them breathe.;Apache 2.0;https://www.kaggle.com/janmejoy/covid19-time-series-analysis-plotly-visualization;1.0;['statsmodels'];['ai', 'rl', 'nn', 'gan'];['filter', 'train', 'model', 'label', 'understanding'];https://www.kaggle.com/c/covid19-global-forecasting-week-3;0.659;0.357;2020-12-12 18:15:06;COVID19 Global Forecasting (Week 3);[];COVID19 Time series analysis+Plotly Visualization;Python notebook;1304.0;18;;
2020-04-08 19:33:20;"To Sigmoid or not to Sigmoid, that is the QuestionA lot of people already noticed that the cumulative amount of cases for Hubei follows a sigmoid function. The general opinion however was that in a lot of countries/regions it is still too early to try and fit these sigmoids. In my notebook from last week I tried fitting them anyway, by making some 'educated' guesses about the expected maximum value and grow rate. Thanks to Sudeep Shouche I came across the paper by Milan Batista entitled ""Estimation of the final size of the coronavirus epidemic by the logistic model"". What is interesting here is that Batista is able to provide a mathematical solution to these parameters.  [...]";Apache 2.0;https://www.kaggle.com/jorijnsmit/mathematical-solution-to-sigmoid-parameters;1.0;['sklearn'];['ner', 'ai', 'dl', 'gan', 'rl', 'nn'];['test data', 'regression', 'train', 'fitting', 'model', 'label', 'predict'];https://www.kaggle.com/c/covid19-global-forecasting-week-3;0.647;0.352;2020-12-12 18:15:07;multiple data sources;['covid19'];Mathematical Solution to Sigmoid Parameters;Python notebook;1029.0;17;0.92665;0.29567
2020-04-07 13:32:19;COVID-19 Prediction using Different modelsIn this project, I will use data from the last three months to predict confirmed cases and deaths for the month of April. The work has just begun, good results have been obtained. Much work remains to be done, for exampl:  to explore new functions try other models adjust their parameters  I will post all updates here. I ask you to support the project like if it seemed useful to you.;Apache 2.0;https://www.kaggle.com/mrmorj/covid-19-eda-xgboost;1.0;['xgboost', 'sklearn', 'lightgbm'];['ai', 'rl', 'gan', 'gbm'];['filter', 'test data', 'train', 'model', 'label', 'predict', 'random forest'];https://www.kaggle.com/c/covid19-global-forecasting-week-3;0.65;0.352;2020-12-12 18:15:07;COVID19 Global Forecasting (Week 3);[];🦠Covid-19: EDA & XGBOOST;Python notebook;1088.0;17;1.03464;0.08217
2020-05-16 06:32:25;The Story of COVID-19 in IndiaThe COVID-19 pandemic is the defining global health crisis of our time and the greatest global humanitarian challenge the world has faced since World War II. The virus has spread widely, and the number of cases is rising daily as governments work to slow its spread. India has moved quickly, implementing a proactive, nationwide, lockdown, with the goal of flattening the curve and using the time to plan and resource responses adequately.;Apache 2.0;https://www.kaggle.com/nitishabharathi/the-story-of-covid-19-in-india-eda-and-prediction;1.0;['statsmodels', 'xgboost', 'sklearn', 'lightgbm'];['ai', 'dl', 'gan', 'gbm', 'rl'];['filter', 'train', 'model', 'label', 'predict', 'random forest'];https://www.kaggle.com/c/covid19-global-forecasting-week-3;0.788;0.581;2020-12-12 18:15:06;multiple data sources;['beginner, data visualization, exploratory data analysis, +1 moreindia'];The Story of COVID-19 in India EDA and Prediction;Python notebook;30570.0;330;;
2020-04-16 05:54:20;Timeseries Analysis and Factors influencing Spread of COVID-19;Apache 2.0;https://www.kaggle.com/aestheteaman01/covtan-covid-19-timeseries-analysis-notebook;1.0;['xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'gan', 'gbm', 'rl', 'nn'];['filter', 'training data', 'train', 'model', 'label', 'gradient boosting', 'predict', 'understanding'];https://www.kaggle.com/c/covid19-global-forecasting-week-4;0.683;0.379;2020-12-12 18:17:36;multiple data sources;[];CovTAN : COVID-19 Timeseries Analysis Notebook;Python notebook;2110.0;23;;
2020-09-24 16:00:35;For a more detailed analysis on India refer to India vs Coronavirus 🦠;Apache 2.0;https://www.kaggle.com/anshuls235/covid19-explained-through-visualizations;1.0;['xgboost', 'sklearn'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'nn', 'ann'];['filter', 'training data', 'test data', 'train', 'model', 'layer', 'label', 'predict', 'understanding'];https://www.kaggle.com/c/covid19-global-forecasting-week-4;0.78;0.563;2020-12-12 18:17:35;multiple data sources;['data visualization, exploratory data analysis, feature engineering, +2 moredata cleaning, covid19'];COVID19🦠 Explained through Visualizations;Python notebook;24279.0;247;;
2020-10-22 07:34:46;Live COVID -19 Tracking World and India  FIRST   THEN  The 2019–20 coronavirus pandemic is an ongoing pandemic of coronavirus disease 2019 (COVID-19) caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). The outbreak was identified in Wuhan, China, in December 2019, declared to be a Public Health Emergency of International Concern on 30 January 2020, and recognized as a pandemic by the World Health Organization on 11 March 2020. As of 16 April 2020, more than 2.1 million cases of COVID-19 have been reported in 210 countries and territories, resulting in more than 140,000 deaths. More than 532,000 people have recovered, although there may be a possibility of relapse or reinfection. The deaths per diagnosed cases varies significantly between countries. The virus is primarily spread between people during close contact, often via small droplets produced by coughing, sneezing, or talking. While these droplets are produced when breathing out, they usually fall to the ground or onto surfaces rather than being infectious over long distances. People may also become infected by touching a contaminated surface and then touching their eyes, nose or mouth. The virus can survive on surfaces, up to 72 hours on some It is most contagious during the first three days after the onset of symptoms, although spread may be possible before symptoms appear and in later stages of the disease Common symptoms include fever, cough and shortness of breath. Complications may include pneumonia and acute respiratory distress syndrome.The time from exposure to onset of symptoms is typically around five days, but may range from two to fourteen days There is no known vaccine or specific antiviral treatment. Primary treatment is symptomatic and supportive therapy. Recommended preventive measures include hand washing, covering one's mouth when coughing, maintaining distance from other people, and monitoring and self-isolation for people who suspect they are infected. Authorities worldwide have responded by implementing travel restrictions, quarantines, curfews and stay-at-home orders, workplace hazard controls, and facility closures.;Apache 2.0;https://www.kaggle.com/chekoduadarsh/epidemic-model-covid-19-india-visualizations;1.0;['pattern'];['ner', 'ai', 'dl', 'cnn', 'gan', 'rl', 'ml', 'nn', 'ann'];['filter', 'train', 'model', 'predict', 'recommend'];https://www.kaggle.com/c/covid19-global-forecasting-week-4;0.745;0.472;2020-12-12 18:17:36;multiple data sources;['data visualization, deep learning, health, +1 morecovid19'];Epidemic Model COVID-19🦠 India + Visualizations;Python notebook;8952.0;70;;
2020-12-04 00:42:40;COVID-19: current situation on DecemberThe kernel is inspired by the great EDA kernel COVID-19: Digging a Bit Deeper by @abhinand05 in week1. Please upvote his kernel as well :) I will write an EDA including the recent updates, recovering country analysis & sigmoid fitting convergence date estimation. [Note] It seems JHU has changed the data format, and stopped providing recovered cases. So I could not analyze recovered cases. plotly visualization is heavy used in this kernel so that we can interactively see the figure, map etc. As a side effect, it might take a little bit more time to load the kernel, wait a minute please. Version HistoryThe data is updated daily-basis. I will try to update the kernel DAILY basis too, so that you can refer latest information. Below are the version history to see the information until specified date.  Version History (Expand by clicking here)  - Version 15: Added **Daily NEW confirmed cases** analysis & **Asia** region EDA.  - [Version 18](https://www.kaggle.com/corochann/covid-19-eda-with-recent-update-on-march?scriptVersionId=31151381): Shows figure as of 2020/3/28.  - Version 19: Added sigmoid fitting to estimate when the coronavirus converge in each country, jump to [When will it converge? - Estimation by sigmoid fitting](#id_converge).  - [Version 21](https://www.kaggle.com/corochann/covid-19-eda-with-recent-update-on-april?scriptVersionId=31276251): Shows figure as of 2020/3/31.  - [Version 23](https://www.kaggle.com/corochann/covid-19-eda-with-recent-update-on-april?scriptVersionId=31329249): Shows figure as of 2020/4/1, moved to use week3 competition data.  - [Version 29](https://www.kaggle.com/corochann/covid-19-eda-with-recent-update-on-april?scriptVersionId=31384138): 2020/4/2  - [Version 30](https://www.kaggle.com/corochann/covid-19-eda-with-recent-update-on-april?scriptVersionId=31436722): 2020/4/3  - [Version 31](https://www.kaggle.com/corochann/covid-19-eda-with-recent-update-on-april?scriptVersionId=31489960): 2020/4/4  - [Version 32](https://www.kaggle.com/corochann/covid-19-eda-with-recent-update-on-april?scriptVersionId=31547500): 2020/4/5  - [Version 33](https://www.kaggle.com/corochann/covid-19-eda-with-recent-update-on-april?scriptVersionId=31604729): 2020/4/6  - [Version 35](https://www.kaggle.com/corochann/covid-19-eda-with-recent-update-on-april?scriptVersionId=31670710): 2020/4/7, **Moved to week4 dataset**  - [Version 36](https://www.kaggle.com/corochann/covid-19-eda-with-recent-update-on-april?scriptVersionId=31723129): 2020/4/8  - [Version 38](https://www.kaggle.com/corochann/covid-19-eda-with-recent-update-on-april?scriptVersionId=31782521): 2020/4/9  - [Version 39](https://www.kaggle.com/corochann/covid-19-eda-with-recent-update-on-april?scriptVersionId=31839132): 2020/4/10  - [Version 40](https://www.kaggle.com/corochann/covid-19-eda-with-recent-update-on-april?scriptVersionId=31898610): 2020/4/11  - [Version 41](https://www.kaggle.com/corochann/covid-19-eda-with-recent-update-on-april?scriptVersionId=31957894): 2020/4/12  - [Version 42](https://www.kaggle.com/corochann/covid-19-eda-with-recent-update-on-april?scriptVersionId=32023899): 2020/4/13  - [Version 43](https://www.kaggle.com/corochann/covid-19-eda-with-recent-update-on-april?scriptVersionId=32082933): 2020/4/14  - [Version 49](https://www.kaggle.com/corochann/covid-19-eda-with-recent-update-on-april?scriptVersionId=32266557): 2020/4/17, **Moved to use data from 2019 Novel Coronavirus COVID-19 (2019-nCoV) Data Repository by Johns Hopkins CSSE**. Internet connection is required, since it will download latest data from the repository.  - [Version 50](https://www.kaggle.com/corochann/covid-19-eda-with-recent-update-on-april?scriptVersionId=32321582): 2020/4/18, removed unused data.  - [Version 51](https://www.kaggle.com/corochann/covid-19-eda-with-recent-update-on-april?scriptVersionId=32382070): 2020/4/19  - [Version 52](https://www.kaggle.com/corochann/covid-19-eda-with-recent-update-on-april?scriptVersionId=32623228): 2020/4/23  - [Version 53](https://www.kaggle.com/corochann/covid-19-eda-with-recent-update-on-april?scriptVersionId=32751754): 2020/4/25  - [Version 54](https://www.kaggle.com/corochann/covid-19-eda-with-recent-update-on-april?scriptVersionId=32821067): 2020/4/26  - [Version 55](https://www.kaggle.com/corochann/covid-19-eda-with-recent-update-on-april?scriptVersionId=32966399): 2020/4/28  - [Version 56](https://www.kaggle.com/corochann/covid-19-eda-with-recent-update-on-april?scriptVersionId=33111789): 2020/4/30  - [Version 57](https://www.kaggle.com/corochann/covid-19-current-situation-on-may-daily-update?scriptVersionId=33178751): 2020/5/1      - [Version 58](https://www.kaggle.com/corochann/covid-19-current-situation-on-may-daily-update?scriptVersionId=33246349): 2020/5/2     - [Version 59](https://www.kaggle.com/corochann/covid-19-current-situation-on-may-daily-update?scriptVersionId=33316049): 2020/5/3  - [Version 60](https://www.kaggle.com/corochann/covid-19-current-situation-on-may-daily-update?scriptVersionId=33388532): 2020/5/4  - [Version 61](https://www.kaggle.com/corochann/covid-19-current-situation-on-may-daily-update?scriptVersionId=33456431): 2020/5/5  - [Version 62](https://www.kaggle.com/corochann/covid-19-current-situation-on-may-daily-update?scriptVersionId=33523879): 2020/5/6  - [Version 63](https://www.kaggle.com/corochann/covid-19-current-situation-on-may-daily-update?scriptVersionId=33592887): 2020/5/7  - [Version 64](https://www.kaggle.com/corochann/covid-19-current-situation-on-may-daily-update?scriptVersionId=33665835): 2020/5/8  - [Version 65](https://www.kaggle.com/corochann/covid-19-current-situation-on-may-daily-update?scriptVersionId=33728654): 2020/5/9  - [Version 66](https://www.kaggle.com/corochann/covid-19-current-situation-on-may-daily-update?scriptVersionId=33801408): 2020/5/10  - [Version 69](https://www.kaggle.com/corochann/covid-19-current-situation-on-may-daily-update?scriptVersionId=33943023): 2020/5/12  - [Version 70](https://www.kaggle.com/corochann/covid-19-current-situation-on-may?scriptVersionId=34085641): 2020/5/14  - [Version 71](https://www.kaggle.com/corochann/covid-19-current-situation-on-may?scriptVersionId=34273754): 2020/5/17  - [Version 72](https://www.kaggle.com/corochann/covid-19-current-situation-on-may?scriptVersionId=34415107): 2020/5/19  - [Version 73](https://www.kaggle.com/corochann/covid-19-current-situation-on-may?scriptVersionId=34661387): 2020/5/22, Added growth factor  - [Version 75](https://www.kaggle.com/corochann/covid-19-current-situation-on-may?scriptVersionId=34870894): 2020/5/25  - [Version 76](https://www.kaggle.com/corochann/covid-19-current-situation-on-may?scriptVersionId=35075854): 2020/5/28  - [Version 77](https://www.kaggle.com/corochann/covid-19-current-situation-on-june?scriptVersionId=35340282): 2020/6/1  - [Version 78](https://www.kaggle.com/corochann/covid-19-current-situation-on-june?scriptVersionId=35475709): 2020/6/3  - [Version 79](https://www.kaggle.com/corochann/covid-19-current-situation-on-june?scriptVersionId=35767313): 2020/6/7  - [Version 80](https://www.kaggle.com/corochann/covid-19-current-situation-on-june?scriptVersionId=36013977): 2020/6/10  - [Version 81](https://www.kaggle.com/corochann/covid-19-current-situation-on-june?scriptVersionId=37235122): 2020/6/21  - [Version 82](https://www.kaggle.com/corochann/covid-19-current-situation-on-june?scriptVersionId=37739722): 2020/6/28  - [Version 83](https://www.kaggle.com/corochann/covid-19-current-situation-on-july?scriptVersionId=38064445): 2020/7/2  - [Version 84](https://www.kaggle.com/corochann/covid-19-current-situation-on-july?scriptVersionId=38768566): 2020/7/13  - [Version 85](https://www.kaggle.com/corochann/covid-19-current-situation-on-july?scriptVersionId=39279123): 2020/7/21  - [Version 86](https://www.kaggle.com/corochann/covid-19-current-situation-on-august?scriptVersionId=39996289): 2020/8/1  - [Version 87](https://www.kaggle.com/corochann/covid-19-current-situation-on-august?scriptVersionId=40873956): 2020/8/15  - [Version 88](https://www.kaggle.com/corochann/covid-19-current-situation-on-august?scriptVersionId=41227754): 2020/8/22  - [Version 89](https://www.kaggle.com/corochann/covid-19-current-situation-on-september?scriptVersionId=41936057): 2020/9/2  - [Version 90](https://www.kaggle.com/corochann/covid-19-current-situation-on-september?scriptVersionId=43173201): 2020/9/20  - [Version 91](https://www.kaggle.com/corochann/covid-19-current-situation-on-october?scriptVersionId=44115812): 2020/10/4  - [Version 93](https://www.kaggle.com/corochann/covid-19-current-situation-on-october?scriptVersionId=45297457): 2020/10/21  - [Version 94](https://www.kaggle.com/corochann/covid-19-current-situation-on-october?scriptVersionId=46904410): 2020/11/13       Latest Version: 2020/12/2;Apache 2.0;https://www.kaggle.com/corochann/covid-19-current-situation-on-december;1.0;['catboost', 'xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'nlu', 'dl', 'gbm', 'gan', 'rl', 'ml', 'nn', 'ann'];['filter', 'test data', 'train', 'fitting', 'model', 'loss', 'label', 'predict', 'ground truth'];https://www.kaggle.com/c/covid19-global-forecasting-week-4;0.789;0.569;2020-12-12 18:17:35;multiple data sources;['data visualization, exploratory data analysis, time series analysis, +2 moregeospatial analysis, survey analysis'];COVID-19: current situation on December;Python notebook;32279.0;271;;
2020-04-17 20:28:54;https://www.kaggle.com/milantripathi/covid19-forecasting based on. Study was done for the 4th week. Improved models parameters.Also added Visualizations.;Apache 2.0;https://www.kaggle.com/mielek/covid19-forecasting-xgboost;1.0;['xgboost', 'sklearn'];['ai'];['train', 'model', 'label', 'predict'];https://www.kaggle.com/c/covid19-global-forecasting-week-4;0.644;0.375;2020-12-12 18:17:36;COVID19 Global Forecasting (Week 4);[];COVID19-ForeCasting XGBoost;Python notebook;985.0;22;0.76770;0.03734
2020-04-16 12:40:15;"COVID Global Forecast: SIR model + ML regressionsIn the context of the global COVID-19 pandemic, Kaggle has launched several challenges in order to provide useful insights that may answer some of the open scientific questions about the virus. This is the case of the COVID19 Global Forecasting, in which participants are encouraged to fit worldwide data in order to predict the pandemic evolution, hopefully helping to determine which factors impact the transmission behavior of COVID-19. TABLE OF CONTENTS  Exploratory data analysis (EDA) 1.1. COVID-19 global tendency excluding China 1.2. COVID-19 tendency in China 1.3. Italy, Spain, UK and Singapore  SIR model 2.1. Implementing the SIR model 2.2. Fit SIR parameters to real data  Data enrichment 3.1. Join data, filter dates and clean missings 3.2. Compute lags and trends 3.3. Add country details  Predictions for the early stages of the transmission 4.1. Linear Regression for one country 4.2. Linear Regression for all countries (method 1) 4.3. Linear Regression for all countries (method 2) 4.4. Linear regression with lags  Predictions for the late stages of the transmission 5.1. Logistic curve fit 5.2. Logistic curve fit for all countries 5.3. ARIMA  Statement of the author   Disclaimer 1: this notebook is being updated frequently with the objective of improving predictions by using new models. Disclaimer 2: the training dataset is also updated on a daily basis in order to include the most recent cases. In order to be up to date and prevent data leaking and other potential problems, daily updates on ""filtered dates"" will be applied. Disclaimer 3: the COVID Global Forecasting competition is updated week by week (with a new competition). I'll move the notebook from previous weeks to the new one, so that it only appears in the most recent competition.";Apache 2.0;https://www.kaggle.com/saga21/covid-global-forecast-sir-model-ml-regressions;1.0;['statsmodels', 'xgboost', 'lightgbm', 'sklearn', 'pattern'];['ner', 'ai', 'gbm', 'cv', 'rl', 'ml', 'nn', 'ann'];['linear regression', 'filter', 'machine learning', 'regression', 'training data', 'train', 'fitting', 'model', 'test data', 'label', 'logistic regression', 'predict', 'recommend'];https://www.kaggle.com/c/covid19-global-forecasting-week-4;0.819;0.628;2020-12-12 18:17:35;multiple data sources;['beginner, exploratory data analysis, feature engineering, +1 morecovid19'];COVID Global Forecast: SIR model + ML regressions;Python notebook;88899.0;733;;
2020-04-15 04:06:31;SEIR & PR Model for COVID19 Global forecastSEIR MODEL Reference:  Many thanks for @datasaurus great Kernel : https://www.kaggle.com/anjum48/seir-model-with-intervention Compartmental models in epidemiology - SEIR SEIR Great APP  PR model Reference:  My previous kernel;Apache 2.0;https://www.kaggle.com/super13579/covid-19-global-forecast-seir-visualize;1.0;['sklearn'];['ner', 'ai', 'gan', 'nn', 'ann'];['regression', 'train', 'fitting', 'model', 'label', 'predict'];https://www.kaggle.com/c/covid19-global-forecasting-week-4;0.746;0.467;2020-12-12 18:17:36;multiple data sources;['covid19'];COVID-19 Global Forecast : SEIR + Visualize;Python notebook;9292.0;65;1.17182;0.32686
2020-07-24 17:09:57;[Introduction] First I really appreciate this initiative, datasets, and all the contributors of them For a resident in one of the epicentres of COVID-19, this data must be heartbreaking but valuable sources to learn from We Kagglers as data scientists may have a sort of duty to confront this crisis more seriously and collaboratively than ever It's better to confess that I have not enough knowledge nor skills on data science to tackle this professionally But I decided to dive as soon as possible after I found this initiative. Because it's a matter and war of timing It'd be an honor if this effort helped any better understand the disease, spread of it, and its impact on us;Apache 2.0;https://www.kaggle.com/dkjung/covid-19-eda-s-korea-forecasting-global;1.0;['statsmodels', 'sklearn', 'pattern'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'ml', 'nn', 'rnn', 'ann'];['linear regression', 'filter', 'machine learning', 'regression', 'training data', 'train', 'fitting', 'model', 'test data', 'understanding', 'neural network', 'loss', 'label', 'lstm', 'predict', 'decision tree', 'classification'];https://www.kaggle.com/c/covid19-global-forecasting-week-5;0.756;0.478;2020-12-12 18:20:14;multiple data sources;['data visualization, exploratory data analysis, covid19'];[COVID-19] EDA (S.Korea) | Forecasting (Global);Python notebook;12170.0;75;;
2020-05-10 18:37:31;In this kernal i'm going to create a predictive model for covid19 global-forecasting week 5 data which contains around 7 lakhs data for  training and we have to predict the target values for 3 lakhs test data In this model first i have did some analysis with the data with some graphs and also the the effect of corona in  India have been analysed seperately. Finally I created a ensemble learning model with almost 0.96 Rsquared score;Apache 2.0;https://www.kaggle.com/granjithkumar/covid19-model-using-ensemble-learning-with-95-acc;1.0;['sklearn'];['ann', 'ai', 'nn', 'ml'];['training data', 'test data', 'train', 'model', 'label', 'predict', 'rank'];https://www.kaggle.com/c/covid19-global-forecasting-week-5;0.665;0.4;2020-12-12 18:20:14;COVID19 Global Forecasting (Week 5);['data visualization, covid19, random forest'];Covid19 Model using Ensemble Learning with 95% acc;Python notebook;1464.0;29;0.69870;0.23556
2020-05-11 08:08:50;This notebook tracks and Analyse the spread of the coronavirus(COVID-19) 🦠.;Apache 2.0;https://www.kaggle.com/nischaydnk/covid19-week5-visuals-randomforestregressor;1.0;['sklearn'];['ner', 'ai', 'nlu', 'dl', 'gan', 'cv', 'rl', 'nn'];['train', 'model', 'predict'];https://www.kaggle.com/c/covid19-global-forecasting-week-5;0.733;0.491;2020-12-12 18:20:14;COVID19 Global Forecasting (Week 5);['beginner, data visualization, covid19, +1 morerandom forest'];Covid19 Week5 (Visuals+RandomForestRegressor);Python notebook;6728.0;89;0.62053;0.26023
2020-05-29 22:10:19;Modelling COVID-19 with Mobility FeaturesThis notebook aims to provide a basic workflow of how mobility data shared by Google and Apple can potentially be used as features into COVID-19 models. I will be maintaining a structured version of the dataset here: https://www.kaggle.com/rohanrao/covid19-mobility-data and also likely will use it to some extent for my final submission of this competition. The notebook demonstrates how the dataset can be merged and used with the competition data. I've also shared the validation and LB scores with and without using the features. P.S. If you plan to use the data / notebook, be careful to use the features with appropriate lagged values since the actual test data duration is 28 days.;Apache 2.0;https://www.kaggle.com/rohanrao/covid-19-forecasting-modelling-with-mobility;1.0;['lightgbm', 'sklearn'];['ai', 'rl', 'ml', 'gbm'];['test data', 'regression', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/covid19-global-forecasting-week-5;0.682;0.387;2020-12-12 18:20:14;multiple data sources;[];COVID-19 Forecasting: Modelling with Mobility;Python notebook;2094.0;25;;
2020-09-07 09:11:37;Will COVID-19 end in INDIA ??;Apache 2.0;https://www.kaggle.com/sunehanigam/will-covid-19-end-in-india;1.0;['statsmodels'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nn', 'ann'];['understanding', 'model', 'label', 'predict'];https://www.kaggle.com/c/covid19-global-forecasting-week-5;0.642;0.367;2020-12-12 18:20:14;multiple data sources;['beginner, data visualization, exploratory data analysis, +2 morecovid19, india'];Will COVID-19 end in INDIA ??;Python notebook;935.0;20;;
2020-10-09 14:55:25;The Story of COVID-19 in World and Time Forecasting in Turkey;Apache 2.0;https://www.kaggle.com/thepinokyo/esin-covid19-forecasting-capstone;1.0;['statsmodels', 'lightgbm', 'sklearn', 'pattern'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'ml', 'nn', 'ann'];['linear regression', 'filter', 'test data', 'regression', 'train', 'model', 'loss', 'label', 'predict', 'rank', 'understanding'];https://www.kaggle.com/c/covid19-global-forecasting-week-5;0.589;0.311;2020-12-12 18:20:15;multiple data sources;['covid19, python, time series analysis'];Esin - COVID19 Forecasting (Capstone);Python notebook;377.0;11;;
2020-03-21 06:23:26;ObjectiveThis notebook shows a simulation example of a SEIR model. My work is based on COVID-19 CA: by simple SEIR⚽️ and many pionners to interpret the dissemination of COVID-19: https://towardsdatascience.com/modelling-the-coronavirus-epidemic-spreading-in-a-city-with-python-babd14d82fa2 https://qiita.com/kotai2003/items/ed28fb723a335a873061 (Japanese) https://arxiv.org/abs/2002.06563. I appreciate them. We adopt a optimizer to fit SEIR parameters to real data. Thanks to this kernel for the idea: https://www.kaggle.com/saga21/covid-global-forecast-sir-model;Apache 2.0;https://www.kaggle.com/akihisayamakawa/covid-19-ca-seir-with-parameter-optimization;1.0;['sklearn'];['ner', 'ai', 'nn', 'ml'];['regression', 'train', 'model', 'label', 'predict', 'linear regression'];https://www.kaggle.com/c/covid19-local-us-ca-forecasting-week-1;0.658;0.268;2020-12-12 18:21:16;COVID19 Local US-CA Forecasting (Week 1);[];SEIR model with parameter optimization;Python notebook;1279.0;7;3.09473;0.47048
2020-03-29 16:04:22;Global Covid-19 Forecasting Using Time Series ProphetWe will use prophet time series to predict log(1+ConfirmedCases).This is a simple starter code meant as an illustration for Prophet.;Apache 2.0;https://www.kaggle.com/dferhadi/covid-19-time-series-starter-code;1.0;['sklearn'];['ner', 'ai', 'gan', 'rl', 'nn'];['test data', 'training data', 'train', 'model', 'predict'];https://www.kaggle.com/c/covid19-local-us-ca-forecasting-week-1;0.661;0.327;2020-12-12 18:21:16;multiple data sources;['beginner'];Covid-19 Time Series Starter Code;Python notebook;1356.0;13;;
2020-03-24 16:00:09;We see there are no null or missing values in the dataset.;Apache 2.0;https://www.kaggle.com/esotericazzo/basic-eda-and-model-of-covid-19-for-us-ca;1.0;['sklearn'];['ai', 'nn'];['filter', 'training data', 'regression', 'train', 'fitting', 'model', 'label', 'predict', 'bayesian'];https://www.kaggle.com/c/covid19-local-us-ca-forecasting-week-1;0.581;0.236;2020-12-12 18:21:16;COVID19 Local US-CA Forecasting (Week 1);['covid19'];Basic EDA and Model of Covid-19 for US-CA;Python notebook;331.0;5;2.67866;0.23650
2020-03-20 05:46:21;Object:As a optoin, we tried to modeling by using SEIR. Many pionners try to interpret the dissemination of COVID-19: https://towardsdatascience.com/modelling-the-coronavirus-epidemic-spreading-in-a-city-with-python-babd14d82fa2 https://qiita.com/kotai2003/items/ed28fb723a335a873061 (Japanese) https://arxiv.org/abs/2002.06563 big thanks to them. Result:Our SEIR model cleary overestimated the number of cases. We should adjust paramaters and/or further considering.;Apache 2.0;https://www.kaggle.com/kmatsuyama/covid-19-ca-by-simple-seir;1.0;['catboost', 'xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'nn', 'gbm'];['filter', 'training data', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/covid19-local-us-ca-forecasting-week-1;0.646;0.319;2020-12-12 18:21:16;COVID19 Local US-CA Forecasting (Week 1);[];COVID-19 CA: by simple SEIR⚽️;Python notebook;1016.0;12;4.36641;0.70197
2020-04-25 19:52:57;COVID-19 USA(California) Confirmed Cases and Fatalities Forecasting;Apache 2.0;https://www.kaggle.com/mdmahmudferdous/covid-19-us-ca-forecasting-top-4-notebook-6th;1.0;['sklearn'];['ai', 'nn', 'rl'];['test data', 'regression', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/covid19-local-us-ca-forecasting-week-1;0.671;0.423;2020-12-12 18:21:16;COVID19 Local US-CA Forecasting (Week 1);[];COVID-19 US-CA Forecasting-(Top 4% Notebook)-6th;Python notebook;1664.0;38;;
2020-03-24 21:27:18;Epidemiological curves for California and other regions of the world;Apache 2.0;https://www.kaggle.com/panosc/california-curves-vs-other-world-regions;1.0;['pattern'];['ai', 'nn', 'rl'];['label', 'filter'];https://www.kaggle.com/c/covid19-local-us-ca-forecasting-week-1;0.664;0.367;2020-12-12 18:21:16;multiple data sources;['covid19, california'];California curves vs other world regions;R notebook;1431.0;20;;
2020-03-25 10:12:34;I have tried to find many data bases which can help in this case. I feel if we can get SARS ourbreak time data or other such outbreak in which the virus can be transmitted through person to person as corona does it can be helpful in predicting the future casualties;Apache 2.0;https://www.kaggle.com/sagaramu/analysis-by-moving-average-with-differencing;1.0;['statsmodels'];['ner', 'ai', 'dl', 'rl', 'nn', 'ml'];['train', 'model', 'label', 'predict'];https://www.kaggle.com/c/covid19-local-us-ca-forecasting-week-1;0.576;0.214;2020-12-12 18:21:16;COVID19 Local US-CA Forecasting (Week 1);['beginner, data visualization'];Analysis by moving average with differencing ;Python notebook;302.0;4;;
2018-04-07 12:29:42;Hello Kagglers!! I hope you are busy doing analysis and building models on Kaggle.  This competition is hosted by the 2018 CVPR workshop on autonomous driving (WAD). Here Kagglers are challenged to develop a robust segmentation algorithm that can be used for self-driving cars. I have been working in this field since last year, so I know how crucial this part is. Before we dive into the data analysis part, I would like to elaborate on some important aspects regarding segmentation:  For a self-driving car, segmentation or to be more precise semantic segmentation gives your car a view of what lies ahead of it. Though little bit computationally expensive compared to the algorithms generating bounding boxes, semantic segmentation gives a car much more idea about scene understanding. Also, it overcomes all those critical situations where bounding box fails miserably.  It is not possible to label each and every type of object/instance on the road. This poses another challenge i.e. how to interpret something that is labeled by the model as an unknown instance. How do you interpret the label map generated in this case?  Most important point Self-driving cars run with chipsets integrated within the car system. Though most people use Drive PX2 but not all of them. Self-driving car makes sense only when your model is able to run on an embedded device and you get efficient, if not almost real-time, FPS.  So, don't ensemble first. Try to develop something that is lightweight and is capable of running on an embedded device because that is the model for which this competition is hosted   Let's dive into the dataset!!;Apache 2.0;https://www.kaggle.com/aakashnain/firstlook;1.0;['skimage', 'sklearn'];['ner', 'ai', 'nn', 'cv'];['training data', 'train', 'model', 'label', 'understanding', 'labeled'];https://www.kaggle.com/c/cvpr-2018-autonomous-driving;0.697;0.425;2020-12-12 18:34:37;CVPR 2018 WAD Video Segmentation Challenge;['data visualization, exploratory data analysis'];FirstLook;Python notebook;2895.0;39;;
2018-04-07 10:25:03;Recovering the VideosIn this notebook we will show how to view the videos contained in the CVPR 2018 WAD Video Segmentation Challenge dataset. Sources and Resources http://tiao.io/posts/notebooks/embedding-matplotlib-animations-in-jupyter-as-interactive-javascript-widgets/ https://matplotlib.org/gallery/animation/dynamic_image2.html;Apache 2.0;https://www.kaggle.com/andrewrib/recovering-the-videos;1.0;['skimage'];['ai', 'ml', 'cv'];['train'];https://www.kaggle.com/c/cvpr-2018-autonomous-driving;0.705;0.405;2020-12-12 18:34:37;CVPR 2018 WAD Video Segmentation Challenge;['data visualization'];Recovering the Videos;Python notebook;3434.0;31;;
2018-04-19 06:43:48;IntroIn this kernel I explore the dataset for the CVPR competition. We are given images from videos produced as a car drives around and records activity from the car's point of view. My primary purpose is to see what's in the images and get a general feel for the objects we are asked to segment. I'll also create a data frame of labels for the train set that can be used for more in-depth classification. New: I've been trying to optimize the code for reading all train images and generating the labels. Maybe you have some ideas to speed it up?.;Apache 2.0;https://www.kaggle.com/bisonsam/cvpr-eda-with-faster-labeling;1.0;['tensorflow', 'skimage'];['ner', 'ai', 'dl', 'cv', 'nn'];['train', 'label', 'classification'];https://www.kaggle.com/c/cvpr-2018-autonomous-driving;0.592;0.0;2020-12-12 18:34:37;CVPR 2018 WAD Video Segmentation Challenge;['gpu'];CVPR EDA with faster labeling;Python notebook;390.0;0;;
2018-04-23 21:21:32;Hello Kagglers!! I hope you are busy doing analysis and building models on Kaggle.  This competition is hosted by the 2018 CVPR workshop on autonomous driving (WAD). Here Kagglers are challenged to develop a robust segmentation algorithm that can be used for self-driving cars. I have been working in this field since last year, so I know how crucial this part is. Before we dive into the data analysis part, I would like to elaborate on some important aspects regarding segmentation:  For a self-driving car, segmentation or to be more precise semantic segmentation gives your car a view of what lies ahead of it. Though little bit computationally expensive compared to the algorithms generating bounding boxes, semantic segmentation gives a car much more idea about scene understanding. Also, it overcomes all those critical situations where bounding box fails miserably.  It is not possible to label each and every type of object/instance on the road. This poses another challenge i.e. how to interpret something that is labeled by the model as an unknown instance. How do you interpret the label map generated in this case?  Most important point Self-driving cars run with chipsets integrated within the car system. Though most people use Drive PX2 but not all of them. Self-driving car makes sense only when your model is able to run on an embedded device and you get efficient, if not almost real-time, FPS.  So, don't ensemble first. Try to develop something that is lightweight and is capable of running on an embedded device because that is the model for which this competition is hosted   Let's dive into the dataset!!;Apache 2.0;https://www.kaggle.com/efezinoerome/firstlook;1.0;['skimage', 'sklearn'];['ner', 'ai', 'nn', 'cv'];['training data', 'train', 'model', 'label', 'understanding', 'labeled'];https://www.kaggle.com/c/cvpr-2018-autonomous-driving;0.58;0.188;2020-12-12 18:34:37;CVPR 2018 WAD Video Segmentation Challenge;[];FirstLook;Python notebook;326.0;3;;
2018-05-20 05:56:16;This is my idea for using a U-Net like architecture for instance segmentation. I use ResNet50 for encoder and add my own decoder. The instance classification task is implicitly done by placing instances from each category into one of 7 categorical masks. I've seen others (in literature) using a separate fully connected classification layer on top of the final feature map for instance classification. However, I want to experiment with this implicit classification approach (and to remove dedicated classification layer all together). Instance segmentation is done by predicting boundaries of each masks, then separate the masks in the post. This is still work in progress, I only got the model to train properly and still need more training. I also need to work on the post processing. Please let me know if you have any suggestion to improve.;Apache 2.0;https://www.kaggle.com/ishootlaser/cvrp-2018-starter-kernel-u-net-with-resnet50;1.0;['tensorflow', 'skimage', 'keras'];['ner', 'ai', 'rl', 'nn', 'ann'];['filter', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'resnet', 'classification', 'u-net'];https://www.kaggle.com/c/cvpr-2018-autonomous-driving;0.707;0.319;2020-12-12 18:34:37;CVPR 2018 WAD Video Segmentation Challenge;[];CVRP 2018 Starter Kernel U-Net with ResNet50 ;Python notebook;3549.0;12;;
2018-06-07 01:43:57;IntroIn this kernel I explore the dataset for the CVPR competition. We are given images from videos produced as a car drives around and records activity from the car's point of view. My primary purpose is to see what's in the images and get a general feel for the objects we are asked to segment. I'll also create a data frame of labels for the train set that can be used for more in-depth analysis. Here in this kernel we'll just look at counts and distributions for the train set.;Apache 2.0;https://www.kaggle.com/jpmiller/cvpr-image-classes;1.0;['skimage'];['ner', 'ai', 'dl', 'cv'];['train', 'label'];https://www.kaggle.com/c/cvpr-2018-autonomous-driving;0.747;0.46;2020-12-12 18:34:37;CVPR 2018 WAD Video Segmentation Challenge;['exploratory data analysis, image data, automobiles and vehicles'];CVPR Image Classes;Python notebook;9512.0;60;;
2018-04-21 19:05:15;OverviewThe notebook aims to organize the data and hack Keras so that we can train a model in a fairly simple way. The aim here is to get a model working that can reliably segment the images into objects and then we can make a model that handles grouping the objects into categories based on the labels. As you will see the Keras requires a fair bit of hackery to get it to load images from a dataframe and then get it to read the label images correctly (uint16 isn't supported well). Once that is done, training a U-Net model is really easy.;Apache 2.0;https://www.kaggle.com/kmader/data-preprocessing-and-unet-segmentation-gpu;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'nn'];['filter', 'training data', 'train', 'model', 'epoch', 'layer', 'vgg', 'loss', 'label', 'predict', 'rank', 'resnet', 'relu', 'u-net'];https://www.kaggle.com/c/cvpr-2018-autonomous-driving;0.771;0.468;2020-12-12 18:34:37;CVPR 2018 WAD Video Segmentation Challenge;['gpu, cnn, computer vision'];Data Preprocessing and UNet Segmentation (GPU);Python notebook;18390.0;66;;
2018-07-10 20:57:53;OverviewThe notebook aims to organize the data and hack Keras so that we can train a model in a fairly simple way. The aim here is to get a model working that can reliably segment the images into objects and then we can make a model that handles grouping the objects into categories based on the labels. As you will see the Keras requires a fair bit of hackery to get it to load images from a dataframe and then get it to read the label images correctly (uint16 isn't supported well). Once that is done, training a U-Net model is really easy. FocusThe focus here is to get the vehicles as accurately as possible without looking at the other classes. We can also try to differentiate between the various class;Apache 2.0;https://www.kaggle.com/kmader/hr-vehicle-spatial-unet-segmentation;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cnn', 'gan', 'cv', 'rl', 'nn'];['unlabeled', 'filter', 'training data', 'train', 'model', 'epoch', 'layer', 'vgg', 'loss', 'label', 'u-net', 'predict', 'rank', 'resnet', 'relu', 'labeled'];https://www.kaggle.com/c/cvpr-2018-autonomous-driving;0.605;0.0;2020-12-12 18:34:37;multiple data sources;['gpu'];HR-Vehicle Spatial-UNet Segmentation;Python notebook;484.0;0;;
2018-04-23 11:49:36;OverviewThe notebook aims to organize the data and hack Keras so that we can train a model in a fairly simple way. The aim here is to get a model working that can reliably segment the images into objects and then we can make a model that handles grouping the objects into categories based on the labels. As you will see the Keras requires a fair bit of hackery to get it to load images from a dataframe and then get it to read the label images correctly (uint16 isn't supported well). Once that is done, training a U-Net model is really easy. FocusThe focus here is to get the vehicles as accurately as possible without looking at the other classes. We can also try to differentiate between the various class;Apache 2.0;https://www.kaggle.com/kmader/hr-vehicle-unet-fcl-segmentation;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'nn'];['unlabeled', 'filter', 'training data', 'train', 'model', 'epoch', 'layer', 'vgg', 'loss', 'label', 'u-net', 'predict', 'rank', 'resnet', 'relu', 'labeled'];https://www.kaggle.com/c/cvpr-2018-autonomous-driving;0.621;0.0;2020-12-12 18:34:37;multiple data sources;['gpu'];HR-Vehicle UNet+FCL Segmentation;Python notebook;638.0;0;;
2018-04-22 10:12:24;OverviewThe script pre-reads through all the images and assesses their categories. This should make it easier to focus training on specific labels or groups of labels since not all occur in all images;Apache 2.0;https://www.kaggle.com/kmader/label-analysis;1.0;['skimage'];['ai', 'nn', 'rl'];['train', 'unlabeled', 'label', 'labeled'];https://www.kaggle.com/c/cvpr-2018-autonomous-driving;0.651;0.268;2020-12-12 18:34:37;CVPR 2018 WAD Video Segmentation Challenge;[];Label Analysis;Python notebook;1126.0;7;;
2018-04-27 10:45:40;OverviewThe script applies OpenCV-based detection to all the images to provide a basic baseline for pedestrian detection. The code is based loosely off of https://github.com/opencv/opencv/blob/master/samples/python/peopledetect.py;Apache 2.0;https://www.kaggle.com/kmader/opencv-hog-submission;1.0;['skimage'];['ai', 'rl', 'nn', 'cv'];['unlabeled', 'filter', 'train', 'label', 'labeled'];https://www.kaggle.com/c/cvpr-2018-autonomous-driving;0.679;0.188;2020-12-12 18:34:37;CVPR 2018 WAD Video Segmentation Challenge;[];OpenCV HOG Submission;Python notebook;1946.0;3;0.00002;0.00000
2018-04-27 14:31:49;OverviewThe notebook uses the pretrained PSPNet to segment the scenes in the CVPR dataset. It then matches the relevant labels together so predictions can be made.;Apache 2.0;https://www.kaggle.com/kmader/pretrained-pspnet-on-driving-scenes;1.0;['tensorflow', 'skimage'];['ner', 'ai', 'cv', 'rl', 'nn', 'ann'];['unlabeled', 'train', 'model', 'layer', 'label', 'predict', 'labeled'];https://www.kaggle.com/c/cvpr-2018-autonomous-driving;0.695;0.188;2020-12-12 18:34:37;multiple data sources;['gpu'];Pretrained PSPNet on Driving Scenes;Python notebook;2768.0;3;0.00089;0.00000
2018-04-23 00:16:42;OverviewThe notebook aims to organize the data and hack Keras so that we can train a model in a fairly simple way. The aim here is to get a model working that can reliably segment the images into objects and then we can make a model that handles grouping the objects into categories based on the labels. As you will see the Keras requires a fair bit of hackery to get it to load images from a dataframe and then get it to read the label images correctly (uint16 isn't supported well). Once that is done, training a U-Net model is really easy. FocusThe focus here is to get the vehicles as accurately as possible without looking at the other classes. We can also try to differentiate between the various class;Apache 2.0;https://www.kaggle.com/kmader/vehicle-unet-fcl-segmentation;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'nn'];['unlabeled', 'filter', 'training data', 'train', 'model', 'epoch', 'layer', 'vgg', 'loss', 'label', 'u-net', 'predict', 'rank', 'resnet', 'relu', 'labeled'];https://www.kaggle.com/c/cvpr-2018-autonomous-driving;0.717;0.362;2020-12-12 18:34:37;multiple data sources;['gpu, cnn'];Vehicle UNet+FCL Segmentation;Python notebook;4470.0;19;;
2018-05-11 03:57:36;This quick bit of code could help improve the quality of the masks.Here, we ultimately want to alter the masks to differentiate each object, such that there will be a 255 pixel border around discrete objects. Blobs of, for example, cars, will be broken into individual cars.Any pixel not completely surrounded by pixels of the same label gets marked as a boundary. Boundaries are 2 pixels thick.;Apache 2.0;https://www.kaggle.com/mattobrien415/improving-masks-creating-borders-between-objects;1.0;['pytorch', 'skimage'];['ai'];['train', 'label'];https://www.kaggle.com/c/cvpr-2018-autonomous-driving;0.633;0.214;2020-12-12 18:34:37;CVPR 2018 WAD Video Segmentation Challenge;[];"Improving masks; creating borders between objects";Python notebook;794.0;4;;
2017-01-17 10:47:34;IntroductionWorking with these files can be a challenge, especially given their heterogeneous nature. Some preprocessing is required before they are ready for consumption by your CNN. Fortunately, I participated in the LUNA16 competition as part of a university course on computer aided diagnosis, so I have some experience working with these files. At this moment we top the leaderboard there :) This tutorial aims to provide a comprehensive overview of useful steps to take before the data hits your ConvNet/other ML method. What we will cover:  Loading the DICOM files, and adding missing metadata   Converting the pixel values to Hounsfield Units (HU), and what tissue these unit values correspond to Resampling to an isomorphic resolution to remove variance in scanner resolution. 3D plotting, visualization is very useful to see what we are doing. Lung segmentation Normalization that makes sense. Zero centering the scans.   Before we start, let's import some packages and determine the available patients.;Apache 2.0;https://www.kaggle.com/akh64bit/full-preprocessing-tutorial;1.0;['skimage'];['ner', 'ai', 'dl', 'cnn', 'rl', 'ml', 'nn', 'ann'];['train', 'label'];https://www.kaggle.com/c/data-science-bowl-2017;0.843;0.4;2020-12-12 18:38:03;Data Science Bowl 2017;[];Full Preprocessing Tutorial;Python notebook;229188.0;29;;
2017-01-24 23:23:13;The previously suggested Lung Segmentation methods in the challenge Kernels mainly involve thresholding the lung tissue based on its hounsfield value and using morphological dilation to include nodules in border regions. These methods have the severe drawback of also including lots of tissue that is neither lung, nor a region of interest. I coded up an algorithm based on the one presented in R Shojaii et al (2005, DOI: 10.1109/ICIP.2005.1530294) with some modifications, that I will present here. Some preprocessing and presentation code for this is also taken from the Kernels presented by Guido Zuidhof and ArnavJain. Lots of thanks to them for sharing their code. The resulting CT Images are in HU and have the same (not necessarily equidistant) scale as the original scans.;Apache 2.0;https://www.kaggle.com/ankasor/improved-lung-segmentation-using-watershed;1.0;['skimage'];['ner', 'ai', 'dl'];['label', 'filter'];https://www.kaggle.com/c/data-science-bowl-2017;0.775;0.514;2020-12-12 18:38:03;Data Science Bowl 2017;[];Improved Lung Segmentation using Watershed;Python notebook;20875.0;121;;
2017-04-07 19:22:48;Data Science Bowl 2017The yearly tradition continues! - this time with another computer vision problem. we have to classify whether someone will be diagnosed with lung cancer at some point during the next year. We are given DICOM files, which is a format that is often used for medical scans. Using CT scans from 1400 patients in the training set, we have to build a model which can predict on the patients in the test set. Shameless plug: If you have any questions or want to discuss competitions/hardware/games/anything with other Kagglers, then join the KaggleNoobs Slack channel! I feel like it could use a lot more users :) And as always, if this helped you, some upvotes would be very much appreciated! :D;Apache 2.0;https://www.kaggle.com/anokas/exploratory-data-analysis-4;1.0;['sklearn'];['ai', 'gan', 'rl', 'nn', 'ann'];['training data', 'train', 'fitting', 'model', 'layer', 'loss', 'label', 'predict', 'computer vision'];https://www.kaggle.com/c/data-science-bowl-2017;0.797;0.575;2020-12-12 18:38:03;Data Science Bowl 2017;['data visualization, exploratory data analysis'];Exploratory Data Analysis;Python notebook;41891.0;299;;
2017-01-14 06:21:14;Whoa CT data. Very interesting! Let's take a quick look and see if we can visualize it in any way that makes sense.;Apache 2.0;https://www.kaggle.com/apapiu/exploratory-analysis-visualization;1.0;['skimage'];['nn', 'cnn', 'ml', 'cv'];['recommend', 'filter'];https://www.kaggle.com/c/data-science-bowl-2017;0.732;0.452;2020-12-12 18:38:03;Data Science Bowl 2017;[];Exploratory Analysis + Visualization;Python notebook;6446.0;54;;
2017-04-10 19:28:29;@gzuidhof 's tutorial inspired me a lot. So, I tried to experiment on segmenting lungs.;Apache 2.0;https://www.kaggle.com/armamut/getting-the-lungs-right;0.7;['skimage'];['ai', 'nn', 'cv'];[];https://www.kaggle.com/c/data-science-bowl-2017;0.751;0.437;2020-12-12 18:38:03;Data Science Bowl 2017;[];Getting the lungs right;Python notebook;10465.0;45;;
2017-04-11 17:58:39;In this kernel, I will be talking about the methods that will help in better understanding of the problem statement and visualisation of the data. I will also provide links of useful resources and information. The script is written in Python. I recommend people to install anaconda on their desktop because of its advantages mentioned here. The libraries that will be used in this tutorial for reading, processing and visualisation of data are matplotlib, numpy, skimage and pydicom. The images are of size (z, 512, 512) where z is the number of slices in the CT Scan and varies depending on the resolution of the scanner. Such large images cant be fed directly into a Convolution Network architectures because of the limit on the computation power. Thus we will have to find the regions that are more probable of having cancer. We will be reducing our search space by first segmenting the lungs and then removing the low intensity regions. In this tutorial, we will first start with reading the dataset and visualising it. After that, we will be segmenting the lung structures and then find the region of interest(possible cancer regions) in the CT Scans using Image processing methods. Then I will talk about how to preprocess LUNA16 dataset for training architectures like UNet for segmentation and candidate classification. The segmentation of lung structures is very challenging problem because homogeneity is not present in the lung region, similar densities in the pulmonary structures, different scanners and scanning protocols. The segmented lungs can be further used to find the lung nodule candidates and regions of interest which may help in better classification of the CT Scans. Finding the lung nodule regions is a very hard problem because there are nodules that are attached to the blood vessels or are present at the boundary of the lung region. The lung nodule candidates can be further used for classification by cutting 3D voxels around them and passing it through a 3D CNNs which can be trained on LUNA16 dataset. The LUNA 16 dataset has the location of the nodules in each CT Scan thus will be useful for training the classifier.;Apache 2.0;https://www.kaggle.com/arnavkj95/candidate-generation-and-luna16-preprocessing;1.0;['xgboost', 'sklearn', 'tensorflow', 'simpleitk', 'keras', 'skimage'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'recognition', 'logistic regression', 'predict', 'relu', 'ground truth', 'training data', 'train', 'epoch', 'recommend', 'classification', 'model', 'neural network', 'layer', 'loss', 'understanding', 'test data', 'regression', 'generation', 'fitting', 'deep learning', 'gradient descent', 'label', 'convolutional neural network'];https://www.kaggle.com/c/data-science-bowl-2017;0.816;0.601;2020-12-12 18:38:03;Data Science Bowl 2017;['deep learning, computer vision, advanced'];Candidate Generation and LUNA16 preprocessing;Python notebook;79721.0;457;;
2017-02-22 00:17:21;Welcome everyone to my post that will describe my experiments to get good scores for this problem. My aim will be to transfer my knowledge and make it easy for others to follow along. Talking about easy, we will in fact be building and training our neural networks without doing programming. Instead we will use drag and drop GUI based platform (Deep Learning Studio) to build and train neural network. We will try different experiments as we move forward with this competition. I will try to documents as much details as I can on this notebook. Please feel free to send your suggestions and comments. Today we will try 3D Convolutional Neural Network for this problem. Full discloure: I am one of the cofounder of the company who developed Deep Learning Studio software. Deep Learning Studio has a free monthly plan and it offers 2 hours of complementary training time on best GPU available in the Cloud (Nvidia K80 with 12GB RAM);Apache 2.0;https://www.kaggle.com/deepman/3d-convolutional-neural-network-w-o-programming;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cnn', 'rl', 'nn', 'ann'];['autoencoder', 'image classification', 'filter', 'train', 'fitting', 'model', 'neural network', 'epoch', 'deep learning', 'layer', 'lstm', 'label', 'loss', 'relu', 'classification', 'convolutional neural network'];https://www.kaggle.com/c/data-science-bowl-2017;0.762;0.435;2020-12-12 18:38:03;Data Science Bowl 2017;[];3D Convolutional Neural Network w/o Programming;Python notebook;14526.0;44;;
2017-02-24 07:16:36;IntroductionWorking with these files can be a challenge, especially given their heterogeneous nature. Some preprocessing is required before they are ready for consumption by your CNN. Fortunately, I participated in the LUNA16 competition as part of a university course on computer aided diagnosis, so I have some experience working with these files. At this moment we top the leaderboard there :) This tutorial aims to provide a comprehensive overview of useful steps to take before the data hits your ConvNet/other ML method. What we will cover:  Loading the DICOM files, and adding missing metadata   Converting the pixel values to Hounsfield Units (HU), and what tissue these unit values correspond to Resampling to an isomorphic resolution to remove variance in scanner resolution. 3D plotting, visualization is very useful to see what we are doing. Lung segmentation Normalization that makes sense. Zero centering the scans.   Before we start, let's import some packages and determine the available patients.;Apache 2.0;https://www.kaggle.com/gzuidhof/full-preprocessing-tutorial;1.0;['skimage'];['ner', 'ai', 'dl', 'cnn', 'rl', 'ml', 'nn', 'ann'];['train', 'label'];https://www.kaggle.com/c/data-science-bowl-2017;0.846;0.684;2020-12-12 18:38:03;Data Science Bowl 2017;[];Full Preprocessing Tutorial;Python notebook;264190.0;2170;;
2017-03-24 05:30:33;IntroductionWorking with these files can be a challenge, especially given their heterogeneous nature. Some preprocessing is required before they are ready for consumption by your CNN. Fortunately, I participated in the LUNA16 competition as part of a university course on computer aided diagnosis, so I have some experience working with these files. At this moment we top the leaderboard there :) This tutorial aims to provide a comprehensive overview of useful steps to take before the data hits your ConvNet/other ML method. What we will cover:  Loading the DICOM files, and adding missing metadata   Converting the pixel values to Hounsfield Units (HU), and what tissue these unit values correspond to Resampling to an isomorphic resolution to remove variance in scanner resolution. 3D plotting, visualization is very useful to see what we are doing. Lung segmentation Normalization that makes sense. Zero centering the scans.   Before we start, let's import some packages and determine the available patients.;Apache 2.0;https://www.kaggle.com/jyotiislam/full-preprocessing-tutorial;1.0;['skimage'];['ner', 'ai', 'dl', 'cnn', 'rl', 'ml', 'nn', 'ann'];['train', 'label'];https://www.kaggle.com/c/data-science-bowl-2017;0.719;0.393;2020-12-12 18:38:03;Data Science Bowl 2017;[];Full Preprocessing Tutorial;Python notebook;4728.0;27;;
2017-01-13 06:27:13;Here I'll go over the process of loading the DICOM images in python with pydicom and doing some light processing tasks on them;Apache 2.0;https://www.kaggle.com/mumech/loading-and-processing-the-sample-images;1.0;['tensorflow', 'keras'];['ner', 'ai', 'dl', 'cnn', 'nn', 'ann'];['generation', 'train', 'fitting', 'model', 'epoch', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/data-science-bowl-2017;0.75;0.435;2020-12-12 18:38:03;Data Science Bowl 2017;[];Loading and processing the sample images;Python notebook;10263.0;44;;
2017-03-16 05:58:43;Crop, Save and View Nodules in 3DFinal results:  This kernel shows you how to crop the nodule with given coordinates in patient's CT scan, how to save it in .npy and .mhd/.raw file, and how to view it in 3D. About half of the code is learned from other kernels. (Tutorial: U-Net Segmentation Approach to Cancer Diagnosis by Jonathan Mulholland and Aaron Sander, Booz Allen Hamilton, Full Preprocessing Tutorial by Guido Zuidhof, Candidate Generation and LUNA16 preprocessing by ArnavJain) The most fun part of this code is also learned from the Internet. I wanted a better way to visualize the region of interest my code generated. Then I searched online and found a method to save .mhd/.raw file posted by Price Jackson, with source code. The part I found useful was built on the MIT licensed work by Bing Jian and Baba C. Vemuri. I happened to know Fiji was a good tool to view volume stacks in 3D, with original intensity values. After integrating them together, I find visualize and check the results is not that much of pain. Actually, it comes with some fun and may give you some insights on the journey. This incites me to open a kernel here, though most of the code are from others. Running the code below, with given CT scan and given coordinates, will give you a cropped nodule in [19, 19, 19] dimensional numpy array, with spacing [1, 1, 1]mm. I will use LUNA16 as input data in the code. Because it comes with some annotated nodules. So I cannot run it here but I put the psedo-output in Markdown cells. The code has been tested in Python 3.5.;Apache 2.0;https://www.kaggle.com/rodenluo/crop-save-and-view-nodules-in-3d;1.0;['simpleitk'];['ner', 'ai', 'nlu', 'ml', 'nn', 'ann'];['model', 'filter', 'u-net', 'generation'];https://www.kaggle.com/c/data-science-bowl-2017;0.735;0.362;2020-12-12 18:38:03;Data Science Bowl 2017;[];Crop, Save and View Nodules in 3D;Python notebook;6992.0;19;;
2017-02-10 15:10:32;"Applying a 3D convolutional neural network to the dataWelcome everyone to my coverage of the Kaggle Data Science Bowl 2017. My goal here is that anyone, even people new to kaggle, can follow along. If you are completely new to data science, I will do my best to link to tutorials and provide information on everything you need to take part. This notebook is my actual personal initial run through this data and my notes along the way. I am by no means an expert data analyst, statistician, and certainly not a doctor. This initial pass is not going to win the competition, but hopefully it can serve as a starting point or, at the very least, you can learn something new along with me. This is a ""raw"" look into the actual code I used on my first pass, there's a ton of room for improvment. If you see something that you could improve, share it with me! Quick introduction to Kaggle If you are new to kaggle, create an account, and start downloading the data. It's going to take a while. I found the torrent to download the fastest, so I'd suggest you go that route. When you create an account, head to competitions in the nav bar, choose the Data Science Bowl, then head to the ""data"" tab. You will need to accept the terms of the competition to proceed with downloading the data. Just in case you are new, how does all this work? In general, Kaggle competitions will come with training and testing data for you to build a model on, where both the training and testing data comes with labels so you can fit a model. Then there will be actual ""blind"" or ""out of sample"" testing data that you will actually use your model on, which will spit out an output CSV file with your predictions based on the input data. This is what you will upload to kaggle, and your score here is what you compete with. There's always a sample submission file in the dataset, so you can see how to exactly format your output predictions. In this case, the submission file should have two columns, one for the patient's id and another for the prediction of the liklihood that this patient has cancer, like: id,cancer 01e349d34c02410e1da273add27be25c,0.5 05a20caf6ab6df4643644c923f06a5eb,0.5 0d12f1c627df49eb223771c28548350e,0.5 ... You can submit up to 3 entries a day, so you want to be very happy with your model, and you are at least slightly disincentivised from trying to simply fit the answer key over time. It's still possible to cheat. If you do cheat, you wont win anything, since you will have to disclose your model for any prizes. At the end, you can submit 2 final submissions (allowing you to compete with 2 models if you like). This current competition is a 2 stage competition, where you have to participate in both stages to win. Stage one has you competing based on a validation dataset. At the release of stage 2, the validation set answers are released and then you make predictions on a new test set that comes out at the release of this second stage. About this specific competitionAt its core, the aim here is to take the sample data, consisting of low-dose CT scan information, and predict what the liklihood of a patient having lung cancer is. Your submission is scored based on the log loss of your predictions. The dataset is pretty large at ~140GB just in initial training data, so this can be somewhat restrictive right out of the gate. I am going to do my best to make this tutorial one that anyone can follow within the built-in Kaggle kernels Requirements and suggestions for following alongI will be using Python 3, and you should at least know the basics of Python 3. We will also be making use of: Pandas for some data analysis Matplotlib for data visualization You do not need to go through all of those tutorials to follow here, but, if you are confused, it might be useful to poke around those. For the actual dependency installs and such, I will link to them as we go. Alright, let's get started!";Apache 2.0;https://www.kaggle.com/sentdex/first-pass-through-data-w-3d-convnet;1.0;['tensorflow'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ann'];['unlabeled', 'activation function', 'training data', 'train', 'model', 'neural network', 'epoch', 'deep learning', 'layer', 'validation data', 'loss', 'label', 'predict', 'relu', 'labeled', 'convolutional neural network'];https://www.kaggle.com/c/data-science-bowl-2017;0.823;0.632;2020-12-12 18:38:03;Data Science Bowl 2017;['cnn, advanced'];First pass through Data w/ 3D ConvNet;Python notebook;104844.0;778;;
2017-01-16 06:37:33;IntroductionWorking with these files can be a challenge, especially given their heterogeneous nature. Some preprocessing is required before they are ready for consumption by your CNN. Fortunately, I participated in the LUNA16 competition as part of a university course on computer aided diagnosis, so I have some experience working with these files. At this moment we top the leaderboard there :) This tutorial aims to provide a comprehensive overview of useful steps to take before the data hits your ConvNet/other ML method. What we will cover:  Loading the DICOM files, and adding missing metadata   Converting the pixel values to Hounsfield Units (HU), and what tissue these unit values correspond to Resampling to an isomorphic resolution to remove variance in scanner resolution. 3D plotting, visualization is very useful to see what we are doing. Lung segmentation Normalization that makes sense. Zero centering the scans.   Before we start, let's import some packages and determine the available patients.;Apache 2.0;https://www.kaggle.com/vanausloos/full-preprocessing-tutorial;1.0;['skimage'];['ner', 'ai', 'dl', 'cnn', 'rl', 'ml', 'nn', 'ann'];['train', 'label'];https://www.kaggle.com/c/data-science-bowl-2017;0.738;0.39;2020-12-12 18:38:03;Data Science Bowl 2017;[];lung cancer - Full Preprocessing Tutorial;Python notebook;7639.0;26;;
2018-03-06 16:46:29;What this kernel is about:There are visualisations of diferent image types present in train & test datasets, code is mainly from https://www.kaggle.com/mpware/stage1-eda-microscope-image-types-clustering Main impact  of this kernel is creating a mosaic from train and test data.  Skip to part 5 to see complited mosaics.  UPD. In the comment section you can find csv with: original img id, cluster, big picture id to use on your own;Apache 2.0;https://www.kaggle.com/bonlime/train-test-image-mosaic;1.0;['sklearn'];['ner', 'ai', 'dl', 'cv', 'ml', 'nn', 'ann'];['test data', 'filter', 'train', 'clustering', 'label', 'predict'];https://www.kaggle.com/c/data-science-bowl-2018;0.757;0.48;2020-12-12 18:38:54;multiple data sources;['data visualization, clustering'];Train & Test Image Mosaic;Python notebook;12633.0;77;;
2018-01-20 12:53:34;In this Kernel, I'd like to show you a very basic segmentation technique whihc only applies pure computer vision techniques. Nothing fancy. At first, I'll show the step-by-step processing and after that I will create the submission for the competition. With this kernel, I could reach 0.229 LB which is not very nice but I am sure that with a few tweaks we could get better score. And consider that we don't even use the train data! which is pretty awesome in my opinion.;Apache 2.0;https://www.kaggle.com/gaborvecsei/basic-pure-computer-vision-segmentation-lb-0-229;1.0;['skimage'];['ai', 'rl', 'cv'];['train', 'computer vision', 'label'];https://www.kaggle.com/c/data-science-bowl-2018;0.749;0.476;2020-12-12 18:38:54;2018 Data Science Bowl;['beginner, biology, computer vision'];Basic Pure Computer Vision Segmentation (LB 0.229);Python notebook;10022.0;73;;
2018-03-13 07:13:53;"Object Detection : Historical PerspectiveThis notebook is forked and edited from the awesome youtube channel of Siraj Rawal where he demo'd about YOLO v2. It's amazing, but to apreciate the accuracy of object detection,segmentation and labelling of YOLOv2, one must go through the eventful history of progress in this field. This gives an idea on how every major Deep Learning Architecture works int the field of Computer Vision. Once done that, one'll realize that these advance networks are not so blackbox-y anymore and really simple to understand and easy to build upon. Have Fun!! Some Object Detection History (2001-2017)1. The first efficient Face Detector (Viola-Jones Algorithm, 2001) An efficient algorithm for face detection was invented by Paul Viola & Michael Jones  Their demo showed faces being detected in real time on a webcam feed. Was the most stunning demonstration of computer vision and its potential at the time.  Soon, it was implemented in OpenCV & face detection became synonymous with Viola and Jones algorithm. BASIC IDEA:  Took a bunch of faces as data.  Hard-coded the features of a face. Trained an SVM(Classifier) on the featureset of the faces. Used that Classifier to detect faces!       Disadvantage : It was unable to detect faces in other orientation or configurations (tilted,upside down,wearing a mask,etc.)    2. Much more efficient detection technique (Histograms of Oriented Gradients, 2005) Navneet Dalal and Bill Triggs invented ""HOG"" for pedestrian detection Their feature descriptor, Histograms of Oriented Gradients (HOG), significantly outperformed existing algorithms in this task Handcoded features, just like before  For every single pixel, we want to look at the pixels that directly surrounding it:     Goal is, how dark is current pixel compared to surrounding pixels? We will then draw an arrow showing in which direction the image is getting darker:    We repeat that process for every single pixel in the image Every pixel is replaced by an arrow. These arrows are called gradients Gradients show the flow from light to dark across the entire image:    We'll break up the image into small squares of 16x16 pixels each In each square, we’ll count up how many gradients point in each major direction Then we’ll replace that square in the image with the arrow directions that were the strongest. End result? Original image converted into simple representation that captures basic structure of a face in a simple way: Detecting faces means find the part of our image that looks the most similar to a known HOG pattern that was extracted from a bunch of other training faces:    BASIC IDEA :  For an Image II, analyze each pixel PiPi of II for the relative dark pixels directly surounding it. Then add an arrow pointing in the direction of the flow of darkness relative to PiPi. This process of assigning an oriented gradient to a pixel p by analyzing it's surrounding pixels is performed for every pixel in the image. Assuming HOG(II) as a function that takes an input as an Image I, what it does is replaces every pixel with an arrow. Arrows = Gradients. Gradients show the flow from light to dark across an antire image. Since complex feaatures like eyes may end up giving too many gradients, we need to aggregate the whole HOG(I) in order to make a 'global representation' .  So, we break up the image into squares of 1616x1616 and assign an aggregate gradient G′G′ to each square ,where the aggregate function could be max(All gradients inside the square),min(),etc.      Disadvantage : Despite being good in many applications, it still used hand coded features which failed in a more generalized setting with much noise and distractions in the background.    The Deep Learning Era begins (2012) Convolutional Neural Networks became the gold standard for image classification after Kriszhevsky's CNN's performance during ImageNet   While these results are impressive, image classification is far simpler than the complexity and diversity of true human visual understanding.  In classification, there’s generally an image with a single object as the focus and the task is to say what that image is  But when we look at the world around us, we carry out far more complex task  We see complicated sights with multiple overlapping objects, and different backgrounds and we not only classify these different objects but also identify their boundaries, differences, and relations to one another! Can CNNs help us with such complex tasks? Yes.    We can take a classifier like VGGNet or Inception and turn it into an object detector by sliding a small window across the image At each step you run the classifier to get a prediction of what sort of object is inside the current window.  Using a sliding window gives several hundred or thousand predictions for that image, but you only keep the ones the classifier is the most certain about. This approach works but it’s obviously going to be very slow, since you need to run the classifier many times.It's a brute-force-y approach.AND computationaly expensive.  BASIC IDEA :  Take an image II and divide it into nn equal squares(ii). Then, II is a set of smaller images  (i1i1,i2i2,i3i3...inin) Run X a pre-trained image classifier CNN over each square ii. X analyzes each square ii and classifies it into a object class ll with a probability score of αα. This operation result into a bunch of labels X(II) = (l1,α1l1,α1),(l2,α2l2,α2) ... (ln,αnln,αn)  , where  (l1,α1l1,α1) = X(i1i1). We keep only those labels, which the CNN feels most confident about i.e. the labels with the highest scores. Approach for identifiction is Labeling then Detection.     A better approach, R-CNN  R-CNN creates bounding boxes, or region proposals, using a process called Selective Search  At a high level, Selective Search looks at the image through windows of different sizes, and for each size tries to group together adjacent pixels by texture, color, or intensity to identify objects.    Generate a set of proposals for bounding boxes. Run the images in the bounding boxes through a pre-trained AlexNet and finally an SVM to see what object the image in the box is. Run the box through a linear regression model to output tighter coordinates for the box once the object has been classified.  Some improvements to R-CNNR-CNN: https://arxiv.org/abs/1311.2524 Fast R-CNN: https://arxiv.org/abs/1504.08083 Faster R-CNN: https://arxiv.org/abs/1506.01497 Mask R-CNN: https://arxiv.org/abs/1703.06870  But YOLO takes a different approach What is YOLO?If you aren't motivated enough to know what it is may be this video will get you excited! (https://www.youtube.com/watch?v=VOC3huqHrss)  YOLO takes a completely different approach.  It’s not a traditional classifier that is repurposed to be an object detector.  YOLO actually looks at the image just once (hence its name: You Only Look Once) but in a clever way.  YOLO divides up the image into a grid of 13 by 13 cells:   Each of these cells is responsible for predicting 5 bounding boxes.  A bounding box describes the rectangle that encloses an object. YOLO also outputs a confidence score that tells us how certain it is that the predicted bounding box actually encloses some object. This score doesn’t say anything about what kind of object is in the box, just if the shape of the box is any good.  The predicted bounding boxes may look something like the following (the higher the confidence score, the fatter the box is drawn):   For each bounding box, the cell also predicts a class.  This works just like a classifier: it gives a probability distribution over all the possible classes.  YOLO was trained on the PASCAL VOC dataset, which can detect 20 different classes such as:  bicycle  boat car cat dog person  The confidence score for the bounding box and the class prediction are combined into one final score that tells us the probability that this bounding box contains a specific type of object.  For example, the big fat yellow box on the left is 85% sure it contains the object “dog”:    Since there are 13×13 = 169 grid cells and each cell predicts 5 bounding boxes, we end up with 845 bounding boxes in total.  It turns out that most of these boxes will have very low confidence scores, so we only keep the boxes whose final score is 30% or more (you can change this threshold depending on how accurate you want the detector to be).  The final prediction is then:   From the 845 total bounding boxes we only kept these three because they gave the best results.  But note that even though there were 845 separate predictions, they were all made at the same time — the neural network just ran once. And that’s why YOLO is so powerful and fast.  The architecture of YOLO is simple, it’s just a convolutional neural network:  This neural network only uses standard layer types: convolution with a 3×3 kernel and max-pooling with a 2×2 kernel. No fancy stuff. There is no fully-connected layer in YOLOv2. The very last convolutional layer has a 1×1 kernel and exists to reduce the data to the shape 13×13×125. This 13×13 should look familiar: that is the size of the grid that the image gets divided into. So we end up with 125 channels for every grid cell. These 125 numbers contain the data for the bounding boxes and the class predictions. Why 125? Well, each grid cell predicts 5 bounding boxes and a bounding box is described by 25 data elements:  x, y, width, height for the bounding box’s rectangle the confidence score the probability distribution over the classes  Using YOLO is simple: you give it an input image (resized to 416×416 pixels), it goes through the convolutional network in a single pass, and comes out the other end as a 13×13×125 tensor describing the bounding boxes for the grid cells. All you need to do then is compute the final scores for the bounding boxes and throw away the ones scoring lower than 30%. Improvements to YOLO v1YoLO v2 vs YoLO v1  Speed (45 frames per second — better than realtime) Network understands generalized object representation (This allowed them to train the network on real world images and predictions on artwork was still fairly accurate). faster version (with smaller architecture) — 155 frames per sec but is less accurate.  Paper here https://arxiv.org/pdf/1612.08242v1.pdf";Apache 2.0;https://www.kaggle.com/infernop/object-detection-techniques;1.0;['pattern'];['ner', 'ai', 'cnn', 'cv', 'rl', 'nn', 'ann'];['r-cnn', 'image classification', 'object detection', 'linear regression', 'regression', 'train', 'model', 'neural network', 'deep learning', 'layer', 'vgg', 'alexnet', 'label', 'predict', 'computer vision', 'understanding', 'classification', 'convolutional neural network'];https://www.kaggle.com/c/data-science-bowl-2018;0.773;0.444;2020-12-12 18:38:54;2018 Data Science Bowl;['beginner, cnn'];Object Detection Techniques;Python notebook;19720.0;49;;
2018-03-14 16:00:39;In this notebook we explain our morphological postprocessing step that improved our score from 0.421 to 0.429 on LBTo see the full end-to-end pipeline go to https://github.com/neptune-ml/data-science-bowl-2018;Apache 2.0;https://www.kaggle.com/jakubczakon/morphological-postprocessing-on-unet-lb-0-429;1.0;['skimage', 'sklearn'];['ner', 'ai', 'dl', 'nn', 'ml'];['filter', 'train', 'label', 'predict', 'ground truth'];https://www.kaggle.com/c/data-science-bowl-2018;0.744;0.468;2020-12-12 18:38:54;multiple data sources;[];Morphological Postprocessing on Unet [LB 0.429];Python notebook;8697.0;66;;
2018-03-12 09:19:52;Exploratory AnalysisDuring my undergraduate studies I had biology as one of my subjects and I enjoyed preparing the slides and looking at them using a microscope. So these images are interesting, and I get to learn a bit more about how Deep Learning impact the medical field. I liked the video overview given by Dr. Anne Carpenter and I am sure I will be able to learn quite a few things by participating in this. The images consist of different modalities and magnification as mentioned in this thread We want a single model that just works across all kinds of image modalities, no matter the size of the nuclei or the color scheme. Such a model could be built into software that biologists use with all kinds of microscopes and eliminate the need for them to train on their individual data or provide metadata about their cell type, microscope, resolution, etc. [Dr. Anne Carpenter](https://www.kaggle.com/drannecarpenter)  DisclaimerMy knowledge of Computer Vision, Microbiology & Deep Learning is very limited. I have been trying to follow courses and learn these interesting techniques, but I have realized that this is a vast field and there are too many things to learn.  My approach may not be the right one, but I am still going to try Most of the code here is borrowed from what others have been doing. I have just tweaked a few things here and there and expanded on the steps, so that I can see and understand what is happening behind the scenes. Any suggestions to improve the code here is welcome.;Apache 2.0;https://www.kaggle.com/jerrythomas/exploratory-analysis;1.0;['pattern', 'sklearn', 'opencv-python'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['image segmentation', 'filter', 'test data', 'object detection', 'train', 'model', 'deep learning', 'label', 'k-means', 'clustering', 'computer vision'];https://www.kaggle.com/c/data-science-bowl-2018;0.721;0.449;2020-12-12 18:38:54;2018 Data Science Bowl;['beginner, exploratory data analysis, computer vision'];Exploratory Analysis;Python notebook;5001.0;52;;
2018-01-18 12:47:50;IntroHello! This rather quick and dirty kernel shows how to get started on segmenting nuclei using a neural network in Keras. The architecture used is the so-called U-Net, which is very common for image segmentation problems such as this. I believe they also have a tendency to work quite well even on small datasets. Let's get started importing everything we need!;Apache 2.0;https://www.kaggle.com/keegil/keras-u-net-starter-lb-0-277;1.0;['tensorflow', 'skimage', 'keras'];['ner', 'ai', 'dl', 'rl', 'nn', 'ann'];['image segmentation', 'filter', 'training data', 'train', 'model', 'neural network', 'epoch', 'validation data', 'layer', 'loss', 'label', 'predict', 'recommend', 'u-net'];https://www.kaggle.com/c/data-science-bowl-2018;0.846;0.649;2020-12-12 18:38:53;2018 Data Science Bowl;[];Keras U-Net starter - LB 0.277;Python notebook;259572.0;1083;;
2018-01-17 10:07:11;OverviewThe competition involves a number of different image modalities and so this kernel tries to make them all look similar so we can perform nucleus detection using a single model (which can later be trained);Apache 2.0;https://www.kaggle.com/kmader/normalizing-brightfield-stained-and-fluorescence;1.0;['skimage', 'sklearn'];['ai', 'nn', 'ann', 'cv'];['train', 'model', 'label', 'training data'];https://www.kaggle.com/c/data-science-bowl-2018;0.724;0.505;2020-12-12 18:38:54;2018 Data Science Bowl;['data visualization, exploratory data analysis, computer vision'];Normalizing brightfield, stained and fluorescence;Python notebook;5358.0;108;;
2018-01-17 10:38:53;OverviewThe kernel goes through  the preprocessing steps to load the data a quick visualization of the color-space training a simple CNN applying the model to the test data creating the RLE test data;Apache 2.0;https://www.kaggle.com/kmader/nuclei-overview-to-submission;1.0;['tensorflow', 'skimage', 'keras'];['ner', 'ai', 'dl', 'cnn', 'rl', 'nn', 'ann'];['training data', 'test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'labeled'];https://www.kaggle.com/c/data-science-bowl-2018;0.786;0.572;2020-12-12 18:38:54;2018 Data Science Bowl;['beginner, data visualization, exploratory data analysis, +2 morecnn, computer vision'];Nuclei Overview to Submission;Python notebook;29306.0;287;0.00000;0.00000
2018-03-21 22:46:20;Currently we've many models around with different performances. For model without any post-processing we can expect:  LinkNet: Around LB 0.36 UNet: Around LB 0.37 to 0.43 Mask RCNN: Around LB 0.45 to 0.50  Predictions to deliver for each image for is a list of masks detected (the instances). Now, how can we ensemble models ouputs to get better performances? For models that provide per pixel probabilities (LinkNet, UNet) one can simply do averaging/stacking on the probabilities. But for models that provide instances (with or without scoring), what can be done? This kernel is to try to experiment solutions to ensemble instances. 2018-03-20: First, we apply really basic NMS (Non-Maximum-Suppression) with bounding boxes extracted from predicted masks. 2 predictions provided as a starting point:  Model#0: LB 0.421 (Mask RCNN - Resnet101 backbone, pretrained - Coco, CV fold1) Model#1: LB 0.413 (Mask RCNN - Resnet101 backbone, pretrained - Coco, CV fold2)  Forks and contributions welcome!;Apache 2.0;https://www.kaggle.com/mpware/ensembling-on-instance-segmentation-lb-0-419;1.0;['pattern', 'skimage'];['ner', 'ai', 'cnn', 'cv', 'rl', 'nn'];['train', 'model', 'label', 'predict', 'resnet'];https://www.kaggle.com/c/data-science-bowl-2018;0.76;0.482;2020-12-12 18:38:54;multiple data sources;['ensembling'];Ensembling on Instance Segmentation (LB 0.419);Python notebook;13527.0;79;;
2018-01-29 22:37:10;This notebook provides additional information about stage1_train dataset that should help to balance into train/valid for cross-validation. It starts from this interesting thread about image types. Group A are histological slides, group B are fluorescent images, and group C are bright-field images. It can complete this other kernel. It looks we have the following breakdown:  fluorescent: 81.5% histological: 16.1% bright-field: 2.4%;Apache 2.0;https://www.kaggle.com/mpware/stage1-eda-microscope-image-types-clustering;1.0;['pattern', 'skimage', 'sklearn'];['ann', 'ai', 'nn', 'ml'];['train', 'label', 'predict'];https://www.kaggle.com/c/data-science-bowl-2018;0.74;0.46;2020-12-12 18:38:54;2018 Data Science Bowl;['beginner, data visualization, exploratory data analysis'];Stage1 EDA: Microscope image types clustering;Python notebook;7980.0;60;;
2018-02-16 18:38:02;"Author: Raoul Malm Abstract: The 2018 Data Science Bowl ""Find the nuclei in divergent images to advance medical discovery"" provides in its first stage a training and test data set consisting of 670 and 65 microscopic images of varying size showing ensembles of cells and their nuclei. For the training images the nuclei are segmented by humans such that we know their number and location within each image. The goal is to find the correct number and location of all nuclei shown in the test images. The performance of an algorithm is evaluated on the mean average precision at different intersection over union (IoU) thresholds, which will be referred to as the score in the following. For the task we implement a deep neural network of the U-Net type consisting of several convolutional and max-pooling layers. The network is written in TensorFlow. Each model can be saved/loaded and the training process can be visualized with TensorBoard. The input of the network are images of shape (height, width, channels) while the output are corresponding binary masks of shape (height, width, 1). Prior to training the network we resize, normalize and transform the images. We use 10% of the training data for validation. Furthermore, we implement data augmentation by making use of translations, rotations, horizontal/vertical flipping and zoom. Choosing an image size of 384x384 pixels the network requires roughly 30 training epochs before the training seems to converge. The network achieves a score of 0.56/0.352 on the validation/test set. A major reason for the score discrepancy can be explained by overlapping/touching nuclei that are identified as a single nucleous by the current implementation. Furthermore, we have not tuned the hyperparameters, so there is still a lot of room for improvement. Being constrained on kaggel hardware and running time, we can choose an image size of 256x256 pixels and train for 4 epochs, which takes roughly 40 minutes. The network can achieve a score of 0.45 on the validation set. Outline:  Modules and global settings Analyse data Manipulate data Score Metric Implement the Neural Network class Train the Neural Network Validate the Neural Network Make Test Prediction Submit  Reference: U-Net: Convolutional Networks for Biomedical Image Segmentation";Apache 2.0;https://www.kaggle.com/raoulma/nuclei-dsb-2018-tensorflow-u-net-score-0-352;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ann'];['filter', 'predict', 'relu', 'training data', 'train', 'epoch', 'activation function', 'labeled', 'model', 'neural network', 'layer', 'loss', 'image segmentation', 'test data', 'generation', 'output layer', 'validation data', 'label', 'u-net'];https://www.kaggle.com/c/data-science-bowl-2018;0.759;0.522;2020-12-12 18:38:54;2018 Data Science Bowl;['deep learning, image data, cnn, +1 moreneural networks'];Nuclei DSB 2018 TensorFlow U-Net Score 0.352;Python notebook;13288.0;137;0.00000;0.00000
2018-01-23 03:13:49;Here comes an example of randomly rotate and resize an image. The augmented sample could be not the same shape as the original  image, they should all be resize before feed in deep learning model.;Apache 2.0;https://www.kaggle.com/shenmbsw/data-augmentation-and-tensorflow-u-net;1.0;['tensorflow', 'skimage', 'keras'];['ner', 'ai', 'ml', 'nn', 'ann'];['filter', 'train', 'model', 'deep learning', 'layer', 'loss', 'label', 'predict', 'relu', 'ground truth'];https://www.kaggle.com/c/data-science-bowl-2018;0.781;0.512;2020-12-12 18:38:54;2018 Data Science Bowl;['computer vision'];Data augmentation and Tensorflow U-Net;Python notebook;24585.0;118;;
2018-02-01 22:40:10;This kernel will implement classical image techniques and will hopefully serve as a useful primer to people who have never worked with image data before. Ultimately, we will develop a simple pipeline using scipy and numpy (and a little bit of scikit-image) that we can apply to the test images -- in fact, we won't even use the training images except to optimize parameters. I'll keep updating this notebook to try and improve it - user Gabro Vecsei takes a similar approach and scores 0.22 in this kernel. My main intention here, though, is to help out people who are new to analyses, not to score highly.;Apache 2.0;https://www.kaggle.com/stkbailey/teaching-notebook-for-total-imaging-newbies;1.0;['skimage'];['ner', 'ai', 'dl', 'rl', 'nn', 'ann'];['filter', 'training data', 'train', 'model', 'label', 'labeled'];https://www.kaggle.com/c/data-science-bowl-2018;0.794;0.605;2020-12-12 18:38:53;2018 Data Science Bowl;[];Teaching notebook for total imaging newbies;Python notebook;37411.0;489;0.00000;0.00000
2018-01-22 01:22:01;This code is inspirated by https://www.kaggle.com/keegil/keras-u-net-starter-lb-0-277;Apache 2.0;https://www.kaggle.com/takuok/keras-generator-starter-lb-0-326;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'rl', 'cv'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'u-net'];https://www.kaggle.com/c/data-science-bowl-2018;0.742;0.46;2020-12-12 18:38:54;2018 Data Science Bowl;['beginner'];Keras generator Starter (LB=0.326);Python notebook;8430.0;60;;
2018-04-16 11:55:29;IntroFirst of all thanks to Kjetil Åmdal-Sævik for providing excellent code for data preparation. Being a novice python programmer, my code may not be that much efficient but it may serve as a starting point for using TensorFlow.;Apache 2.0;https://www.kaggle.com/vijaybj/basic-u-net-using-tensorflow;1.0;['tensorflow', 'skimage'];['ai', 'nn', 'ann', 'cv'];['filter', 'train', 'layer', 'label', 'loss', 'relu'];https://www.kaggle.com/c/data-science-bowl-2018;0.789;0.444;2020-12-12 18:38:54;2018 Data Science Bowl;['deep learning'];Basic U-net using Tensorflow;Python notebook;32102.0;49;;
2018-05-18 07:40:34;"IntroThis piece of work is inspired by a youtube video lecture by Martin Gorner, a Google developer  who put forth this idea of combining YOLO grid with SqueezeNet (instead of DarkNet - original stack for YOLO). Original paper states - "" Our model struggles with small objects that appear in groups, such as flocks of birds."", but it seems that YOLO can be useful for swarm type things as well.";Apache 2.0;https://www.kaggle.com/vijaybj/yolo-for-detection-of-bounding-boxes-tensorflow;1.0;['tensorflow', 'skimage'];['ner', 'ai', 'cv', 'nn', 'ann'];['filter', 'train', 'model', 'layer', 'label', 'loss', 'relu'];https://www.kaggle.com/c/data-science-bowl-2018;0.775;0.458;2020-12-12 18:38:54;multiple data sources;['neural networks'];YOLO for detection of bounding boxes - TensorFlow;Python notebook;20821.0;58;;
2018-01-16 19:34:15;This is an example notebook to demonstrate how the IoU metric works for a single image. Please note: this is not the official scoring implementation, but should work in the same manner.;Apache 2.0;https://www.kaggle.com/wcukierski/example-metric-implementation;1.0;['skimage'];['ner', 'ai', 'nn', 'ann'];['train', 'label', 'ground truth', 'predict'];https://www.kaggle.com/c/data-science-bowl-2018;0.751;0.516;2020-12-12 18:38:54;2018 Data Science Bowl;['biology'];Example Metric Implementation;Python notebook;10647.0;126;;
2020-01-12 08:35:47;Come, lets dive together! I guess a lot of us use CatBoost but how many of us actually understand what's going on behind the scenes?  In this kernel we'll be exploring how CatBoost works and some key insights that you may find helpful in this competition.;Apache 2.0;https://www.kaggle.com/abhinand05/catboost-a-deeper-dive;1.0;['catboost', 'xgboost', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['machine learning', 'random forest', 'generation', 'train', 'fitting', 'model', 'understanding', 'deep learning', 'loss', 'label', 'gradient boosting', 'predict', 'rank', 'decision tree', 'recommend', 'bayesian'];https://www.kaggle.com/c/data-science-bowl-2019;0.726;0.534;2020-12-12 18:40:29;2019 Data Science Bowl;['beginner, classification, gradient boosting'];CatBoost: A Deeper Dive;Python notebook;5555.0;162;;
2019-11-18 04:13:16;General informationIn this kernel I work with data from 2019 Data Science Bowl Challenge. This is quite an interesting data about children playing educational games. We need to predict how will a user perform in the next assessment. I have decided to try a different approach to feature engineering and modelling in this kernel - most of the code will be written in classes for better usability and reproducibility. These are my first attempts to do it on Kaggle, so the code may evolve into something different in the future.;Apache 2.0;https://www.kaggle.com/artgor/oop-approach-to-fe-and-models;1.0;['xgboost', 'lightgbm', 'catboost', 'sklearn', 'tensorflow'];['ner', 'ai', 'gbm', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'training data', 'test data', 'generation', 'train', 'fitting', 'model', 'loss', 'label', 'predict', 'rank', 'classification', 'bayesian'];https://www.kaggle.com/c/data-science-bowl-2019;0.749;0.535;2020-12-12 18:40:29;multiple data sources;['beginner, exploratory data analysis, classification, +1 morefeature engineering'];OOP approach to FE and models;Python notebook;10167.0;164;0.464;0.453
2019-11-21 16:10:58;General informationIn this kernel I introduce a regression approach to this task. There were already several competitions on kaggle with kappa metric. Usually a regression approach with thresholds worked the best. I use the code for feature generation from this kernel: https://www.kaggle.com/braquino/890-features And modelling is taken from my previous kernel. The code was changed to regression quite fast, so it may look not nice for now.;Apache 2.0;https://www.kaggle.com/artgor/quick-and-dirty-regression;1.0;['xgboost', 'lightgbm', 'catboost', 'sklearn', 'tensorflow'];['ner', 'ai', 'gbm', 'cv', 'rl', 'ml'];['filter', 'training data', 'regression', 'generation', 'train', 'model', 'layer', 'loss', 'label', 'predict', 'rank', 'classification', 'ground truth', 'bayesian'];https://www.kaggle.com/c/data-science-bowl-2019;0.799;0.619;2020-12-12 18:40:29;multiple data sources;['beginner, feature engineering, regression, +1 moreoptimization'];Quick and dirty regression;Python notebook;43930.0;618;0.535;0.536
2019-12-16 00:39:16;Objective In the last notebook we create our baseline model including a feature selection part.  Cohen cappa score of 0.456 (lb) with a local cv score of 0.529 In this notebook we are going to add more features and remove others that i think they overfitt the train set and then check if our local cv score improve. Next, we will check if this improvement aligns with the lb.;Apache 2.0;https://www.kaggle.com/braquino/convert-to-regression;1.0;['xgboost', 'lightgbm', 'catboost', 'sklearn', 'tensorflow', 'keras'];['ner', 'ai', 'dl', 'cnn', 'gbm', 'cv', 'rl', 'nn'];['filter', 'regression', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/data-science-bowl-2019;0.789;0.581;2020-12-12 18:40:29;2019 Data Science Bowl;[];Convert to Regression;Python notebook;32407.0;328;0.521;0.538
2020-01-20 13:40:19;2019 Data Science BowlUncover the factors to help measure how young children learnCrislânio Macêdo -  January, 02th, 2020 Github __Sapere Aude Tech __AboutMe__Twitter__Ensina.AI__Quora__Hackerrank 📒 EDA: 📒👦👧 DS Bowl - Start here: A GENTLE Introduction;Apache 2.0;https://www.kaggle.com/caesarlupum/ds-bowl-start-here-a-gentle-introduction;1.0;['xgboost', 'lightgbm', 'catboost', 'sklearn', 'pattern'];['ner', 'ai', 'gbm', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'regression', 'test data', 'train', 'model', 'reward', 'loss', 'label', 'predict', 'rank', 'understanding', 'classification', 'labeled', 'ground truth'];https://www.kaggle.com/c/data-science-bowl-2019;0.747;0.546;2020-12-12 18:40:29;2019 Data Science Bowl;['beginner, exploratory data analysis, data cleaning'];📒👦👧 DS Bowl - Start here: A GENTLE Introduction;Python notebook;9514.0;192;;
2019-10-25 15:04:43;This notebook compares 3 ways to compute QWK metric.;Apache 2.0;https://www.kaggle.com/cpmpml/ultra-fast-qwk-calc-method;1.0;['sklearn'];['ner', 'ai', 'ml'];['train', 'training data', 'filter'];https://www.kaggle.com/c/data-science-bowl-2019;0.711;0.526;2020-12-12 18:40:29;2019 Data Science Bowl;[];Ultra Fast QWK Calc Method;Python notebook;3933.0;144;;
2019-12-15 10:49:53;"Data Science Bowl 2019IntroductionPBS KIDS, a trusted name in early childhood education for decades, aims to gain insights into how media can help children learn important skills for success in school and life. In this challenge, you’ll use anonymous gameplay data, including knowledge of videos watched and games played, from the PBS KIDS Measure Up! app, a game-based learning tool developed as a part of the CPB-PBS Ready To Learn Initiative with funding from the U.S. Department of Education. Competitors will be challenged to predict scores on in-game assessments and create an algorithm that will lead to better-designed games and improved learning outcomes. Your solutions will aid in discovering important relationships between engagement with high-quality educational media and learning processes. Where does the data for the competition come from? The data used in this competition is anonymous, tabular data of interactions with the PBS KIDS Measure Up! app. Select data, such as a user’s in-app assessment score or their path through the game, is collected by the PBS KIDS Measure Up! app, a game-based learning tool. What is the PBS KIDS Measure Up! app? In the PBS KIDS Measure Up! app, children ages 3 to 5 learn early STEM concepts focused on length, width, capacity, and weight while going on an adventure through Treetop City, Magma Peak, and Crystal Caves. Joined by their favorite PBS KIDS characters, children can also collect rewards and unlock digital toys as they play. Besides the info provided above by Kaggle, I found the following additional info on the website of the app: Specific features of Measure Up! include:  19 unique measuring games. 10 measurement-focused video clips. Sticker books featuring favorite PBS KIDS characters. Rewards for completion of tasks. Embedded challenges and reports to help parents and caregivers monitor kids’ progress. Ability to track your child's progress using the PBS KIDS Super Vision companion app.  Evaluation Submissions are scored based on the quadratic weighted kappa, which measures the agreement between two outcomes. This metric typically varies from 0 (random agreement) to 1 (complete agreement). In the event that there is less agreement than expected by chance, the metric may go below 0. The outcomes in this competition are grouped into 4 groups (labeled accuracy_group in the data): 3: the assessment was solved on the first attempt 2: the assessment was solved on the second attempt 1: the assessment was solved after 3 or more attempts 0: the assessment was never solved For each installation_id represented in the test set, you must predict the accuracy_group of the last assessment for that installation_id. Note that the training set contains many installation_ids which never took assessments, whereas every installation_id in the test set made an attempt on at least one assessment. The file train_labels.csv has been provided to show how these groups would be computed on the assessments in the training set. Assessment attempts are captured in event_code 4100 for all assessments except for Bird Measurer, which uses event_code 4110. If the attempt was correct, it contains ""correct"":true.";Apache 2.0;https://www.kaggle.com/erikbruin/data-science-bowl-2019-eda-and-baseline;1.0;['catboost', 'xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'gbm', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'training data', 'regression', 'train', 'model', 'reward', 'layer', 'loss', 'label', 'predict', 'rank', 'understanding', 'classification', 'labeled', 'ground truth'];https://www.kaggle.com/c/data-science-bowl-2019;0.782;0.598;2020-12-12 18:40:29;2019 Data Science Bowl;[];Data Science Bowl 2019 EDA and Baseline;Python notebook;25586.0;435;;
2019-12-10 04:29:28;Base on https://www.kaggle.com/artgor/quick-and-dirty-regression @artgor Please upvote the original kernel, thanks. 👋;Apache 2.0;https://www.kaggle.com/hengzheng/bayesian-optimization-seed-blending;1.0;['xgboost', 'lightgbm', 'catboost', 'sklearn', 'tensorflow'];['ner', 'ai', 'gbm', 'cv', 'rl', 'ml'];['filter', 'training data', 'regression', 'train', 'model', 'layer', 'loss', 'label', 'predict', 'rank', 'classification', 'ground truth', 'bayesian'];https://www.kaggle.com/c/data-science-bowl-2019;0.742;0.512;2020-12-12 18:40:29;2019 Data Science Bowl;[];Bayesian Optimization Seed Blending;Python notebook;8452.0;118;0.534;0.511
2019-10-28 16:34:41;"I had posted my very naive baseline at https://www.kaggle.com/mhviraf/a-baseline-for-dsb-2019. In that kernel I only used the mode label for each Assessment and I thought it should be very easy to beat. This kernel shows how you can beat that baseline by actually applying a model. In this kernel via get_data() function, I go over each installation_id and try to extract some features based on his/her behavior prior to the assessment. I will then train a Catboost classifier on it and make predictions on the test set. Note that the features I made in this kernel are so very basic and you can easily add many more to it. Good luck and happy kaggling. Don't forget to upvote if you found it useful ;)";Apache 2.0;https://www.kaggle.com/mhviraf/a-new-baseline-for-dsb-2019-catboost-model;1.0;['catboost', 'sklearn'];['ner', 'ai', 'rl', 'cv'];['train', 'fitting', 'model', 'layer', 'loss', 'label', 'predict'];https://www.kaggle.com/c/data-science-bowl-2019;0.763;0.579;2020-12-12 18:40:29;2019 Data Science Bowl;[];A new baseline for DSB 2019 - Catboost model;Python notebook;14863.0;319;;
2019-12-23 06:16:37;"This notebook is original fork from Convert to Regression, thanks to Bruno Aquino.  The idea of sampling is from discusion. The idea of ""use agg stat feature of prediction"" is from qchemdog's solusion in Kaggle home credit default risk competition";Apache 2.0;https://www.kaggle.com/poteman/sampling-train-data-and-use-prediction-as-feature;1.0;['xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'gbm', 'cv', 'rl', 'ml'];['filter', 'training data', 'regression', 'train', 'model', 'layer', 'loss', 'label', 'predict'];https://www.kaggle.com/c/data-science-bowl-2019;0.726;0.509;2020-12-12 18:40:29;2019 Data Science Bowl;[];sampling train data and use prediction as feature;Python notebook;5586.0;114;0.496;0.512
2019-11-14 16:27:42;Objective In the last notebook we create our baseline model including a feature selection part.  Cohen cappa score of 0.456 (lb) with a local cv score of 0.529 In this notebook we are going to add more features and remove others that i think they overfitt the train set and then check if our local cv score improve. Next, we will check if this improvement aligns with the lb.;Apache 2.0;https://www.kaggle.com/ragnar123/feature-engineering-v-1-0;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'gbm', 'cv', 'rl', 'nn'];['filter', 'train', 'model', 'layer', 'loss', 'label', 'predict'];https://www.kaggle.com/c/data-science-bowl-2019;0.733;0.515;2020-12-12 18:40:29;2019 Data Science Bowl;[];Feature Engineering V_1.0;Python notebook;6594.0;124;0.461;0.472
2019-10-26 06:04:59;"2019 Data Science BowlA Simple Introductiontl;dr In this challenge, you’ll use anonymous gameplay data, including knowledge of videos watched and games played, from the PBS KIDS Measure Up! app, a game-based learning tool developed as a part of the CPB-PBS Ready To Learn Initiative with funding from the U.S. Department of Education. Competitors will be challenged to predict scores on in-game assessments and create an algorithm that will lead to better-designed games and improved learning outcomes.   Note that this is a synchronous rerun code competition and the private test set has approximately 8MM rows. You should be mindful of memory in your notebooks to avoid submission errors. 😅";Apache 2.0;https://www.kaggle.com/robikscube/2019-data-science-bowl-an-introduction;1.0;['sklearn'];['ner', 'ai', 'dl', 'rl', 'ml'];['filter', 'training data', 'test data', 'train', 'model', 'layer', 'label', 'predict', 'labeled', 'ground truth'];https://www.kaggle.com/c/data-science-bowl-2019;0.783;0.606;2020-12-12 18:40:29;2019 Data Science Bowl;[];🚸 2019 Data Science Bowl - An Introduction;Python notebook;26423.0;494;;
2019-12-10 01:19:35;"About this notebookYou might have noticed that the train dataset is composed of over 11M data points, but there are only 17k training labels, and 1000k test labels you are predicting. The reason for that is there are many thousand different entries for each installation_id, each representing an event. This notebook simply gathers all the events into 17k groups, each group corresponds to an installation_id. Then, it takes the aggregation (using sums, counts, mean, std, etc.) of those groups, thus resulting in a dataset of summary statistics of each installation_id. After that, it simply fits a model on that dataset. UpdatesV20:  Updated variable names for clarity.  V17:  Removed statistics on event codes, since that created a lot of columns and LGBM seems to overfit on that information.  V16:  Added mode of title accuracy_group (retrieved from training set) as a feature  V10:  Fixed labelling problem. Before that, I was blindly predicting the target without even the title I was trying to assess 🤦. I added that now by using the ""title"" column from train_labels.csv, and using the last row of each installation_id from test.csv to construct a test_labels dataframe.  V8:  Added cv_train, a function that trains k-models on each of k-fold CV splits. Then, you can use function cv_predict to use the list of models to predict an output (and blend the results). Added more summary statistics for event_code and game_time, including skewness of the distribution.  References CV idea inspired from this kernel. Thank you! Adding mode as a feature: https://www.kaggle.com/mhviraf/a-baseline-for-dsb-2019";Apache 2.0;https://www.kaggle.com/xhlulu/dsb-2019-simple-lgbm-using-aggregated-data;1.0;['tensorflow', 'lightgbm', 'sklearn', 'keras'];['ai', 'dl', 'gbm', 'cv', 'rl'];['filter', 'regression', 'train', 'model', 'loss', 'label', 'predict', 'classification'];https://www.kaggle.com/c/data-science-bowl-2019;0.744;0.509;2020-12-12 18:40:29;2019 Data Science Bowl;['feature engineering'];DSB 2019: Simple LGBM using aggregated data;Python notebook;8771.0;113;;
2019-03-17 11:32:43;Table of contents 1. The CareerVillage.org analytics competition 2. Exploratory Data Analysis 2.1 Students 2.2 Professionals 2.2.1 Locations 2.2.2 Industries   2.3 Questions and answers 2.3.1 Questions tags   2.4 Emails 2.5 Matches;Apache 2.0;https://www.kaggle.com/erikbruin/careervillage-org-data-exploration;1.0;['pattern'];['ner', 'ai', 'dl', 'rl', 'nn', 'ann'];['filter', 'generation', 'model', 'label', 'recommend'];https://www.kaggle.com/c/data-science-for-good-careervillage;0.664;0.418;2020-12-12 18:41:32;Data Science for Good: CareerVillage.org;[];CareerVillage.org Data Exploration;Python notebook;1443.0;36;;
2019-04-05 13:54:33;CareerVillage knowledge graph analysis with node embeddings1. Introductiona.) What is a knowledge graph?It is a network that represents multiple types of entities (nodes) and relations (edges) in the same graph. Each link of the network represents an (entity,relation,value) triplet. For example I give you some examples from the small knowledge graph below:  Eiffel Tower (entity) is located in (relation) in Paris (value) Paris (entity) is an instance of (relation) city (value) Alice (entity) is an instance of (relation) person (value)   The CareerVillage data set contains several different entities (persons, groups, schools, locations etc.). Thus one possible approach to analyse this data is to build a large knowledge graph representing as many relations as possible. b.) What are node embeddings?Embeddings, especially word representations (e.g. Word2Vec), is a hot research topic nowadays. The basic idea behind node embedding algorithms (e.g. node2vec, Line, DeepWalk etc.) is that if you generate node sequences originating from a given vertex and feed them to Word2Vec (like sentences from a text) you can map the nodes of the network into a low dimensional vector space. Usually these methods are optimized for the criteria to preserve the global/local role of each vertex in the graph.  c.) My workIn this work I use the node2vec algorithm to generate low dimensional representation for CareerVillage users based on the knowledge graph that I extracted from the data. My ultimate goal is to discover interesting user groups / clusters (e.g. popular professionals, satisfied students etc.) using only the available network structure.;Apache 2.0;https://www.kaggle.com/ferdzso/knowledge-graph-analysis-with-node2vec;1.0;['sklearn'];['ner', 'ai', 'rl', 'ml', 'nn', 'ann'];['train', 'model', 'label'];https://www.kaggle.com/c/data-science-for-good-careervillage;0.754;0.403;2020-12-12 18:41:32;Data Science for Good: CareerVillage.org;[];Knowledge graph analysis with node2vec;Python notebook;11461.0;30;;
2019-04-08 11:16:22;"Hi There! I'am going to use the Neo4j graph database based on this, on my local computer and post here the neccesary codes, to import the CSV to the  databased and use it for the ""who can answer these questions"" recommendation. Maybe even pictures from the database, because I love graph visualisations. :D";Apache 2.0;https://www.kaggle.com/ironben/rdbs-to-graphdb-neo4j-network-approach;1.0;['pattern'];['ner', 'ai', 'dl', 'cv', 'nlp', 'nn', 'ann'];['filter', 'train', 'understanding', 'label', 'recommend'];https://www.kaggle.com/c/data-science-for-good-careervillage;0.683;0.346;2020-12-12 18:41:32;multiple data sources;['advanced'];RDBS_to_GraphDB_(Neo4j_Network_Approach);Python notebook;2101.0;16;;
2019-04-13 15:34:06;Use tags followed by students to create feature Which days and months have students joining the most? Use tags specified in questions to create feature Use KMeans clustering. Features used question title, body, tags and student tags Use Cosine similarity. Features used question title, body, tags and student tags;Apache 2.0;https://www.kaggle.com/rblcoder/recommend-based-on-nearest-neighbors;1.0;['keras', 'sklearn', 'nltk', 'gensim'];['ner', 'ai', 'dl', 'cnn', 'gan', 'rl', 'ml', 'nn', 'ann'];['gru', 'train', 'model', 'reward', 'layer', 'clustering', 'lstm', 'label', 'k-means', 'predict', 'rank', 'recommend', 'classification'];https://www.kaggle.com/c/data-science-for-good-careervillage;0.652;0.375;2020-12-12 18:41:32;Data Science for Good: CareerVillage.org;['text data, recommender systems'];Recommend based on Nearest Neighbors ;Python notebook;1133.0;22;;
2019-04-23 18:55:11;SummaryThe problemThis Kernel is an entry into the CareerVillage.org (CV) Kaggle competition with the following objective: develop a method to recommend relevant questions to the professionals who are most likely to answer them. The proposed solution should support the CV metric: A good recommender system should help us to reach a target of a high (95%?) percent of questions which get a 10-quality-point-answer within 24 hours, without churning the Pros, and within the bounds of fairness. Proposed SolutionA triage question handler is proposed together with a set of recommendations to handle the cold start problem and a method that provides a list of suggested questions for professionals that visit the CV site. The triage question handler compares a new question with all the previously asked questions and puts the question into one of three categories:  When there are many good matches with similar previously answered questions, students should be given immediate feedback by displaying this list of similar questions. They could be asked if their question was answered or if they still want professionals to be asked. This gives old questions/answers new life and the opportunity for professionals to get regular feedback to promote continued engagement. When there are fewer less good matches with similar previously answered questions, there is a group of questions where the matches are still good enough to find professionals who will find the student's question relevant. When there are very few or no good matches with similar previously answered questions the system can immediately flag this problem. Ideally CV could recruit a group of very engaged professionals who are willing to get involved in answering these difficult to answer questions. In some cases that answer may require the development of a dialogue which would require an extension to the current system.  A number of technologies are considered to drive the model. Six of these are explored in detail:  tfidf questions bags of words similarity  Word2Vec  FastText  GloVe  Universal sentence encoder (USE)  tfidf professionals bag of words similarity   For the first 5 models, the 10 best matches are found for the last 100 questions in the data set that are answered. An extensive but subjective comparison shows the FastText system is the most suitable with Word2Vec almost as good. The subjective analysis of the last 20 questions shows that the FastText method can deliver 4 relevant similar question out of 5 whereas the tfidf method only delivers 2 relevant similar question out of 3. A process is then developed to use the recommendations to tune the model to fulfil the problem requirements. SupportThe proposed solution is supported by an extensive Exploratory Data Analysis and recommendations for further improving the effectiveness of the system.;Apache 2.0;https://www.kaggle.com/rdhnw1/triage-recommender-with-cold-start;1.0;['vocabulary', 'nltk', 'gensim', 'sklearn', 'tensorflow', 'pattern'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'ml', 'nlp', 'nn', 'ann'];['filter', 'reward', 'predict', 'gru', 'machine learning', 'train', 'epoch', 'text classification', 'recommend', 'classification', 'labeled', 'model', 'layer', 'loss', 'rank', 'understanding', 'bayesian', 'regression', 'generation', 'artificial intelligence', 'deep learning', 'label'];https://www.kaggle.com/c/data-science-for-good-careervillage;0.7;0.39;2020-12-12 18:41:32;multiple data sources;[];Triage Recommender with Cold Start  ;Python notebook;3077.0;26;;
2019-04-24 09:46:45;🔎CareerVillage.org Recommendation System🔍 Objective: To develop a method to recommend relevant questions on CareerVillage.com to the professionals who are most likely to answer them.;Apache 2.0;https://www.kaggle.com/teenutarcis/careervillage-recommendation-system;1.0;['nltk', 'gensim'];['ner', 'ai', 'dl', 'rl', 'nn', 'ann'];['filter', 'machine learning', 'generation', 'train', 'model', 'label', 'recommend'];https://www.kaggle.com/c/data-science-for-good-careervillage;0.656;0.34;2020-12-12 18:41:32;Data Science for Good: CareerVillage.org;['beginner, text mining, recommender systems'];👩🏻‍💼CareerVillage Recommendation System👨🏻‍💼;Python notebook;1218.0;15;;
2019-04-17 14:14:56;Ikigai - A Career Village RecSysby Marsh [ @vbookshelf ] 9 April 2019;Apache 2.0;https://www.kaggle.com/vbookshelf/ikigai-a-career-village-recsys;1.0;['nltk', 'sklearn', 'tensorflow', 'vocabulary', 'keras'];['ner', 'ai', 'dl', 'cnn', 'gan', 'rl', 'ml', 'nlp', 'nn', 'rnn', 'ann'];['filter', 'machine learning', 'train', 'model', 'understanding', 'neural network', 'reward', 'deep learning', 'layer', 'label', 'rank', 'recommend', 'labeled'];https://www.kaggle.com/c/data-science-for-good-careervillage;0.629;0.346;2020-12-12 18:41:32;multiple data sources;['recommender systems'];Ikigai - A Career Village RecSys;Python notebook;743.0;16;;
2019-03-06 00:47:43;IntroductionThe U.S. has almost 500 students for every guidance counselor. Underserved youth lack the network to find their career role models, making CareerVillage.org the only option for millions of young people in America and around the globe with nowhere else to turn. Our goal is to develop a method to recommend relevant questions to the professionals who are most likely to answer them. Outline of kernel is as follows:  Exploring questions and answers (1) Exploring questions and answers (2) and mind-blowing observation Exploring students Exploring professionals (added filtering active professionals) Exploring professionals and answers Exploring tags Exploring questions bigram Building tag_chart Content Based Recommender (added get similar professionals) t-SNE visualization  Please remember to upvote if you find the work useful! Thank you for visiting.;Apache 2.0;https://www.kaggle.com/wjshenggggg/update-5-text-processing;1.0;['pattern', 'sklearn', 'nltk'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'generation', 'model', 'label', 'rank', 'recommend'];https://www.kaggle.com/c/data-science-for-good-careervillage;0.703;0.447;2020-12-12 18:41:32;Data Science for Good: CareerVillage.org;['beginner, data visualization, exploratory data analysis'];UPDATE 5: text processing;Python notebook;3297.0;51;;
2019-06-21 02:26:51;"Introduction The purpose of this kernel is to convert the collection of 684 job bulletin text files into a single structured .csv file (aka flat file) A job bulletin has a hierarchical structure: within the Carpenter bulletin, the job titles ""carpenter"" and ""cabinetmaker"" are within the apprenticeship experience requirement; another branch of the tree only requires full time paid experience doing carpenter or cabinetmaker work I think that this is the fundamental problem: in a csv, each leaf of the tree should either be on its own line (if it has parents, e.g. a sub-requirement) or in its own column (if it has no parents, e.g. duties or salary).  Getting this right will let us feed the hierarchical structure of requirements directly into a graph of promotions If this csv format is followed, then every line in the csv should correspond to a path in the promotion graph My strategy is to use regular expressions to tokenize the entries in the columns of the structured csv To help with this, I've taken some vocabulary from Los Angeles area college course catalogs";Apache 2.0;https://www.kaggle.com/claurin1/building-a-structured-csv-file-data-dictionary;1.0;['pattern', 'vocabulary'];['ner', 'ai', 'dl', 'ml', 'nn', 'ann'];['rank', 'filter', 'train'];https://www.kaggle.com/c/data-science-for-good-city-of-los-angeles;0.675;0.319;2020-12-12 18:42:37;multiple data sources;['beginner, data cleaning'];Building a Structured CSV File & Data Dictionary;R notebook;1792.0;12;;
2019-05-24 21:38:30;Table of Content Introduction Preparation Data Extraction  Submission Exploratory Data Analysis (EDA);Apache 2.0;https://www.kaggle.com/danielbecker/l-a-jobs-data-exctraction-eda;1.0;['spacy'];['ner', 'ai', 'dl', 'rl', 'ml', 'nlp', 'nn', 'ann'];['filter', 'train', 'label', 'rank', 'recommend', 'classification'];https://www.kaggle.com/c/data-science-for-good-city-of-los-angeles;0.664;0.34;2020-12-12 18:42:37;Data Science for Good: City of Los Angeles;['data visualization, exploratory data analysis, data cleaning'];L.A. Jobs (Data Exctraction, EDA);Python notebook;1440.0;15;;
2019-05-08 04:59:36;Data Science for Good: City of Los Angeles;Apache 2.0;https://www.kaggle.com/paultimothymooney/explore-job-postings;1.0;['pattern', 'nltk'];['ner', 'ai', 'gan', 'rl', 'nn', 'ann'];['train', 'recommend', 'layer'];https://www.kaggle.com/c/data-science-for-good-city-of-los-angeles;0.682;0.352;2020-12-12 18:42:37;Data Science for Good: City of Los Angeles;['data visualization'];Explore Job Postings;Python notebook;2082.0;17;;
2019-05-14 09:31:58;Data Science for Good: City of Los AngelesIntroductionHere is an attempt to get the data in quickly. Bit ugly and not as required for later. But we can look at the explicit links and see what could be done implicitly and also review the language from a diversity point of view. Explicit links first....The first set of plots show the subordinate positions to a role, ie who could be promoted. The second set of plots show what promotions are available to a role. There are some amazing routes...;Apache 2.0;https://www.kaggle.com/rdhnw1/la-jobs-explicit-links-diagrams;1.0;['nltk'];['ner', 'ai', 'dl', 'ml', 'nn', 'ann'];['label'];https://www.kaggle.com/c/data-science-for-good-city-of-los-angeles;0.602;0.327;2020-12-12 18:42:37;Data Science for Good: City of Los Angeles;[];LA Jobs: Explicit Links Diagrams;Python notebook;466.0;13;;
2019-06-21 05:29:01;Data Science for Good: City of Los Angeles;Apache 2.0;https://www.kaggle.com/shahules/discovering-opportunities-at-la;1.0;['vocabulary', 'nltk', 'gensim', 'sklearn', 'pattern'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nn', 'ann'];['train', 'model', 'layer', 'label', 'clustering', 'understanding'];https://www.kaggle.com/c/data-science-for-good-city-of-los-angeles;0.772;0.567;2020-12-12 18:42:37;Data Science for Good: City of Los Angeles;['beginner, exploratory data analysis, data cleaning, +2 morenlp, text data'];Discovering opportunities at LA;Python notebook;19288.0;264;;
2019-06-21 10:50:34;Data Science For Good : CoLA A Complete Pipeline for Structuring, Analysis and Recommendation Improve Hiring Process and Decisions  The workforce at The City of Los Angeles serve as the backbone for a number of services.  As an organization, they are in a unique hiring situation. One-third of their workers are retiring very soon and they have opened a number of job roles. The organization wants to improve the job bulletins that will fill all the open positions. Most of this data is present in unstructured form and it needs to be converted into a structured format before it can be analysed and obtain actionable insights. The content, tone, and format of job bulletins can strongly influence the quality of the applicants. Also, within such a huge organization, it also becomes difficult to clearly identify which promotions are available. Key Objectives: Keeping these challenges in mind, an ideal solution for the City of Los Angeles has following key objectives: Develop an nlp framework to accurately structurize the job descriptions. Develop an analysis framework to identify the implict bias in the text and encourage diversity. Develop a system which can clearly identify the promotion pathways within the organization. My Submission: Following are parts of Kernels Submissions in order:  Part 1: Job Bulletin Structuring Engine - City of Los Angeles   Part 2: Encourage Diversity and Remove Unconsious Bias from Job Bulletins - A Deep Analysis  Part 3: Impact of Content, Tone, and Language : CTL Analysis for CoLA  Part 4: Increasing the Discoverability of Promotional Pathways (Explicit)  Part 5: Implicit Promotional Pathways Discoverability  In the first kernel, a complete job bulletin entity extraction and data structuring engine is developed. In the second kernel, a deep analysis of unconscious bias is performed and a framework is shared to validate and reproduce the results. In the third kernel, impact of content, tone, and language is measured. And finally, in the last two kernels, a methodology is shared to visualize the promotion pathways (both explict and implict) and identifying the possible promotions pathways for a role.  Part 1: Job Bulletins Structuring Engine  Other Parts: Part 1 | Part 2 | Part 3 | Part 4 | Part 5 Table of Contents1. Approach Overview 2. Complete Code Implementation  2.1 BulletinParser Class 2.2 Formatter Class 2.3 Extractor Class   3. Final Structured CSV 4. Code Documentation 5. Reusable Python Package 6. Key Highlights of the Approach  1. Approach OverviewIn this challenge, a corpus text files is shared in which every file is a job bulletin of a job role. The task is to parse the text files, extract different entities, pieces of information and produce a well-defined structured file. This task is a typical example of a text parsing problem in which the end goal is to simplify the text data into meaningful entities.I have developed a python based engine called Job Bulletin Structuring Engine which takes input as a corpus of text files and generates a structured file as the output. The overall architecture diagram is described below:    This architcuture has three main classes - A. Bulletin Parsing Class, B. Formatter Class, and the C. Extractor Class. The first class is the Bulletin Parsing Class is the core class which is used to extract different entities and different fields, It uses different techniques of text mining and information reterival to obtain the entities.  Layout based Pattern Identification    Keyword based Patterns Identification       Regular Expressions Matching      Using these techniques, I have developed systematic and hierarichial parsing rules tailored for specific entity and general entities. Entities here mean different fields/information to be extracted from text files. The process of developing these nlp / text mining based rules was very iterative. I randomly read and explored more than 50 text files and observed the key patterns in them. Develop the parsing rule, test it, validate it, identify failure cases and iterated again. The second class is the Formatter class in which results of different entities are passed as input, they are standardized, cleaned, formatted to desired format, and validated. The results are then stored in a csv file which is given as the output. Finally, The third class is the Extractor class which is used to execute the overall parsing and cleaning processes based on user inputs. Key features:  Reusable and Generic Functions: The engine consists of code snippets which are generic codes for many fileds.    Cleaning Functions : In many cases, extracted entities contain noise, hence many custom functions to clean the results are added.     Code and Documentation : The comprehensive documentation of both the codes and the text parsing rules is also shared.    Edge Case Handelling: Since this is a very unstructured problem, there were many edge cases in text parsing, I have incorporated as many as such cases possible to give best possible results.      2. Complete Code Implementation (DOCUMENTATION)The next section contains the entire well-documentated source code which follows pep8 guidelines and uses best coding practices. In the section 5, I have also shared a python package which can be used to produce the results with 2 lines of code. Package link: https://pypi.org/project/pycola/  2.1 BulletinParser ClassThe first component is BulletinParser Class whose role is to obtain entities and information using different text mining rules.;Apache 2.0;https://www.kaggle.com/shivamb/1-bulletin-structuring-engine-cola;1.0;['pattern'];['ner', 'ai', 'dl', 'gan', 'rl', 'nlp', 'nn', 'ml'];['recommend', 'filter'];https://www.kaggle.com/c/data-science-for-good-city-of-los-angeles;0.759;0.502;2020-12-12 18:42:37;Data Science for Good: City of Los Angeles;['nlp, text mining'];1. Bulletin Structuring Engine - CoLA;Python notebook;13065.0;103;;
2019-06-20 16:06:41;"Data Science For Good : CoLA A Complete Pipeline for Structuring, Analysis and Recommendation Improve Hiring Process and Decisions  Key Objectives: Keeping these challenges in mind, an ideal solution for the City of Los Angeles has following key objectives: Develop an nlp framework to accurately structurize the job descriptions. Develop an analysis framework to identify the implict bias in the text and encourage diversity. Develop a system which can clearly identify the promotion pathways within the organization. My Submission: Following are parts of Kernels Submissions in order:  Part 1: Job Bulletin Structuring Engine - City of Los Angeles   Part 2: Encourage Diversity and Remove Unconsious Bias from Job Bulletins - A Deep Analysis  Part 3: Impact of Content, Tone, and Language : CTL Analysis for CoLA  Part 4: Increasing the Discoverability of Promotional Pathways (Explicit)  Part 5: Implicit Promotional Pathways Discoverability Part 2: Encourage Diversity, Reduce Unconscious Bias - Deep Analysis  Other Parts: Part 1 | Part 2 | Part 3 | Part 4 | Part 5The aim of this kernel is to analyse, measure, and quantify unconscious (or implicit) bias present in the job bulletin's of City of Los Angeles. This kernel uses bag of words, dictionary approch to check the presence of certain category of keywords in the text, it then applies different normalization techniques in order to quantify the amount of unconscious bias present in the text. Different data visualizations are used to showcase the key insights and related trends. In the end, I perform a simulation experiment to validate the hypothesis. Table of Contents1. What is Diversity Hiring?  2. Unconscious Gender Bias in City's Bulletins      2.1 Use of Gendered Keywords in City's Bulletins      2.2 Measuring the gender bias in City's Bulletins      2.3 Bulletins with High Masculine (or Feminine) Denotation      2.4 Masculine and Feminine Words Usage      2.5 Does (Masculine) Jobs are Offered Higher Salaries ?      2.6 Does More Masculine Class means Higher Salary?      2.7 Does Job Seniority Levels also show Gender Bias?      2.8 Has the use of gendered language changed over time?  3. Other forms of Unconscious Gender Bias      3.1 Use of Superlatives Keywords      3.2 Use of Master/Expert in Bulletins      3.3 Describing the Requirements - Number of lines      3.4 Keywords containing ""man""      3.5 Bad Assumption that there are only two genders  4. Quantifying Unconscious Gender Bias  5. Design Experiment for Validation : A Simple Simulation     5.1 Analogy from Econometric Theory      5.2 Using the Analogy to Design Experiment      5.3 Creating Scenarios and Evaluating      5.4 Analysis - Does reducing bias garners more applicants?      5.5 Effect on Male Applicants      5.6 Effect on Female Applicants  6. Key Recommendations   1. What is Diversity HiringA Gentle Introduction to Diversity Hiring""Diversity is the collective strength of any successful organization"". Diversity hiring is the hiring process that is free from bias based on age, race, gender, religion, sexual orientation, and other personal characteristics. Diversity is very crutial for any company as it leads to creation of a culture that enables new ways of thinking, gives them an edge versus their competitors, and in turn, impacts the bottom line and overall success of the company (Source: Forbes). However, Many companies struggle to ensure high levels of diversity among the employees and even the potential applicants for the open positions. In some cases, this is the due to explicit nature of companies to give less importance to diversity. But in large number of cases, it is due to the implicit Unconscious bias among different elements of the company such as hiring manager's mindset, company's actions, and even the job bulletins for the open positions. Unconscious Bias : What it it, Why it occurs? Unconscious bias is the set of assumptions directly linked to one's thinking, judgements, social background, personal values, etc. is often defined as prejudice or unsupported judgments in favor of or against one thing, person, or group as compared to another, in a way that is usually considered unfair. Most common example of Unconscious bias is the gender bias which exists in different cycles of hiring process. (Source: Empiric) Unconscious Bias in Job BulletinsResearch shows that use of masculine language in bulletins such as including adjectives like “competitive” and “determined,” results in women’s “perceiving that they would not belong in the work environment.” On the other hand, use of words like “collaborative” and “cooperative” tend to draw more women than men. Use of language and word choice plays a key role in encourgaing applicant's diversity. Thus, it is important for the company to write job bulletins which are gendered-neutral or are free of any Unconscious bias. In this kernel, I have performed different types of analysis which measure, quantify and analyse the Unconscious bias - specifically gender bias.  2. Unconscious Gender Bias in City of LA's Job Bulletins ? Job bulletins biased toward a specific gender can limit the candidate pool and diversity.  Following are some of the common traits of a gendered bias job bulletin.  1. High Use of Genderded Keywords: Words which are more ‘aggressive’, ‘assertive’ or ‘independent’ rather than things ‘conscientious’, ‘dedicated’ and ‘sociable’ will typically put off women. Using gender-charged words in job description can isolate a gender from applying 2. High Use of Superlatives Usage: Excessive use of superlatives such as “expert,” “superior,” “world class” can turn off female candidates who are more collaborative than competitive in nature    3. Less Use of Relationship/Family Keywords Usage: Descriptions in which there is more usage of family oriented keywords tend to attract more female than men.  4. Very Demanding Requirements: Research shows that women are unlikely to apply for a position unless they meet 100 percent of the requirements, while men will apply if they meet 60 percent of the requirements.   5. Use of Gendered pronouns: Using pronouns which are targeted for particular gender is not considered a good style of writing.   6. Use of Keywords containing ""man"": Keywords containing ""man"" may sound that they are only meant for males.     I used following sources to obtain all the relevant information related to unconscious bias in job bulletins. Sources: OnGig, LinkedIn, HarvardBusinessSchool, Lever, SHRM, Catalyst, SheGeeksOut, Katmatfield, ZipRecruiter, BBC, Textio In the following cell I have developed different functions that analyse these traits in the job bulletins. I curated several lists from multiple sources and complied them for different categories - masculine denotation, feminine denotation, superlatives, relationships etc. Following word clouds shows the top keywords related to feminine and masculine category.";Apache 2.0;https://www.kaggle.com/shivamb/2-encourage-diversity-reduce-bias-cola;1.0;['spacy', 'nltk'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nlp', 'nn', 'ann'];['train', 'model', 'understanding', 'label', 'recommend'];https://www.kaggle.com/c/data-science-for-good-city-of-los-angeles;0.699;0.416;2020-12-12 18:42:37;multiple data sources;['data visualization, exploratory data analysis, text mining'];2. Encourage Diversity, Reduce Bias - CoLA ;Python notebook;2979.0;35;;
2019-06-21 08:53:07;"Data Science For Good : CoLA A Complete Pipeline for Structuring, Analysis and Recommendation Improve Hiring Process and Decisions  Key Objectives: Keeping these challenges in mind, an ideal solution for the City of Los Angeles has following key objectives: Develop an nlp framework to accurately structurize the job descriptions. Develop an analysis framework to identify the implict bias in the text and encourage diversity. Develop a system which can clearly identify the promotion pathways within the organization.My Submission: Following are parts of Kernels Submissions in order:  Part 1: Job Bulletin Structuring Engine - City of Los Angeles   Part 2: Encourage Diversity and Remove Unconsious Bias from Job Bulletins - A Deep Analysis  Part 3: Impact of Content, Tone, and Language : CTL Analysis for CoLA  Part 4: Increasing the Discoverability of Promotional Pathways (Explicit)  Part 5: Implicit Promotional Pathways DiscoverabilityPart 3: Impact of Content, Tone, and Language in Job Bulletins  Other Parts: Part 1 | Part 2 | Part 3 | Part 4 | Part 5 The aim of this kernel is to provide an analysis framework which performs various types of text analysis on the job bulletins of City of Los Angeles. The goal of all types of analysis is to measure how well the job descriptions are written. The hypothesis is if the text is well written and fully serves its purpose, then it is likely to attract a good quality and quantity of applicants. To validate the hypothesis, I have also created a benchmark index using an indirect method, which can be used to compare CoLA insights with the market insightsTable of Contents1. Why Content, Tone, Format and Language Matters? 2. Creating a Benchmark Index for Hypothesis Validation     2.1 Analogy of using a Market Benchmark     2.2 Analysis of Job Bulletins of Fortune 500 Companies 3. Content: Is the Content of CoLA Job Descriptions Optimal?     3.1 Are the Job Descriptions of City of LA too Lengthy?     3.2 Are the Job Descriptions of City of LA too Wordy?     3.3 Are the Job Bulletins difficult to read ?     3.4 What does the Readability analysis of Bulletins suggest?     3.5 Which Job Bulletins are too wordy?     3.6 What are the outlier Job Bulletins - least wordy     3.7 Outlier Job Bulletins - easier to read     3.8 Relatively, which Job Bulletins are difficult to read 4. Language: Is the Language of CoLA Job Descriptions Optimal?     4.1 How well the Job Bulletins describes Duties?     4.2 Does the Word Choice convey a lot of strictness? 5. Is the format optimal?  6. Tone: What does the Tone and Sentiment of CoLA Job Descriptions suggest? 7. Key Recommendations  1. Why Content, Tone, Language and Layout Matters ?A number of studies (LinkedIn, Forbes, and Glassdoor) have suggested that both the quality and the quantity of applicant's pool can be significantly influenced by how a job description is written. ""A well-written, complete, and insightful job description can result in attracting some of the top and diverse talents for the role"". On the other hand, a description which lacks key features (example - an optimal word limit, choice of the words, language used, overall tone) may result in attracting fewer candidates. It is important for City of Los Angeles to share the job descriptions with optimal and satisfactory content, language, tone, and the layout. The job descriptions are meant to effectively communicate about a particular job class, duties, responsibilities, requirements, and company to the audience. The point worth noting is that, the audience may have versatile backgrounds, demographics, different thought processes, intelligence, intellectuals, and different skills. With such diversity possible in applicants, it become important for the company to make sure that job descriptions are generic and not focussed to target a particular group.  Content: Content plays the most important role in describing the overall quality of a job description. Use of too many words, long paragraphs, and irrelevant verbose may not be perceived equally by all candidates, Especially women who according to Harvard Business Review, tend to get 100% clarity about the job before applying. Another example from Linkedin study was related to length of job descriptions, Shorter job posts garnered a higher application rate than longer ones. Thus, keeping the job description text concise and optimal helps candidates immediately get the info they need.  Tone: For any big company it is important to express a professional tone in the job descriptions. An ideal text should be written in a formal tone and should reflect company's actual culture. The overall tone can be formal, generic or casual tones. Moreover, Use of particular wordings or phrases can also communicate emotional tones, which can have a direct impact on the applicant pool. For instance, more use of words with negative sentiment may reflect a pessimistic tone and may give a bad impression. It may result in only a fraction of potential applicants will apply.  Language: Choice of words and phrases is another important factor that makes up a good job description. Langauge analysis is about evaluating if the text conveys the proper message it is meant to be. One key example is about job duties which are meant to convey what the person will be doing if they are hired. It is possible that langauge or text of job duties section may not properly convey all those actions.    2. Creating A Benchmark Index for Hypothesis Validation The problem statement of this challenge is very open ended and without actual applicant's response data, one cannot validate if all the intution and hypothesis are correct or not. Though I have used a number of other studies and researches conducted by many other companies as the reference to suggest key hypothesis but it is also important to develop a high level validation strategy.  2.1 Analogy of using a Market Benchmark Index  Analogy: In stock markets, investors refer to S&P 500 index which is an aggreagted stock index based on the market capitalizations of 500 large companies having common stock listed on the NYSE, NASDAQ, or the Cboe BZX Exchange. Investors use this index to understand how the overall market is performing and if their stock is also aligned (or below, or above) with it. Hence, it serve as a benchmark index.      In the similar manner, I created my own benchmark index by analysing the Job Descriptions of Fortune 500 Companies (Forbes: Fortune 500 companies). Use of this index, gives us a ""Industry"" benchmark (similar to ""market"" in S&P 500). Ofcourse, this index may not convey an exact reflection of metrics but this index definately gives the most ideal metrics which are used by some of the top and big companies having diverse sectors.    To state an example, it will be interesting to compare what is the average number of words used in City of Los Angeles job descriptions and that of Fortune 500 companies descriptions.      The following diagram explains how I developed this index   I obtained the list of 2019 fortune 500 companies from Forbes. I made different input queries (location=""la"", role=""CityofLA Job Roles"", company=""One of the 500 companies"") and queried them in Free Public API of Indeed to obtain the job bulletins of these 500 companies. I obtained maximum three job descriptions per company, obtained the text data, and calculated all the relevant metrics to be used as a benchmark. The script of this process is shared in the next cell. The code is commented, it requires two arguments - API_KEY (which can be obtained from this link - https://opensource.indeedeng.io/api-documentation/) and a list of job roles to be searched. Adding this benchmark comparison gives a data-driven perspective to this problem along with our hypothesis.";Apache 2.0;https://www.kaggle.com/shivamb/3-impact-of-ctl-content-tone-language-cola;1.0;['pattern', 'textblob', 'spacy', 'nltk'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nlp', 'nn', 'ann'];['train', 'recommend', 'label', 'filter'];https://www.kaggle.com/c/data-science-for-good-city-of-los-angeles;0.657;0.357;2020-12-12 18:42:37;multiple data sources;['text mining'];3. Impact of CTL (Content, Tone, Language) - CoLA;Python notebook;1261.0;18;;
2019-06-21 13:39:10;Data Science For Good : CoLA A Complete Pipeline for Structuring, Analysis and Recommendation Improve Hiring Process and Decisions  Key Objectives: Keeping these challenges in mind, an ideal solution for the City of Los Angeles has following key objectives: Develop an nlp framework to accurately structurize the job descriptions. Develop an analysis framework to identify the implict bias in the text and encourage diversity. Develop a system which can clearly identify the promotion pathways within the organization.My Submission: Following are parts of Kernels Submissions in order:  Part 1: Job Bulletin Structuring Engine - City of Los Angeles   Part 2: Encourage Diversity and Remove Unconsious Bias from Job Bulletins - A Deep Analysis  Part 3: Impact of Content, Tone, and Language : CTL Analysis for CoLA  Part 4: Increasing the Discoverability of Promotional Pathways (Explicit)   Part 5: Implicit Promotional Pathways Discoverability Part 5: Implicit - Promotional Pathways Discoverability Other Parts: Part 1 | Part 2 | Part 3 | Part 4 | Part 5  In the last kernel, I explored the method to identify and visualize promotional pathways which are mentioned explicitly in the job requirements. In this kernel, I have made an attempt to identify the promotional pathways using the contextual anlaysis of job requirements (implict). I have shared the methodology below: Methodology:  From the structured data, obtain the complete requirement text and perform basic text cleaning.    Represent every requirement text as a vector in which the context and semantics are preserved. I have used Pre-Trained Word Embeddings using fasttext for this purpose. For every job class requirement, representing it as a vector is very helpful as the word embedding vectors can be used to identify other job classes which shares similar requirements. In cases when a job class is not mentioned explicitly in the requirment, this method can be used to identify implict links.    Compute a contextual similarity matrix which gives similarity scores of one class with the others.   Use the similarity matrix to identify possible candidates. Filter them using a dictionary of seniority levels and flexible ngram matching to ensure that parent job class is actually linked to a child job class.    The overview of the methodology is shown in the following process flow diagram.    There are two parts in this method: A: Pre-Processing Stage : Compute requirement context vectors, and context similarity matrix B: Identification Stage : Finding the implicit links using similarity scores, dictionary, and ngram matching. Following are the contents of the kernel: Contents:1. Load Pre-Trained Word Embeddings 2. Load and Clean the Requirements Text Data 3. Convert Requirements to Requirements Context Vectors 4. Compute Contextual Similarity Matrix 5. Identify and Filter the Implicit Links 6. Write the Visualization Functions 7. Examples  1. Load Pre-Trained Word EmbeddingsA popular idea in modern machine learning is to represent words by vectors (also called word embeddings). These vectors capture hidden information about a language, like word analogies or semantic. Let's load the 2M word embedding vectors in a python object from fasttext dataset.;Apache 2.0;https://www.kaggle.com/shivamb/5-implicit-promotional-pathways-discoverability;1.0;['sklearn', 'nltk'];['ner', 'ai', 'dl', 'gan', 'rl', 'nlp', 'nn', 'ml'];['train', 'filter', 'recommend', 'machine learning'];https://www.kaggle.com/c/data-science-for-good-city-of-los-angeles;0.644;0.362;2020-12-12 18:42:37;multiple data sources;['data visualization'];5. Implicit Promotional Pathways Discoverability;Python notebook;986.0;19;;
2019-05-14 14:33:56;"Problem Objective:Help the City of Los Angeles to structure and analyze its job descriptions The City of Los Angeles faces a big hiring challenge: 1/3 of its 50,000 workers are eligible to retire by July of 2020. The city has partnered with Kaggle to create a competition to improve the job bulletins that will fill all those open positions. The content, tone, and format of job bulletins can influence the quality of the applicant pool. Overly-specific job requirements may discourage diversity. The Los Angeles Mayor’s Office wants to reimagine the city’s job bulletins by using text analysis to identify needed improvements. The goal is to convert a folder full of plain-text job postings into a structured CSV file and then to use this data to: (1) identify language that can negatively bias the pool of applicants; (2) improve the diversity and quality of the applicant pool; and/or (3) make it easier to determine which promotions are available to employees in each job class.";Apache 2.0;https://www.kaggle.com/sudalairajkumar/dsfg-exploration-of-jobs-at-la;1.0;['pattern', 'nltk'];['ner', 'ai', 'dl', 'rl', 'nn', 'ann'];['label'];https://www.kaggle.com/c/data-science-for-good-city-of-los-angeles;0.7;0.421;2020-12-12 18:42:37;Data Science for Good: City of Los Angeles;[];DSFG - Exploration of Jobs at LA;Python notebook;3094.0;37;;
2019-06-21 15:14:50;"Data Science for Good: City of Los AngelesTable of contents  1. Overview 1.1 Related existing systems at City of LA 1.2 Problem Statement 1.3 Challenges 1.4 Ideal Solution   2. What's in the Kernel 3. Data Conversion 3.1 Functions & Logic Explanations   4. Exploratory Data Analysis 4.1 Recommendation 1 (Reduce bias : competency analysis) 4.2 Recommendation 2 (Selection of job opening days) 4.3 Recommendation 3 (Engage quality applications) 4.4 Recommendation 4 (Increase applicant pool : content analysis) 4.5 Recommendation 5 (Readable to all : reach large audience) 4.6 Recommendation 6 (Attract diversity) 4.7 Recommendation 7 (HR Buzz words) 4.8 Recommendation 8 (Neutral message) 4.9 Recommendation 9 (Convice applicants) 4.10 Recommendation 10 (Find the match)   5. Applications 5.1 Application 1 - Job Search 5.2 Application 2 - Readability Score 5.3 Application 3 - Gender Biasedness Check 5.4 Application 4 - Promotional Paths   6. Extra Notes   1. OverviewThe City of Los Angeles faces a big hiring challenge - 1/3 of its 50,000 workers are eligible to retire by July of 2020. This is an issue of big concern. As mentioned by one of the competition hosts, there are some job classes that will be challenging to fill with qualified candidates fullfilling the vision of City of LA. Their vision is to maintain excellence, provide consistent services to customers, and to meet the challenges of tomorrow through expertise, innovation, and cooperative partnerships. To acheive this, they aim to fill the vacancies with quality resources maintaining diversity. We tried to parse the data for job bulletins and tried to simplify and highlight things to realise good and bad points to overcome this challenge. Here are few points we tried to focus on in the successive sections:  To get insights from the text. To identify implicit bias in text that might be putting off people of specific gender, age, race from applying to a job class. To achieve high quality and quantity of applications. To identify and simplify the process of promotional paths.   1.1 Related Existing Systems at City of LAJob Match The functionality is available at LA city web portal. Users can select multiple fields of their interest, education/training and experience, based on which jobs are searched and displayed. Job Analysis Below is an excerpt from LA city web portal. Job analysis is the systematic identification and documentation of the tasks performed on the job and the competencies required to perform the tasks based on information/data provided by a representative group of job experts.  Information in the job analysis must be sufficiently descriptive and detailed to provide an understanding of the job.  Job is a class in the City of Los Angeles Classification Plan. Tasks are discrete, self-contained units of work. They reflect the specific behavior of individuals when performing the work. Competencies are the knowledge, skill, ability, aptitude, capability, or other personal characteristics needed to perform the job. Representative group refers to a sufficiently large sample that proportionally reflects the class. Job experts are individuals with in-depth knowledge of the job and its requirements.  City of Los Angeles Personnel Department staff conducts job analyses by interviewing job experts, usually job incumbents and/or supervisors, and having them complete questionnaires. A formal observation of the job may also be conducted as part of the job analysis. Job Awareness From AMA discussion section:  Social media promotions Word of mouth, general interest in government. Job bulletins are available on current job openings web page.   1.2 Problem StatementKaggle describes it as: For filling vacancies several job ads are posted which plays one of the vital role to attract job applications. The content, tone, and format of job bulletins can influence the quality of the applicant pool. Overly-specific job requirements may discourage diversity. The Los Angeles Mayor’s Office wants to reimagine the city’s job bulletins by using text analysis to identify needed improvements. The goal is to convert a folder full of plain-text job postings into a single structured CSV file and then to use this data to:  identify language that can negatively bias the pool of applicants; improve the diversity and quality of the applicant pool; make it easier to determine which promotions are available to employees in each job class.  Data Description The job bulletins are provided as a folder of plain-text files, one for each job classification. Job Bulletins Folder  683 plain-text job postings  Instructions and Additional Documents Folder  Job Bulletins with Annotations Annotation Descriptions.docx City Job Paths PDFs Description of promotions in job bulletins.docx Job_titles.csv Kaggle_data_dictionary.csv Sample job class export template.csv   1.3 ChallengesDealing with unstructured data is a real challenge yet the most important task. The plain text/data have a low degree of organization and is thus bit difficult to scan. It is on top priority to make this kind of data easily scannable to make it into a good use. Here as well, the Job bulletins have data which is in unstructured format. It has internal structure but is not structured via pre-defined data models or schema which makes it difficult to parse. Extracting information from text files, converting unstructured information into a structured format, combining the data, and ensuring data quality are a few roadblocks faced when it comes to making sense of the data.  To get head around nondescript data and use it to validate assumptions and support decision-making ability, as well as integrate it with visualization tools is a challenge which needs to be overcome.  Finding an ideal data extraction solution required some time and effort, but it allows to consolidate structured and unstructured data and give it a clear purpose for a more effective solution.  1.4 Possible Solution Highlights1. Be where your candidates are!  Professional Job Platforms (LinkedIn)  City of LA web portal doesn't have link to the most used professionals' network portal. Social networking sites  Whether that’s Snapchat, Reddit, or LinkedIn. Use social media platform which helps to logon to most popular websites and reach large audience. Mobile App  According to Indeed, 65% of job seekers use their mobile devices to look for jobs. The ability to apply on mobile is especially important for hourly workers who might not have access to a desktop computer.  2. Deal with bias  Proactive measures  Understanding the hiring bias and how it works and by being actively alert to it creeping into your hiring process, you can nip it in the bud. Evaluate  Shortlist!! - Names, pictures and even post codes can influence the hiring decision. Ideally, candidates are judged on their qualifications and skills, not geography or the characteristics of their particular demographic. A blind resume review helps eliminate a number of unconscious biases from the process, while also help to avoid overcompensating for the same biases.  Put an everyday problem to your candidates, and assess whether their solution aligns with your organisation’s values or ways of getting things done. This keeps everything professional, and avoids a number of common biases, such as age, gender, personality or appearance.  Trainings to mitigate biases and increase cultural competency  3. Diversity Initiatives  For Female Employees  Show a viable path forward. Introduce them with females at senior levels or visible role models.  Improve and showcase work life balance.  Improve and showcase childcare and parental leaves. For General Diversity  Standardize the interview process. In order to get to the interview stage, you need to have an open minded diverse team of interviewee to ensure you’re not putting off great candidates.  Morever most people like everything straight. Indeed found 42% of job seekers found lengthy applications the most frustrating part of the application process. Try to cut-out on unwanted information. Keep it short: If possible, reduce candidate friction by creating a 1-click application process. If that doesn’t work for you, keep your qualification questions to a minimum (e.g., five and less)  The job description is often the first insight candidates have into your organisation’s culture. Be as neutral as possible, and be aware of the message that certain language sends.  You don’t have to write a completely bland job description devoid of any adjectives. However, if you seek to strike a balance, you may see changes in your pool of candidates.    2. What's in the KernelData Conversion Exploratory Data Analysis Recommendations Applications     3. Data ConversionLoading libraries";Apache 2.0;https://www.kaggle.com/tyagit3/dsfg-cityofla-analysis-and-solution;1.0;['vocabulary', 'nltk', 'sklearn', 'spacy', 'pattern'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nlp', 'nn', 'ann'];['filter', 'train', 'model', 'understanding', 'natural language processing', 'label', 'predict', 'rank', 'recommend', 'classification', 'natural language'];https://www.kaggle.com/c/data-science-for-good-city-of-los-angeles;0.669;0.319;2020-12-12 18:42:37;multiple data sources;[];DSFG-CityOfLA-Analysis and Solution;Python notebook;1586.0;12;;
2019-05-14 16:24:36;"Objective Parse job bulletin text files and create output dataframe with the structure mentioned in ""Sample job class export template.csv"" Columns Added     'FILE_NAME', 'JOB_CLASS_TITLE', 'JOB_CLASS_NO', 'REQUIREMENT_SET_ID',     'REQUIREMENT_SUBSET_ID', 'ENTRY_SALARY_GEN', 'ENTRY_SALARY_DWP', 'OPEN_DATE','JOB_DUTIES',    'EDUCATION_MAJOR','SCHOOL_TYPE','EXP_JOB_CLASS_TITLE'";Apache 2.0;https://www.kaggle.com/tyagit3/starter-text-bulletins-to-dataframe;1.0;['pattern', 'spacy', 'nltk'];['ner', 'ai', 'dl', 'rl', 'ml', 'nlp', 'nn', 'ann'];['label'];https://www.kaggle.com/c/data-science-for-good-city-of-los-angeles;0.712;0.446;2020-12-12 18:42:37;Data Science for Good: City of Los Angeles;['data cleaning, nlp'];Starter - Text Bulletins to DataFrame;Python notebook;3978.0;50;;
2020-07-19 03:33:29;Introduction:This tutorial is for beginners learning the concept of Scikit-Learn library which is a high level framework designed for supervised and unsupervised machine learning algorithms, built on top of NumPy and SciPy libraries, each responsible for lower-level data science tasks. Author: Abdelwahed AshrafLinkedin: LinkKaggle: LinkThe sequence of steps are as follows:  Check for missing values in the dataset Pre-process data by splitting into Train-Test sets Models Classification Feature Scaling by standardizing and normalizing your data Learn its effect by improved accuracy    Reduce the dimension of your data using PCA Learn its effect by improved accuracy    Applying Gaussian Mixture and Grid Search Learn its effect by improved accuracy    Fit our best model;Apache 2.0;https://www.kaggle.com/abdelwahed43/data-science-london-classification;1.0;['pattern', 'xgboost', 'sklearn'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ann'];['filter', 'logistic regression', 'k-nearest neighbor', 'predict', 'machine learning', 'training data', 'train', 'classification', 'naive bayes', 'model', 'support vector machines', 'loss', 'decision tree', 'bayesian', 'test data', 'regression', 'fitting', 'label', 'random forest'];https://www.kaggle.com/c/data-science-london-scikit-learn;0.584;0.302;2020-12-12 18:43:22;Data Science London + Scikit-learn;[];Data_Science_London_Classification;Python notebook;344.0;10;0.99160;0.99143
2020-11-09 20:18:48;we can applay GAUSSIAN MIXTURE MODEL;Apache 2.0;https://www.kaggle.com/aliwagdy/data-science-london-with-sklearn;1.0;['sklearn'];['ai', 'nn', 'cv'];['filter', 'machine learning', 'train', 'model', 'label', 'predict', 'random forest', 'bayesian'];https://www.kaggle.com/c/data-science-london-scikit-learn;0.489;0.152;2020-12-12 18:43:22;Data Science London + Scikit-learn;[];Data Science London with Sklearn;Python notebook;87.0;2;;
2019-10-18 12:13:03;Splitting Training data into train and validation sets;Apache 2.0;https://www.kaggle.com/pranaymns/datascience-london-sklearn-rfc-svm;1.0;['sklearn'];['ai', 'nn', 'cv'];['training data', 'train', 'model', 'label', 'gradient boosting', 'predict', 'decision tree', 'random forest'];https://www.kaggle.com/c/data-science-london-scikit-learn;0.546;0.099;2020-12-12 18:43:22;Data Science London + Scikit-learn;[];Datascience_london_sklearn_RFC_SVM;Python notebook;193.0;1;;
2019-09-06 15:47:31;Introduction:This tutorial is for beginners learning the concept of Scikit-Learn library which is a high level framework designed for supervised and unsupervised machine learning algorithms, built on top of NumPy and SciPy libraries, each responsible for lower-level data science tasks. This tutorial seeks inspiration from https://www.kaggle.com/chahat1/data-science-london-classification The sequence of steps are as follows:  Check for missing values in the dataset Pre-process data by splitting into Train-Test sets Models Classification Feature Scaling by standardizing and normalizing your data Learn its effect by improved accuracy    Reduce the dimension of your data using PCA Learn its effect by improved accuracy    Applying Gaussian Mixture and Grid Search Learn its effect by improved accuracy    Fit our best model;Apache 2.0;https://www.kaggle.com/sabahkarim/ds-tutorial-pca-gussian-mixture-grid-search;1.0;['pattern', 'tensorflow', 'xgboost', 'sklearn'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['machine learning', 'test data', 'regression', 'random forest', 'train', 'fitting', 'model', 'label', 'logistic regression', 'predict', 'decision tree', 'classification', 'naive bayes', 'bayesian'];https://www.kaggle.com/c/data-science-london-scikit-learn;0.615;0.253;2020-12-12 18:43:22;Data Science London + Scikit-learn;[];DS-Tutorial-(PCA+Gussian_Mixture+Grid_Search);Python notebook;583.0;6;0.99192;0.99180
2020-02-18 07:02:25;Split the data in to train and test;Apache 2.0;https://www.kaggle.com/spanda2/data-science-london-scikit;1.0;['sklearn'];['ai', 'nn', 'cv'];['training data', 'test data', 'regression', 'train', 'model', 'label', 'logistic regression', 'predict', 'decision tree', 'classification'];https://www.kaggle.com/c/data-science-london-scikit-learn;0.56;0.099;2020-12-12 18:43:22;Data Science London + Scikit-learn;[];Data Science London + Scikit;Python notebook;236.0;1;0.89154;0.88785
2020-02-05 10:36:01;DeepFake Starter KitContent Introduction  Preliminary data exploration  Load the packages   Load the data   Check files type     Meta data exploration  Missing data    Unique values   Most frequent originals     Video data exploration  Missing video (or meta) data   Few fake videos   Few real videos   Videos with same original   Test video files   Play video files   Face detection  Resources  References;Apache 2.0;https://www.kaggle.com/gpreda/deepfake-starter-kit;1.0;['pytorch', 'tensorflow', 'pattern'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['test data', 'object detection', 'generation', 'train', 'model', 'neural network', 'deep learning', 'artificial neural network', 'label', 'predict', 'recommend', 'generative adversarial network'];https://www.kaggle.com/c/deepfake-detection-challenge;0.812;0.614;2020-12-12 18:44:56;multiple data sources;['beginner, computer vision, gan'];DeepFake Starter Kit;Python notebook;69823.0;572;;
2020-02-19 04:58:22;Simple baseline binary classifier using FFHQ dataset to balance the dataThis kernal shows a simple training pipeline. I'm sure a lot can be improved upon. View this kernal for inference and submission: https://www.kaggle.com/greatgamedota/xception-binary-classifier-inference Thanks to: @unkownhihi for dataset and corresponding kernal: https://www.kaggle.com/unkownhihi/starter-kernel-with-cnn-model-ll-lb-0-69235 @humananalog for inference kernal: https://www.kaggle.com/humananalog/inference-demo Link to my FFHQ dataset: https://www.kaggle.com/greatgamedota/ffhq-face-data-set Update 1: Fixed data leak when balancing data and added more augmentations;Apache 2.0;https://www.kaggle.com/greatgamedota/xception-classifier-w-ffhq-training-lb-537;1.0;['pytorch', 'albumentations', 'sklearn', 'pytorchcv'];['ai', 'nn', 'cnn', 'cv'];['filter', 'train', 'model', 'output layer', 'epoch', 'layer', 'label', 'loss', 'relu', 'resnet'];https://www.kaggle.com/c/deepfake-detection-challenge;0.731;0.482;2020-12-12 18:44:56;multiple data sources;['gpu'];Xception Classifier w/ FFHQ - Training - LB: .555;Python notebook;6391.0;79;;
2020-02-03 10:41:05;Proper Clustering with Facenet EmbeddingsThis kernel shows how to use facenet embeddings to cluster similar faces throughout the training data and create a safe validation strategy for trainining and validation splits. You can see below how to use PCA, T-SNE and DBSCAN to efficiently cluster high-dimensional data. The found clusters are exported and can be used to improve your training and validation split. Some of the code is borrowed from @carlossouza and @timesler kernels, so thanks heaps to both. However, the results with facenet seem considerably better and more consistent than what is showed on the original kernel.;Apache 2.0;https://www.kaggle.com/hmendonca/proper-clustering-with-facenet-embeddings-eda;1.0;['pytorch', 'sklearn'];['ner', 'ai', 'cnn', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'training data', 'train', 'recognition', 'model', 'vgg', 'clustering', 'loss', 'label', 'predict', 'recommend', 'resnet'];https://www.kaggle.com/c/deepfake-detection-challenge;0.751;0.526;2020-12-12 18:44:56;multiple data sources;['data visualization, exploratory data analysis, deep learning, +1 moreclustering'];Proper Clustering with Facenet Embeddings + EDA;Python notebook;10459.0;144;;
2020-01-26 14:36:45;Training a binary image classifier for deepfakesEarlier I published this kernel that shows how to do inference on the Deepfakes competition. It includes a ResNeXt50 checkpoint that I trained on my own machine and that gets 0.46788 on the leaderboard. I did not include code for training that ResNeXt50 model because my process involves running a bunch of different scripts to create and clean up a training set, amongst other things. It's not feasible to do all of this in a Kaggle kernel. However, Kaggler dagnelies has made this dataset of face crops available. Using this dataset, we can actually train our model using a Kaggle kernel! Tip: Enable GPU for this. It's really slow using CPU.;Apache 2.0;https://www.kaggle.com/humananalog/binary-image-classifier-training-demo;1.0;['pytorch'];['ai', 'rl', 'cv', 'nn', 'ann'];['training data', 'train', 'model', 'epoch', 'layer', 'label', 'loss', 'resnet'];https://www.kaggle.com/c/deepfake-detection-challenge;0.752;0.522;2020-12-12 18:44:56;multiple data sources;['gpu'];Binary Image Classifier Training Demo;Python notebook;10942.0;137;;
2020-01-24 23:27:35;Inference Kernel DemoThis is the kernel I’ve used for my recent submissions. It takes about 5-6 hours on the test set, using only CPU. I’ve provided this kernel because a lot of people have problems making submissions. This method works and has never errored out for me. (Although I haven't tried making a submission using the GPU yet -- so no guarantees there.) It uses BlazeFace for face extraction (see also my BlazeFace kernel) and ResNeXt50 as the classifier model. We take the average prediction over 17 frames from each video. (Why 17? Using more frames makes the kernel slower, but doesn't appear to improve the score much. I used an odd number so we don't always land on even frames.) Please use this kernel only to learn from... Included is the checkpoint for a ResNeXt50 model that hasn't really been trained very well yet. I'm sure you can improve on it by training your own model! You could use the included trained weights to get yourself an easy top-50 score on the leaderboard (as of 24 Jan 2020) but it’s nicer to use it as a starting point for your own work. :-);Apache 2.0;https://www.kaggle.com/humananalog/inference-demo;1.0;['pytorch'];['ai', 'nn', 'cv'];['train', 'model', 'layer', 'label', 'predict', 'resnet'];https://www.kaggle.com/c/deepfake-detection-challenge;0.775;0.573;2020-12-12 18:44:56;multiple data sources;[];Inference Demo;Python notebook;20675.0;289;0.46788;0.46788
2020-03-15 05:57:11;Guide to Google Cloud Training, Ensembling & Learning Learning RatesThe objectives of this kernel are to first provide a quick overview of the steps I followed to set up virtual machine (VM) instance on Google Cloud Platform, to download the required competition files, to train the models, how I changed the parameters to obtain the public score of <0.45, and also how to leave the instance running upon exiting the terminal. In particular, this will be my last public kernel (with scores) until the competition ends. The end of the competition is in about a month, and I figured that some insights on the tweeks to the existing training scripts could help those who have yet to make some sort of breakthrough at this point. Best regards, Wei Hao;Apache 2.0;https://www.kaggle.com/khoongweihao/gcloud-ensembling-learning-learning-rates;1.0;['pytorch', 'pytorchcv'];['ner', 'ai', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'train', 'model', 'output layer', 'epoch', 'layer', 'label', 'predict', 'relu', 'resnet'];https://www.kaggle.com/c/deepfake-detection-challenge;0.714;0.475;2020-12-12 18:44:56;multiple data sources;['beginner, exploratory data analysis, deep learning, +1 moreensembling'];GCloud, Ensembling & Learning Learning Rates;Python notebook;4180.0;72;0.43803;0.43803
2019-12-30 04:49:02;"Running FaceForensics++ in a Kaggle Notebook In this notebook I test out the state of the art FaceForensics++ package on the provided dataset. Later in this notebook I modify the code slightly to predict for our dataset. This notebook imports from a dataset for:  dlib package wheel (needs to be installed for code to work) other required packages not in the default kernel pretrained models by FaceForensics++  The paper that was published can be found here: https://arxiv.org/pdf/1901.08971.pdf  The github repo is here: https://github.com/ondyari/FaceForensics  Reference: @inproceedings{roessler2019faceforensicspp,     author = {Andreas R\""ossler and Davide Cozzolino and Luisa Verdoliva and Christian Riess and Justus Thies and Matthias Nie{\ss}ner},     title = {Face{F}orensics++: Learning to Detect Manipulated Facial Images},     booktitle= {International Conference on Computer Vision (ICCV)},     year = {2019} }";Apache 2.0;https://www.kaggle.com/robikscube/faceforensics-baseline-dlib-no-internet;1.0;['sklearn', 'pillow', 'pytorch', 'spacy', 'keras'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'nlp', 'nn', 'ann'];['filter', 'train', 'model', 'deep learning', 'layer', 'vgg', 'loss', 'label', 'relu', 'predict', 'computer vision', 'resnet', 'classification'];https://www.kaggle.com/c/deepfake-detection-challenge;0.762;0.53;2020-12-12 18:44:56;multiple data sources;[];FaceForensics++ Baseline (dlib & no internet);Python notebook;14340.0;152;;
2019-12-22 14:50:28;"Can you detect the deepfake? Come here for a summary? Here is a tl;dr:  I strongly encourage you start first with the official Getting Started guide here. What is the goal of the Deepfake Detection Challenge? According to the FAQ ""The AI technologies that power deepfakes and other tampered media are rapidly evolving, making deepfakes so hard to detect that, at times, even human evaluators can’t reliably tell the difference. The Deepfake Detection Challenge is designed to incentivize rapid progress in this area by inviting participants to compete to create new ways of detecting and preventing manipulated media."" This is a Code Competition: CPU Notebook <= 9 hours run-time, GPU Notebook <= 9 hours run-time on Kaggle's P100 GPUs, No internet access enabled External data is allowed up to 1 GB in size. External data must be freely & publicly available, including pre-trained models   This code competition's training set is not available directly on Kaggle, as its size is prohibitively large to train in Kaggle. Instead, it's strongly recommended that you train offline and load the externally trained model as an external dataset into Kaggle Notebooks to perform inference on the Test Set. Review Getting Started for more detailed information.";Apache 2.0;https://www.kaggle.com/robikscube/kaggle-deepfake-detection-introduction;1.0;['face_recognition', 'sklearn', 'pillow'];['ner', 'ai', 'dl', 'gan', 'cv', 'nn', 'ml'];['predict', 'train', 'recognition', 'model', 'label', 'loss', 'recommend'];https://www.kaggle.com/c/deepfake-detection-challenge;0.797;0.585;2020-12-12 18:44:56;Deepfake Detection Challenge;[];🙂🙃 Kaggle DeepFake Detection Introduction;Python notebook;41247.0;350;;
2020-03-02 01:39:17;Baseline submission using FacenetThis notebook demonstrates how to use the facenet-pytorch package to build a rudimentary deepfake detector without training any models. It also demonstrates a method for (1) loading all video frames, (2) finding all faces, and (3) calculating face embeddings at over 30 frames per second (or greater than 1 video per 10 seconds). The following steps are performed:  Create pretrained facial detection (MTCNN) and recognition (Inception Resnet) models. See the following kernel for a strided implementation of MTCNN that is able to process all frames in each video: https://www.kaggle.com/timesler/facenet-pytorch-mtcnn-process-every-frame See the following kernel for a performance comparison for different face detection implementations: https://www.kaggle.com/timesler/comparison-of-face-detection-packages   For each test video, calculate face feature vectors for ALL faces in each video. Calculate the distance from each face to the centroid for its video. Use these distances as your means of discrimination.  For (much) better results, finetune the resnet to the fake/real binary classification task instead - this is just a baseline. Alternatively, I'm sure there is much more interesting things that can be done with the feature vectors.;Apache 2.0;https://www.kaggle.com/timesler/facial-recognition-model-in-pytorch;1.0;['pytorch'];['ner', 'ai', 'cnn', 'cv', 'rl', 'nn', 'ml'];['filter', 'regression', 'train', 'recognition', 'model', 'vgg', 'label', 'logistic regression', 'predict', 'resnet', 'classification'];https://www.kaggle.com/c/deepfake-detection-challenge;0.794;0.568;2020-12-12 18:44:56;multiple data sources;['gpu'];Facial recognition model in pytorch;Python notebook;36914.0;270;;
2020-02-25 06:37:56;Fast MTCNN detectorThis notebook demonstrates how to achieve 45 frames per second speeds for loading frames and detecting faces on full resolution videos. AlgorithmStriding: The algorithm used is a strided modification of MTCNN in which face detection is performed on only every N frames, and applied to all frames. For example, with a batch of 9 frames, we could pass frames 0, 3, and 6 to MTCNN. Then, the bounding boxes (and potentially landmarks) returned for frame 0 would be naively applied to frames 1 and 2. Similarly, the detections for frame 3 are applied to frames 4 and 5, and the detections for frames 6 are applied to frames 7 and 8. Although this assume that faces do not move between frames significantly, this is generally a good approximation for low stride numbers. If the stride is 3, we are assuming that the face does not significantly alter position for an additional 2 frames, or ~0.07 seconds. If faces are moving faster than this, they are likely to be extremely blurry anyway. Furthermore, ensuring that faces are cropped with a small margin mitigates the impact of face drift. Scale pyramid: The algorithm uses a slightly smaller scaling factor (0.6 vs 0.709) than the original MTCNN algorithm to construct the scaling pyramid applied to input images. For details of the scaling pyramid, see the original paper for details of the scaling pyramid approach. Multi-threading: A modest performance gain comes from loading video frames (with cv2.VideoCapture) using threading. This functionality is provided by the FileVideoStream class of the imutils package. Other resourcesSee the following kernel for a guide to using the MTCNN functionality of facenet-pytorch: https://www.kaggle.com/timesler/guide-to-mtcnn-in-facenet-pytorch;Apache 2.0;https://www.kaggle.com/timesler/fast-mtcnn-detector-55-fps-at-full-resolution;1.0;['pytorch', 'imutils'];['ner', 'ai', 'cnn', 'cv', 'rl', 'nn'];['vgg'];https://www.kaggle.com/c/deepfake-detection-challenge;0.763;0.49;2020-12-12 18:44:56;multiple data sources;[];Fast MTCNN detector (~55 FPS at full resolution);Python notebook;14782.0;88;;
2020-05-05 22:23:04;This notebook aims to demonstrate the different ways to use the MTCNN face detection module of facenet-pytorch. Originally reported in Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks, the MTCNN network is able to simultaneously propose bounding boxes, five-point facial landmarks, and detection probabilities. Taken from the original paper: Face detection and alignment in unconstrained environments are challenging due to various poses, illuminations and occlusions. Recent studies show that deep learning approaches can achieve impressive performance on these two tasks. In this paper, we propose a deep cascaded multi-task framework which exploits the inherent correlation between them to boost up their performance. In particular, our framework adopts a cascaded structure with three stages of carefully designed deep convolutional networks that predict face and landmark location in a coarse-to-fine manner. In addition, in the learning process, we propose a new online hard sample mining strategy that can improve the performance automatically without manual sample selection. Our method achieves superior accuracy over the state-of-the-art techniques on the challenging FDDB and WIDER FACE benchmark for face detection, and AFLW benchmark for face alignment, while keeps real time performance.  facenet-pytorch includes an efficient, cuda-ready implementation of MTCNN that will be demonstrated in this notebook. The following topics will be covered:  Documentation Basic usage Preventing image normalization Margin adjustment Multiple faces in a single image Batched detection Bounding boxes and facial landmarks Saving face datasets  Other resources:  The facenet-pytorch github repo Notebook demonstrating combined use of face detection and recognition The FastMTCNN algorithm;Apache 2.0;https://www.kaggle.com/timesler/guide-to-mtcnn-in-facenet-pytorch;1.0;['pytorch'];['ner', 'ai', 'cnn', 'cv', 'nn', 'ann'];['train', 'recognition', 'model', 'deep learning', 'vgg', 'predict'];https://www.kaggle.com/c/deepfake-detection-challenge;0.781;0.515;2020-12-12 18:44:56;multiple data sources;[];Guide to MTCNN in facenet-pytorch;Python notebook;25036.0;123;;
2020-03-16 04:25:50;Here is just an example of how to use mobilenet face extractor for inference, and also lrcn. I didn't make the weights public, because people(including me) don't like high scoring infernece kernel. BUT I'm also taking request to make the weights public. I'm OK with making the weights public.;Apache 2.0;https://www.kaggle.com/unkownhihi/dfdc-lrcn-inference;1.0;['tensorflow', 'keras', 'pillow'];['ml', 'cv'];['model', 'layer', 'lstm', 'label', 'predict'];https://www.kaggle.com/c/deepfake-detection-challenge;0.742;0.495;2020-12-12 18:44:56;multiple data sources;['gpu'];dfdc-lrcn-inference;Python notebook;8307.0;94;;
2020-01-17 02:25:08;If you found this helpful, please upvote this kerel and the associated dataset.;Apache 2.0;https://www.kaggle.com/unkownhihi/starter-kernel-with-cnn-model-ll-lb-0-69235;1.0;['opencv-python', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cnn', 'cv', 'nn', 'ml'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'lstm', 'predict', 'relu'];https://www.kaggle.com/c/deepfake-detection-challenge;0.764;0.515;2020-12-12 18:44:56;multiple data sources;['gpu'];Starter Kernel(with CNN model) ll(LB:0.69235);Python notebook;14952.0;123;0.69287;0.69287
2018-08-29 14:28:35;In this notebook, I have tried to depict the following  Little Bit TS Theory from Wiki , Different Blogposts and Online Books EDA Seasonality Demonstration Moving Average, Exponential Average and Smoothen Few Pivot Plots Keras Embedding(Re-added for Testing) Prophet (With and Without Transformations) ARIMA Validating The Forecast via Plots and Different Metrics Modelling LSTM Modelling( Next Update and Probably the last by me...)  Here's the collection of Resources (including all the publicly shared kernels)  https://www.kaggle.com/c/demand-forecasting-kernels-only/discussion/63568  And in particular this discussion (Thanks a Lot, I learnt a lot from it locally)  https://www.kaggle.com/c/demand-forecasting-kernels-only/discussion/62592;Apache 2.0;https://www.kaggle.com/adityaecdrid/my-first-time-series-comp-added-prophet;1.0;['statsmodels', 'xgboost', 'lightgbm', 'sklearn', 'tensorflow', 'pattern', 'keras'];['ner', 'ai', 'dl', 'gan', 'gbm', 'cv', 'rl', 'nn'];['training data', 'regression', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'lstm', 'predict', 'relu', 'understanding'];https://www.kaggle.com/c/demand-forecasting-kernels-only;0.787;0.532;2020-12-12 18:46:39;Store Item Demand Forecasting Challenge;['beginner, data visualization, exploratory data analysis, +1 moretime series analysis'];My First Time Series Comp (Added Prophet);Python notebook;30200.0;157;12.79451;14.14034
2018-09-22 11:32:34;EDA+Prophet+ MLP Neural Network ForecastingArindam Dutta 22-09-2018 (Version-8);Apache 2.0;https://www.kaggle.com/arindamgot/eda-prophet-mlp-neural-network-forecasting;1.0;['pattern'];['ner', 'ai', 'gan', 'rl', 'ml', 'nn', 'ann'];['machine learning', 'training data', 'test data', 'neuron', 'train', 'fitting', 'model', 'recognition', 'neural network', 'artificial neural network', 'layer', 'label', 'predict', 'rank', 'hidden layer', 'bayesian'];https://www.kaggle.com/c/demand-forecasting-kernels-only;0.806;0.584;2020-12-12 18:46:39;Store Item Demand Forecasting Challenge;['data visualization, exploratory data analysis, time series analysis'];EDA+Prophet+ MLP Neural Network Forecasting;R notebook;55430.0;347;;
2018-09-24 09:03:16;IntroductionIn this notebook, I go through how I worked to find a decent solution for this challenge using simple uncomplicated techniques. No machine learning, no fancy black-box models. Throw away your ARIMAs and Gradient Boosts. Think simple.;Apache 2.0;https://www.kaggle.com/ashishpatel26/keeping-it-simple-by-xyzt;1.0;['pattern'];['ner', 'ai', 'dl', 'rl', 'nn', 'ann'];['linear regression', 'machine learning', 'test data', 'regression', 'train', 'fitting', 'model', 'label', 'predict', 'understanding', 'ground truth'];https://www.kaggle.com/c/demand-forecasting-kernels-only;0.706;0.408;2020-12-12 18:46:39;Store Item Demand Forecasting Challenge;[];Keeping it simple by XYZT;Python notebook;3510.0;32;12.58776;13.85181
2018-08-17 13:59:13;Table of contents  Introduction Preparation Dependencies Load the datasets   ARIMA Time series data exploration Distribution of sales How does sales vary across stores How does sales vary across items Time-series visualization of the sales    IntroductionKernel for the demand forecasting Kaggle competition. Answer some of the questions posed:  What's the best way to deal with seasonality? Should stores be modeled separately, or can you pool them together? Does deep learning work better than ARIMA? Can either beat xgboost?  PreparationDependencies;Apache 2.0;https://www.kaggle.com/ashishpatel26/light-gbm-demand-forecasting;1.0;['statsmodels', 'xgboost', 'lightgbm', 'sklearn', 'pattern'];['ai', 'gbm', 'cv', 'rl', 'nn', 'ml'];['filter', 'regression', 'train', 'model', 'deep learning', 'label', 'predict', 'understanding', 'bayesian'];https://www.kaggle.com/c/demand-forecasting-kernels-only;0.774;0.456;2020-12-12 18:46:39;multiple data sources;['gpu'];Light GBM demand-forecasting;Python notebook;20040.0;57;13.06690;13.95666
2018-08-30 13:53:30;Table of contents  Introduction Preparation Dependencies Load the datasets   ARIMA Time series data exploration Distribution of sales How does sales vary across stores How does sales vary across items Time-series visualization of the sales    IntroductionKernel for the demand forecasting Kaggle competition. Answer some of the questions posed:  What's the best way to deal with seasonality? Should stores be modeled separately, or can you pool them together? Does deep learning work better than ARIMA? Can either beat xgboost?  PreparationDependencies;Apache 2.0;https://www.kaggle.com/ashishpatel26/lstm-demand-forecasting;1.0;['statsmodels', 'xgboost', 'lightgbm', 'sklearn', 'tensorflow', 'pattern', 'keras'];['ai', 'dl', 'gbm', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'regression', 'train', 'model', 'epoch', 'deep learning', 'layer', 'loss', 'label', 'lstm', 'predict', 'understanding', 'bayesian'];https://www.kaggle.com/c/demand-forecasting-kernels-only;0.781;0.408;2020-12-12 18:46:39;multiple data sources;['gpu'];LSTM demand-forecasting;Python notebook;25058.0;32;19.65674;23.43072
2018-06-30 19:34:10;A very basic kernel with some naive features for predicting seasonal or hierachical autoregressive problems (such as store sales) Kernel will be updated;Apache 2.0;https://www.kaggle.com/danofer/getting-started-with-time-series-features;1.0;['xgboost', 'sklearn'];['ai', 'gan', 'cv', 'rl', 'nn'];['train', 'model', 'label', 'predict'];https://www.kaggle.com/c/demand-forecasting-kernels-only;0.736;0.383;2020-12-12 18:46:39;Store Item Demand Forecasting Challenge;[];Getting started with Time-series features;Python notebook;7151.0;24;150.77992;148.57800
2018-07-16 07:46:40;OverviewThe goal of this kernel is data exploration of a time-series sales data of store items. The tools pandas, matplotlib  and, plotly  are used for slicing & dicing the data and visualizations. Note: There are some interesting insights waiting for you at the end of this notebook! Feel free to jump to Time-series visualization of the sales Content Load the datasets Distribution of sales How does sales vary across stores How does sales vary across items Time-series visualization of the sales;Apache 2.0;https://www.kaggle.com/darshanadiga/time-series-data-exploration;1.0;['pattern'];['ai', 'nn', 'ml', 'rl'];['train', 'model', 'filter', 'predict'];https://www.kaggle.com/c/demand-forecasting-kernels-only;0.742;0.423;2020-12-12 18:46:39;Store Item Demand Forecasting Challenge;['beginner, data visualization, exploratory data analysis, +2 morefeature engineering, data cleaning'];Time series data exploration;Python notebook;8438.0;38;;
2019-01-08 20:59:41;Deep Learning for Time Series Forecasting The goal of this notebook is to develop and compare different approaches to time-series problems.Content: Time series visualization with ploty. How to transform a time series dataset into a supervised learning problem. How to develop a Multilayer Perceptron model for a univariate time series forecasting problem. How to develop a Convolutional Neural Network model for a univariate time series forecasting problem. How to develop a Long Short-Term Memory network model for a univariate time series forecasting problem. How to develop a Hybrid CNN-LSTM model for a univariate time series forecasting problem.  The content here was inspired by this article at machinelearningmastery.com, How to Get Started with Deep Learning for Time Series Forecasting (7-Day Mini-Course)Dependencies;Apache 2.0;https://www.kaggle.com/dimitreoliveira/deep-learning-for-time-series-forecasting;1.0;['pattern', 'tensorflow', 'sklearn', 'keras'];['ai', 'nn', 'cnn', 'ml'];['autoencoder', 'filter', 'train', 'model', 'neural network', 'epoch', 'deep learning', 'layer', 'loss', 'label', 'lstm', 'predict', 'relu', 'supervised learning', 'convolutional neural network', 'hidden layer'];https://www.kaggle.com/c/demand-forecasting-kernels-only;0.815;0.553;2020-12-12 18:46:39;multiple data sources;['gpu, deep learning, neural networks, +2 moretensorflow, lstm'];Deep Learning for Time Series Forecasting;Python notebook;77625.0;214;;
2018-09-18 22:22:59;Forecasting 3 Months of SalesGiven 5 years of daily sales data across 10 stores for 50 items, we have been tasked to forecast the next 3 months of sales. We will be exploring the data using Pandas and building models using ARIMA, tensorflow's DNN regressor, and xgboost. Let's get started! NOTEThis is my first competition and I'm still learning the models myself. At the end I share what I learned while building this.;Apache 2.0;https://www.kaggle.com/enolac5/time-series-arima-dnn-xgboost-comparison;1.0;['statsmodels', 'tensorflow', 'xgboost'];['ner', 'ai', 'gan', 'rl', 'ml', 'nn', 'ann'];['training data', 'test data', 'train', 'fitting', 'model', 'neural network', 'epoch', 'layer', 'clustering', 'label', 'predict', 'hidden layer'];https://www.kaggle.com/c/demand-forecasting-kernels-only;0.759;0.383;2020-12-12 18:46:39;Store Item Demand Forecasting Challenge;['beginner'];Time Series - ARIMA, DNN, XGBoost Comparison;Python notebook;13291.0;24;15.28838;16.64227
2018-07-23 07:42:37;Complete exploratory data analysisWe will be using pandas, scipy, seaborn and plotly to explore the train.csv data. Interactive plots will be used to visualize the time series since we have many data points. Some key factors about this dataset:  Number of rows: 913k Just three columns: store, item and sales. Fifty different items and ten stores Sales are measured for each item, store and date (daily) Five years time frame (2013/01/01 to 2017/12/31) No missing data  I will be updating this notebook as possible. Please upvote if you find usefull, thanks.;Apache 2.0;https://www.kaggle.com/jsaguiar/complete-eda-time-series-with-plotly;1.0;['statsmodels'];['ai', 'rl'];['filter', 'train', 'fitting', 'model', 'label'];https://www.kaggle.com/c/demand-forecasting-kernels-only;0.725;0.379;2020-12-12 18:46:39;Store Item Demand Forecasting Challenge;[];Complete EDA: Time series with Plotly;Python notebook;5408.0;23;;
2018-10-02 22:48:17;"This kernel features... Intro EDA (feat. Boken) Prophet The winning ""dumb"" solution Outro";Apache 2.0;https://www.kaggle.com/myster/eda-prophet-winning-solution-3-0;1.0;['statsmodels', 'xgboost', 'lightgbm', 'catboost', 'sklearn', 'tensorflow', 'pattern'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'training data', 'regression', 'test data', 'train', 'fitting', 'model', 'neural network', 'validation data', 'label', 'gradient boosting', 'predict', 'bayesian'];https://www.kaggle.com/c/demand-forecasting-kernels-only;0.748;0.421;2020-12-12 18:46:39;multiple data sources;['gpu, data visualization, exploratory data analysis'];EDA + Prophet + Winning Solution 3.0;Python notebook;9854.0;37;;
2018-08-20 07:28:05;"IntroductionARIMA is one of the most classic time series forecasting models. During the modeling process, we mainly want to find 3 parameters. Auto-regression(AR) term, namly the lags of previous value; Integral(I) term for non-stationary differencing and Moving Average(MA) for error term. I'm a newbie in this field. Found many online tutorials used grid search technique(auto.arima in R). Meanwhile I also found many hypothesis test to validate the time series, i.e. see if it's stationary, looking at ACF and PACF to suggest a AR term etc... Facebook has a package called prophet, which is quite complex and consider many things automaticlly. But out of curiosity, I want to understand what's the reasoning behind the model. ARIMA is definitely a good starting point. My goal for this notebook: Understand ARIMA, SARIMA, ARIMAX   Walkthrough the necessary tests that ARIMA needs to statisfy Find a set of reasonable parameters base on a statistic tests and visualizations     Notebook Outline: ARIMA introduction   Decompose the ts Stationarize the data   Interpret ACF and PACF   Determine p, d, q Adding seasonality: S-ARMIA Adding holiday factors to be SARIMA-X  A few things on my TODO list: mulitple seasonality outlier detection";Apache 2.0;https://www.kaggle.com/sumi25/understand-arima-and-tune-p-d-q;1.0;['statsmodels', 'pattern'];['ner', 'ai', 'cv', 'rl', 'nn', 'ml'];['linear regression', 'filter', 'regression', 'train', 'model', 'validation data', 'label', 'predict', 'understanding'];https://www.kaggle.com/c/demand-forecasting-kernels-only;0.811;0.507;2020-12-12 18:46:39;multiple data sources;[];Understand ARIMA and tune P, D, Q;Python notebook;66029.0;110;;
2018-09-25 05:08:02;IntroductionIn this notebook, I go through how I worked to find a decent solution for this challenge using simple uncomplicated techniques. No machine learning, no fancy black-box models. Throw away your ARIMAs and Gradient Boosts. Think simple.;Apache 2.0;https://www.kaggle.com/thexyzt/keeping-it-simple-by-xyzt;1.0;['pattern'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['linear regression', 'machine learning', 'test data', 'regression', 'train', 'fitting', 'model', 'label', 'predict', 'understanding', 'ground truth'];https://www.kaggle.com/c/demand-forecasting-kernels-only;0.758;0.494;2020-12-12 18:46:39;Store Item Demand Forecasting Challenge;['beginner'];Keeping it simple by XYZT;Python notebook;12867.0;93;12.57945;13.84508
2018-02-06 18:38:38;Hello Kagglers!! This week was totally boring, so in order to cheer up myself, I wanted to put up a new kernel with some cool stuff. I know ..I know...I know autoencoders aren't something new but for some people, they are  a big deal, especially for people new to the field of deep learning. Well, without saying anything further, let's dive in and try to build an autoencoder in Keras.;Apache 2.0;https://www.kaggle.com/aakashnain/denoising-autoencoders-to-the-rescue;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'nn', 'rl'];['autoencoder', 'train', 'model', 'epoch', 'deep learning', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/denoising-dirty-documents;0.744;0.431;2020-12-12 18:52:45;Denoising Dirty Documents;[];Denoising: Autoencoders to the rescue!!;Python notebook;8794.0;42;;
2020-11-09 09:19:39;Remove noisy background from images/documents using Auto-encoders, Tensorflow v2 and Keras;Apache 2.0;https://www.kaggle.com/michalbrezk/denoise-images-using-autoencoders-tf-keras;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cv', 'rl', 'nn', 'ann'];['autoencoder', 'filter', 'train', 'model', 'neural network', 'epoch', 'validation data', 'artificial neural network', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/denoising-dirty-documents;0.672;0.416;2020-12-12 18:52:45;Denoising Dirty Documents;['gpu, deep learning, image data, +1 morecnn'];Denoise images using Autoencoders [TF, Keras];Python notebook;1682.0;35;;
2020-03-14 15:01:01;Data images don't have the same shape some have a shape of (285, 540), others have (450, 540). The following script just to extract this information.;Apache 2.0;https://www.kaggle.com/phylake1337/clear-it;1.0;['tensorflow', 'keras'];['ai'];['autoencoder', 'test data', 'train', 'fitting', 'model', 'input layer', 'epoch', 'validation data', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/denoising-dirty-documents;0.6;0.253;2020-12-12 18:52:45;Denoising Dirty Documents;['gpu, beginner, data visualization'];Clear it!;Python notebook;448.0;6;0.03115;0.03115
2020-04-26 02:30:51;!unzip ../input/denoising-dirty-documents/test.zip !unzip ../input/denoising-dirty-documents/train.zip !unzip ../input/denoising-dirty-documents/train_cleaned.zip;Apache 2.0;https://www.kaggle.com/sushanth1995/image-augmentation-and-neural-encoder-decoder;1.0;['opencv-python', 'pillow', 'albumentations', 'tensorflow', 'keras'];['ai', 'rl', 'cv', 'nn', 'ml'];['autoencoder', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/denoising-dirty-documents;0.631;0.236;2020-12-12 18:52:45;Denoising Dirty Documents;['gpu'];Image-augmentation and Neural Encoder-Decoder;Python notebook;769.0;5;0.02098;0.02098
2018-05-09 17:02:22;OverviewThe goal is to make a nice retinopathy model by using a pretrained inception v3 as a base and retraining some modified final layers with attention This can be massively improved with  high-resolution images better data sampling ensuring there is no leaking between training and validation sets, sample(replace = True) is real dangerous better target variable (age) normalization pretrained models attention/related techniques to focus on areas;Apache 2.0;https://www.kaggle.com/kmader/inceptionv3-for-retinopathy-gpu-hr;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'rl', 'nlp', 'nn', 'ann'];['test data', 'train', 'model', 'epoch', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'resnet', 'classification'];https://www.kaggle.com/c/diabetic-retinopathy-detection;0.803;0.554;2020-12-12 18:54:56;multiple data sources;['gpu, image data, transfer learning'];InceptionV3 for Retinopathy (GPU-HR);Python notebook;49996.0;216;;
2018-05-10 10:34:02;OverviewHere the goal is to show how to use the tf.data Dataset and Pipelines API to fine-tune a pretrained Keras model for classifying Retinal diseases. The dataset here is quite small (only 1000 images) but we can use data augmentation to expand the set a bit. AugmentationWe create the old-style Keras Generator inputs and the new Dataset / Keras Tensor Inputs and use the new style for training and the old style for computing metrics and visualizations on the validation set. Since the APIs are still new, the model has to be saved;Apache 2.0;https://www.kaggle.com/kmader/tf-data-tutorial-with-retina-and-keras;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'rl', 'nlp', 'nn', 'ann'];['test data', 'train', 'model', 'epoch', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'resnet', 'classification'];https://www.kaggle.com/c/diabetic-retinopathy-detection;0.764;0.4;2020-12-12 18:54:56;multiple data sources;['gpu, classification, computer vision'];tf.data Tutorial with Retina and Keras;Python notebook;15349.0;29;;
2018-05-15 12:51:31;OverviewThe goal is to make a nice retinopathy model by using a pretrained inception v3 as a base and retraining some modified final layers with attention This can be massively improved with  high-resolution images better data sampling ensuring there is no leaking between training and validation sets, sample(replace = True) is real dangerous better target variable (age) normalization pretrained models attention/related techniques to focus on areas;Apache 2.0;https://www.kaggle.com/kmader/vgg16-640hr-nloss-retinopathy;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'rl', 'nlp', 'nn', 'ann'];['test data', 'train', 'model', 'epoch', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/diabetic-retinopathy-detection;0.691;0.292;2020-12-12 18:54:56;multiple data sources;['gpu'];VGG16 640HR NLoss Retinopathy;Python notebook;2495.0;9;;
2019-12-11 05:57:52;OverviewThe goal is to make a nice retinopathy model by using a pretrained inception v3 as a base and retraining some modified final layers with attention This can be massively improved with  high-resolution images better data sampling ensuring there is no leaking between training and validation sets, sample(replace = True) is real dangerous better target variable (age) normalization pretrained models attention/related techniques to focus on areas;Apache 2.0;https://www.kaggle.com/reeteshsingh/diabetic-retinopathy-using-pretrained-model;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'rl', 'nlp', 'nn', 'ann'];['test data', 'train', 'model', 'epoch', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'resnet', 'classification'];https://www.kaggle.com/c/diabetic-retinopathy-detection;0.646;0.253;2020-12-12 18:54:56;multiple data sources;['gpu'];diabetic retinopathy using pretrained model;Python notebook;1015.0;6;;
2019-02-28 22:19:14;Diabetic RetinopathyDiabetic retinopathy (DR), also known as diabetic eye disease, is a medical condition in which damage occurs to the retina due to diabetes mellitus. It is a leading cause of blindness. Diabetic retinopathy affects up to 80 percent of those who have had diabetes for 20 years or more. Diabetic retinopathy often has no early warning signs. Retinal (fundus) photography with manual interpretation is a widely accepted screening tool for diabetic retinopathy, with performance that can exceed that of in-person dilated eye examinations. The below figure shows an example of a healthy patient and a patient with diabetic retinopathy as viewed by fundus photography (source):  An automated tool for grading severity of diabetic retinopathy would be very useful for accerelating detection and treatment. Recently, there have been a number of attempts to utilize deep learning to diagnose DR and automatically grade diabetic retinopathy. This includes this competition and work by Google. Even one deep-learning based system is FDA approved. Clearly, this dataset and deep learning problem is quite well-characterized. A look at the data:Data description from the competition: You are provided with a large set of high-resolution retina images taken under a variety of imaging conditions. A left and right field is provided for every subject. >Images are labeled with a subject id as well as either left or right (e.g. 1_left.jpeg is the left eye of patient id 1). A clinician has rated the presence of diabetic retinopathy in each image on a scale of 0 to 4, according to the following scale: 0 - No DR 1 - Mild 2 - Moderate 3 - Severe 4 - Proliferative DR Your task is to create an automated analysis system capable of assigning a score based on this scale.  ... Like any real-world data set, you will encounter noise in both the images and labels. Images may contain artifacts, be out of focus, underexposed, or overexposed. A major aim of this competition is to develop robust algorithms that can function in the presence of noise and variation.  A minor problem! Due to the large image file size, there are only 1000 files with labels and one csv file with the labels of all the images in the directory available in the kernel, as demonstrated below. The actual competition had on the order of 35,000 files so this is clearly a very small subset of the data.  In addition, this is a highly imbalanced dataset. Originally, I had aimed to create a model that would be close to the SOTA, but clearly, with only 1000 images that's not possible. AIM OF KERNEL: I will utilize transfer learning, oversampling, and progressive resizing on this small, imbalanced dataset. Given that many real-world datasets are also small and imbalanced, it will be interesting to see how far these techniques will take us.;Apache 2.0;https://www.kaggle.com/tanlikesmath/diabetic-retinopathy-with-resnet50-oversampling;1.0;['pytorch', 'spacy', 'sklearn', 'pillow'];['ner', 'ai', 'cnn', 'rl', 'nn', 'ml'];['train', 'model', 'neural network', 'epoch', 'deep learning', 'layer', 'loss', 'label', 'predict', 'computer vision', 'resnet', 'classification', 'labeled'];https://www.kaggle.com/c/diabetic-retinopathy-detection;0.75;0.357;2020-12-12 18:54:56;Diabetic Retinopathy Detection;['gpu'];Diabetic Retinopathy with ResNet50, Oversampling;Python notebook;10299.0;18;;
2018-11-27 19:44:44;Diabetic RetinopathyDetection This Notebook aims to provide a prediction kernel using Transfer learning - Fine Tuned VGG-16 architecture.;Apache 2.0;https://www.kaggle.com/tanumoynandy/diabeticretinopathyvgg16-finetuning;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'ml', 'cv'];['training data', 'train', 'model', 'epoch', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/diabetic-retinopathy-detection;0.722;0.292;2020-12-12 18:54:56;Diabetic Retinopathy Detection;['gpu, beginner, deep learning, +2 moreclassification, transfer learning'];DiabeticRetinopathyVGG16-FineTuning;Python notebook;5060.0;9;;
2018-11-10 14:03:27;OverviewThe goal is to make a nice retinopathy model by using a pretrained inception v3 as a base and retraining some modified final layers with attention This can be massively improved with  high-resolution images better data sampling ensuring there is no leaking between training and validation sets, sample(replace = True) is real dangerous better target variable (age) normalization pretrained models attention/related techniques to focus on areas;Apache 2.0;https://www.kaggle.com/viniciusaraujo/inceptionv3-for-retinopathy-gpu-hr-d82fb7;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'rl', 'nlp', 'nn', 'ann'];['test data', 'train', 'model', 'epoch', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'resnet', 'classification'];https://www.kaggle.com/c/diabetic-retinopathy-detection;0.683;0.268;2020-12-12 18:54:56;multiple data sources;['gpu'];InceptionV3 for Retinopathy (GPU-HR) d82fb7;Python notebook;2118.0;7;;
2018-03-06 19:14:16;Dog Breed Identification with Keras and the InceptionV3 modelThis notebook only uses the top 20 breeds due to memory limitations of the kernel.Also included are full instructions on how to get the InceptionV3 (actually, all) pretained model/data.;Apache 2.0;https://www.kaggle.com/careyai/inceptionv3-full-pretrained-model-instructions;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'rl', 'cv', 'nn'];['filter', 'test data', 'train', 'model', 'epoch', 'validation data', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'resnet'];https://www.kaggle.com/c/dog-breed-identification;0.766;0.319;2020-12-12 18:55:48;multiple data sources;[];InceptionV3 - full pretrained model instructions;Python notebook;16128.0;12;;
2020-10-15 17:46:05;This notebook is an exercise in the Deep Learning for Computer Vision course.  You can reference the tutorial at this link.;Apache 2.0;https://www.kaggle.com/dansbecker/exercise-intro-to-dl-for-computer-vision;1.0;['pattern'];['dl', 'ner', 'ai', 'nn'];['filter', 'train', 'model', 'deep learning', 'computer vision'];https://www.kaggle.com/c/dog-breed-identification;0.802;0.524;2020-12-12 18:55:48;multiple data sources;['deep learning, learn'];Exercise: Intro to DL for Computer Vision;Python notebook;48500.0;141;;
2020-10-15 17:44:27;IntroAt the end of this lesson, you will be able to write TensorFlow and Keras code to use one of the best models in computer vision. Lesson;Apache 2.0;https://www.kaggle.com/dansbecker/tensorflow-programming;1.0;['tensorflow', 'keras'];['ner', 'ai', 'nn', 'ann'];['train', 'model', 'label', 'predict', 'computer vision', 'resnet'];https://www.kaggle.com/c/dog-breed-identification;0.841;0.612;2020-12-12 18:55:48;multiple data sources;['learn'];TensorFlow Programming;Python notebook;209029.0;553;;
2017-12-16 17:32:43;Transfer learning with pretrained Keras modelsAlthough Kernel resources were increased recently we still can not train useful CNNs without GPU. The original ImageNet set has quite a few different dog classes so we can reuse CNNs with pretrained ImageNet weights. Fortunately prediction is much faster (<1s/image) making it possible to run meaningful experiments with Kaggle Kernels.;Apache 2.0;https://www.kaggle.com/gaborfodor/dog-breed-pretrained-keras-models-lb-0-3;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'nn', 'cnn'];['regression', 'train', 'model', 'vgg', 'loss', 'label', 'predict', 'rank', 'resnet', 'classification'];https://www.kaggle.com/c/dog-breed-identification;0.809;0.584;2020-12-12 18:55:48;multiple data sources;['deep learning, cnn, computer vision, +1 moreanimals'];Dog Breed - Pretrained keras models(LB 0.3) ;Python notebook;62619.0;345;;
2019-07-18 04:19:27;"Private LB SimulationPART I: Private Dataset [5 min read]  I'm back! no more discussions about memorizers or rules, it's boring. I think this can help everyone, no matter what kind of GAN you use: memorizer, GAN, CGAN, RaLSGAN etc In this kernel I simulate the private dataset! And we'll see if the dataset we use to generate matters when it comes to getting a good result. This took me some time, so I hope you'll appreciate it if it works for you. Remember, the upvote button is near the fork button. And as you see, the title says part I, the part II is about the mysterious pretrained NN ;)  Datasets PetFinder.my Adoption Prediction Dogs vs. Cats Dog Breed Identification  CIFAR-10  Why this datasets could be the private dataset aka ""mysterious private dog images"" ? We are using Stanford Dogs Dataset, it's public, like these others datasets. For example, CIFAR-10 is also a well known dataset and has dogs images (among others). But keep reading, you'll see the best part soon ;) My test Train using these datasets and generate User Generate N Dogs Images Use as Mysterious NN the inception model (risky hypothesis) Use as Mysterious Dog Dataset (private) the Generative Dogs Dataset  In other words, I do the opposite of what kaggle does. Let's see if the dog dataset we use to generate images is important when it comes to getting a great LB score! If the results do not vary much, then perhaps the dataset is not important   NOTE  I can't import all these datasets (the kernel doesn't start properly) so I only import 2 of them (my winning horses) You'll see this kernel has many versions, probably I'll try one different dataset in each version.";Apache 2.0;https://www.kaggle.com/jesucristo/private-lb-simulation-i;1.0;['tensorflow', 'keras'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nn', 'ann'];['training data', 'generation', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'generative adversarial network'];https://www.kaggle.com/c/dog-breed-identification;0.661;0.418;2020-12-12 18:55:48;multiple data sources;['gpu'];Private LB Simulation I;Python notebook;1355.0;36;;
2017-12-05 08:41:05;UPDATE : I perform many updates to provide a better explanation of my code. In addition, I added layers and dropout in my CNN to have better results.Convolutional Neural Network with tensorflowMy goal is to use Tensorflow (not Keras) for this competition. Just a quick word about Keras. In order to have better result, it's better to use pre-trained model which can be export from Keras and do transfert leraning.To quickly summarize, you can reuse some weights from the pre-trained models and add or remove some of the layers in order to create a new model. Here we will not do it. We just want t create from scratch our own CNN. I share a Python code which shows how to use Tensorflow to build a simple convolutional network (2 layers of convolutional network). I learn a lot from Hvass-Labs github so go to see his tutorial, it's definitely one of the best. As you will see, I copy a lot from his code for the convolutional network part. To simplify the game, I will reduce the dataset with the 8 main breeds (take only 3 or 5 if you want to run the code faster).. Please let me know if you manage to improve the results (by using Tensorflow) and how did you do? I really need your help as you will see the results are not good. As well, if you find some mistakes or have some questions, do not hesitate to put a comment. I will continue to add more informations on this code to make it more clear. ArchitectureWe will create a Convolutional Neural Network (CNN) which willl be able to classify dogs depending on their breed. Our CNN architecture will be as followed:  Convolutional Layer n°1 with 32 filters Max pooling Relu   Convolutional Layer n°2 with 64 filters Max pooling Relu   Convolutional Layer n°3 with 128 filters Max pooling Relu DropOut   Flatten Layer Fully Connected Layer with 500 nodes Relu DropOut   Fully Connected Layer with n nodes (n = number of breeds)  Preliminary work1. PackagesLet's import all the packages we need.;Apache 2.0;https://www.kaggle.com/kaggleslayer/simple-convolutional-n-network-with-tensorflow;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'cnn', 'rl', 'nn', 'ann'];['filter', 'training data', 'test data', 'train', 'model', 'input layer', 'neural network', 'validation data', 'layer', 'loss', 'label', 'predict', 'relu', 'convolutional neural network'];https://www.kaggle.com/c/dog-breed-identification;0.75;0.383;2020-12-12 18:55:48;Dog Breed Identification;['neural networks, computer vision, animals'];Simple Convolutional N. Network with Tensorflow;Python notebook;10327.0;24;;
2020-06-28 08:02:30;Beginner's Guide to Image Augmentation & Transforms;Apache 2.0;https://www.kaggle.com/kmldas/beginner-s-guide-image-augmentation-transforms;1.0;['pytorch', 'sklearn'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'nn', 'ml'];['train', 'model', 'neural network', 'deep learning', 'label', 'understanding'];https://www.kaggle.com/c/dog-breed-identification;0.597;0.327;2020-12-12 18:55:48;multiple data sources;['beginner, data visualization, exploratory data analysis, +1 morecomputer vision'];Beginner's Guide: Image Augmentation & Transforms;Python notebook;426.0;13;;
2020-02-14 04:54:52;"Preface: This is my first Kernel (I hope I'm doing it right)! I'd love to do more like this. So if you have any feedback or advice, let me know in the comments or on Twitter.  🐶 Using Transfer Learning and TensorFlow 2.x to Classify Different Dog BreedsWho's that doggy in the window? Dogs are incredible. But have you ever been sitting at a cafe, seen a dog and not known what breed it is? I have. And then someone says, ""it's an English Terrier"" and you think, how did they know that? In this project we're going to be using machine learning to help us identify different breeds of dogs. To do this, we'll be using data from the Kaggle dog breed identification competition. It consists of a collection of 10,000+ labelled images of 120 different dog breeds. This kind of problem is called multi-class image classification. It's multi-class because we're trying to classify mutliple different breeds of dog. If we were only trying to classify dogs versus cats, it would be called binary classification. Multi-class image classification is an important problem because it's the same kind of technology Tesla uses in their self-driving cars or Airbnb uses in atuomatically adding information to their listings. Since the most important step in a deep learng problem is getting the data ready (turning it into numbers), that's what we're going to start with. We're going to go through the following TensorFlow/Deep Learning workflow:   Get data ready (download from Kaggle, store, import). Prepare the data (preprocessing, the 3 sets, X & y). Choose and fit/train a model (TensorFlow Hub, tf.keras.applications, TensorBoard, EarlyStopping). Evaluating a model (making predictions, comparing them with the ground truth labels). Improve the model through experimentation (start with 1000 images, make sure it works, increase the number of images). Save, sharing and reloading your model (once you're happy with the results).  For preprocessing our data, we're going to use TensorFlow 2.x. The whole premise here is to get our data into Tensors (arrays of numbers which can be run on GPUs) and then allow a machine learning model to find patterns between them. For our machine learning model, we're going to be using a pretrained deep learning model from TensorFlow Hub. The process of using a pretrained model and adapting it to your own problem is called transfer learning. We do this because rather than train our own model from scratch (could be timely and expensive), we leverage the patterns of another model which has been trained to classify images. Getting our workspace readyBefore we get started, since we'll be using TensorFlow 2.x and TensorFlow Hub (TensorFlow Hub), let's import them. And we'll also check if we're using a GPU.";Apache 2.0;https://www.kaggle.com/mrdbourke/tensorflow-2-x-tensorflow-hub-end-to-end-example;1.0;['pattern', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'rl', 'nn', 'ann'];['filter', 'input layer', 'predict', 'ground truth', 'machine learning', 'training data', 'train', 'epoch', 'activation function', 'recommend', 'classification', 'image classification', 'model', 'layer', 'loss', 'understanding', 'test data', 'fitting', 'output layer', 'validation data', 'deep learning', 'gradient descent', 'label'];https://www.kaggle.com/c/dog-breed-identification;0.714;0.34;2020-12-12 18:55:48;multiple data sources;['beginner, deep learning, neural networks, +1 moretransfer learning'];TensorFlow 2.x + TensorFlow Hub End-to-End Example;Python notebook;4220.0;15;;
2018-04-27 17:46:49;Dog Breed Identification with KerasThis notebook only uses the top 20 breeds due to memory limitations.Dataset=https://www.kaggle.com/c/dog-breed-identification/data;Apache 2.0;https://www.kaggle.com/nafisur/dog-breed-identification-keras-cnn-basic;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'rl'];['machine learning', 'train', 'fitting', 'model', 'epoch', 'deep learning', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/dog-breed-identification;0.697;0.327;2020-12-12 18:55:48;Dog Breed Identification;[];Dog-breed-identification-keras-CNN-basic;Python notebook;2885.0;13;;
2020-06-28 05:49:14;End to End Dog Breed Multi Class ClassificationThis notebook is written in tensorflow 2.0 and tensorhub 1.ProblemThere are 120 breeds of dog in the data. We have to identify according to their breeds. 2.DataThere are training set and a test set of images of dogs. Each image has a filename that is its unique id. The dataset comprises 120 breeds of dogs.  train.zip - the training set, you are provided the breed for these dogs test.zip - the test set, you must predict the probability of each breed for each image sample_submission.csv - a sample submission file in the correct format labels.csv - the breeds for the images in the train set  EvaluationPredicting the probability of each breed in test data. Features we are dealing with the unstructure data set. There are about 10000+ images in the training data. There are about 10000+ images in the test data.  Now Since we have unstructured data we have to work with the library like tensorflow. so lets import the necessary libraries and directly jump into the project;Apache 2.0;https://www.kaggle.com/nirajpoudel/dogbreedidentification;1.0;['pattern', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'rl', 'nn', 'ann'];['training data', 'test data', 'train', 'fitting', 'model', 'input layer', 'output layer', 'epoch', 'validation data', 'layer', 'loss', 'label', 'predict', 'classification', 'ground truth'];https://www.kaggle.com/c/dog-breed-identification;0.647;0.346;2020-12-12 18:55:48;Dog Breed Identification;['gpu, data visualization, computer science, +1 moredata cleaning'];DogBreedIdentification;Python notebook;1037.0;16;;
2020-03-02 15:30:14;"Introduction  This kernel is a detailed guide for transfer learning on Dog Breeds problem, it's all about learning a new technique, evaluate it using only Kaggle training set without cheating.  The aim of this kernel is to show you how to use pre-trained CNN models as feature extractors, which one of the most effective transfer learning techniques.  A reasonable question comes to your mind, 'Wait, why do we have to use this technique, why don't we just use regular transfer learning ?', if you try to do so, you will figure out that the problem is pretty hard for a single model to handle (you would get higher loss and less accuracy).  It's even hard for humankind to distinguish between 120 dog breeds!, single poor CNN would struggle.   Explanation  Take look at general CNN architecture for image classification in two main parts, “feature extractor” that based on conv-layers, and “classifier” which usually based on fully connected layers:    Simply, feature extractor could be created as follow > (Feature Extractor = Pretrained Model - Late Fully Connected Layers)  For example, InceptionV3 feature extractor (without last FC layer) outputs 2048 vector for each image sample, each value represent a certain feature of dog image (Coded in numerical values of course), like Dog color?, How big is his head?, Shape of the eyes?, length of the tale?, Size? .. etc  Hence, more ""different"" feature extractors mean more features to be used to determine which breed does this dog belong.  So our strategy goes as the following,  Create 4 feature extractor using different pre-trained CNN models Extract features from raw data and stacks the features together. Use a simple DNN with one dense layer and a heavy dropout layer to figure out patterns in the feature extracted from the data.     The code is simple, concise and fully-commented. Feel free to ask for help / more info / more explanation in the comments.  Finally if this kernel helps you somehow, kindly don't forget to leave a little upvote.  ENJOY.";Apache 2.0;https://www.kaggle.com/phylake1337/0-18-loss-simple-feature-extractors;1.0;['pattern', 'tensorflow', 'keras'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'nn'];['image classification', 'test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'resnet', 'classification'];https://www.kaggle.com/c/dog-breed-identification;0.656;0.346;2020-12-12 18:55:48;Dog Breed Identification;['gpu, beginner, transfer learning'];0.18 loss - Simple Feature Extractors;Python notebook;1239.0;16;0.18212;0.18212
2017-10-12 15:39:22;Transfer learning in kernels with PyTorchFollowing the same strategy from Beluga's kernel Use pretrained Keras models, this kernel uses a dataset with PyTorch pretrained networks weights. Training in the CPU is quite slow, but it is still feasible to use a pre-trained network, replace the final layer and train just this last layer. Thanks Beluga for your great kernel. This one uses not only the concept but also a lot of the code.;Apache 2.0;https://www.kaggle.com/pvlima/use-pretrained-pytorch-models;1.0;['pytorch', 'keras'];['dl', 'ai', 'nn'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'rank', 'resnet'];https://www.kaggle.com/c/dog-breed-identification;0.796;0.486;2020-12-12 18:55:48;multiple data sources;[];Use pretrained PyTorch models;Python notebook;40077.0;84;;
2018-01-06 17:26:36;IntroWith some experimentation I found that VGG16 and VGG19 did not perform as well as Inception and XceptionV3 on the data. Therefore this kernel is about how to get the best out of the Xception and InceptionV3 pretrained weights using different ensembling methods.;Apache 2.0;https://www.kaggle.com/robhardwick/xception-inceptionv3-ensemble-methods;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'rl'];['regression', 'train', 'model', 'neural network', 'epoch', 'validation data', 'layer', 'vgg', 'loss', 'label', 'logistic regression', 'predict', 'resnet'];https://www.kaggle.com/c/dog-breed-identification;0.73;0.408;2020-12-12 18:55:48;multiple data sources;[];Xception, InceptionV3 Ensemble methods;Python notebook;6147.0;32;;
2020-08-08 01:04:01;IntroYou don't directly choose the numbers to go into your convolutions for deep learning... instead the deep learning technique determines what convolutions will be useful from the data (as part of model-training). We'll come back to how the model does that soon.  But looking closely at convolutions and how they are applied to your image will improve your intuition for these models, how they work, and how to debug them when they don't work. Let's get started. ExercisesWe'll use some small utilty functions to visualize raw images and some results of your code. Execute the next cell to load the utility functions.;Apache 2.0;https://www.kaggle.com/salmaneunus/computer-vision-fundamentals;1.0;['pattern'];['dl', 'ai', 'nn'];['train', 'model', 'filter', 'deep learning'];https://www.kaggle.com/c/dog-breed-identification;0.532;0.362;2020-12-12 18:55:48;multiple data sources;[];Computer Vision Fundamentals;Python notebook;156.0;19;;
2018-08-20 17:07:00;AboutThis kernel applies the techniques from fastai's deep learning for coders course to the dogbreed dataset;Apache 2.0;https://www.kaggle.com/stefanbuenten/dog-breed-test-with-fastai;1.0;['pytorch', 'sklearn'];['ner', 'ai', 'cv', 'rl', 'nn', 'ml'];['predict', 'train', 'model', 'epoch', 'deep learning', 'validation data', 'label', 'loss', 'resnet'];https://www.kaggle.com/c/dog-breed-identification;0.717;0.334;2020-12-12 18:55:48;Dog Breed Identification;['gpu, beginner, deep learning'];Dog breed test with fastai;Python notebook;4476.0;14;0.34460;0.34460
2018-11-07 18:03:16;In this kernel we will explore the concept of Test Time Augmentation (TTA) and will run an experiment on Dogs vs. Cats competition. Compare the results with and without TTA.;Apache 2.0;https://www.kaggle.com/andrewkh/test-time-augmentation-tta-worth-it;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'nn', 'ann'];['generation', 'train', 'model', 'epoch', 'layer', 'vgg', 'loss', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/dogs-vs-cats;0.781;0.416;2020-12-12 18:56:58;Dogs vs. Cats;['deep learning, classification'];Test Time Augmentation (TTA) ... worth it?;Python notebook;24592.0;35;;
2020-07-02 13:06:38;"IntroductionIn this notebook, i will be bringing you through the use of Transfer Learning in pretrained models like VGG16, Resnet etc to solve similar tasks; image classification of Dogs and Cats. We will see how we can use these pretrained models as feature extractors to generate features to be fed into another classifier, as well as finetuning these models to solve our problem. The notebook will be using Keras, a high-level API that allow us to build prototypes quickly with minimum coding, without loss in performance.  Building a custom CNN Using a pre-trained model as feature extractor (VGG16) Fine tuning an existing pre-trained model (ResNet50)";Apache 2.0;https://www.kaggle.com/angqx95/feature-extractor-fine-tuning-with-keras;1.0;['pytorch', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cnn', 'cv', 'ml', 'nn', 'ann'];['filter', 'vgg', 'logistic regression', 'predict', 'relu', 'machine learning', 'training data', 'neuron', 'train', 'epoch', 'alexnet', 'classification', 'image classification', 'model', 'neural network', 'layer', 'loss', 'resnet', 'test data', 'regression', 'fitting', 'output layer', 'gradient descent', 'label', 'convolutional neural network'];https://www.kaggle.com/c/dogs-vs-cats;0.689;0.357;2020-12-12 18:56:58;multiple data sources;[];Feature Extractor & Fine-tuning with Keras;Python notebook;2396.0;18;;
2020-08-25 20:29:15;IntroductionConvolutional Neural Networks (CNN) are everywhere. It is arguably the most popular deep learning architecture. The main advantage of CNN compared to its predecessors is that it automatically detects the important features without any human supervision. For example, given many pictures of cats and dogs it learns distinctive features for each class by itself. CNN is also computationally efficient. It uses special convolution and pooling operations and performs parameter sharing. This enables CNN models to run on any device, making them universally attractive.;Apache 2.0;https://www.kaggle.com/dktalaicha/cat-dog-classification-using-keras-cnn;1.0;['keras'];['ner', 'ai', 'cnn', 'gan', 'rl', 'nn', 'ml'];['filter', 'input layer', 'predict', 'relu', 'training data', 'neuron', 'train', 'epoch', 'activation function', 'classification', 'model', 'neural network', 'layer', 'loss', 'test data', 'fitting', 'output layer', 'validation data', 'deep learning', 'gradient descent', 'label', 'convolutional neural network'];https://www.kaggle.com/c/dogs-vs-cats;0.615;0.302;2020-12-12 18:56:58;Dogs vs. Cats;['gpu, image data, cnn'];Cat & Dog Classification using Keras CNN;Python notebook;581.0;10;;
2020-07-29 19:51:51;Dog-Cat Classifier (VGG) + GradCAM with TF 2.0In this Notebook:  Observe CAM with ResNet50 trained model on ImageNet Retrain output layer of ResNet50 model with Dog vs Cat data Add Fully connected layers before output layer and train Observe GradCAM with the re-trained models  Following is the architecture of ResNet50. It does not have fully-connected layers (FC) between pooling layer và output layers. Therefore, to check if GradCAM is really effective with the presence of FC layers, I will train a model with additional FC layers to ResNet50 and see how GradCAM works. Visualization with Ipython Widget that can be run locally: https://github.com/nguyenhoa93/GradCAM_and_GuidedGradCAM_tf2 Image source: Qingge Ji et al.  Table of contents1. Data preparation 2. Data exploration 3. GradCAM & GuidedBackProp Class definition  GradCAM GuidedBackprop  4. Observe GradCAM & Guided GradCAM with ResNet50 trained on ImageNet 5. Re-train output layer of ResNet50 model on dogs and cats data  Data generator Model Compile Train Observe GradCAM & Guided GradCAM  6. Add FC layers and train  Training Observe GradCAM & Guided GradCAM  7. References;Apache 2.0;https://www.kaggle.com/nguyenhoa/dog-cat-classifier-gradcam-with-tensorflow-2-0;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cnn', 'gbm', 'cv', 'rl', 'nn', 'ann'];['filter', 'train', 'model', 'output layer', 'epoch', 'validation data', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'resnet', 'propagation'];https://www.kaggle.com/c/dogs-vs-cats;0.685;0.34;2020-12-12 18:56:58;Dogs vs. Cats;['gpu, model explainability'];Dog-Cat Classifier+ GradCAM with Tensorflow 2.0;Python notebook;2192.0;15;;
2019-06-30 15:43:08;Transfer Learning in pytorch using Resnet18;Apache 2.0;https://www.kaggle.com/pintu161/transfer-learning-in-pytorch-using-resnet18;1.0;['pytorch'];['ai', 'nn', 'ann'];['test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'resnet'];https://www.kaggle.com/c/dogs-vs-cats;0.738;0.302;2020-12-12 18:56:58;Dogs vs. Cats;['gpu, cnn, transfer learning'];Transfer Learning in pytorch using Resnet18;Python notebook;7593.0;10;;
2019-05-05 14:51:54;Trying to practice as I go through this course https://www.coursera.org/learn/convolutional-neural-networks-tensorflow/ Github repo for the course https://github.com/lmoroney/dlaicourse This tutorial helped with flow_from_dataframe https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c I first tried cv2.imread from https://www.kaggle.com/abhishekrock/cat-dog-try Found an example of flow_from_dataframe on kaggle and it helped https://www.kaggle.com/takamichitoda/fine-tuning-vgg16;Apache 2.0;https://www.kaggle.com/rblcoder/learning-cnn-in-tensorflow-coursera-course;1.0;['tensorflow', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['train', 'model', 'output layer', 'epoch', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/dogs-vs-cats;0.706;0.327;2020-12-12 18:56:58;Dogs vs. Cats;['beginner, deep learning, classification, +2 moreimage data, transfer learning'];Learning: CNN in Tensorflow Coursera course;Python notebook;3466.0;13;;
2020-06-29 15:59:50;Hello All ! This is pretty basic tutorial to start off with Convolutional networks. Let's start with a bit of introduction Convolutional neural networks are primarily used to classify images or identify pattern similarities between them. So a convolutional network receives a normal color image as a rectangular box whose width and height are measured by the number of pixels along those dimensions, and whose depth is three layers deep, one for each letter in RGB. Those depth layers are referred to as channels. For simplification needs we will only consider gray scale image here. As images move through a convolutional network, different patterns are recognised just like a normal neural network. But here rather than focussing on one pixel at a time, a convolutional net takes in square patches of pixels and passes them through a filter. That filter is also a square matrix smaller than the image itself, and equal in size to the patch. It is also called a kernel.  Well that's it with the theory let's get started with the practical.;Apache 2.0;https://www.kaggle.com/ruchibahl18/cats-vs-dogs-basic-cnn-tutorial;1.0;['pattern', 'tensorflow', 'keras'];['ai', 'cnn', 'cv', 'nn', 'ann'];['filter', 'machine learning', 'training data', 'neuron', 'train', 'test data', 'model', 'neural network', 'epoch', 'layer', 'gradient descent', 'loss', 'label', 'predict', 'relu', 'understanding', 'convolutional neural network'];https://www.kaggle.com/c/dogs-vs-cats;0.8;0.494;2020-12-12 18:56:57;Dogs vs. Cats;['beginner, deep learning, neural networks'];Cats vs Dogs:- Basic CNN tutorial;Python notebook;45685.0;93;;
2020-04-16 14:42:21;Content 1. Summary 2. Cats and Dogs Dataset  2.1. Randomly Visualization of Samples in the Dataset    2.2. Some Evaluations About the Dataset   3. Convolutional Neural Network(CNN)  3.1. Implementing CNN Architecture with Keras   4.Transfer Learning 1: Feature Extractor;Apache 2.0;https://www.kaggle.com/serkanpeldek/keras-cnn-transfer-learnings-on-cats-dogs-dataset;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cnn', 'cv', 'ml', 'nn', 'ann'];['image classification', 'machine learning', 'test data', 'regression', 'train', 'model', 'neural network', 'epoch', 'deep learning', 'layer', 'vgg', 'loss', 'label', 'relu', 'predict', 'computer vision', 'classification', 'convolutional neural network'];https://www.kaggle.com/c/dogs-vs-cats;0.746;0.449;2020-12-12 18:56:58;Dogs vs. Cats;['gpu'];Keras CNN, Transfer Learnings on Cats&Dogs Dataset;Python notebook;9329.0;52;;
2020-05-31 09:21:36;This is another well known dataset to do hands on Image Classification  using Convolutional Neural Network (CNN).CNN as a subset of Deep Learning uses Convolution instead of linear matrix operation. Convolution is a mathematical operation between 2 functions f(x) and g(x) expressing how the shape of one is modified by the other as f o g(x).Import the libraries.;Apache 2.0;https://www.kaggle.com/subhamoybhaduri/cnn-cat-and-dog-classification;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cnn', 'rl', 'nn', 'ann'];['image classification', 'filter', 'test data', 'train', 'fitting', 'model', 'neural network', 'epoch', 'deep learning', 'layer', 'validation data', 'loss', 'label', 'predict', 'relu', 'classification', 'convolutional neural network'];https://www.kaggle.com/c/dogs-vs-cats;0.633;0.292;2020-12-12 18:56:58;Dogs vs. Cats;[];CNN Cat and Dog Classification;Python notebook;797.0;9;;
2019-06-16 04:14:44;This Kernel for someone want to deep dive into image classification. I use CNN for classification model. If you found this Kernel helpful please up vote it. If you have some feedback and question don't forget to comment below. I have simplier model with  https://www.kaggle.com/uysimty/get-start-image-classification;Apache 2.0;https://www.kaggle.com/uysimty/keras-cnn-dog-or-cat-classification;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cnn', 'rl', 'nn', 'ann'];['image classification', 'train', 'fitting', 'model', 'input layer', 'output layer', 'epoch', 'layer', 'relu', 'loss', 'label', 'predict', 'computer vision', 'classification'];https://www.kaggle.com/c/dogs-vs-cats;0.831;0.62;2020-12-12 18:56:57;Dogs vs. Cats;['beginner, classification, cnn, +2 morecomputer vision, binary classification'];Keras CNN Dog or Cat Classification;Python notebook;139970.0;629;;
2019-01-15 14:55:47;"This Notebook Introduces How to apply 'Transfer Learning' in KaggleThank you for opening this Notebook! Press ""Fork"" at the top-right of this screen to run this notebook yourself and build each of the examples. I have made all efforts to document each and every step involved so that this notebook acts as a good starting point for new Kagglers who hope to apply Transfer Learning to their problem.";Apache 2.0;https://www.kaggle.com/abhiksark/introduction-to-transfer-learning-cats-dogs;1.0;['caffe', 'tensorflow', 'keras'];['ai', 'rl', 'cv'];['machine learning', 'test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'resnet'];https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition;0.723;0.367;2020-12-12 18:58:25;multiple data sources;['deep learning, image data, cnn, +1 moretransfer learning'];Introduction to Transfer Learning (Cats & Dogs);Python notebook;5247.0;20;;
2020-02-24 09:15:17;Cats or Dogs - using CNN with Transfer LearningContent Introduction  Load packages and set parameters  Read the data  Data exploration Class distribution Images samples   Model  Prepare the model  Train the model  Validation accuracy and loss  Validation accuracy per class    Prepare submission  Conclusions References;Apache 2.0;https://www.kaggle.com/gpreda/cats-or-dogs-using-cnn-with-transfer-learning;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'nn', 'cnn', 'cv'];['activation function', 'training data', 'test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'resnet', 'classification'];https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition;0.756;0.449;2020-12-12 18:58:25;multiple data sources;['gpu, deep learning, classification, +2 morecnn, transfer learning'];Cats or Dogs - using CNN  with Transfer Learning;Python notebook;11993.0;52;;
2018-08-01 02:28:07;Image classification with Convolutional Neural Networks;Apache 2.0;https://www.kaggle.com/hortonhearsafoo/fast-ai-lesson-1;1.0;['pytorch', 'sklearn'];['ner', 'ai', 'dl', 'cnn', 'rl', 'ml', 'nn', 'ann'];['predict', 'machine learning', 'train', 'epoch', 'recommend', 'classification', 'image classification', 'model', 'neural network', 'layer', 'loss', 'understanding', 'resnet', 'fitting', 'deep learning', 'gradient descent', 'label', 'computer vision', 'convolutional neural network'];https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition;0.784;0.527;2020-12-12 18:58:25;Dogs vs. Cats Redux: Kernels Edition;['gpu'];fast.ai lesson 1;Python notebook;27181.0;146;;
2018-08-25 12:19:43;Image classification with Convolutional Neural Networks;Apache 2.0;https://www.kaggle.com/ialimustufa/lesson-1;1.0;['pytorch', 'sklearn'];['ner', 'ai', 'dl', 'cnn', 'rl', 'ml', 'nn', 'ann'];['predict', 'machine learning', 'train', 'epoch', 'recommend', 'classification', 'image classification', 'model', 'neural network', 'layer', 'loss', 'understanding', 'resnet', 'fitting', 'deep learning', 'gradient descent', 'label', 'computer vision', 'convolutional neural network'];https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition;0.627;0.379;2020-12-12 18:58:25;Dogs vs. Cats Redux: Kernels Edition;['gpu'];Lesson 1;Python notebook;721.0;23;;
2016-09-04 02:27:27;Starter EDA and ConvNet implementation using Keras. Inspiration for this notebook comes from this Keras blog post and the VGG ConvNet paper.;Apache 2.0;https://www.kaggle.com/jeffd23/catdognet-keras-convnet-starter;1.0;['keras', 'theano'];['ner', 'ai', 'cv', 'rl', 'nn', 'ann'];['filter', 'training data', 'train', 'fitting', 'model', 'output layer', 'epoch', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition;0.808;0.577;2020-12-12 18:58:25;Dogs vs. Cats Redux: Kernels Edition;[];CatdogNet - Keras Convnet Starter;Python notebook;60287.0;308;;
2017-02-12 21:32:59;Was inspired by the Udacity Deep Learning Course.  Fairly new to Tensorflow so wanted to repurpose the NotMNIST-ConvNet from the course for this Cats & Dogs competition.  This ConvNet gets >72% accuracy after only using a small fraction of the training data and very few epochs.  To prevent overfitting you should probably add (a) hinton dropout (b) perform data augmentation.  To provide better accuracy you can (a) train using all data  (b) increase # of epochs/training time  (c) build out full VGG-16 like architecture.;Apache 2.0;https://www.kaggle.com/kbhits/tensorflow-starter-kit-fixed;1.0;['tensorflow'];['ai', 'cv', 'rl', 'ml', 'nn', 'ann'];['training data', 'test data', 'train', 'fitting', 'model', 'epoch', 'deep learning', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition;0.762;0.418;2020-12-12 18:58:25;Dogs vs. Cats Redux: Kernels Edition;[];TensorFlow Starter Kit (Fixed!);Python notebook;14306.0;36;;
2018-12-16 08:56:01;A Comprehensive Guide to Transfer LearningIn this kernel I have demonstrated the general techniques that can be used with Transfer Learning. For this kernel I have used the Flower Recognition dataset but the basic TL principles remains the same. Basically , you need to watch two things 1) The simalarity of your dataset with that of the pre-trained model and  2) The amount of the data that you have. Depending on these two conditions you can choose to either fine tune the weights or just train a classifier on top of the pre-trained model.;Apache 2.0;https://www.kaggle.com/rajmehra03/a-comprehensive-guide-to-transfer-learning;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'train', 'fitting', 'model', 'recognition', 'epoch', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition;0.769;0.504;2020-12-12 18:58:25;multiple data sources;['beginner, cnn, computer vision, +1 moretransfer learning'];A Comprehensive Guide to Transfer Learning;Python notebook;17382.0;106;;
2020-07-09 13:01:07;Cat or Dog - Using CNN with Transfer Learning   Using pretrained ResNet-50;Apache 2.0;https://www.kaggle.com/sanchitvj/cat-or-dog-transfer-learning-using-resnets;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cnn', 'cv', 'nn', 'ml'];['activation function', 'training data', 'test data', 'train', 'model', 'epoch', 'validation data', 'layer', 'gradient descent', 'loss', 'label', 'predict', 'resnet'];https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition;0.613;0.375;2020-12-12 18:58:25;multiple data sources;['gpu, deep learning, transfer learning'];Cat or Dog - Transfer Learning using ResNets;Python notebook;564.0;22;0.06313;0.06313
2018-01-12 11:29:35;Building a strong image classification model from less data The implementation is a slight variation of the one in https://gist.github.com/fchollet/0830affa1f7f19fd47b06d4cf89ed44d Mainly, in this kernel , the method flow(x,y) is used whereas, in the above gist, method flow_from_directory(directory) is used. For more info, you can refer https://keras.io/preprocessing/image/ The change is made to have an appropriate kernel to deal with the way data is structured in kaggle. Appropriate changes in other parts of the source code is also done.;Apache 2.0;https://www.kaggle.com/sarvajna/dogs-vs-cats-keras-solution;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cv', 'nn', 'ann'];['image classification', 'train', 'fitting', 'model', 'neural network', 'epoch', 'supervised learning', 'layer', 'loss', 'label', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition;0.803;0.512;2020-12-12 18:58:25;Dogs vs. Cats Redux: Kernels Edition;['classification, neural networks, computer vision, +1 moreanimals'];Dogs vs Cats: Keras Solution;Python notebook;49933.0;118;;
2017-02-22 23:29:35;Full run through of raw images to classification with Convolutional Neural NetworkIn this tutorial, we're going to be running through taking raw images that have been labeled for us already, and then feeding them through a convolutional neural network for classification. The images are either of dog(s) or cat(s). Once you have downloaded and extracted the data from https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data, you're ready to begin.;Apache 2.0;https://www.kaggle.com/sentdex/full-classification-example-with-convnet;1.0;['tensorflow'];['ner', 'ai', 'cnn', 'cv', 'ml', 'nn', 'ann'];['unlabeled', 'training data', 'test data', 'regression', 'train', 'model', 'output layer', 'neural network', 'epoch', 'deep learning', 'layer', 'loss', 'label', 'predict', 'relu', 'classification', 'labeled', 'convolutional neural network'];https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition;0.79;0.522;2020-12-12 18:58:25;Dogs vs. Cats Redux: Kernels Edition;[];Full Classification Example with ConvNet;Python notebook;33009.0;137;;
2018-04-29 08:40:13;Keras Warm-up: Cats vs Dogs CNN with VGG16In this notebook, I'm replicating the technique mentioned at Building powerful image classification models using very little data. Using the pretrained model and build the model on-top of embeddings have been a norm in industry. Fine-tuning VGG model may be my next notebook. Steps:  Image Data Preparation. VGG16 Image Embeddings Backfill. Training Multi-layer Perceptron Classifier. Submission. Appendix: PCA of VGG16 Embeddings (for inspection only)  If you find this notebook useful, please help vote it. Thanks! 1. Library ImportStandard library import. Checking if the execution environment contains GPU at our disposal.;Apache 2.0;https://www.kaggle.com/shaochuanwang/keras-warm-up-cats-vs-dogs-cnn-with-vgg16;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'nn', 'cnn'];['image classification', 'training data', 'train', 'model', 'epoch', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition;0.743;0.379;2020-12-12 18:58:25;multiple data sources;['gpu, classification, image data, +1 morecnn'];Keras Warm-up: Cats vs Dogs CNN with VGG16;Python notebook;8489.0;23;0.65430;0.65430
2018-10-29 11:56:17;CNN Architectures : VGG, Resnet, InceptionNet, XceptionNetUseCases : Image Feature Extraction + Transfer Learning A Gold mine dataset for comuter vision is the ImageNet dataset. It consists of about 14 M hand-labelled annotated images which contains over 22,000 day-to-day categories. Every year ImageNet competition is hosted in which the smaller version of this dataset (with 1000 categories) is used with an aim to accurately classify the images. Many winning solutions of the ImageNet Challenge have used state of the art convolutional neural network architectures to beat the best possible accuracy thresholds. In this kernel, I have discussed these popular architectures such as VGG16, 19, ResNet, AlexNet etc. In the end, I have explained how to generate image features using pretrained models and use them in machine learning models. Contents From the high level perspective, I have discussed three main components  1. CNN Architectures     1. 1 VGG16 1.2 VGG19  1.3 InceptionNet 1.4 Resnet  1.5 XceptionNet  2. Image Feature Extraction   3. Transfer Learning   1. CNN Architectures1.1    VGG16 VGG16 was publised in 2014 and is one of the simplest (among the other cnn architectures used in Imagenet competition). It's Key Characteristics are:  This network contains total 16 layers in which weights and bias parameters are learnt.     A total of 13 convolutional layers are stacked one after the other and 3 dense layers for classification.      The number of filters in the convolution layers follow an increasing pattern (similar to decoder architecture of autoencoder).      The informative features are obtained by max pooling layers applied at different steps in the architecture.     The dense layers comprises of 4096, 4096, and 1000 nodes each.    The cons of this architecture are that it is slow to train and produces the model with very large size.     The VGG16 architecture is given below:  Implementation : VGG16Let's see how we can create this architecture using python's keras library. The following code block shows the implementation of VGG16 in keras.;Apache 2.0;https://www.kaggle.com/shivamb/cnn-architectures-vgg-resnet-inception-tl;1.0;['pattern', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cnn', 'rl', 'ml', 'nn', 'ann'];['filter', 'recognition', 'vgg', 'predict', 'relu', 'autoencoder', 'machine learning', 'training data', 'object detection', 'train', 'alexnet', 'classification', 'model', 'neural network', 'layer', 'resnet', 'test data', 'output layer', 'label', 'convolutional neural network'];https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition;0.814;0.61;2020-12-12 18:58:25;multiple data sources;['deep learning, cnn'];CNN Architectures : VGG, ResNet, Inception + TL;Python notebook;73441.0;529;;
2018-10-05 08:08:44;Tutorial Keras: Transfer Learning with ResNet50 for image classification on Cats & Dogs datasetSuni Kumar;Apache 2.0;https://www.kaggle.com/suniliitb96/tutorial-keras-transfer-learning-with-resnet50;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['activation function', 'image classification', 'machine learning', 'training data', 'test data', 'train', 'model', 'epoch', 'deep learning', 'layer', 'loss', 'label', 'predict', 'resnet', 'classification', 'labeled'];https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition;0.819;0.477;2020-12-12 18:58:25;multiple data sources;['deep learning, image data, binary classification, +1 moretransfer learning'];Tutorial Keras: Transfer Learning with ResNet50;Python notebook;88385.0;74;0.67143;0.67143
2020-10-13 15:06:56;Rapids is an open-source GPU accelerated Data Science and Machine Learning library, developed and mainatained by Nvidia. It is designed to be compatible with many existing CPU tools, such as Pandas, scikit-learn, numpy, etc. It enables massive acceleration of many data-science and machine learning tasks, oftentimes by a factor fo 100X, or more. Rapids is still undergoing developemnt, and as of right now it's not availabel in the Kaggle Docker environment. If you are interested in installing and running Rapids locally on your own machine, then you should refer to the followong instructions. The purpose of this kernel is to take a look at dimensionality reduction that one gets with t-SNE algorithms. We will apply these algorithms to various image embeddings done with top pretrained Deep Learnign architectures.;Apache 2.0;https://www.kaggle.com/tunguz/cats-and-dogs-with-rapids-t-sne;1.0;['xgboost'];['ai', 'nn', 'ml', 'rl'];['machine learning', 'train', 'vgg', 'label', 'resnet'];https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition;0.589;0.34;2020-12-12 18:58:25;multiple data sources;['gpu'];Cats and Dogs with Rapids t-SNE;Python notebook;375.0;15;;
2017-08-22 02:42:30;Ten class images classification - CIFAR-10 - Acc 87%Yassine Ghouzam, PhD22/07/2017Du to web access restriction on kaggle kernels , i can't run this notebook on kaggle but you can view itPlease check my ipython notebook at  http://nbviewer.jupyter.org/gist/YassineGhouzam/e4536eae104a770c715045ae1b9f3894 1. Introduction 2. Data preparation 2.1 Load data 2.2 Normalization 2.3 Reshape 2.4 Label encoding 2.5 Split training and valdiation set   3. CNN 3.1 Define the model 3.2 Set the optimizer and annealer 3.3 Data augmentation   4. Evaluate the model 4.1 Training and validation curves 4.2 Confusion matrix   5. Prediction and submition 5.1 Predict and Submit results;Apache 2.0;https://www.kaggle.com/yassineghouzam/dogs-cats-aren-t-enough-object-recognition;1.0;['tensorflow', 'keras'];['ai', 'nn', 'cnn', 'ann'];['image classification', 'train', 'recognition', 'model', 'neural network', 'epoch', 'label', 'predict', 'classification', 'convolutional neural network'];https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition;0.7;0.357;2020-12-12 18:58:25;Dogs vs. Cats Redux: Kernels Edition;[];Dogs & cats aren't enough ? : Object recognition;Python notebook;3066.0;18;;
2018-12-14 13:52:26;General informationThis kernel is dedicated to extensive EDA of DonorsChoose.org Application Screening competition as well as feature engineering and modelling.;Apache 2.0;https://www.kaggle.com/artgor/eda-feature-engineering-and-xgb-lgb;1.0;['xgboost', 'sklearn', 'lightgbm', 'nltk'];['ner', 'ai', 'dl', 'gan', 'gbm', 'cv', 'rl', 'nn'];['filter', 'test data', 'regression', 'train', 'model', 'layer', 'label', 'predict', 'classification'];https://www.kaggle.com/c/donorschoose-application-screening;0.739;0.536;2020-12-12 19:01:17;DonorsChoose.org Application Screening;['data visualization, exploratory data analysis, classification, +2 morefeature engineering, nlp'];EDA, feature engineering and xgb + lgb;Python notebook;7837.0;166;;
2018-03-30 02:46:50;Beginner's Guide to Capsule NetworksAuthor: Zafar Last Updated: 03/30/18  In the recently concluded Toxic Comments Classification Challenge, Capsule Network (aka CapsNet) proved to be a huge success. This notebook introduces and implements a Capsule Network in Keras and evaluates its performance in the DonorsChoose.Org Application Screening Competition. Contents Introduction to Capsule Networks 1.1 Human Visual Recognition 1.2 Capsules 1.3 Routing by Agreement 1.4 Mathematics behind CapsNet 1.5 The Dyanmic Routing Algorithm 1.6 A word about squash function 1.7 The advantage of Capsule Networks   Boilerplate Code CapsNet implementation Training Submission Conclusion References  Before you read further, it is important to note that the examples presented here are just for the purpose of understanding.;Apache 2.0;https://www.kaggle.com/fizzbuzz/beginner-s-guide-to-capsule-networks;1.0;['tensorflow', 'sklearn', 'keras', 'nltk'];['ner', 'ai', 'cnn', 'rl', 'nn'];['activation function', 'gru', 'neuron', 'train', 'recognition', 'model', 'epoch', 'layer', 'relu', 'loss', 'label', 'lstm', 'text classification', 'predict', 'rank', 'understanding', 'classification'];https://www.kaggle.com/c/donorschoose-application-screening;0.798;0.603;2020-12-12 19:01:17;multiple data sources;['beginner, deep learning, nlp, +1 moretext data'];Beginner's Guide to Capsule Networks;Python notebook;42656.0;468;;
2018-03-12 03:51:06;Hi, Welcome to my kernel. We will show you how we achieve 80+% in this challenge.If you find this helpful, please support us!!!We will focus on the rate of REJECTED according to different factors. This may help you to design your model on features that truly matter. DonorsChoose is an US organisation that provide funding to school teachers who wish to improve their education environment. They received approximately thounsands of project proposals every year and the challange they are facing is dealing with enormous of proposal with limited volunteers. We're writing this kernel to help the organizer and participants to filter out insignificant features when designing pre-screening algorithm.Let's see what we going to analyze in this kernel: Introduction of datasetImporting the libraries Data preparation     AnalysisWhich state has the highest rate of rejected? What is the relationship between funding amount and rate of rejected?   Will grade categories affect the rate of rejected?  Which combination of category and sub-category has highest rate of rejected?  What is the relationship between essay sentiment and rate of rejected?    Suggestion LGBM + TFIDF GRU-ATT Results;Apache 2.0;https://www.kaggle.com/hoonkeng/how-to-get-81-gru-att-lgbm-tf-idf-eda;1.0;['lightgbm', 'nltk', 'theano', 'sklearn', 'textblob', 'keras'];['ai', 'gan', 'gbm', 'rl', 'nn'];['gru', 'filter', 'machine learning', 'train', 'fitting', 'model', 'epoch', 'layer', 'loss', 'label', 'lstm', 'text classification', 'predict', 'rank', 'sentiment analysis', 'classification'];https://www.kaggle.com/c/donorschoose-application-screening;0.717;0.476;2020-12-12 19:01:17;multiple data sources;['beginner, data visualization, exploratory data analysis, +1 morefeature engineering']; (How to get 81%) GRU-ATT + LGBM + TF-IDF + EDA;Python notebook;4541.0;73;0.80319;0.81177
2018-04-19 07:52:28;Understanding Approval:- Donor Choose EDA Contents: Introduction About Donors Choose Competition Objective Kernel objective   Imports and overview Custom Helper Functions Plotting Functions Text functions Extract text stats Make Wordclouds     Individual Feature impact on Approval rates Categorical features - Teacher-prefix, Gender, Grade/class Cleaning up - Subject category and Subject sub-category   Text columns exploration Title Student description Project description Resource summary   Resources dataset Custom Word Vectors (Word2Vec) Product Descriptions Similar Products Primer to product clustering    Product Clustering Are teachers asking for the same type of products getting rejected?   Price points Exploring some costly items   Pre-processing and cleaning text Feature Engineering Label encoding Create date features Custom Vectorizer for ELI5 compatability   Baseline Models -- XGBoost and LightGBM ROC curve and    Understanding how the model predicts - ELI5 Explore correct classifications Explore mis-classifications    1. Introduction:1.1 About Donors Choose:Donorschoose.org is a crowdfunding platform which connects Public school teachers and Donors.   As per their website, they have raised $645,575,280 till date and claim that 77 percent of all the public schools in America have at least one teacher who has posted a project on DonorsChoose.org. Amazing! With such high numbers, the number of applications they receive is increasing every year and the current screening process is manually vetting the applications by a team of volunteers. As a result, there are three main problems they need to solve:  How to scale current manual processes and resources to screen 500,000 projects so that they can be posted as quickly and as efficiently as possible How to increase the consistency of project vetting across different volunteers to improve the experience for teachers How to focus volunteer time on the applications that need the most assistance  1.2 Competition Objective:The goal of the competition is to predict whether or not a DonorsChoose.org project proposal submitted by a teacher will be approved, using the text of project descriptions as well as additional metadata about the project, teacher, and school. DonorsChoose.org can then use this information to identify projects most likely to need further review before approval. 1.3 Kernel objective:To explore and understand factors that make a successful project and hopefully create an approval process pipeline/algorithm to help Donorschoose.org with the vetting process of approving a project. 2. Imports and overview:Lets get started by importing all the required packages and performing basic sanity checks like the test-train split ratio, Missing value checks,etc.;Apache 2.0;https://www.kaggle.com/jagangupta/understanding-approval-donorschoose-eda-fe-eli5;1.0;['statsmodels', 'xgboost', 'lightgbm', 'nltk', 'gensim', 'sklearn', 'pattern'];['ner', 'ai', 'dl', 'gbm', 'gan', 'cv', 'rl', 'ml', 'nlp', 'nn', 'ann'];['filter', 'test data', 'generation', 'train', 'model', 'layer', 'clustering', 'label', 'predict', 'rank', 'understanding', 'classification'];https://www.kaggle.com/c/donorschoose-application-screening;0.72;0.425;2020-12-12 19:01:17;multiple data sources;['beginner, data visualization, exploratory data analysis, +1 morenlp'];Understanding Approval-DonorsChoose-EDA,FE,ELI5;Python notebook;4829.0;39;;
2018-04-24 00:25:11;Word Vectors and Features I have been wanting to try out a model that combines word vectors with feature engineering. I also wanted my model to use KFold CV with a validation set within each fold. Finally, I wanted to ensemble the predictions to produce a combined model that out performs its individual parts. Over time, this kernel has grown to include XGBoost, LightGBM and CatBoost models. CatBoost has been dropped in favor of NB-SVM. The final output of each mode is ensembled using a technique from another kernel in this competition. This isn't the prettiest kernel with the highest leaderboard score but I hope that it's useful for those less proficient in python than I am. For those farther along, please suggest improvements! I will add more annotations, explanations, modify parameters and make changes over the course of the competition. Stay tuned...;Apache 2.0;https://www.kaggle.com/jmbull/xtra-credit-xgb-lgb-tfidf-feature-stacking;1.0;['xgboost', 'lightgbm', 'nltk', 'catboost', 'sklearn', 'pattern'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'nlp', 'nn', 'ann'];['training data', 'regression', 'train', 'fitting', 'model', 'label', 'logistic regression', 'predict'];https://www.kaggle.com/c/donorschoose-application-screening;0.706;0.371;2020-12-12 19:01:17;multiple data sources;['feature engineering, nlp, xgboost, +1 moregradient boosting'];Xtra Credit: XGB / LGB + TFIDF + Feature Stacking;Python notebook;3493.0;21;0.76509;0.77448
2018-07-27 19:58:51;Have you ever wondered what if summary statistics is more just a simple summary?Introducing, pandas_profiling for simple and fast exploratory data analysis of a Pandas Datafram;Apache 2.0;https://www.kaggle.com/nulldata/intro-to-pandas-profiling-simple-fast-eda;1.0;['vocabulary'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'training data', 'train', 'model', 'understanding', 'layer', 'recommend'];https://www.kaggle.com/c/donorschoose-application-screening;0.823;0.45;2020-12-12 19:01:17;DonorsChoose.org Application Screening;['beginner, data visualization, exploratory data analysis'];Intro to pandas_profiling - Simple Fast EDA;Python notebook;103427.0;53;;
2018-04-25 12:34:48;Sections  Introduction  Data Cleaning  Feature Engineering 3.1. Resource Features 3.2. Statistical Features 3.3. Sentimental Analysis 3.4. Time Features 3.5. Polynomial Features 3.6. Categorical Features 3.7. Text Features  Training  Output  Further Possible Improvements    Update (v14) thanks to Stranger we fixed a bug in my categorical variables treatment part Update (v11) new treatment for subject categories and sub-categories + new features Update (v8) Included Neural Networks in the learning ensemble;Apache 2.0;https://www.kaggle.com/safavieh/ultimate-feature-engineering-xgb-lgb-nn;1.0;['xgboost', 'lightgbm', 'nltk', 'sklearn', 'tensorflow', 'textblob', 'pattern', 'keras'];['ner', 'ai', 'gbm', 'cv', 'rl', 'nn', 'ml'];['regression', 'train', 'model', 'neural network', 'epoch', 'layer', 'loss', 'label', 'predict', 'rank', 'decision tree', 'relu'];https://www.kaggle.com/c/donorschoose-application-screening;0.741;0.444;2020-12-12 19:01:17;DonorsChoose.org Application Screening;['feature engineering, neural networks, xgboost, +2 moretabular data, text mining'];Ultimate Feature Engineering -> XGB+LGB+NN;Python notebook;8063.0;49;0.81085;0.81655
2018-04-26 01:20:47;I'd like to first thank DonorsChoose.org and Kaggle for providing us with an interesting, real world dataset of text based applications to play with! A little about my path: last fall I enrolled in Andrew Ng's Deep Learning course on Coursera and fell under the spell of machine learning.  After Coursera, I read a number of Python machine learning and DNN books.  But my real machine learning education has been through Kaggle.  I participated in the Porto Seguro  and Recruit Restaurant competitions, doing pretty badly but gaining a lot of knowledge through the kernels and discussions shared by other participants.  I particularly enjoy reading about the innovative top solutions posted at the end of the competitions, even competitions I didn't participate in.  Over time I have built up a bag of tricks, and some reusable ML utility code.  DonorsChoose.org was my introduction to NLP and a great dataset for me to put these tools to use in. Summary of  Models: My final ensemble of many models was blended together using the HillClimb algorithm (more about that later) and also stacked using a non-linear XBG stacker: 4 parts HillClimb, 1 part XGB.  So three levels in all.  Quick overview of model groups:  GRU-ATT and GRU-LSTM models as introduced by Peter in the GRU-ATT kernel.  Each model used a different word embedding or had their sentences reversed (a kind of data augmentation). Bi-LSTM models inspired by huiqin's Deep learning is all you need!, some with two different word embeddings in the same model.   I re-used the feature hashing huiqin introduced in my other DNN models that included categorical features. Capsule Network models. Combined Bi-GRU and Conv1D models based on Zafar's The All-in-one Model  kernel. LGB model of depth 17. XBG model of depth 7 (shallow vs LGB's deep).  Each DNN model had a different take on the data, increasing diversity.  DNN provided 54% of the blend vs 46% for gradient boosted trees.;Apache 2.0;https://www.kaggle.com/shadowwarrior/1st-place-solution;1.0;['vocabulary', 'tensorflow', 'keras', 'theano'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'nlp', 'nn', 'rnn', 'ml'];['gru', 'filter', 'machine learning', 'regression', 'train', 'fitting', 'model', 'neural network', 'epoch', 'deep learning', 'layer', 'relu', 'loss', 'lstm', 'predict', 'rank', 'classification'];https://www.kaggle.com/c/donorschoose-application-screening;0.753;0.472;2020-12-12 19:01:17;DonorsChoose.org Application Screening;['feature engineering, nlp, neural networks, +2 moretext data, gradient boosting'];1st Place Solution;Python notebook;11307.0;70;;
2018-06-27 04:08:52;IntroductionThis is a feature engineering notebook for the DonorsChoose.org Application Screening competition. The objective is to predict whether teachers' project proposals are accepted or rejected. In this notebook, I have described different types of features that can be engineered with the given dataset. These features can be used in the classification models. Contents Aggregated Features Date-Time Features Text Based Features NLP Based Features TF-IDF Features Word Level TF-IDF Character Level TF-IDF   Word Embedding Features Topic Modelling Features Count Features;Apache 2.0;https://www.kaggle.com/shivamb/extensive-text-data-feature-engineering;1.0;['nltk', 'sklearn', 'tensorflow', 'textblob', 'vocabulary', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'nlp', 'nn'];['filter', 'training data', 'train', 'model', 'neural network', 'layer', 'predict', 'classification'];https://www.kaggle.com/c/donorschoose-application-screening;0.749;0.477;2020-12-12 19:01:17;multiple data sources;['beginner, feature engineering, text data'];Extensive Text Data Feature Engineering;Python notebook;10162.0;74;;
2018-03-09 00:12:27;This tutorial provides an overview of the DonorsChoose data set, as well as a quick-start guide to building your first model in TensorFlow and submitting your entry to Kaggle. For a refresher on machine learning fundamentals, check out Machine Learning Crash Course. For more practice building models in TensorFlow, check out the companion exercises.;Apache 2.0;https://www.kaggle.com/skleinfeld/getting-started-with-the-donorschoose-data-set;1.0;['vocabulary', 'tensorflow', 'sklearn'];['dl', 'ner', 'ai', 'nn'];['machine learning', 'training data', 'regression', 'test data', 'train', 'model', 'epoch', 'validation data', 'loss', 'label', 'predict', 'linear regression', 'classification'];https://www.kaggle.com/c/donorschoose-application-screening;0.755;0.467;2020-12-12 19:01:17;DonorsChoose.org Application Screening;[];Getting Started with the DonorsChoose Data Set;Python notebook;11779.0;65;;
2018-03-19 07:58:27;Objective of this Notebook: In this notebook, let us try to do some Interactive Exploratory Data Analysis. Then we can concentrate on the Feature Engineering part followed by Modeling. The language in the notebook will be Python. About DonorsChoose: DonorsChoose.org empowers public school teachers from across the country to request much-needed materials and experiences for their students. At any given time, there are thousands of classroom requests that can be brought to life with a gift of any amount. Objective of the competition: DonorsChoose.org receives hundreds of thousands of project proposals each year for classroom projects in need of funding. Right now, a large number of volunteers is needed to manually screen each submission before it's approved to be posted on the DonorsChoose.org website.The goal of the competition is to predict whether or not a DonorsChoose.org project proposal submitted by a teacher will be approved, using the text of project descriptions as well as additional metadata about the project, teacher, and school. DonorsChoose.org can then use this information to identify projects most likely to need further review before approval. Let us start with importing the necessary modules.;Apache 2.0;https://www.kaggle.com/sudalairajkumar/simple-eda-fe-notebook-donorschoose;1.0;['pattern'];['dl', 'ai', 'nn', 'rl'];['filter', 'test data', 'train', 'model', 'label', 'predict', 'understanding'];https://www.kaggle.com/c/donorschoose-application-screening;0.651;0.371;2020-12-12 19:01:17;DonorsChoose.org Application Screening;['exploratory data analysis, feature engineering'];Simple EDA & FE Notebook - DonorsChoose;Python notebook;1117.0;21;;
2018-03-18 15:49:21;Beginner's guide: NN with multichannel input  in KerasAuthor: Kirill Vlasov  IntroductionIn this article we will not discuss types of Neural Network. We will try to build network with multichannel input, because this case is so difficult for novice. Plan:  Explanation of model’s usefulness How to develop a neural network with multichannel input in Keras. Practice: using this approach in DonorsChoose Competition  Let's start! Explanation of model’s usefulnessImagine, we have a dataset of images and we need to solve the problem of classification. Probably, we will develop a convolutional neural network. What are you going to do, in order to supplement meta data (texts, some categorical features and etc.) in model? Obviously, we need different types of NN for different types of data, e.g. RNN, CNN and etc. But NN with multichannel input allows to create ONE NN, which could merge all different types of needed NNs. It could divide different flows of calculation, and then merge them together inside one joint NN. How to develop a neural network with multichannel input in Keras. Firts of all, we define the type of each data and choose apropriate type of NN for each type of data.  Then, we develop each NN. By class concatenate of module layers.merge in Keras we merge all outputs of these different NNs Enjoy! :)   That's all! Practice: using this approach in DonorsChoose Competition </a>0. Importing Libraries;Apache 2.0;https://www.kaggle.com/vlasoff/beginner-s-guide-nn-with-multichannel-input;1.0;['tensorflow', 'sklearn', 'keras', 'nltk'];['ner', 'ai', 'cnn', 'nn', 'rnn', 'ann'];['filter', 'train', 'fitting', 'model', 'neural network', 'epoch', 'layer', 'loss', 'label', 'lstm', 'predict', 'relu', 'sentiment analysis', 'classification', 'convolutional neural network'];https://www.kaggle.com/c/donorschoose-application-screening;0.76;0.527;2020-12-12 19:01:17;DonorsChoose.org Application Screening;['beginner, neural networks, text data, +1 morebinary classification']; Beginner's guide: NN with multichannel input;Python notebook;13452.0;147;;
2018-11-25 05:27:54;Happy Thanks Giving! Outline of Notebook 1.Import Dataset 2.Design Attention Layer 3.Split Dataset 4.Model Desing and Result Evaluation 5.KFold LSTM Model Training 6.Result Distribution 7.Filter Data Using Threshold 8.Final Model Training 9.Submission;Apache 2.0;https://www.kaggle.com/ashishpatel26/updated-cuda-dnn-lstm-stacked-model-99;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'nn'];['gru', 'filter', 'train', 'model', 'epoch', 'validation data', 'layer', 'loss', 'label', 'lstm', 'predict'];https://www.kaggle.com/c/dont-call-me-turkey;0.681;0.362;2020-12-12 19:03:18;Don't call me turkey!;['beginner, classification, lstm'];Updated Cuda DNN LSTM Stacked Model (99%);Python notebook;2015.0;19;0.99026;0.99026
2020-10-03 14:16:09;Let's bring in the imports and the data;Apache 2.0;https://www.kaggle.com/chitramdasgupta/turkey-or-not;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'rl'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'lstm', 'predict', 'relu'];https://www.kaggle.com/c/dont-call-me-turkey;0.439;0.152;2020-12-12 19:03:18;Don't call me turkey!;['gpu, tensorflow, keras'];Turkey or Not;Python notebook;46.0;2;0.93704;0.93704
2020-04-12 20:13:45;EDA & Modeling for a great Thanksgiving;Apache 2.0;https://www.kaggle.com/frtgnn/yam-potatoes-thanksgiving-2018;1.0;['xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'dl', 'gbm', 'cv', 'nn', 'ann'];['filter', 'test data', 'regression', 'train', 'model', 'label', 'logistic regression', 'predict', 'random forest'];https://www.kaggle.com/c/dont-call-me-turkey;0.674;0.493;2020-12-12 19:03:18;Don't call me turkey!;['data visualization, exploratory data analysis, classification, +1 morexgboost'];Yam & Potatoes, ThanksGiving 2018;Python notebook;1752.0;92;;
2018-11-22 11:38:12;Happy Thanksgiving day to all, what's on the menu tonight?This kernel is just a baseline for LGB model. No Deep Learning innvolved, LB(0.984) without parameter tuning, No LSTM, No Attention and finally no time factor. I hope this kernel will help you in understanding the data and how easily we can separate the data... Library Used:  -- I used plotly and LGBM the two packages which are widely used in kaggle and it is better to start with this. Exploration includes PCA, TSNE Once again Happy Thanksgiving, Feel free to post your feedback, comments I will take it constructively..;Apache 2.0;https://www.kaggle.com/karthik7395/exploratory-data-analysis;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'gbm', 'cv', 'rl', 'nn'];['train', 'model', 'deep learning', 'lstm', 'label', 'predict', 'understanding'];https://www.kaggle.com/c/dont-call-me-turkey;0.606;0.236;2020-12-12 19:03:18;Don't call me turkey!;['beginner, data visualization, exploratory data analysis, +2 moreclassification, pca'];Exploratory Data Analysis + LGBM (Roll Up all sec);Python notebook;499.0;5;;
2018-11-20 03:30:28;Our files are here and load without error. Let's check to make sure the columns match and see the submission format.;Apache 2.0;https://www.kaggle.com/michaelapers/lstm-starter-notebook;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'rl'];['training data', 'train', 'model', 'epoch', 'validation data', 'layer', 'vgg', 'loss', 'label', 'lstm', 'predict', 'relu', 'labeled'];https://www.kaggle.com/c/dont-call-me-turkey;0.709;0.447;2020-12-12 19:03:18;Don't call me turkey!;[];LSTM Starter Notebook;Python notebook;3789.0;51;;
2018-11-26 06:25:08;"TL; DRThis update Ashish Patel(阿希什) kernel https://www.kaggle.com/ashishpatel26/cuda-dnn-lstm-stacked-model-99 I'am replace LSTM cell to GRU  This is just a simple fork from Wiston Van's basic LSTM model https://www.kaggle.com/winstonvan/the-van-plan-for-kaggle-swaggle We slapped an Attention layer on top of the LSTM results, also we leave the prediction probabilites alone instead of rounding it. Anyway, Happy Thanks Giving! Don't forget upvote :{";Apache 2.0;https://www.kaggle.com/rooshroosh/top4-lb-0-991-score-actually-gru-lstm;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'nn', 'rl'];['gru', 'training data', 'train', 'model', 'epoch', 'validation data', 'layer', 'loss', 'label', 'lstm', 'predict'];https://www.kaggle.com/c/dont-call-me-turkey;0.66;0.387;2020-12-12 19:03:18;Don't call me turkey!;['gpu'];top4 Lb 0.991 score:  actually GRU >> LSTM ;Python notebook;1333.0;25;0.99039;0.99039
2018-11-21 09:28:36;This is just a simple fork from Wiston Van's basic LSTM model https://www.kaggle.com/winstonvan/the-van-plan-for-kaggle-swaggle Apparently;Apache 2.0;https://www.kaggle.com/sanket30/cudnnlstm-lstm-99-accuracy;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'nn', 'rl'];['gru', 'predict', 'training data', 'train', 'model', 'epoch', 'validation data', 'layer', 'lstm', 'loss', 'relu'];https://www.kaggle.com/c/dont-call-me-turkey;0.761;0.352;2020-12-12 19:03:18;Don't call me turkey!;['gpu, lstm'];CuDNNLSTM + LSTM 99% Accuracy;Python notebook;14048.0;17;;
2018-11-26 23:27:02;"TL; DRThis is a fork of  Wiston Van's basic LSTM model https://www.kaggle.com/winstonvan/the-van-plan-for-kaggle-swaggle We slapped an Attention layer on top of the LSTM results, also we leave the prediction probabilites alone instead of rounding it. Anyway, Happy Thanksgiving!";Apache 2.0;https://www.kaggle.com/suicaokhoailang/10-fold-lstm-with-attention-0-991-lb;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'nn', 'rnn', 'cv'];['gru', 'training data', 'test data', 'train', 'model', 'epoch', 'validation data', 'layer', 'loss', 'label', 'lstm', 'predict', 'relu'];https://www.kaggle.com/c/dont-call-me-turkey;0.734;0.437;2020-12-12 19:03:18;Don't call me turkey!;['gpu'];10-fold LSTM with Attention [0.991 LB];Python notebook;6804.0;45;0.99112;0.99112
2018-11-22 03:50:03;I use these:  Based on Starter Kernel LSTM with Attention AUC Metric and Callback;Apache 2.0;https://www.kaggle.com/takaishikawa/turkey-or-not-turkey-that-is-the-question-0-987;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'nn', 'rl'];['filter', 'training data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'lstm', 'predict', 'relu'];https://www.kaggle.com/c/dont-call-me-turkey;0.589;0.214;2020-12-12 19:03:18;Don't call me turkey!;['lstm'];Turkey, or not turkey: that is the question;Python notebook;376.0;4;0.98683;0.98683
2018-11-27 13:33:56;Don't Call me Turkey!This kernel will show three approaches to tackle the challenge Don't Call me Turkey! using TensorFlow Estimator API  Logistic Regression  Multilayer Perceptron LSTM;Apache 2.0;https://www.kaggle.com/tauranis/tensorflow-estimator-approach-0-982;1.0;['vocabulary', 'tensorflow', 'sklearn'];['ai', 'rl', 'nn', 'rnn', 'ann'];['regression', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'logistic regression', 'lstm', 'predict', 'relu'];https://www.kaggle.com/c/dont-call-me-turkey;0.637;0.268;2020-12-12 19:03:18;Don't call me turkey!;[];TensorFlow Estimator Approach [0.982];Python notebook;865.0;7;;
2019-03-15 19:16:02;Winner Winner Turkey Dinner !A First Approach to Turkey Sounds DetectionCurrent Leaderboard score : 0.990 Feel free to fork, but please upvote if you do !;Apache 2.0;https://www.kaggle.com/theoviel/winner-winner-turkey-dinner-lb-0-990;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'nn', 'rl'];['gru', 'train', 'fitting', 'model', 'output layer', 'epoch', 'validation data', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/dont-call-me-turkey;0.696;0.44;2020-12-12 19:03:18;Don't call me turkey!;['gpu, deep learning'];Winner Winner Turkey Dinner ! ->  LB : 0.990;Python notebook;2813.0;47;;
2019-05-17 13:19:57;"Our MissionWe have neither won the competition nor yielded a high score on the leaderboard. Even though we want to share our idea how to model the true distributions that may have been used to generate the data. We assumed that the competition sponsors used 2 gaussian distributions to draw random samples - a small part given as train and a big part given as test. To solve the task we tried to learn how these gaussians look like in sense of their mean and variance values. We setup a semi-supervised gaussian mixture model that starts with intial values for means and variances using the train data. Our idea was then to adjust these values by learning how the gaussians fit the test data best. Hence instead of leaderboard probing we tried to use the information that is already provided by the test data... Unfortunately our model does mad things and learning was not as expected. We are now on our journey to find out what has happened and we like to share our ideas with you. :-) Please feel free to comment, let us know what has negatively influenced the learning process in your opinion. Let's share learning experiences! Happy kaggling ;-) Caution: Still work in progress Table of contents Preparation Exploring the data structure Recursive feature elimination with logistic regression Trying to catch the true distributions Fit on Chris Deottes Top Useful Features What have we learnt?";Apache 2.0;https://www.kaggle.com/allunia/don-t-overfit-searching-true-distributions;1.0;['sklearn'];['ner', 'ai', 'dl', 'rl', 'nn', 'ml'];['unlabeled', 'filter', 'training data', 'regression', 'test data', 'train', 'model', 'label', 'logistic regression', 'predict', 'labeled'];https://www.kaggle.com/c/dont-overfit-ii;0.636;0.383;2020-12-12 19:05:09;Don't Overfit! II;[];Don't overfit! - Searching true distributions;Python notebook;843.0;24;;
2019-04-24 16:11:54;"General informationIn Don't Overfit! II competition we have a binary classification task. 300 columns, 250 training samples and 79 times more samples in test data! We need to be able to build a model without overfitting. In this kernel I'll write the following things:  EDA on the features and trying to get some insights; Using permutation importance to select most impactful features; Comparing various models: bayer classification, linear models, tree based models; Trying various approaches to feature selection including taking top features from eli5 and shap; Hyperparameter optimization for models; Feature generation; Other things;";Apache 2.0;https://www.kaggle.com/artgor/how-to-not-overfit;1.0;['statsmodels', 'xgboost', 'lightgbm', 'catboost', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'test data', 'regression', 'generation', 'train', 'fitting', 'model', 'random forest', 'validation data', 'loss', 'label', 'logistic regression', 'predict', 'rank', 'classification'];https://www.kaggle.com/c/dont-overfit-ii;0.792;0.607;2020-12-12 19:05:08;Don't Overfit! II;['beginner, data visualization, classification, +1 moremodel explainability'];How to not overfit?;Python notebook;34827.0;504;0.827;0.835
2019-02-18 13:36:05;Feature Selector Baseline Don't Overfit  Outline of the Notebook  Step.1 Read Dataset Step.2 Display dataset Step.3 Remove unwanted columns Step.4 Create Instance of Feature Selector Step.5 Missing Value Step.6 Single Unique Value Step.7 Plot Feature Importances Step.8 Low Importance Features Step.9 Removing Features Step.10 Handling One-Hot Features Step.11 Model Training Step.12 Model Evaluation Framework to check Importance Step.13 Model Training and Evaluation Framework to check Importance   Reference Github : https://github.com/WillKoehrsen/feature-selector Reference Kernel :  1. https://www.kaggle.com/sovchinnikov/logistic-regression 2. https://www.kaggle.com/artgor/how-to-not-overfit/;Apache 2.0;https://www.kaggle.com/ashishpatel26/model-interpretation-with-voting-classifier-hard;1.0;['lightgbm', 'sklearn'];['ai', 'dl', 'gbm', 'cv', 'rl', 'nn', 'ml'];['filter', 'machine learning', 'regression', 'train', 'fitting', 'model', 'validation data', 'loss', 'label', 'logistic regression', 'gradient boosting', 'predict', 'classification'];https://www.kaggle.com/c/dont-overfit-ii;0.728;0.473;2020-12-12 19:05:08;Don't Overfit! II;['gpu'];Model Interpretation with Voting Classifier(Hard);Python notebook;5907.0;71;0.736;0.756
2019-04-21 13:18:54;Code for beginners to easily start participating in this competition;Apache 2.0;https://www.kaggle.com/ateplyuk/dntoverfit-starter;1.0;['sklearn'];['ner', 'ai', 'nn'];['test data', 'regression', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/dont-overfit-ii;0.639;0.4;2020-12-12 19:05:08;Don't Overfit! II;[];DntOverfit_Starter;Python notebook;895.0;29;0.825;0.833
2019-05-06 01:05:03;"Can we Trust CV and LB?Kaggle's ""Don't Overfit II"" is a unique competition where the training dataset only has 250 observations and the public test dataset has 1975 observations. Can we trust the training dataset CV and public dataset LB? Do higher AUC scores on these small datasets indicate that a more accurate model was found? In this kernel we explore this question with four experiments. We find that we can trust LB but must be careful trusting CV. Afterward in the appendix, using insights from these experiments, we estimate how many useful variables exist in the real dataset. Experiment 1 : CV with 300 useless variablesLet's create a synthetic sample of size 250. We will create 300 useless variables and a completely random (meaningless) target and see what CV says.";Apache 2.0;https://www.kaggle.com/cdeotte/can-we-trust-cv-and-lb;1.0;['pattern', 'sklearn'];['ner', 'ai', 'cv', 'ml', 'nn', 'ann'];['training data', 'test data', 'regression', 'train', 'model', 'label', 'logistic regression', 'predict'];https://www.kaggle.com/c/dont-overfit-ii;0.676;0.421;2020-12-12 19:05:08;Don't Overfit! II;[];Can we Trust CV and LB?;Python notebook;1845.0;37;;
2019-04-24 19:27:55;"How to Make an Animation!The data for the ""Don't Overfit! II"" competition has 300 features. Therefore it resides in 300 dimensional space and we have trouble visualizing it. In this kernel, we project it into 2 dimensional space and create an animation by rotating it through a third dimension. This visualization shows us that the training data target=1 and target=0 is separable by a hyperplane.  Load the data";Apache 2.0;https://www.kaggle.com/cdeotte/fun-data-animation;1.0;['sklearn'];['ai', 'nn', 'ann'];['training data', 'test data', 'regression', 'train', 'model', 'label', 'logistic regression', 'classification'];https://www.kaggle.com/c/dont-overfit-ii;0.711;0.5;2020-12-12 19:05:08;Don't Overfit! II;[];Fun Data Animation;Python notebook;3889.0;100;;
2019-05-18 03:00:48;"LB Probing Techniques - Don't Overfit! II - 2nd Place SolutionIf this kernel, we discuss efficient strategies to probe the Kaggle leaderboard (LB) to gain information about the public test dataset. LR Logistic regression, SVC support vector classifiation, and LDA naive Bayes, are three methods that find linear hyperplanes to classify data. In ""Don't Overfit II"" competition, the public test dataset has 8 times more data than the training dataset. Instead of finding the hyperplane that classifies the training data, we would prefer to find the hyperplane that classifies the public test dataset. We can. Let's assume target=Heaviside(a0x0+a1x1+...a298x298+a299x299+noise)target=Heaviside(a0x0+a1x1+...a298x298+a299x299+noise) Our task is to determine the 300 hyperplane coefficients a_k. Assuming the a_k are independent, then the following code extracts them from the public test dataset via LB probing: var = 33 test = pd.read_csv('test.csv') sub = pd.read_csv('sample_submission.csv') sub['target'] = test[str(var)] sub.to_csv('submission'+str(var)+'.csv',index=False)     Then the value of a_k is the just LB_SCORE_K minus 0.500. For example a33=LB_SCORE33−0.500=0.671−0.500=0.171a33=LB_SCORE33−0.500=0.671−0.500=0.171 When a variable is negatively correlated with target (as opposed to positively correlated), then the LB_SCORE_K will be less than 0.500.  a217=LB_SCORE217−0.500=0.382−0.500=−0.118a217=LB_SCORE217−0.500=0.382−0.500=−0.118 It's that simple! By doing this, we can recover the a_k in 20 days (100 submissions) with the following 3 additional tricks:  Only probe the 100 most important a_k. If abs(CV_SCORE_K - 0.5) < 0.04 set a_k=0 and don't probe. Use train data plus public for more accuracy. Replace LB_SCORE_K with (8/9)*LB_SCORE_K + (1/9)*CV_SCORE_K. Apply L1-penalty. If abs(LB_SCORE_K - 0.5) < 0.04 then set a_k=0.    These additional tricks help prevent overfitting LB. Instead of modeling only the public test dataset and risk overfitting, we use information from both the training data plus public test data for a combined sample size of 2225. With this sample size, it was shown here that any variable with AUC of 0.54 or less by itself may be a useless variable. So we remove all variables with abs(AUC - 0.5) < 0.04 from our model where AUC = (8/9)*LB_AUC + (1/9)*CV_AUC to prevent overfitting useless variables. Note that we are using a linear approximation to find a_k since 0.3 < AUC < 0.7 as explained here.";Apache 2.0;https://www.kaggle.com/cdeotte/lb-probing-strategies-0-890-2nd-place;1.0;['sklearn'];['ner', 'ai', 'cv', 'ml', 'nn', 'ann'];['training data', 'test data', 'regression', 'train', 'fitting', 'model', 'logistic regression', 'predict', 'naive bayes'];https://www.kaggle.com/c/dont-overfit-ii;0.738;0.516;2020-12-12 19:05:08;Don't Overfit! II;[];LB Probing Strategies - [0.890] - 2nd Place;Python notebook;7604.0;125;0.869;0.890
2019-05-01 07:10:05;IntroductionThis competition asks us to build a model of k = 300 features with only N = 250 observations. This resembles the situation often faced by scientists in the real world: we have limited observations and many possible explanations. In a normal scientific context, we could use domain knowledge to help navigate this situation: we would likely know something about these variables' meanings, the accuracy with which they are measured, their temporal orderings, or best of all, their causal relationships.  But, here we have a purely data science context. We have no domain knowledge about these features at all, so we have only our data-science tools to help sort out this mess. First, I'll get my environment ready, load the data, and define some custom helper functions.;Apache 2.0;https://www.kaggle.com/derekpowll/bayesian-lr-w-cauchy-prior-in-pymc3;1.0;['sklearn', 'theano'];['ner', 'ai', 'dl', 'rl', 'nn', 'ml'];['autoencoder', 'filter', 'regression', 'train', 'fitting', 'model', 'logistic regression', 'predict', 'bayesian'];https://www.kaggle.com/c/dont-overfit-ii;0.679;0.393;2020-12-12 19:05:08;Don't Overfit! II;['data visualization, exploratory data analysis, model comparison, +1 morebayesian statistics'];Bayesian LR w/ Cauchy Prior in PyMC3;Python notebook;1930.0;27;0.843;0.860
2019-05-02 16:17:36;Overfitting the private leaderboard  Content Introduction  Prepare the data analysis  Data exploration  Check the data  Density plots of features  Distribution of mean and std  Distribution of min and max  Distribution of skew and kurtosis  Features correlations    Feature engineering  Add features by aggregation  Add noise    Model Submission  References;Apache 2.0;https://www.kaggle.com/gpreda/overfitting-the-private-leaderboard;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'gbm', 'cv', 'rl'];['filter', 'training data', 'test data', 'train', 'fitting', 'model', 'label', 'predict'];https://www.kaggle.com/c/dont-overfit-ii;0.678;0.403;2020-12-12 19:05:08;Don't Overfit! II;['data visualization, exploratory data analysis, classification, +1 morefeature engineering'];Overfitting the private leaderboard;Python notebook;1903.0;30;;
2019-02-24 16:45:30;In this kernel I will be showing 2 techniques to perfome feature importance (tree based models Feature importance and eli5 weights );Apache 2.0;https://www.kaggle.com/ishivinal/feature-importance-techniques;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'gbm', 'cv', 'rl', 'nn'];['train', 'model', 'machine learning', 'regression'];https://www.kaggle.com/c/dont-overfit-ii;0.627;0.39;2020-12-12 19:05:09;Don't Overfit! II;['beginner, feature engineering, random forest'];⛮⛮ Feature Importance Techniques ⛮⛮;Python notebook;718.0;26;;
2019-03-24 23:50:05;"Spike-and-Slab Model:  An attempt to imitate the winning stategy from Don't Overfit IBayesian tools have come a long way since Tim Salimans wrote his own Gibbs sampler for the first competition.  These days, it's extremely rare for people to write their own samplers.  Instead, higher level modeling languages like PyMC3 and Stan are used to specify the model with a back-end ""inference engine"" doing the sampling. However, learning how to specify models properly and using the high-level tools to fit them still requires overcoming a learning curve and thinking a bit differently than the traditional data science workflow, so here's a notebook to help get started. I actually prefer Stan, but the Spike-and-Slab model has discrete parameters that are not possible to fit. EDIT:  I've changed the prior on the coefficients to StudentT(3,0,1).  We don't want to over-regularize the included variables. EDIT (again):  A normal prior works even better.  For .86 score, use p=.05 for hyperprior on xi and N(0,.75) as a prior for beta.";Apache 2.0;https://www.kaggle.com/melondonkey/bayesian-spike-and-slab-in-pymc3;1.0;['theano'];['ner', 'ai', 'rl', 'nn', 'ml'];['regression', 'train', 'model', 'label', 'logistic regression', 'predict', 'recommend', 'bayesian'];https://www.kaggle.com/c/dont-overfit-ii;0.715;0.413;2020-12-12 19:05:08;Don't Overfit! II;['bayesian statistics'];Bayesian Model Averaging in PyMC3;Python notebook;4314.0;34;;
2019-03-06 20:38:25;Dealing with very small datasetsIn this kernel we will see some techniques to handle very small datasets, where the main challenge is to avoid overfitting.  Why small datasets lead to overfitting? Use simple models Beware the outliers Select the features Balance the dataset with synthetic samples (SMOTE) Combine models for the final submission References;Apache 2.0;https://www.kaggle.com/rafjaa/dealing-with-very-small-datasets;1.0;['pattern', 'tensorflow', 'xgboost', 'sklearn'];['ner', 'ai', 'dl', 'rl', 'ml'];['anomaly detection', 'machine learning', 'filter', 'regression', 'training data', 'train', 'artificial intelligence', 'model', 'fitting', 'test data', 'neural network', 'random forest', 'label', 'logistic regression', 'k-nearest neighbor', 'predict', 'classification'];https://www.kaggle.com/c/dont-overfit-ii;0.802;0.523;2020-12-12 19:05:08;Don't Overfit! II;['classification'];Dealing with very small datasets;Python notebook;48211.0;139;;
2019-03-13 11:47:10;1. Python libraries and data2. Standard Scaler3. X and y4. Cross validation scores5. GridSearch CV and Modeling6. Recursive Feature Elimination (25)7. Submission;Apache 2.0;https://www.kaggle.com/vincentlugat/logistic-regression-rfe;1.0;['sklearn'];['ai', 'nn', 'cv'];['filter', 'regression', 'train', 'fitting', 'model', 'predict'];https://www.kaggle.com/c/dont-overfit-ii;0.721;0.433;2020-12-12 19:05:08;Don't Overfit! II;['beginner, classification'];Logistic Regression & RFE;Python notebook;5000.0;43;0.839;0.850
2020-10-23 04:08:14;Ref Articles  https://towardsdatascience.com/custom-transformers-and-ml-data-pipelines-with-python-20ea2a7adb65 https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/ https://discuss.analyticsvidhya.com/t/what-is-the-difference-between-predict-and-predict-proba/67376 https://github.com/AnilBetta/AV-Janata-Hack-healh-Care-2/blob/master/av-jh-hca2-cat.ipynb https://github.com/gcspkmdr/HA-Hackathon;Apache 2.0;https://www.kaggle.com/funxexcel/don-t-get-kicked-pipeline-feat-engineering;1.0;['catboost', 'sklearn'];['ai', 'dl', 'cv', 'ml', 'nn', 'ann'];['predict', 'random forest', 'train', 'fitting', 'model', 'loss', 'classification'];https://www.kaggle.com/c/DontGetKicked;0.473;0.268;2020-12-12 19:05:42;Don't Get Kicked!;[];Don't Get Kicked Pipeline | Feat Engineering;Python notebook;71.0;7;;
2020-10-29 11:29:41;Ref Articles  https://towardsdatascience.com/custom-transformers-and-ml-data-pipelines-with-python-20ea2a7adb65 https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/ https://discuss.analyticsvidhya.com/t/what-is-the-difference-between-predict-and-predict-proba/67376 https://github.com/AnilBetta/AV-Janata-Hack-healh-Care-2/blob/master/av-jh-hca2-cat.ipynb https://github.com/gcspkmdr/HA-Hackathon;Apache 2.0;https://www.kaggle.com/funxexcel/don-t-get-kicked-pipeline-improved;1.0;['catboost', 'sklearn'];['ai', 'dl', 'cv', 'ml', 'nn', 'ann'];['predict', 'random forest', 'train', 'fitting', 'model', 'loss', 'classification'];https://www.kaggle.com/c/DontGetKicked;0.489;0.281;2020-12-12 19:05:42;Don't Get Kicked!;[];Don't Get Kicked Pipeline Improved;Python notebook;87.0;8;;
2016-05-12 00:05:56;Read in filesThis is pretty routine stuff.  We get a list of jpeg files, reading them in as needed with matplotlib.pyplot.imread.;Apache 2.0;https://www.kaggle.com/bkamphaus/exploratory-image-analysis;1.0;['skimage', 'keras', 'sklearn'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nn', 'ann'];['filter', 'train', 'model', 'deep learning', 'layer', 'clustering', 'loss', 'label', 'relu', 'predict', 'computer vision', 'classification'];https://www.kaggle.com/c/draper-satellite-image-chronology;0.789;0.515;2020-12-12 19:09:16;Draper Satellite Image Chronology;[];Exploratory Image Analysis;Python notebook;32383.0;123;;
2016-05-31 06:32:49;Read in filesThis is pretty routine stuff.  We get a list of jpeg files, reading them in as needed with matplotlib.pyplot.imread.;Apache 2.0;https://www.kaggle.com/pramods/exploratory-image-analysis;1.0;['skimage', 'keras', 'sklearn'];['ner', 'ai', 'dl', 'gan', 'rl', 'nn', 'ann'];['filter', 'train', 'model', 'deep learning', 'layer', 'clustering', 'loss', 'label', 'relu', 'predict', 'computer vision', 'classification'];https://www.kaggle.com/c/draper-satellite-image-chronology;0.579;0.099;2020-12-12 19:09:16;Draper Satellite Image Chronology;[];Exploratory Image Analysis;Python notebook;318.0;1;;
2020-03-24 15:16:30;DS4G: Environmental Insights Explorer 🌏Exploring alternatives for emissions factor calculations;Apache 2.0;https://www.kaggle.com/caesarlupum/ds4g-go-to-the-green-future;1.0;['pattern', 'sklearn'];['ner', 'ai', 'gan', 'rl', 'ml', 'nn', 'ann'];['anomaly detection', 'gru', 'filter', 'generation', 'train', 'model', 'layer', 'label', 'predict', 'understanding'];https://www.kaggle.com/c/ds4g-environmental-insights-explorer;0.703;0.463;2020-12-12 19:11:13;DS4G - Environmental Insights Explorer;['data visualization, geospatial analysis'];🌏🌿DS4G: Go to the Green Future!;Python notebook;3304.0;62;;
2020-03-24 18:01:22;DS4G: Environmental Insights Explorer 🌏Exploring alternatives for emissions factor calculations;Apache 2.0;https://www.kaggle.com/caesarlupum/green-future-anomaly-analysis-time-series;1.0;['statsmodels', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['anomaly detection', 'filter', 'machine learning', 'training data', 'generation', 'train', 'fitting', 'model', 'epoch', 'layer', 'loss', 'label', 'lstm', 'predict'];https://www.kaggle.com/c/ds4g-environmental-insights-explorer;0.67;0.416;2020-12-12 19:11:13;multiple data sources;['geospatial analysis, environment, pollution'];🌏🌿Green Future: Anomaly Analysis & Time Series;Python notebook;1619.0;35;;
2020-03-25 12:57:20;"(ignore this ⤴ warning about deleted datasets!) An Analytical Approach to NO2 EmissionsTL;DR: I take an analytical approach, measuring a line density of NO2 on windy days at each point and fitting a distribution function to this line. This function gives the emissions in kg/hr. I use night time lights satellite imagery as a proxy for human activity to separate power and non-power emissions and then use the generation at each site with this value to calculate an emissions factor in kg/MWh. OverviewWe need to calculate the emissions factor in kg/MWh (or some equivalent) averaged for one year of Puerto Rico's energy production. Bonus points if we can calculate sub-annual and marginal emissions factors. So we need to figure out the following system:  Puerto Rico's wind blows mainly from the east, so there won't be any pollution blown in. But the rest still need to be accounted for. This problem definitely seems to want an analytical approach (rather than statistics/machine learning) so I'm going to go with that (and check if it makes sense along the way). In addition, I'm going to keep the data sources as simple as possible! There are several places where I could improve the accuracy by including more data from Google Earth Engine and other sources, but as this is a demonstration of a method, I'm going to keep it simple. For example, as I'm going to focus on the troposphere as a whole, I should probably use several wind fields that apply to the whole troposphere, instead of just the GFS data near the ground. Emissions factorSimplifying from the EPA formula: EF = E / G where:  EF: emissions factor (kg/MWh) E: emissions (kg/hr) G: generation (MWh/hr)  So if I can determine the emissions that are attributable to electricity generation, and if I know the generation, then I can calculate the emissions factor! Quick explanation that may be useful: a plant's capacity, usually measured in MW (megawatts) is the maximum instantaneous power it can output, while it's generation, often in MWh (megawatt-hours) is the amount of energy actually produced in a given time period. If the plant runs at full capacity non-stop (i.e. capacity factor equals 100%) then the generation will be a simple multiple of capacity. Normally, however, plants produce much less, and have a capacity factor below 100%. It might be 30% for wind and solar, 50-60% for fossil fuels, and 80%+ for nuclear power.";Apache 2.0;https://www.kaggle.com/chrisarderne/ds4g-an-analytical-approach-to-no2-emissions;1.0;['pattern'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'training data', 'generation', 'train', 'fitting', 'model', 'understanding', 'layer', 'label', 'recommend'];https://www.kaggle.com/c/ds4g-environmental-insights-explorer;0.656;0.371;2020-12-12 19:11:13;multiple data sources;['geospatial analysis, pollution'];DS4G: An analytical approach to NO2 emissions;Python notebook;1219.0;21;;
2020-02-23 13:57:42;"GoalDevelop a methodology to calculate an average historical emissions factor of electricity generated for a sub-national region, using remote sensing data and techniques. (from competition overview) Emission factorAn emissions factor is a representative value that attempts to relate the quantity of a pollutant released to the atmosphere with an activity associated with the release of that pollutant. These factors are usually expressed as the weight of pollutant divided by a unit weight, volume, distance, or duration of the activity emitting the pollutant (e.g., kilograms of particulate emitted per megagram of coal burned). Such factors facilitate estimation of emissions from various sources of air pollution. In most cases, these factors are simply averages of all available data of acceptable quality and are generally assumed to be representative of long-term averages for all facilities in the source category (i.e., a population average). The general equation for emissions estimation is as follows: E = A × EF × (1–ER)/100 where E = emissions; A = activity rate; EF = emission factor, and ER = overall emission reduction efficiency, %. Source";Apache 2.0;https://www.kaggle.com/gpoulain/eda-ef-with-n2o-time-series-earth-engine;1.0;['pattern'];['ner', 'ai', 'cv', 'rl', 'nn', 'ml'];['gru', 'filter', 'generation', 'model', 'layer', 'predict'];https://www.kaggle.com/c/ds4g-environmental-insights-explorer;0.654;0.334;2020-12-12 19:11:13;DS4G - Environmental Insights Explorer;['beginner, exploratory data analysis, geospatial analysis'];EDA - EF with N2O Time Series - Earth Engine;Python notebook;1192.0;14;;
2020-03-24 20:45:16;Methodology for the Emissions Factors Calculation: Spatial Panel Data Modeling;Apache 2.0;https://www.kaggle.com/katemelianova/ds4g-spatial-panel-data-modeling;1.0;['pattern'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nn', 'ann'];['filter', 'regression', 'generation', 'model', 'layer', 'label', 'k-nearest neighbor', 'predict', 'recommend'];https://www.kaggle.com/c/ds4g-environmental-insights-explorer;0.711;0.413;2020-12-12 19:11:13;multiple data sources;['geospatial analysis'];DS4G: Spatial Panel Data Modeling;R notebook;3938.0;34;;
2020-02-19 22:45:21;ObjectiveIn this notebook i will perform a basic exploratory data analysis of the data, also we will make a simple model to calculate the emission factor coefficient of electricity that produce Green House Gases for Puerto Rico. Here is a link of a public kernel that help me understand better the problem we are trying to solve: https://www.kaggle.com/parulpandey/understanding-the-data-wip  The model needs to produce a value for the an annual average historical grid-level electricity emissions factor (based on rolling 12-months of data from July 2018 - July 2019) for the sub-national region?  We also recieve bonuses for other objectives but we will not cover them in this initial notebook;Apache 2.0;https://www.kaggle.com/ragnar123/exploratory-data-analysis-and-factor-model-idea;1.0;['sklearn'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ann'];['filter', 'regression', 'generation', 'train', 'model', 'layer', 'label', 'predict', 'understanding'];https://www.kaggle.com/c/ds4g-environmental-insights-explorer;0.689;0.431;2020-12-12 19:11:13;DS4G - Environmental Insights Explorer;[];Exploratory Data Analysis and Factor Model Idea;Python notebook;2405.0;42;;
2020-08-17 09:43:29;OVERVIEWThe Environmental Insights Explorer team at Google is keen to gather insights on ways to improve calculations of global emissions factors of sub-national regions.The ultimate goal of this challenge is to test if calculations of emission factor using remote sensing technique are possible.;Apache 2.0;https://www.kaggle.com/raviyadav2398/ds4g-emission-factor;1.0;['pattern'];['ner', 'ai', 'rl', 'nn', 'ann'];['filter', 'generation', 'layer', 'label', 'understanding', 'classification'];https://www.kaggle.com/c/ds4g-environmental-insights-explorer;0.537;0.327;2020-12-12 19:11:13;multiple data sources;['beginner, data visualization, exploratory data analysis'];DS4G : Emission Factor;Python notebook;168.0;13;;
2020-02-25 11:42:11;DS4G: Modelling of emission of power plants Project overview and problem statement;Apache 2.0;https://www.kaggle.com/tiurii/ds4g-modelling-of-emissions-of-power-plants;1.0;['xgboost', 'sklearn'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['filter', 'generation', 'train', 'model', 'layer', 'loss', 'label', 'predict', 'recommend'];https://www.kaggle.com/c/ds4g-environmental-insights-explorer;0.638;0.346;2020-12-12 19:11:13;DS4G - Environmental Insights Explorer;[];DS4G: Modelling of emissions of power plants ;Python notebook;877.0;16;;
2020-03-24 12:56:04;The goal of this challenge is to:Develop a methodology to calculate an average historical emissions factor of electricity generated for a sub-national region, using remote sensing data and techniques.  1. What is a emission factor (EF)?In short, is a number that converts human activities to amount of pollutant released due to that activity. In this challenge, the focus is on trying to relate energy produced with NO22 released: NO22 = EF * Energy_created - Other_Factors The exact units of EF depend on the units of the NO22 and the energy used. I'll use EF in   1033 kg NO22/electrical generating megawatts /year. 2. Why is is hard to measure and how could it be easier?From the challenge description says: Current emissions factors methodologies are based on time-consuming data collection and may include errors derived from a lack of access to granular datasets, inability to refresh data on a frequent basis, overly general modeling assumptions, and inaccurate reporting of emissions sources like fuel consumption.  If we could use satelitte images, particularly of some pollutants, and 'trace them back' to what produced them (for example a power plant), then we could have a handy measurement of the emission factors, for some properties of the power plant (fuel type, energy capacity). 3. Summary of this analysisHere I'm using the satelite images of NO22 column density and 'distribute' that NO22 amongst the power plants of Puerto Rico, using a (rather naive) assumption that the closest a pixel is of a power plant, the more the NO22 on that pixel should have been produced by that power plant, but some of it might have still be produced by some closer by power plant. More on this lower down. I'll also add some other data sets privided in the challenge, that should try to account for either other sources of NO22 production (such as people travelling around) or the fact that the NO22 may move around due to winds, rain, etc. Although the actual electricity produced by a power plant should be a more precise way of measuring the EF, I'll use the electrical generating capacity in megawatts in the provided data set, that is more easily available. I'll also focus on power plants that use Oil as their primary fuel, although in principle I could have used the same analysis for other kinds of power plants. When calculating the EF, I'll use a Hierarchical Bayesian simple model, which has the advatage of using all the data of all Oil power plants to calculate an yearly average EF for these power plants, while still accounting for the fact that each oil power plant will have a slightly different EF due to other properties (year of construction, average use) that may even not be known. 4. Outlook1. Power Plants 2. Satelite data 3. Splitting NO22 between (overlapping) the power plants 4. EF calculation: Bayesian approach;Apache 2.0;https://www.kaggle.com/vpatricio/ds4g-where-does-the-no2-come-from;1.0;['pattern', 'theano'];['ner', 'ai', 'dl', 'rl', 'nn', 'ann'];['filter', 'generation', 'model', 'label', 'predict', 'rank', 'bayesian'];https://www.kaggle.com/c/ds4g-environmental-insights-explorer;0.658;0.383;2020-12-12 19:11:13;multiple data sources;['data visualization, exploratory data analysis, geospatial analysis, +2 moreenvironment, bayesian statistics'];DS4G: where does the NO2 come from?;Python notebook;1270.0;24;;
2017-01-03 19:11:41;This notebook is not going to use polygons from the training set, we're going to use raster data only =) Let's prepare the playground first;Apache 2.0;https://www.kaggle.com/aamaia/trees-are-red-buildings-are-blue-sort-of;1.0;['skimage'];['ai', 'nn', 'ann', 'cv'];['train', 'k-means'];https://www.kaggle.com/c/dstl-satellite-imagery-feature-detection;0.708;0.334;2020-12-12 19:16:58;Dstl Satellite Imagery Feature Detection;[];Trees are red, buildings are blue (sort of);Python notebook;3698.0;14;;
2017-02-06 18:15:50;End-to-end object-based solution for DSTLThere are typically two approaches for geo-image-segmentation: pixel-based and object-based and I'm just surprised that the latter was rarely mentioned in the forum and there seems no kernels available for this competition so I decided to share my object-based solution and hopefully it will be of help. Again, this competition comes with tons of challenges mostly in programmming/engineering which have been a pain for me. I'm grateful for those who shared their scripts/solutions. Without them, I weren't be able to make a single valid submission. This solution was inspried by the following two articles:  Python for Object Based Image Analysis (OBIA) https://www.machinalis.com/blog/obia/  A Python-Based Open Source System for Geographic Object-Based Image Analysis (GEOBIA) Utilizing Raster Attribute Tables http://www.mdpi.com/2072-4292/6/7/6111/htm   Many ideas/functions/tools were borrowed from Konstantin Lopuhin's great kernel: https://www.kaggle.com/lopuhin/dstl-satellite-imagery-feature-detection/full-pipeline-demo-poly-pixels-ml-poly;Apache 2.0;https://www.kaggle.com/chriscc/object-based-solution-for-dstl;1.0;['xgboost', 'sklearn', 'opencv-python'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ml'];['image segmentation', 'filter', 'training data', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/dstl-satellite-imagery-feature-detection;0.723;0.34;2020-12-12 19:16:58;Dstl Satellite Imagery Feature Detection;[];Object-based solution for DSTL;Python notebook;5257.0;15;;
2016-12-18 21:45:58;Let's try to stitch one of these 16 channel images together;Apache 2.0;https://www.kaggle.com/jeffhebert/stitch-a-16-channel-image-together;0.7;['pattern'];['nn', 'ann'];[];https://www.kaggle.com/c/dstl-satellite-imagery-feature-detection;0.72;0.383;2020-12-12 19:16:58;Dstl Satellite Imagery Feature Detection;[];Stitch a 16 Channel Image Together;R notebook;4896.0;24;;
2017-01-23 11:51:25;This script shows the full training and prediction pipeline for a pixel-based classifier: we create a mask, train logistic regression on one-pixel patches, make prediction for all pixels, create and smooth polygons from pixels.;Apache 2.0;https://www.kaggle.com/lopuhin/full-pipeline-demo-poly-pixels-ml-poly;1.0;['sklearn'];['ai', 'ml', 'cv'];['filter', 'regression', 'train', 'fitting', 'model', 'loss', 'logistic regression', 'predict'];https://www.kaggle.com/c/dstl-satellite-imagery-feature-detection;0.785;0.533;2020-12-12 19:16:58;Dstl Satellite Imagery Feature Detection;[];Full pipeline demo: poly -> pixels -> ML -> poly;Python notebook;28274.0;160;;
2017-05-19 09:51:26;Reflectance Index for Water Way [0.095 LB];Apache 2.0;https://www.kaggle.com/resolut/waterway-0-095-lb;1.0;['skimage'];['ai', 'cv'];['train', 'filter'];https://www.kaggle.com/c/dstl-satellite-imagery-feature-detection;0.741;0.449;2020-12-12 19:16:58;Dstl Satellite Imagery Feature Detection;[];Waterway [0.095 LB];Python notebook;8082.0;52;;
2019-02-14 19:15:08;General informationThis kernel is dedicated to EDA of Elo Merchant Category Recommendation competition as well as feature engineering. In this dataset we can see clients who use Elo and their transactions. We need to predict the loyalty score for each card_id. Work in progress.;Apache 2.0;https://www.kaggle.com/artgor/elo-eda-and-models;1.0;['catboost', 'xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'nn'];['filter', 'test data', 'regression', 'train', 'model', 'label', 'predict', 'recommend'];https://www.kaggle.com/c/elo-merchant-category-recommendation;0.768;0.558;2020-12-12 19:19:32;Elo Merchant Category Recommendation;['data visualization, exploratory data analysis, feature engineering, +2 moredata cleaning, regression'];Elo EDA and models;Python notebook;16876.0;231;3.62801;3.72639
2019-01-31 11:53:19;Thanks to this kernel: https://www.kaggle.com/fabiendaniel/elo-world https://www.kaggle.com/mfjwr1/simple-lightgbm-without-blending;Apache 2.0;https://www.kaggle.com/ashishpatel26/lightgbm-goss-dart-parameter-tuning;1.0;['lightgbm', 'sklearn'];['ai', 'rl', 'gbm'];['filter', 'regression', 'train', 'model', 'label', 'predict', 'recommend', 'bayesian'];https://www.kaggle.com/c/elo-merchant-category-recommendation;0.774;0.522;2020-12-12 19:19:32;multiple data sources;['beginner, feature engineering, india'];LIghtGBM (goss + dart) + Parameter Tuning;Python notebook;20503.0;137;;
2018-12-07 04:24:55;FEEL FREE TO UPVOTE  （＾ｖ＾）;Apache 2.0;https://www.kaggle.com/chauhuynh/my-first-kernel-3-699;1.0;['lightgbm', 'sklearn'];['ai', 'rl', 'gbm'];['filter', 'regression', 'train', 'model', 'label', 'predict', 'recommend'];https://www.kaggle.com/c/elo-merchant-category-recommendation;0.779;0.597;2020-12-12 19:19:31;Elo Merchant Category Recommendation;['feature engineering'];My first kernel (๑╹ᆺ╹);Python notebook;23151.0;424;3.61898;3.69986
2018-12-13 18:08:03;Elo worldIn this kernel, I build a LGBM model that aggregates the new_merchant_transactions.csv and historical_transactions.csv tables to the main train table. New features are built by successive grouping oncard_id and month_lag, in order to recover some information from the time serie. During the competition, I took into account the enlightments provided by others kernels, and included a few features that appeared to be important. In particular, I closely looked at the following kernels (ordered by release time):  You're Going to Want More Categories [LB 3.737] by Peter Hurford EloDA with Feature Engineering and Stacking by Bojan Tunguz A Closer Look at Date Variables by Robin Denz LGB + FE (LB 3.707) by Konrad Banachewicz My first kernel (3.699) by Chau Ngoc Huynh  Notebook  Content Loading the data Feature engineering Training the model Feature importance Submission;Apache 2.0;https://www.kaggle.com/fabiendaniel/elo-world;1.0;['lightgbm', 'sklearn'];['cv', 'ai', 'rl', 'gbm'];['filter', 'regression', 'train', 'model', 'label', 'predict', 'bayesian'];https://www.kaggle.com/c/elo-merchant-category-recommendation;0.806;0.614;2020-12-12 19:19:31;Elo Merchant Category Recommendation;[];Elo world;Python notebook;56335.0;567;;
2020-01-20 09:06:54;An easy and generic method to blend kernelsplanning to provide a more thorough approach soon!;Apache 2.0;https://www.kaggle.com/frtgnn/easy-blend-post-processing;1.0;['sklearn'];['ner', 'ai', 'rl', 'nn', 'ann'];['train'];https://www.kaggle.com/c/elo-merchant-category-recommendation;0.66;0.492;2020-12-12 19:19:32;multiple data sources;['gpu'];Easy Blend - Post Processing;Python notebook;1330.0;90;;
2019-12-29 13:06:06;Statistical Analysis for EloQuite Practical and Far from any Theoretical Conceptslast update: 19/02/2019  You are reading 10 Steps to Become a Data Scientist and are now in the 8th step :   Leren Python Python Packages Mathematics and Linear Algebra Programming & Analysis Tools Big Data Data visualization Data Cleaning You are in the 8th step A Comprehensive ML  Workflow with Python Deep Learning  You can Fork and Run this kernel on Github:  GitHub   I hope you find this kernel helpful and some UPVOTES would be very much appreciated;Apache 2.0;https://www.kaggle.com/mjbahmani/statistical-analysis-for-elo;1.0;['xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'gbm', 'rl', 'nn', 'ml'];['filter', 'machine learning', 'generation', 'train', 'model', 'deep learning', 'loss', 'label', 'predict', 'recommend'];https://www.kaggle.com/c/elo-merchant-category-recommendation;0.749;0.522;2020-12-12 19:19:32;Elo Merchant Category Recommendation;['data visualization, recommender systems'];Statistical Analysis for Elo ;Python notebook;10123.0;136;;
2018-11-29 01:49:11;In this Kernel, I work off of https://www.kaggle.com/rooshroosh/simple-data-exploration-with-python-lb-3-760 but include category_1, category_2, and category_3 from the transactions tables, which end up being very important features when aggregated by mean. Hopefully this shows how you can incorporate more categorical data into your kernel.;Apache 2.0;https://www.kaggle.com/peterhurford/you-re-going-to-want-more-categories-lb-3-737;1.0;['lightgbm', 'sklearn'];['ai', 'rl', 'gbm'];['filter', 'test data', 'regression', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/elo-merchant-category-recommendation;0.737;0.508;2020-12-12 19:19:32;Elo Merchant Category Recommendation;[];You're Going to Want More Categories [LB 3.737];Python notebook;7286.0;112;;
2018-11-28 06:18:25;Competition Objective Elo, one of the largest payment brands in Brazil, has built partnerships with merchants in order to offer promotions or discounts to cardholders.  The objective of the competition is to identify and serve the most relevant opportunities to individuals, by uncovering signal in customer loyalty. Objective of the NotebookObjevtive of the notebook is to explore the given data and get some interesting insights which will help in our model building process.;Apache 2.0;https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-elo;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'gbm', 'rl', 'nn'];['regression', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/elo-merchant-category-recommendation;0.783;0.602;2020-12-12 19:19:31;Elo Merchant Category Recommendation;[];Simple Exploration Notebook - Elo;Python notebook;26730.0;464;;
2018-12-30 19:39:58;One of the most important things to establish for every Kaggle competition is whether there is a significatn differnece in distributions of the train and test sets. So far the CV validation scores for kernels and for public LB have been pretty close, but the local CV seems to be consistently about 0.01 better than the LB scores. It would be interesting, and potentially very valuable, to find out in a more quantitative and specific way how do these distributions compare. For that purpose we'll build an adverserial validation scheme - we'll run a CV classifier that tries to predict if any given question belongs to the train or the test set. Firts, we'll have to deal with data gregation adn building of the combined train and test datasets. This work has already been doen in many of the kernels, and in this kernel we'll realy on Rahul Bamola's excelent kernel.;Apache 2.0;https://www.kaggle.com/tunguz/elo-adversarial-validation;1.0;['lightgbm', 'sklearn'];['ai', 'gbm', 'cv', 'rl', 'nn'];['filter', 'test data', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/elo-merchant-category-recommendation;0.72;0.506;2020-12-12 19:19:32;Elo Merchant Category Recommendation;[];Elo Adversarial Validation;Python notebook;4797.0;109;;
2018-12-12 03:44:14;OverviewThe purpose of this kernel is to take a look at the data, come up with some insights, and attempt to create a predictive model or two. This notebook is still very raw. I will work on it as my very limited time permits, and hope to expend it in the upcoming days and weeks. NB: Most of the feature engineering and some of the modeling is based on Peter Hurford's excellent kernel , and another one by Konrad Banachevitz. PackagesFirst, let's load a few useful Python packages. This section will keep growing in subsequent versions of this EDA.;Apache 2.0;https://www.kaggle.com/tunguz/eloda-with-feature-engineering-and-stacking;1.0;['xgboost', 'sklearn', 'lightgbm'];['ai', 'gbm', 'cv', 'rl', 'nn'];['filter', 'test data', 'regression', 'train', 'model', 'label', 'predict', 'recommend'];https://www.kaggle.com/c/elo-merchant-category-recommendation;0.749;0.524;2020-12-12 19:19:32;Elo Merchant Category Recommendation;[];EloDA with Feature Engineering and  Stacking;Python notebook;9944.0;140;3.61949;3.69972
2018-12-19 07:13:52;Combining your model with a model without outlier;Apache 2.0;https://www.kaggle.com/waitingli/combining-your-model-with-a-model-without-outlier;1.0;['lightgbm', 'sklearn'];['cv', 'ai', 'rl', 'gbm'];['filter', 'regression', 'train', 'model', 'loss', 'label', 'predict', 'classification'];https://www.kaggle.com/c/elo-merchant-category-recommendation;0.767;0.56;2020-12-12 19:19:32;multiple data sources;[];Combining your model with a model without outlier;Python notebook;16637.0;239;;
2019-08-02 07:27:17;IntroductionThis kernel is writtern for the Expedia Hotel Recommendations competetion. If you Like the notebook and think that it helped you,  please upvote.  Table of Content Data Preprocessing Modeling and Evaluation Final Prediction & Submission;Apache 2.0;https://www.kaggle.com/jiaofenx/expedia-hotel-recommendations;1.0;['xgboost', 'sklearn'];['ai', 'nn', 'ann'];['machine learning', 'test data', 'regression', 'train', 'model', 'label', 'predict', 'recommend'];https://www.kaggle.com/c/expedia-hotel-recommendations;0.695;0.34;2020-12-12 19:25:28;Expedia Hotel Recommendations;[];Expedia Hotel Recommendations;Python notebook;2763.0;15;;
2019-09-27 15:43:50;Note Please view in darkmode.  This kernel is inspired by Susan Li. Check her publications at https://towardsdatascience.com/@actsusanli;Apache 2.0;https://www.kaggle.com/bimimi/time-series-anomaly-detection;1.0;['sklearn'];['ner', 'ai', 'ml', 'rl'];['anomaly detection', 'train', 'model', 'clustering', 'label', 'k-means', 'predict', 'supervised learning'];https://www.kaggle.com/c/expedia-personalized-sort;0.674;0.188;2020-12-12 19:25:53;Personalize Expedia Hotel Searches - ICDM 2013;[];Time series anomaly detection;Python notebook;1760.0;3;;
2020-07-03 15:43:26;Notebook reads in sample of data due to memory limits;Apache 2.0;https://www.kaggle.com/danofer/catboost-ranking-ncdg-expedia-search-queries;1.0;['catboost', 'sklearn'];['ner', 'ai', 'dl', 'rl', 'cv'];['train', 'model', 'epoch', 'label', 'loss', 'rank', 'classification'];https://www.kaggle.com/c/expedia-personalized-sort;0.613;0.214;2020-12-12 19:25:53;Personalize Expedia Hotel Searches - ICDM 2013;[];Catboost Ranking NCDG - Expedia search queries;Python notebook;559.0;4;;
2020-04-14 20:54:08;Finding important features and preparing the dataset;Apache 2.0;https://www.kaggle.com/gauravtirodkar42/unsupervisedlearningota;1.0;['sklearn'];['ai'];['train', 'model', 'clustering', 'label', 'k-means', 'predict'];https://www.kaggle.com/c/expedia-personalized-sort;0.574;0.0;2020-12-12 19:25:53;Personalize Expedia Hotel Searches - ICDM 2013;[];UnsupervisedLearningOTA;Python notebook;296.0;0;;
2020-03-26 13:44:53;Expedia Unsupervised Learning-Rishit Dagli About MeTwitter GitHub Medium;Apache 2.0;https://www.kaggle.com/rishitdagli/unsupervised-learning-workflow-working-with-huge;1.0;['tensorflow', 'sklearn'];['ai', 'nn', 'ml', 'rl'];['train', 'model', 'label', 'k-means', 'predict', 'unsupervised learning', 'supervised learning'];https://www.kaggle.com/c/expedia-personalized-sort;0.628;0.152;2020-12-12 19:25:53;Personalize Expedia Hotel Searches - ICDM 2013;['deep learning, clustering'];Unsupervised Learning Workflow,working with huge;Python notebook;731.0;2;;
2020-12-03 15:10:05;Predicting Tags for Questions in Stack Overflow;Apache 2.0;https://www.kaggle.com/canirudh/predicting-tags-for-questions-in-stack-overflow;1.0;['vocabulary', 'sklearn', 'nltk'];['ner', 'ai', 'rl', 'ml', 'nn', 'ann'];['filter', 'training data', 'regression', 'test data', 'train', 'model', 'supervised learning', 'gradient descent', 'loss', 'label', 'k-means', 'clustering', 'logistic regression', 'predict', 'unsupervised learning', 'classification'];https://www.kaggle.com/c/facebook-recruiting-iii-keyword-extraction;0.512;0.0;2020-12-12 19:26:25;Facebook Recruiting III - Keyword Extraction;[];Predicting Tags for Questions in Stack Overflow;Python notebook;118.0;0;;
2020-08-04 09:08:42;What is StackOverflowDescriptionStack Overflow is the largest, most trusted online community for developers to learn, share their programming knowledge, and build their careers. It is something which every programmer use one way or another. Each month, over 50 million developers come to Stack Overflow to learn, share their knowledge, and build their careers. It features questions and answers on a wide range of topics in computer programming. The website serves as a platform for users to ask and answer questions, and, through membership and active participation, to vote questions and answers up or down and edit questions and answers in a fashion similar to a wiki or Digg. As of April 2014 Stack Overflow has over 4,000,000 registered users, and it exceeded 10,000,000 questions in late August 2015. Based on the type of tags assigned to questions, the top eight most discussed topics on the site are: Java, JavaScript, C#, PHP, Android, jQuery, Python and HTML. https://stackoverflow.com/.Business ProblemThe problem says that we will be provided a bunch of questions. A question in Stack Overflow contains three segments Title, Description and Tags. By using the text in the title and description we should suggest the tags related to the subject of the question automatically. These tags are extremely important for the proper working of Stack Overflow.;Apache 2.0;https://www.kaggle.com/koredla25/predicting-tags-for-the-questions-in-satckoverflow;1.0;['sklearn', 'nltk'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'regression', 'training data', 'train', 'fitting', 'model', 'test data', 'random forest', 'support vector machines', 'loss', 'label', 'logistic regression', 'gradient boosting', 'predict', 'decision tree', 'classification'];https://www.kaggle.com/c/facebook-recruiting-iii-keyword-extraction;0.581;0.152;2020-12-12 19:26:25;Facebook Recruiting III - Keyword Extraction;[];Predicting Tags For the Questions in SatckOverflow;Python notebook;327.0;2;;
2020-07-08 18:06:26;Problem Statemtent Suggest the tags based on the content that was there in the question posted on Stackoverflow.;Apache 2.0;https://www.kaggle.com/rajat2341/stackoverflow-tag-prediction;1.0;['pattern', 'sklearn', 'nltk'];['ner', 'ai', 'cv', 'rl', 'ml', 'nn', 'ann'];['machine learning', 'test data', 'regression', 'train', 'model', 'loss', 'label', 'logistic regression', 'predict', 'classification'];https://www.kaggle.com/c/facebook-recruiting-iii-keyword-extraction;0.523;0.0;2020-12-12 19:26:25;multiple data sources;[];StackOverflow Tag Prediction;Python notebook;138.0;0;;
2020-10-13 16:12:30;StackOverFlow Tags PredictionAim : Predict the tags (a.k.a. keywords, topics, summaries), given only the question text and its title About Data :  Train data   size = nearly 6.2GB   Columns= ID,Title,Body,Tags   Duplicates= Yes   Null values = No   Num_rows= Nearly 6.1 Million Rows with Duplicates    Body contains HTML Tags, Code sniffets, urls etc..   Title Contains html Tags..  Test Data  contains the same columns but without the Tags, which you are to predict.;Apache 2.0;https://www.kaggle.com/sai24kumar/stackoverflow-tag-prediction-modified-version;1.0;['pattern', 'sklearn', 'nltk'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['filter', 'training data', 'regression', 'test data', 'train', 'model', 'validation data', 'loss', 'label', 'logistic regression', 'predict', 'classification', 'naive bayes'];https://www.kaggle.com/c/facebook-recruiting-iii-keyword-extraction;0.483;0.0;2020-12-12 19:26:25;Facebook Recruiting III - Keyword Extraction;['beginner, exploratory data analysis, classification, +1 moremultilabel classification'];Stackoverflow tag Prediction Modified version;Python notebook;80.0;0;;
2020-10-24 13:59:21;Notebook - Table of Content Importing necessary libraries  Loading data  Data preprocessing  3.1 Checking for duplicates Basic Data Analysis on Tags  4.1 Frequency of tag_count  4.2 Total number of unique tags  4.3 Frequency of each tag  Word map for most frequent Tags  Text preprocessing  Machine learning models  7.1 Multilabel problem - Handling tags  7.2 Splitting into train and test set with 80:20 ratio  7.3 Featurization of Training Data  7.4 Fitting Logistic Regression with OneVsRest Classifier  7.5 Modelling by assigning more weightage to Title;Apache 2.0;https://www.kaggle.com/vikashrajluhaniwal/multi-label-classification-for-tag-predictions;1.0;['sklearn', 'nltk'];['ner', 'ai', 'dl', 'rl', 'nn', 'ann'];['filter', 'machine learning', 'regression', 'training data', 'train', 'fitting', 'model', 'test data', 'loss', 'label', 'logistic regression', 'predict', 'classification'];https://www.kaggle.com/c/facebook-recruiting-iii-keyword-extraction;0.73;0.4;2020-12-12 19:26:25;Facebook Recruiting III - Keyword Extraction;['beginner, exploratory data analysis, feature engineering, +2 morelogistic regression, multiclass classification'];Multi-label classification for Tag predictions;Python notebook;6180.0;29;;
2016-05-16 22:07:06;Is there any structure to the timestamp data?;Apache 2.0;https://www.kaggle.com/andersonk/timestamps-structure;1.0;['pattern'];['ai', 'ml', 'rl'];['train', 'label', 'training data'];https://www.kaggle.com/c/facebook-v-predicting-check-ins;0.752;0.44;2020-12-12 19:33:25;Facebook V: Predicting Check Ins;[];Timestamp structure;Python notebook;10760.0;47;;
2020-10-19 18:49:50;Social network Graph Link Prediction - Facebook Challenge;Apache 2.0;https://www.kaggle.com/genialgokul1099/social-network-graph-link-prediction;1.0;['xgboost', 'sklearn'];['ner', 'ai', 'cv', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'training data', 'generation', 'train', 'test data', 'model', 'supervised learning', 'clustering', 'loss', 'label', 'predict', 'rank', 'recommend', 'classification'];https://www.kaggle.com/c/FacebookRecruiting;0.559;0.0;2020-12-12 19:33:39;Facebook Recruiting Competition;[];notebookd3f8a80ae2;Python notebook;232.0;0;;
2020-12-01 05:15:48;This kernel experiments with various data augmentation techniques for facial keypoint detection.;Apache 2.0;https://www.kaggle.com/balraj98/data-augmentation-for-facial-keypoint-detection;1.0;['tensorflow', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ml'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/facial-keypoints-detection;0.707;0.423;2020-12-12 19:34:30;multiple data sources;['gpu, beginner, deep learning'];Data Augmentation for Facial Keypoint Detection;Python notebook;3582.0;38;1.96230;2.10521
2018-10-17 06:31:10;Examen Parcial:Para ejecutar el código: crear un kernel en la competencia de kaggle (https://www.kaggle.com/c/facial-keypoints-detection) y partir de este notebook. Una vez terminado, se debe descargar el notebook final y subirlo en paideia. Descripcion de la tareaEl objetivo de esta tarea es predecir las posiciones de los puntos clave en imágenes de rostros. Las imágenes de entrada son de 96x96 píxeles y en escala de grises (descritas con números enteros entre 0 y 255). Cada punto clave se especifica mediante un par de valores reales (x, y) en el espacio de los índices de píxeles. Hay 15 puntos clave, que representan los siguientes elementos de la cara: left_eye_center, right_eye_center, left_eye_inner_corner, left_eye_outer_corner, right_eye_inner_corner, right_eye_outer_corner, left_eyebrow_inner_end, left_eyebrow_outer_end, right_eyebrow_inner_end, right_eyebrow_outer_end, nose_tip, mouth_left_corner, mouth_right_corner, mouth_center_top_lip, mouth_center_bottom_lip   De modo que se debe entrenar una red neuronal que tome como input la imagen en escala de grises y de como output 30 números (las coordenadas x,y de los 15 puntos claves). Al compilar el modelo, especificar como función de pérdida el mean squared error (mse) y como métrica el mean absolute error (mae). Por ejemplo: model.compile(Adam(lr), loss='mse', metrics=['mae'])  Calificación Normalizar las imágenes (1 pt) Definir correctamente la red neuronal (4 pts) Entrenar la red neuronal (2 pts) mae entre 10 y 15 (3 pts) mae entre 8 y 11 (5 pts) mae entre 5 y 8 (7 pts) mae menor o igual a 4.0 (9 pts)   Mostrar 5 resultados aleatorios del set de validación (1 pt) Mostrar las 5 mejores predicciones del set de validación (1 pt) Mostrar las 5 peores predicciones del set de validación (1 pt)  RecomendacionesActivar el uso de GPU en el kernel de kaggle. Dentro del kernel de kaggle, los botones para bajar y subir kernels, se encuentran en la parte superior de la pagina, a la izquierda del boton commit.;Apache 2.0;https://www.kaggle.com/datawanderer/mixing-cnn-regularization-d;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'nn', 'rl'];['neuron', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'rank', 'relu'];https://www.kaggle.com/c/facial-keypoints-detection;0.661;0.236;2020-12-12 19:34:30;Facial Keypoints Detection;['gpu'];Mixing CNN+Regularization :D;Python notebook;1355.0;5;;
2020-07-25 20:51:29;Facial Keypoint DetectionDetect the location of keypoints on face images.;Apache 2.0;https://www.kaggle.com/denisart/facial-keypoint-detection;1.0;['pytorch', 'sklearn'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['predict', 'test data', 'train', 'model', 'output layer', 'epoch', 'validation data', 'layer', 'loss', 'resnet'];https://www.kaggle.com/c/facial-keypoints-detection;0.528;0.214;2020-12-12 19:34:30;Facial Keypoints Detection;['gpu'];Facial Keypoint Detection;Python notebook;148.0;4;2.20799;2.35690
2019-11-04 18:44:24;Multi-Stage Heatmap RegressionHello everyone! In this notebook I will be sharing with you guys what I learned in keypoint detection using neural networks. I am currently doing some research into the human pose estimation problem and thought it would be fun to use what I learned on this simple dataset. The challenge presented with this dataset is to figure out the Cartesian (x,y) coordinates of keypoints in facial images. Some of these keypoints include: left_eye_center, right_eye_center, etc... The simplest approach with deep learning is to try and directly map image input to Cartesian coordinates output. This idea was first introduced by Toshev et al. in his scientific paper about the DeepPose network. However, people have speculated that the direct mapping from image to Cartesian coordinates is really complex and hence any model with sufficient accuracy will also be likely to overfit and not generalize well to new data. Introduce heatmap regression, in which the problem gets slightly changed. Instead of predicting Cartesian coordinates, we will be building a deep net to predict a different heatmap for every keypoint we want to find. A heatmap is simply just a picture that shows the likelyhood of a specific keypoint residing at that pixel. Please follow along this notebook to learn more!;Apache 2.0;https://www.kaggle.com/fmak95/facial-keypoint-detection;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cv', 'rl', 'nn', 'ann'];['filter', 'machine learning', 'regression', 'generation', 'train', 'model', 'neural network', 'epoch', 'deep learning', 'layer', 'loss', 'label', 'predict', 'relu', 'ground truth'];https://www.kaggle.com/c/facial-keypoints-detection;0.676;0.268;2020-12-12 19:34:30;Facial Keypoints Detection;['gpu, beginner, deep learning, +1 moreregression'];Facial_Keypoint_Detection;Python notebook;1845.0;7;;
2019-06-29 23:52:22;Facial Keypoint Detection  First of all let's discuss what we are given. We are given three CSV files. training.csv :- Its has coordinates of facial keypoints like left eye, rigth eye etc and also the image. test.csv :- Its has image only and we have to give coordinates of various facial keypoints by looking at third csv file which is IdLookupTable.csv Rest everything is explained below. I would really appreciate if you could upvote this kernel.;Apache 2.0;https://www.kaggle.com/karanjakhar/facial-keypoint-detection;1.0;['tensorflow', 'keras'];['dl', 'ner', 'ai', 'nn'];['training data', 'test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/facial-keypoints-detection;0.787;0.554;2020-12-12 19:34:30;Facial Keypoints Detection;['gpu, beginner, deep learning'];Facial Keypoint Detection ;Python notebook;29985.0;216;2.93728;3.12946
2020-07-15 18:59:15;Facial Keypoint Detection  First of all let's discuss what we are given. We are given three CSV files. training.csv :- Its has coordinates of facial keypoints like left eye, rigth eye etc and also the image. test.csv :- Its has image only and we have to give coordinates of various facial keypoints by looking at third csv file which is IdLookupTable.csv Rest everything is explained below.**;Apache 2.0;https://www.kaggle.com/mirmahathirmohammad/kaggle-facial-keypoint-detection;1.0;['tensorflow', 'keras'];['dl', 'ner', 'ai', 'nn'];['training data', 'test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/facial-keypoints-detection;0.523;0.214;2020-12-12 19:34:30;Facial Keypoints Detection;[];Kaggle Facial Keypoint Detection ;Python notebook;139.0;4;;
2019-04-13 19:59:39;Overfitting if: training loss << validation loss Underfitting if: training loss >> validation loss or Underfitting – Validation and training error high Good fit if training loss ~ validation loss(Validation error low, slightly higher than the training error);Apache 2.0;https://www.kaggle.com/negi009/facial-keypoint-detection;1.0;['tensorflow', 'sklearn', 'keras'];['dl', 'ner', 'ai', 'nn'];['filter', 'train', 'fitting', 'model', 'input layer', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/facial-keypoints-detection;0.654;0.214;2020-12-12 19:34:30;Facial Keypoints Detection;['gpu, cnn, neural networks'];facial_keypoint_detection;Python notebook;1171.0;4;2.54191;2.76761
2020-03-14 18:04:42;In this kernel we will use the dataset in a special way to get better performance and lower loss without any data augmentation.  I have read in one of the forums that the dataset is actually collected by merging 2 datasets together, the first one contains 7000+ samples with 8 features (4 keypoints) for each image, the second one contains 2000+ images that actually belongs to the first dataset but with 30 features (15 keypoints).  Now the question is, how to handle this sneaky dataset to get better results and lower loss (without data augmentation).  you can try 3 approaches for this one:  Drop any sample that doesn't contain the full 15 key points, in this approach you simply ignore the first dataset, you will get an even smaller dataset with 2140 samples, eventually after training and submitting, you will get almost 3.0 loss.  Fill any missing point with the previous available one, in this approach you will end up with 7000+ samples, but most of the features are filled and not accurate, surprisingly this approach will get almost 2.4 loss which is better than the first one, a reasonable explanation for this result is providing the model with 5000 more samples with 4 accurate keypoints and 11 inaccurate filled keypoints lower the loss a bit.  Enhance the 1st approach by using the ignored dataset (1st dataset) to train a separate model to predict only 4 key points. Why would we do that?, Obviously this model (four-keypoints model) will produce more accurate predictions for those specific key points as the training set contains 7000 samples with accurate labels rather than only 2000 samples (notice that those 4 keypoints are just subset of the 15 keypoints). In this case, we have 2 models, fifteen-keypoints model which produces 30-dim vector for each sample, and four_keypoints model 8-dim vector for each sample (which produces more accurate values for certain four key points), then you should replace the predictions of the four-keypoints model with the corresponding predictions of the fifteen-keypoints model. This approach will lower loss to almost 2.1, this simply because we got more accurate predictions for 8 features.    I think with alittle bit of data augmentation after splitting the dataset you can get more decent loss, also i encourage you to take a look at Ole Gee's solution which got 1.28 loss and achieved the 1st place.  The code is simple, concise and fully-commented. Feel free to ask for help or more info or more explanation in the comments, i will be more than happy to help.  Finally if this kernel helps you somehow, kindly don't forget to leave a little upvote up there.  Hope you enjoy.;Apache 2.0;https://www.kaggle.com/phylake1337/2-15-loss-simple-split-trick;1.0;['tensorflow', 'keras'];['ner', 'ai', 'dl', 'rl', 'nn'];['filter', 'test data', 'train', 'model', 'output layer', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/facial-keypoints-detection;0.613;0.268;2020-12-12 19:34:30;Facial Keypoints Detection;['gpu, beginner'];2.15 Loss - Simple Split Trick;Python notebook;563.0;7;;
2017-11-12 18:31:57;In this tutorial, we'll try to forecast transactions data and poke around open source Prophet library released by Facebook. We'll learn  how to integrate holiday periods and optimize the model by playing parameters. Prophet is a procedure for forecasting time series data. It is based on an additive model where non-linear trends are fit with yearly and weekly seasonality, plus holidays. It works best with daily periodicity data with at least one year of historical data. Prophet is robust to missing data, shifts in the trend, and large outliers. You can learn more about from the docs. Let's start loading libraries and data.;Apache 2.0;https://www.kaggle.com/armamut/predicting-transactions-fb-prophet-tutorial;1.0;['sklearn'];['ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['model', 'regression', 'predict'];https://www.kaggle.com/c/favorita-grocery-sales-forecasting;0.776;0.435;2020-12-12 19:41:27;Corporación Favorita Grocery Sales Forecasting;[];Predicting Transactions - FB Prophet Tutorial;Python notebook;21255.0;44;;
2017-12-26 18:43:50;"IntroductionThis competition is hosted by a large grocery company in Ecuador called ""Corporacion Favorita"" where the aim of the game is to accurately predict and forecast the unit sales for items sold at various Favorita supermarket chains across Ecuador. Apart from the usual training and test data files provided, there are also quite a handful of other supplementary data files (5 extra files to be exact) provided to us. This notebook aims to take a deep-dive analysis into each of the files provided in this competition and to investigate what types of insights or observations can be derived from each. The structure of this analysis is as follows: 1. Data loading and inspection - Loading the data as Python dataframes and conducting data quality checks 2. Supplementary Data exploration - Exploration of all 5 supplementary files with a mix of D3.js visualizations and stacked barplots 3. Training data exploration  4. Feature ranking with learning models - Training a";Apache 2.0;https://www.kaggle.com/arthurtok/comprehensive-python-and-d3-js-favorita-analytics;1.0;['pattern'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['filter', 'training data', 'test data', 'train', 'model', 'layer', 'clustering', 'label', 'predict', 'rank', 'propagation'];https://www.kaggle.com/c/favorita-grocery-sales-forecasting;0.787;0.552;2020-12-12 19:41:27;Corporación Favorita Grocery Sales Forecasting;[];Comprehensive Python and D3.js Favorita analytics;Python notebook;29804.0;210;;
2017-11-25 09:03:38;Memory optimizationSince train.csv has 125 mil records, it is best to consider performing some data engineering before starting any analysis. Note: This kernal was inspired by Jeru666's kernel for the KKBox churn challenge.  If you like this kernel, do checkout his work using the link here -> https://www.kaggle.com/jeru666/memory-reduction-and-data-insights Also a similar kernal that I've written for KKBox churn challenge. https://www.kaggle.com/jagangupta/processing-huge-datasets-user-log;Apache 2.0;https://www.kaggle.com/jagangupta/memory-optimization-and-eda-on-entire-dataset;1.0;['pattern'];['ai', 'ml', 'gan'];['train', 'label', 'test data', 'layer'];https://www.kaggle.com/c/favorita-grocery-sales-forecasting;0.756;0.478;2020-12-12 19:41:27;Corporación Favorita Grocery Sales Forecasting;['beginner, data visualization, exploratory data analysis'];Memory optimization and EDA on entire dataset;Python notebook;12122.0;75;;
2018-09-22 13:49:40;Flavors of Physics This is a problem that is not easy to understand for someone who is not into Quantum Physics. Though a bit intriguing, the problem seems to be very interesting. In simple terms, as I could undertand, the scientists are trying to observe the decay of tau to three muons - a phenomenon that is very rare.  The null hypothesis is that this decay does not happen and the idea here is to see that the decay happens more than what is currently known. The dataset consists of real and simulated events. Real events (or Background events or those with Signal value = 0) and Simulated Events (or Signal Events or those with Signal value = 1) are part of the dataset. The analysis is to be done on the entire dataset to classify the data based on various attributes. Before the algorithm is evaluated (based on AUC metric), the algorithm needs to pass through Agreement Test and Correlation Test. The code for these tests is provided along with the dataset.;Apache 2.0;https://www.kaggle.com/achal71/cern-simple-classification-models;1.0;['xgboost', 'sklearn'];['ner', 'ai', 'cv', 'rl', 'nn', 'ann'];['training data', 'test data', 'train', 'fitting', 'model', 'loss', 'label', 'gradient boosting', 'predict', 'rank', 'recommend', 'random forest', 'labeled'];https://www.kaggle.com/c/flavours-of-physics-kernels-only;0.622;0.214;2020-12-12 19:55:11;Flavours of Physics: Finding τ  →  μμμ (Kernels Only);['beginner, classification'];CERN Simple Classification Models;Python notebook;660.0;4;0.97547;0.97255
2018-08-23 13:48:42;Based on UGBC GS and the Coursera course  Addressing Large Hadron Collider Challenges by Machine Learning ...and whatever else I borrow from other kernels;Apache 2.0;https://www.kaggle.com/mik3hall/tau-notebook;1.0;['sklearn'];['ner', 'ai', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'train', 'model', 'loss', 'label', 'predict', 'rank', 'understanding', 'random forest', 'labeled'];https://www.kaggle.com/c/flavours-of-physics-kernels-only;0.654;0.188;2020-12-12 19:55:11;Flavours of Physics: Finding τ  →  μμμ (Kernels Only);[];Tau notebook;Python notebook;1180.0;3;;
2018-06-27 05:54:14;Full disclosure: I am actually a particle physicist, although I've never worked much with collider experiments. In this challenge, we are tasked with predicting whether or not a given reconstructed event in a particle physics experiment is from a τ→μ+μ−μ− decay. Tau leptons are basically like very heavy electrons, with a mass of 1.78 GeV rather than 511 keV. These are still quite light by the standards of proton colliders. The top quark, which is the heaviest known elementary particle, has a mass about 100 times higher. The LHC was built so that it would be able to create TeV-scale particles such as supersymmetric partners to regular Standard Model particles. Taus are unstable and decay with a lifetime of 3×10−13 s, or 300 femtoseconds. Due to conservation of lepton number, taus are created in τ+τ− pairs or in conjunction with neutrinos. In a facility like the LHC, this means that the taus will typically have a large amount of kinetic energy in the lab frame. The apparent lifetime in the lab frame is boosted from τ=300~fs to γτ, where γ is a relativistic factor equal to the ratio between the total energy in the lab frame and the rest mass. So, if γ=10 (that is, the τ has a total energy 17.8 GeV), it will have a lifetime of 3 picoseconds. Since the tau will be going nearly the speed of light, it will travel on average around 1 mm from the initial vertex before decaying. If you can reconstruct the separation between the tau decay and the vertex (at least in the transverse dimension), this will let you do things like compare the estimated γ of the tau (based on muon kinematics) to the distance traveled. This will give you some ability to at least start to select tau-like events.;Apache 2.0;https://www.kaggle.com/muonneutrino/lightgbm-starter-some-data-exploration;1.0;['lightgbm'];['ner', 'ai', 'gbm', 'cv', 'rl', 'ml', 'nn', 'ann'];['train', 'model', 'label', 'predict'];https://www.kaggle.com/c/flavours-of-physics-kernels-only;0.685;0.393;2020-12-12 19:55:11;Flavours of Physics: Finding τ  →  μμμ (Kernels Only);[];LightGBM Starter & Some Data Exploration;Python notebook;2200.0;27;0.96468;0.96250
2019-10-06 09:42:57;"**Yapacağınız yorumlar için şimdiden teşekkür ederim. Çalışmayı beğenirseniz oylamayı unutmayın ^___^! Sorulara elimden geldiği kadarıyla cevap vermeye çalışacağım. Çalışmada; sorulara ve geri bildirimlere göre düzeltme ve ekleme yapacağım.**  **Yapacağınız yorumlar; çalışmanın daha iyi ve anlaşılır olmasını sağlayacaktır.**";Apache 2.0;https://www.kaggle.com/serkanpeldek/arp-mada-r-me-oldu-mu-3;1.0;['sklearn'];['ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['filter', 'train', 'model', 'loss', 'label', 'predict', 'classification'];https://www.kaggle.com/c/flavours-of-physics-kernels-only;0.641;0.383;2020-12-12 19:55:11;Flavours of Physics: Finding τ  →  μμμ (Kernels Only);['data visualization, feature engineering, binary classification, +1 morephysics'];Çarpışmada Çürüme Oldu mu? τ → 3μ ?;Python notebook;917.0;24;;
2020-02-20 17:31:06;"Special Thanks To @dlibenzi (github) for all his help;";Apache 2.0;https://www.kaggle.com/adityaecdrid/quest-to-use-use-pytorch-xla;1.0;['pytorch', 'tensorflow', 'spacy', 'pillow'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nlp', 'nn', 'ann'];['generation', 'train', 'model', 'epoch', 'layer', 'label', 'classification', 'labeled'];https://www.kaggle.com/c/flower-classification-with-tpus;0.671;0.375;2020-12-12 19:56:26;Flower Classification with TPUs;['tpu'];Quest To Use Use PyTorch-XLA?;Python notebook;1639.0;22;;
2020-06-19 03:16:11;CutMix and MixUp Augmentation using GPU/TPUThis notebook shows how perform cutmix and mixup data augmentation using the GPU/TPU with TensorFlow.data.Dataset. In our previous notebook here, we demonstrated how to perform rotation, shear, zoom, and shift on GPU/TPU. Performing preprocess on GPU/TPU speeds up our training pipeline and allows us to experiment with more ideas quicker. Libraries like Nvidia DALI here help with GPU image preprocess and/or Nvidia RAPIDS here helps with GPU tabular preprocess. CutMix described here MixUp described here;Apache 2.0;https://www.kaggle.com/cdeotte/cutmix-and-mixup-on-gpu-tpu;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['unlabeled', 'training data', 'test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'labeled'];https://www.kaggle.com/c/flower-classification-with-tpus;0.746;0.531;2020-12-12 19:56:26;multiple data sources;['tpu'];CutMix and MixUp on GPU/TPU;Python notebook;9385.0;155;;
2020-06-19 03:13:16;Data Augmentation using GPU/TPU for Maximum Speed!This notebook shows how perform rotation, shear, zoom, and shift data augmentation for the GPU/TPU with TensorFlow.data.Dataset. Data augmentation is a technique to increase model accuracy and using GPU/TPU achieves this goal quicker.  GPUs and TPUs can consume 200 or more images sized 512x512x3 in one second (while training DenseNet201)! That's incredible. If we perform data augmentation beforehand, we need to make sure we are preparing at least 200 images per second. Otherwise we will slow down our GPU/TPU training. This is the advantage of tensorflow.data.Dataset. After writing augmentation in TensorFlow language, your program will optimize these operations for GPU/TPU. Similarily, you can use libraries like Nvidia DALI here for GPU image preprocess and/or Nvidia RAPIDS here for GPU tabular preprocess.;Apache 2.0;https://www.kaggle.com/cdeotte/rotation-augmentation-gpu-tpu-0-96;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['unlabeled', 'training data', 'test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'labeled'];https://www.kaggle.com/c/flower-classification-with-tpus;0.768;0.572;2020-12-12 19:56:26;multiple data sources;['gpu, tpu'];Rotation Augmentation GPU/TPU - [0.96+];Python notebook;16838.0;285;;
2020-03-04 07:50:40;Version 2: disable unfreezing for speed;Apache 2.0;https://www.kaggle.com/dhananjay3/fast-pytorch-xla-for-tpu-with-multiprocessing;1.0;['pytorch', 'tensorflow', 'spacy', 'pillow'];['ai', 'rl', 'cv', 'nlp', 'nn'];['filter', 'train', 'model', 'epoch', 'layer', 'loss', 'rank', 'relu'];https://www.kaggle.com/c/flower-classification-with-tpus;0.701;0.431;2020-12-12 19:56:26;multiple data sources;['tpu'];Fast Pytorch/XLA for TPU with multiprocessing;Python notebook;3122.0;42;;
2020-03-05 04:25:54;Using all 8 cores of a v3 TPU using pytorch/XLA;Apache 2.0;https://www.kaggle.com/dhananjay3/pytorch-xla-for-tpu-with-multiprocessing;1.0;['pytorch', 'tensorflow', 'spacy', 'pillow'];['ai', 'rl', 'cv', 'nlp', 'nn'];['filter', 'train', 'model', 'epoch', 'layer', 'loss', 'rank', 'relu'];https://www.kaggle.com/c/flower-classification-with-tpus;0.691;0.397;2020-12-12 19:56:26;multiple data sources;['tpu'];Pytorch/XLA for TPU with multiprocessing;Python notebook;2507.0;28;;
2020-06-24 02:34:39;This notebooks shows three ways of training a model on TPU:  Using Keras and model.fit() Using a custom training loop Using a custom training loop specifically optimized for TPU  Optimization that benefit all three models:  use dataset.batch(BATCH_SIZE, drop_remainder=True)  The training dataset is infinitely repeated so drop_remainder=True should not be needed. However, whith the setting, Tensorflow produces batches of a known size and although XLA (the TPU compiler) can now handle variable batches, it is slightly faster on fixed batches.  On the validation dataset, this setting can drop some validation images. It is not the case here because the validation dataset happens to contain an integral number of batches.  Optimizations specific to the TPU-optimized custom training loop:  The training and validation step functions run multiple batches at once. This is achieved by placing a loop using tf.range() in the step function. The loop will be compiled to (thanks to @tf.function) and executed on TPU. The validation dataset is made to repeat indefinitely because handling end-of-dataset exception in a TPU loop implemented with tf.range() is not yet possible. Validation is adjusted to always use exactly or more than the entire validation dataset. This could change numerics. It happens that in this example, the validation dataset is used exactly once per validation. The validation dataset iterator is not reset between validation runs. Since the iterator is passed into the step function which is then compiled for TPU (thanks to @tf.function), passing a fresh iterator for every validation run would trigger a fresh recompilation. With a validation at the end of every epoch this would be slow. Losses are reported through Keras metrics. It is possible to return values from step function and return losses in that way. However, in the optimized version of the custom training loop, using tf.range(), aggregating losses returned from multiple batches becomes impractical.;Apache 2.0;https://www.kaggle.com/mgornergoogle/custom-training-loop-with-100-flowers-on-tpu;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['unlabeled', 'machine learning', 'training data', 'test data', 'train', 'model', 'epoch', 'validation data', 'layer', 'loss', 'label', 'predict', 'recommend', 'labeled'];https://www.kaggle.com/c/flower-classification-with-tpus;0.708;0.452;2020-12-12 19:56:26;Flower Classification with TPUs;['tpu'];Custom Training Loop with 100+ flowers on TPU;Python notebook;3660.0;54;;
2020-02-12 13:29:57;This Kernel was built on top of this Kernel. Thanks to the author of the kernel If you find this kernel helpful please consider upvoting. Also dont forget to upvote the original kernel.;Apache 2.0;https://www.kaggle.com/mmmarchetti/flowers-on-tpu-ii;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['unlabeled', 'training data', 'test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'labeled'];https://www.kaggle.com/c/flower-classification-with-tpus;0.705;0.416;2020-12-12 19:56:26;Flower Classification with TPUs;['tpu'];Flowers on TPU II;Python notebook;3416.0;35;0.96222;0.96322
2020-02-21 02:16:10;AboutThis kernel is based on this kernel. Experiments: Increased the score:  The LR schedule defined in this kernel from the TPU Documentation. Skip validation and add the validation dataset to the training dataset.  Lowered the score:  Reducing image size to 224x224 from 512x512;Apache 2.0;https://www.kaggle.com/msheriey/flowers-on-tpu-ensemble-lr-schedule;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['unlabeled', 'training data', 'test data', 'train', 'model', 'epoch', 'validation data', 'layer', 'loss', 'label', 'predict', 'labeled'];https://www.kaggle.com/c/flower-classification-with-tpus;0.699;0.44;2020-12-12 19:56:26;Flower Classification with TPUs;['beginner, deep learning, classification, +1 morecnn'];Flowers on TPU: Ensemble + LR schedule;Python notebook;3004.0;47;0.96325;0.96295
2020-03-06 23:55:25;A Simple TF 2.1 notebookThis is based entirely off of Martin Gorner's excellent starter notebook, and is intended solely as a simple, shorter introduction to the operations being performed there.;Apache 2.0;https://www.kaggle.com/philculliton/a-simple-tf-2-1-notebook;1.0;['tensorflow', 'keras'];['ner', 'ai', 'dl', 'rl', 'nn', 'ann'];['unlabeled', 'training data', 'test data', 'train', 'model', 'epoch', 'layer', 'vgg', 'loss', 'label', 'predict', 'labeled'];https://www.kaggle.com/c/flower-classification-with-tpus;0.723;0.45;2020-12-12 19:56:26;Flower Classification with TPUs;['tpu'];A Simple TF 2.1 notebook;Python notebook;5165.0;53;;
2020-02-16 06:10:42;"About this kernelPretty much a fork of the very comprehensive starter kernel. I didn't add much, remove a whole bunch (please check out the official kernel for more info), hide some big scary functions. I mostly just hooked the largest efficientnet laying around and ran it for a couple 'pochs. Please consume this with moderation (only 30h per week!). PS: This notebook costs ~8$ to run ;)";Apache 2.0;https://www.kaggle.com/ratan123/densenet201-flower-classification-with-tpus;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['unlabeled', 'training data', 'test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'resnet', 'labeled'];https://www.kaggle.com/c/flower-classification-with-tpus;0.71;0.494;2020-12-12 19:56:26;Flower Classification with TPUs;['beginner, deep learning, classification, +1 moreutility script'];DenseNet201 : Flower Classification with TPUs;Python notebook;3845.0;93;0.95621;0.95554
2020-05-18 17:58:33;About this kernel, about this competitionIntroThis competition will be over in about 2 days and it has been my first Kaggle competition. I am rather a beginner in ML and I want to thank Kaggle for this great opportunity  to learn about tensorflow, classification and tpu's. I started with a public ensemble kernel from Wojtek Rosa and tried a lot of basic hyperparameter tuning. As new discussion entries appeared I could learn a lot about augmentation techniques, under/oversampling, optimizers and other stuff. Kudos to the nice people, that fed the community with their knowlege. I will mention the most important contributions in the later sections. 0) TPU stuffTPUs are impressive and @mgoernergoogle made it easy to understand the basic code, which is necessary to start with tpus. https://www.kaggle.com/mgornergoogle/getting-started-with-100-flowers-on-tpu Later he provided a kernel which implemented a custom training loop, that could speed up learning up to 20%. Unfortunately tensorflow 2.1 showed up to be unstable when training 512x512 sized images - this should be fixed in tf 2.2, which has been released 3 days ago. but did not find the way into the Kaggle environment as I write this. https://www.kaggle.com/mgornergoogle/custom-training-loop-with-100-flowers-on-tpu 1) DatasetsWhat could be found in the the beginning was an unbalanced dataset of flowers with 104 classes, which has been nicely assembled from 5 public flower datasets by Martin Goerner. As the competition went on, people incorporated one or more of these public datasets in their training, published them later and it showed that using those datasets could greatly improve LB scores. Thanks to Heng CherKeng, Kirill Blinov and all the others for their contributions. https://www.kaggle.com/c/flower-classification-with-tpus/discussion/140866 https://www.kaggle.com/kirillblinov/tf-flower-photo-tfrec In the last days there has even been a little discussion whether these datasets are allowed to be used. https://www.kaggle.com/c/flower-classification-with-tpus/discussion/148329 2) AugmentationsChris Deotte contributed greatly to this topic, providing notebooks that showed us an implementation Gridmask, CutMix and MixUp augmentations along with his spatial affine transformations. I tried them all and found it very interesting and also introduced me to learn about label smoothing (another technique to handle unbalanced datasets with one-hot encoded class labels). https://www.kaggle.com/cdeotte/rotation-augmentation-gpu-tpu-0-96 https://www.kaggle.com/cdeotte/cutmix-and-mixup-on-gpu-tpu https://www.kaggle.com/yihdarshieh/make-chris-deotte-s-data-augmentation-faster https://www.kaggle.com/yihdarshieh/batch-implementation-of-more-data-augmentations https://www.kaggle.com/xiejialun/gridmask-data-augmentation-with-tensorflow Thanks to Michał Szachniewicz who implemented AugMix to run under tensorflow 2.x. A pitty that the experiments did not produce nice results. https://www.kaggle.com/szacho/augmix-data-augmentation-on-tpu I found it interesting, how good the rather simple cutout augmentation worked - see the random_blockout() function from a competitor below. I also stumbled about AutoAug, a technique used by Google researchers and in AutoML for classification and now even for object detection, to find the best fitting augmentation parameters for a given dataset. AutoAug can be found in the tensorflow repository on github, but is implemented in tensorflow 1.x and I did not have the time to invest in that. 3) Models and Techniques3.1 ModelsState of the art is the usage of the Effcientnet set of models. Theses models are trained on imagenet and noisy-student - both variations of the weights are available in the Keras version on github. Some people combined one or two Efficientnet model with other models in an ensemble, like it is done in this kernel. Wojtek Rosa provided this starter kernel: https://www.kaggle.com/wrrosa/tpu-enet-b7-densenet 3.2 OptimizersThere is a lot of research going on in this field and computer scientists are proposing a lot of new optimizers these days. I started with Adam and did some experiments, especially with the so called Ranger optimizer (a combination of RectifiedAdam and Lookahead - they can be found in the tensorflow addons library). All in all I did not find success using these, maybe because they converge slower and there is limited training time in this competition -  so I went back to plain Adam. 3.3 Learning Rate and other parametersWhen one is finetuning a model (train all weights of a pretrained model) one should implement a rampup phase for some epochs with a lower learning rate, so one doesn't break the pretrained features. The starter notebook provides a LearningRateScheduler with exponential decay. An alternative would be the usage of a cosine decaying learning rate, which I implemented below in this notebook. I did not try cyclic learning rates, which would have been interesting as well. Btw. - the ranger optimizer likes high flat learning rates in the beginning and cosine annealing. On TPU the initial batch size could be doubled with 512x512 sized images, which really was a big improvement (16  strategy.num_replicas_in_sync  2) I could get a bit better results multiplying the proposed learning rate schedule from the starter kernel by 1.2  3.4 Class WeightsClass weights are a method where one can tell the optimizer to underweight the influence of overrepresented classes. A short piece of code in shown below, but I did not use it at last, because it showed, that the losses are getting smaller more slowly. Maybe more epochs would show that this method leads to a good model, but in this competition we are restricted to a runtime of 3 hours and this is not effective. Further there is doubt whether class weights do work at all in tf2.1 on tpu. 3.5 Oversampling/UndersamplingFor an unbalanced dataset people have found success in training with data, where one filters out examples of the overpresented classes or one extends the dataset with (modified) copies of the underrepresented examples. I did not get lucky with it in this competition. https://www.kaggle.com/yihdarshieh/tutorial-oversample 3.6 Progressive ResizingDuring the competition I read about progressive resizing (to train a model with a smaller image size first and then again with a larger image size) but then a notebook which implemented this using the fastai library, brought me back to this idea in the last days, so I implemented it in this kernel. https://www.kaggle.com/kurianbenoy/classifying-flowers-with-fastaiv2-0-96 3.7 Custom Training LoopAs mentioned above the custom training loop from https://www.kaggle.com/mgornergoogle/custom-training-loop-with-100-flowers-on-tpu can save about 20% training time. 3.8 KFoldsUsing KFolds is the idea of putting together training and validation data in one set and then splitting this set differently K-times, train K models and then aggregate the predictions of these K models. https://www.kaggle.com/ragnar123/4-kfold-densenet201 3.9 TTATTA (test time augmentations) is the idea to augment the test data several times and aggregate the predictions on these data. I did not find success with this, but many successful competitors use it. There is a nice notebook from Caleb about this technique: https://www.kaggle.com/calebeverett/comparison-of-tta-prediction-procedures 3.10 Pseudo labeling test dataI did not try, but well doing competitors probably do. Some time ago Chris Deotte provided a nice summary how it is done: https://www.kaggle.com/cdeotte/pseudo-labeling-qda-0-969 Using Mish activationsEfficientnet uses the relatively new swish activation function. In the last days I came across an alternative which seems to do better - mish() As exchanging activations functions in Keras on the fly seems to be difficult, I am not sure if I can try something in that direction in the next days. Final wordsMy best result so far (before the last weekend) has been training a 4 model ensemble for 13 epochs with the 512x512 size images with over 40000 images and no TTA (LB score 0.975) and I am rather sure that training for more epochs and using more training images would improve the score a lot. Probably one has to use 224x224 images, For the next weekend I tend to try smaller images sizes with more epochs and images for fun, because the usage of the external datasets is probably not allowed for the final LB run. Maybe some TTA experiments, if time allows. Update I am sorry, I cannot remember whos kernel I copied - but the 4 model one is working great - thx. Training the 4 model ensemble with all external training data pushed me to a LB score of 0.9837 with a training time of 2h20 - this should be a good base for further experiments :) Update Got an 0.984+ score with training 224x224 images. Update Could not test mish() - but training time seems to be 10% slower on EN models with my simple patch. Could not test TTA - I think I simply did it wrong. No way to climb the LB score without these :) Tried to run 48 epochs with a custom training loop, but it seems to use more then 3 hours.... what a pitty :) I really like to try these improvements next week... This notebook will serve as a summary of some of the knowledge I built up and should be able to reach a LB score of 0.967 with the base dataset in one way or another. One should try different models and run it with validation calculations to find the best alpha for ensembling and then submit it training on both (train and val) datasets. Thanks for the fish :)   (to everybody, who doesn't know this quote, pls google Douglas Adams);Apache 2.0;https://www.kaggle.com/romanweilguny/tpu-flowers-first-love;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'automl', 'rl', 'ml', 'nn', 'ann'];['unlabeled', 'filter', 'predict', 'relu', 'training data', 'object detection', 'train', 'epoch', 'activation function', 'recommend', 'classification', 'labeled', 'model', 'layer', 'loss', 'test data', 'fitting', 'validation data', 'label'];https://www.kaggle.com/c/flower-classification-with-tpus;0.641;0.4;2020-12-12 19:56:26;multiple data sources;[];TPU flowers -  First Love;Python notebook;920.0;29;;
2020-06-01 09:10:12;About this notebook....This notebook give the overview of how to perform cutmix, mixup, Gridmask and Cutout data augmentation. And analyse the performance of AUgmentation. Augmentation help to improve model performance, but it depend on various things, like what is the problem statement, Which Augmentation help to improve the performance, Ratio of Augmentation etc... If you find it helpful please upvote it. Thanks!;Apache 2.0;https://www.kaggle.com/saife245/cutmix-vs-mixup-vs-gridmask-vs-cutout;1.0;['tensorflow'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ann'];['unlabeled', 'image classification', 'training data', 'test data', 'train', 'fitting', 'model', 'generative adversarial network', 'neural network', 'epoch', 'label', 'predict', 'classification', 'labeled', 'convolutional neural network', 'ground truth'];https://www.kaggle.com/c/flower-classification-with-tpus;0.711;0.493;2020-12-12 19:56:26;multiple data sources;['data visualization, feature engineering, image data'];Cutmix vs Mixup vs Gridmask vs Cutout;Python notebook;3967.0;92;;
2020-04-14 14:22:25;ReadMeThis is my attempt to implement AugMix on TPU. In this notebook I implemented data augmentation part whichs seems to be working well.  However, AugMix performs better when used with special loss function (Jensen-Shannon Divergence Consistency Loss). While experimenting with custom implementation of this loss using optimized training loop from this notebook, I encountered significant memory issues what made it pretty useless for the competetition and thus I did not include this loss function. AugMix utilizes simple augmentation operations which are stochastically sampled and layered to produce a high diversity of augmented images.  Above image is from original paper. https://arxiv.org/pdf/1912.02781.pdf This is also my first contact with tensorflow (micro project), so if you spot any errors and mistakes, please report in the comments section.;Apache 2.0;https://www.kaggle.com/szacho/augmix-data-augmentation-on-tpu;1.0;['tensorflow', 'keras'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['unlabeled', 'filter', 'test data', 'train', 'layer', 'loss', 'label', 'predict', 'classification', 'labeled'];https://www.kaggle.com/c/flower-classification-with-tpus;0.68;0.383;2020-12-12 19:56:26;Flower Classification with TPUs;[];AugMix data augmentation on TPU;Python notebook;2003.0;24;;
2020-03-03 09:55:23;About this kernelV1: This one is just a blend of two kernels: https://www.kaggle.com/xhlulu/flowers-tpu-concise-efficientnet-b7 https://www.kaggle.com/ratan123/densenet201-flower-classification-with-tpus Core kernel: starter kernel. (0.95556) V2: added confusion matrix from starter kernel, epochs = 20 (0.95388) V3: Vote up original kernels and this one if you like my work :) (0.95083) V4: Custom LR schedule + adding validation data to training data (https://www.kaggle.com/msheriey/flowers-on-tpu-ensemble-lr-schedule) (0.96049) V5: Skip validation = False + finding best_alpha (0.95784) V6: Manually interrupted V7: Skip validation = True + best_alpha = 0.44 (0.96523) V8: Pushing the max LR up to 0.0001 * strategy.num_replicas_in_sync (0.96059) V9: max LR = 0.00003 * strategy.num_replicas_in_sync (0.95955) V10: max LR = 0.00006 * strategy.num_replicas_in_sync (0.96114) V11: LR_EXP_DECAY = .5 (from .8) (0.96256) V12: LR_EXP_DECAY = .9 (0.96056) V13: LR_RAMPUP_EPOCHS = 3 and LR_EXP_DECAY = .5 (0.96044) V14: Manually interrupted V15: LR_RAMPUP_EPOCHS = 5 and LR_EXP_DECAY = .7 (0.96309) V16: LR_EXP_DECAY = .75 (0.96129) V17: Back to LR_EXP_DECAY = .8 + Skip validation = False + exploring mismatches in a validation data (0.95931) V18: Exploring mismatches in a validation data pt 2 (with image ids) (0.95658) V19: Skip validation = True + prepare for subsetting data (0.96242) V20: Skip validation = True + filtering out mismatches from validation data (0.95948) V21: Rewriting function count_data_items() (0.96049) V22: Removing top 9 mismatches from validation data with display (0.96008) V23: Added rotation augmentation from: https://www.kaggle.com/cdeotte/rotation-augmentation-gpu-tpu-0-96 (0.96137) V24: Skip validation = False + EnetB7(weights = 'noisy-student') (0.95940) V25: Skip validation = True + best_alpha = 0.51 (0.96412) V26: Re-run - good Sunday! (0.96343) V27: Consuming TPU quota (...);Apache 2.0;https://www.kaggle.com/wrrosa/tpu-enet-b7-densenet;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['unlabeled', 'filter', 'training data', 'test data', 'train', 'fitting', 'model', 'epoch', 'validation data', 'layer', 'loss', 'label', 'predict', 'classification', 'labeled'];https://www.kaggle.com/c/flower-classification-with-tpus;0.759;0.5;2020-12-12 19:56:26;Flower Classification with TPUs;['tpu, deep learning, classification'];TPU: ENet B7 + DenseNet;Python notebook;13272.0;101;0.95525;0.96509
2020-03-10 16:37:38;"About this kernelPretty much a fork of the very comprehensive starter kernel. I didn't add much, remove a whole bunch (please check out the official kernel for more info), hide some big scary functions. I mostly just hooked the largest efficientnet laying around and ran it for a couple 'pochs. Please consume this with moderation (only 30h per week!). PS: This notebook costs ~8$ to run ;) Updates V9: Tried warmup by only training softmax layer for 5 epochs before unfreezing all weights. V10: More data augmentations V11: Use LR Scheduler, idea comes from here. V12: Use both training and validation data to train model. V14: Train longer (25 epochs). V15: Back to 20 epochs; Global Max Pooling instead of Average. V16: Roll back to Global Average Pooling V18: Roll back to V13";Apache 2.0;https://www.kaggle.com/xhlulu/flowers-tpu-concise-efficientnet-b7;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['unlabeled', 'training data', 'test data', 'train', 'model', 'epoch', 'validation data', 'layer', 'loss', 'label', 'predict', 'labeled'];https://www.kaggle.com/c/flower-classification-with-tpus;0.753;0.523;2020-12-12 19:56:26;Flower Classification with TPUs;['tpu, cnn'];Flowers TPU: Concise EfficientNet B7;Python notebook;11049.0;139;;
2020-02-29 06:30:32;GridMask data augmentationType of image data augmentation can be rougly divided in to 3 categories :  Spatial transformation (random-crop, flip, rotation...) Color distortion (random gamma, brightness, hue, contrast....) Information dropping (random cutout, random erasing, hide-and-seek..)  GridMask is belong to Information dropping method. Information dropping might help improving model generalization through enforcing model to learn on remain information. But keeping the deletion and reservation region in a balance relation is needed. Too much information dropping might result in under-fitting, but too few might result in over-fitting.  There are also some concerns in old information dropping methods. Since the region they dropped will be randomly. So the information might be totally gone after dropping, which make the data into noise. GridMask deletes the structured regions which are uniformly distributed squares. Since the deleting regions are continuous distributed, so the information missing problem can be improve.  Image rotation is refer to Chris's great kernel and add some of mine code in it. Which can rotate image with different aspect ratio. I also implemented some data augmentation methods(gaussian blur, random cutout..) in this kernel. My Github repo : GridMask_tensorflow(not official)  Official GridMask implementation in pytorch : GridMask  Paper : GridMask Data Augmentation;Apache 2.0;https://www.kaggle.com/xiejialun/gridmask-data-augmentation-with-tensorflow;1.0;['pytorch', 'tensorflow'];['ner', 'ai', 'dl', 'ml', 'nn', 'ann'];['fitting', 'model', 'classification'];https://www.kaggle.com/c/flower-classification-with-tpus;0.682;0.411;2020-12-12 19:56:26;Flower Classification with TPUs;[];GridMask data augmentation with tensorflow;Python notebook;2083.0;33;;
2020-06-19 14:15:00;About this kernel Implement CutMix, MixUp and GridMask in batch. Comparing timings - Batch operations are about 5x - 10x faster. The batch implemention for GridMask is kind partial. For a batch, grid width are fixed in that batch, but rotation angle can be random. References:  CutMix and MixUp on GPU/TPU (by Chris Deotte) GridMask data augmentation with tensorflow (by Xie29);Apache 2.0;https://www.kaggle.com/yihdarshieh/batch-implementation-of-more-data-augmentations;1.0;['tensorflow', 'keras'];['ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['unlabeled', 'training data', 'test data', 'train', 'epoch', 'label', 'predict', 'classification', 'labeled'];https://www.kaggle.com/c/flower-classification-with-tpus;0.642;0.379;2020-12-12 19:56:26;multiple data sources;[];batch implementation of more data augmentations;Python notebook;945.0;23;;
2020-08-28 18:49:06;A detailed guide to custom training with TPUs - Flower Classification  In this notebook, we will go through, step by step, training models with TPUs in a custom way. These includes: use tf.data.Dataset as input pipeline perform a custom training loop correctly define loss function make the custom training loop even faster gradient accumulation with TPUs apply oversampling to deal with imbalanced data Have fun with a special data augmentaion - Perspective transformation  This kernel is based on the following kernels with my own extension (I keep some code in these 2 notebooks):  Getting started with 100+ flowers on TPU - by Martin Görner.  Custom Training Loop with 100+ flowers on TPU - by Martin Görner.;Apache 2.0;https://www.kaggle.com/yihdarshieh/detailed-guide-to-custom-training-with-tpus;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'rnn', 'ann'];['unlabeled', 'image classification', 'machine learning', 'training data', 'test data', 'train', 'fitting', 'model', 'epoch', 'validation data', 'layer', 'loss', 'label', 'predict', 'resnet', 'classification', 'labeled'];https://www.kaggle.com/c/flower-classification-with-tpus;0.698;0.39;2020-12-12 19:56:26;multiple data sources;['tpu, data visualization, exploratory data analysis, +2 moredeep learning, classification'];Detailed guide to custom training with TPUs;Python notebook;2897.0;26;;
2020-06-19 14:04:39;Data Augmentation in batch form and running on GPU/TPU.This notebook implements a batch form of Chris Deotte's great data augmention in Rotation Augmentation GPU/TPU - [0.96+]. It also shows how to perform data augmentation on GPU / TPU directly. * [Important] Although running data augmentation directly on GPU/TPU is faster, it loses the advantage of separating the data processing on CPU and model training on GPU/TPU. * Therefore, we don't encourage the idea of using tf.keras.layers.Layer for data augmentation shown in this kernel. * However, the batch implementation is still beneficial when doing data augmentation on CPU by using tf.data.Dataset. * In order to make the measurement of timing, we measure it with a dummy layer which does the data processing in GPU / TPU, but return dummy tensor. This is to avoid the overhead of sending large tensor back to CPU.;Apache 2.0;https://www.kaggle.com/yihdarshieh/make-chris-deotte-s-data-augmentation-faster;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['unlabeled', 'training data', 'test data', 'train', 'model', 'epoch', 'layer', 'label', 'predict', 'labeled'];https://www.kaggle.com/c/flower-classification-with-tpus;0.667;0.427;2020-12-12 19:56:26;multiple data sources;[];Make Chris Deotte's data augmentation faster;Python notebook;1525.0;40;;
2018-09-18 07:50:14;General informationThis kernel is dedicated to extensive EDA of Forest Cover Type Challenge competition as well as feature engineering.;Apache 2.0;https://www.kaggle.com/artgor/forest-exploration-and-trees;1.0;['statsmodels', 'lightgbm', 'sklearn'];['ner', 'ai', 'gbm', 'cv', 'rl', 'nn'];['predict', 'test data', 'train', 'model', 'label', 'loss'];https://www.kaggle.com/c/forest-cover-type-kernels-only;0.65;0.327;2020-12-12 19:58:02;Forest Cover Type (Kernels Only);['data visualization, exploratory data analysis, classification'];Forest exploration and trees;Python notebook;1096.0;13;;
2018-08-10 15:34:10;Exploration of Forest Cover The National Forest System, the Rocky Mountain Region(Region-2) enjoys a proud heritage in the Forest Service. The Shoshone National Forest in Wyoming and the White River National Forest in Colorado are among the first National Forests Congress created from the original Forest Reserves. The Region, headquartered in Golden, Colorado, comprises 17 national forests and 7 national grasslands. The US Forest Service Rocky Mountain Region has formally identified four overarching themes as emphasis areas on which to focus strategic long-term efforts to preserve their special values: Forest and Grassland Health, Recreation, Water and Public Service. Forests and Grasslands continue to hold in trust America's resources- timber, wildlife, water, range, recreation - to ensure their availability today and tomorrow.;Apache 2.0;https://www.kaggle.com/ashishpatel26/bayesian-random-forest-lightgbm;1.0;['lightgbm', 'sklearn'];['ai', 'dl', 'gbm', 'cv', 'rl', 'nn'];['filter', 'test data', 'regression', 'train', 'model', 'label', 'predict', 'bayesian'];https://www.kaggle.com/c/forest-cover-type-kernels-only;0.652;0.302;2020-12-12 19:58:02;multiple data sources;['gpu, beginner, exploratory data analysis'];Bayesian + RaNDoM FoReSt + Lightgbm;Python notebook;1131.0;10;;
2019-08-08 06:53:08;Forest Cover ClassificationIf you liked this kernel and/or found it helpful, please upvote it so others can see it too!;Apache 2.0;https://www.kaggle.com/elitcohen/forest-cover-type-eda-modeling-error-analysis;1.0;['pattern', 'sklearn'];['ner', 'ai', 'dl', 'rl', 'nn', 'ann'];['filter', 'random forest', 'train', 'model', 'label', 'predict', 'classification'];https://www.kaggle.com/c/forest-cover-type-kernels-only;0.672;0.346;2020-12-12 19:58:02;Forest Cover Type (Kernels Only);['data visualization, exploratory data analysis, classification, +1 moreforestry'];Forest Cover Type: EDA, Modeling, + Error Analysis;Python notebook;1689.0;16;;
2018-09-19 21:45:55;Forest Cover -Ensembling and Stacking with heamyIntroduction@author: Justfor - on Kaggle:  https://www.kaggle.com/justfor This kernel shows Ensemble and Stacking  and has the the intention to show the use of the heamy package and to get a very high Leaderboard score. There are various packages for stacking available, but the heamy package has one great advantage: Caching ! This means your Classifier learns once and is then stored. When you need it again with the same date it is simply fetched. A great time-saver. heamy  is available from rushter's (Artem Golubin) github page:  https://github.com/rushter/heamy Furthermore I got Inspiration from the great kernels  Based on: https://www.kaggle.com/mmueller/allstate-claims-severity/stacking-starter (c) Faron (www.kaggle.com/mmueller) Work frum rushter https://www.kaggle.com/rushter/stacking-using-heamy  Ideas for Feature engineering from  TheGruffelo (https://www.kaggle.com/cbryant) in the  Notebook (https://www.kaggle.com/cbryant/new-features-and-recursive-feature-extraction) and  from schlerp (https://www.kaggle.com/schlerp) in the Notebook https://www.kaggle.com/schlerp/lgb-cv-ensemble-normalisation-fe;Apache 2.0;https://www.kaggle.com/justfor/ensembling-and-stacking-with-heamy;1.0;['xgboost', 'sklearn', 'lightgbm'];['ai', 'gbm', 'cv', 'rl', 'ml', 'nn', 'ann'];['gru', 'regression', 'train', 'model', 'loss', 'label', 'logistic regression', 'predict', 'recommend'];https://www.kaggle.com/c/forest-cover-type-kernels-only;0.709;0.439;2020-12-12 19:58:02;Forest Cover Type (Kernels Only);['multiclass classification, ensembling'];Ensembling and Stacking with heamy;Python notebook;3754.0;46;0.84032;0.84032
2018-09-11 23:28:20;"Contents and goalsThis kernel shows how to:  retreave the data; preprocess the data (transforming One-Hot Encoding into Label Encoding); visualise of the data in 1, 2 and 3 dimentions; engineer new features inspired by the visualisation done in the previous step; use proportion of target classes in the test data in the training and model evaluation to improve consistency between local CV and LB. This is extremely important, as it brings the class mixture in agreemnet between available training and submission datasets, thus making local performance evaluation meaningful. Many kernels in the comp either do not have model performance evaluation, or do it without weights, which leads to a gap between local and LB scores. build various models on the train/test spit of the data and evaluate their performance. Hyper-parameters of the models are optimised in a dedicated kernel:  https://www.kaggle.com/mlisovyi/hyper-parameter-optimisation; build voting classifiers and evaluated their performance in a nested cross-validation (CV); prepare submissions Note, that the proportion of the different classes in test is: 0.37053 : 0.49681 : 0.05936 : 0.00103 : 0.01295 : 0.02687 : 0.03242, as is discussed in https://www.kaggle.com/mlisovyi/class-fractions-in-the-test";Apache 2.0;https://www.kaggle.com/mlisovyi/featureengineering-training-with-weights;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'training data', 'regression', 'test data', 'train', 'fitting', 'model', 'loss', 'label', 'predict', 'decision tree', 'classification'];https://www.kaggle.com/c/forest-cover-type-kernels-only;0.666;0.319;2020-12-12 19:58:02;Forest Cover Type (Kernels Only);[];FeatureEngineering + training with weights;Python notebook;1509.0;12;;
2020-07-29 00:43:20;Ensemble Learning with ExtraTreesIn this Tutorial I am going to explain in details how to classify the cover_type dataset using Ensemble learning. In many cases machine learning algorithms don't perform well without feature engineering which is the process of filling NaNs and missing values , creating new features and etc... . I will be performing some exploratory data analysis to perform feature engineering before implementing the suitable model.  Data Exploration and Analysis Feature Construction Feature Selection Choosing and Optmizing the Model;Apache 2.0;https://www.kaggle.com/moghazy/ensemble-learning-with-feature-engineering;1.0;['xgboost', 'sklearn'];['ai', 'cv', 'ml', 'nn', 'ann'];['machine learning', 'training data', 'test data', 'train', 'model', 'label', 'predict', 'classification'];https://www.kaggle.com/c/forest-cover-type-kernels-only;0.732;0.46;2020-12-12 19:58:01;Forest Cover Type (Kernels Only);['beginner, exploratory data analysis, feature engineering, +1 morerandom forest'];Ensemble Learning with Feature Engineering;Python notebook;6529.0;60;;
2018-07-25 23:41:40;Multi-Class LGBM CV and Seed DiversificationBy Nick Brooks, June 2018 Contains:  Data Load Feature Engineering Exploratory Data Analysis Light GBM Cross Validation Seed Diversification Feature Importance  Load:;Apache 2.0;https://www.kaggle.com/nicapotato/multi-class-lgbm-cv-and-seed-diversification;1.0;['pattern', 'lightgbm', 'sklearn'];['ner', 'ai', 'gbm', 'cv', 'rl', 'nn', 'ann'];['recommend', 'test data', 'train', 'model', 'loss', 'label', 'gradient boosting', 'predict', 'rank', 'decision tree', 'classification'];https://www.kaggle.com/c/forest-cover-type-kernels-only;0.753;0.425;2020-12-12 19:58:02;Forest Cover Type (Kernels Only);['exploratory data analysis, multiclass classification, gradient boosting'];Multi-Class LGBM CV and Seed Diversification;Python notebook;11173.0;39;0.76396;0.76396
2018-10-22 12:48:20;So here are we with Forest Cover Analysis , that on various features we have to predict at least seven types of covers given to us ,Feature engg , polynomial features with pca and xgboost apart from lgbm we can get best result since being a handling various dataset, this problem is merely on few featured ensembel modelsDecision tree , base line modelrandom forest , stackers,gbm , ada, xgboost and lgbmwith taste of PCA too .evauation metrics will be accuracy , AUC , logloss and checking , variance and bias in final model;Apache 2.0;https://www.kaggle.com/rohandx1996/eda-and-feature-selection;1.0;['statsmodels', 'xgboost', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'nn', 'ann'];['machine learning', 'random forest', 'train', 'model', 'understanding', 'loss', 'label', 'predict', 'decision tree', 'classification'];https://www.kaggle.com/c/forest-cover-type-kernels-only;0.686;0.4;2020-12-12 19:58:02;Forest Cover Type (Kernels Only);['gpu, data visualization, exploratory data analysis, +1 morefeature engineering'];EDA And Feature Selection;Python notebook;2259.0;29;;
2018-07-25 08:25:02;So here are we with Forest Cover Analysis , that on various features we have to predict at least seven types of covers given to us ,Feature engg , polynomial features with pca and xgboost apart from lgbm we can get best result since being a handling various dataset, this problem is merely on few featured ensembel modelsDecision tree , base line modelrandom forest , stackers,gbm , ada, xgboost and lgbmwith taste of PCA too .evauation metrics will be accuracy , AUC , logloss and checking , variance and bias in final model;Apache 2.0;https://www.kaggle.com/rohandx1996/features-hybrid-classifier-pls-vote-if-u-like;1.0;['tensorflow', 'xgboost', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'nn', 'ann'];['test data', 'train', 'model', 'epoch', 'validation data', 'layer', 'loss', 'label', 'predict', 'decision tree', 'random forest'];https://www.kaggle.com/c/forest-cover-type-kernels-only;0.657;0.421;2020-12-12 19:58:02;Forest Cover Type (Kernels Only);['beginner, data visualization, feature engineering, +2 morexgboost, pca'];features hybrid classifier pls vote if u like ;Python notebook;1244.0;37;;
2020-09-14 02:04:08;Forest Cover Type PredictionUse cartographic variables to classify forest categories PyCaret;Apache 2.0;https://www.kaggle.com/jessicacc/forest-cover-type-pycaret;1.0;['statsmodels', 'xgboost', 'lightgbm', 'nltk', 'gensim', 'catboost', 'sklearn', 'pillow', 'spacy', 'textblob'];['ner', 'ai', 'gbm', 'rl', 'nn', 'ml'];['filter', 'training data', 'regression', 'test data', 'train', 'fitting', 'model', 'random forest', 'clustering', 'label', 'logistic regression', 'gradient boosting', 'predict', 'decision tree', 'classification', 'naive bayes'];https://www.kaggle.com/c/forest-cover-type-prediction;0.479;0.236;2020-12-12 20:01:44;Forest Cover Type Prediction;['python'];forest_cover_type_PyCaret;Python notebook;76.0;5;;
2018-12-09 17:40:36;Kaggle Forest Cover Type PredictionLogistic regression, Random Forest, and LightGBM;Apache 2.0;https://www.kaggle.com/kashnitsky/topic-10-practice-with-logit-rf-and-lightgbm;1.0;['lightgbm', 'sklearn'];['cv', 'ai', 'ml', 'gbm'];['regression', 'train', 'fitting', 'model', 'label', 'logistic regression', 'predict', 'random forest'];https://www.kaggle.com/c/forest-cover-type-prediction;0.732;0.49;2020-12-12 20:01:43;multiple data sources;[];Topic 10. Practice with logit, RF, and LightGBM;Python notebook;6492.0;88;;
2020-05-04 13:45:05;please upvote the kernle if you have found it useful. It motivates me a lot;Apache 2.0;https://www.kaggle.com/leela2299/eda-feature-engineering-classification;1.0;['xgboost', 'sklearn'];['ai', 'nn', 'ann', 'rl'];['filter', 'training data', 'regression', 'test data', 'train', 'model', 'support vector machines', 'label', 'logistic regression', 'predict', 'random forest', 'naive bayes'];https://www.kaggle.com/c/forest-cover-type-prediction;0.61;0.292;2020-12-12 20:01:44;Forest Cover Type Prediction;['beginner, exploratory data analysis, classification, +1 morefeature engineering'];EDA,feature engineering, classification;Python notebook;529.0;9;0.74475;0.74475
2020-04-28 09:08:22;In this competition you are asked to predict the forest cover type (the predominant kind of tree cover) from strictly cartographic variables (as opposed to remotely sensed data). The data is in raw form (not scaled) and contains binary columns of data for qualitative independent variables such as wilderness areas and soil type.;Apache 2.0;https://www.kaggle.com/nehabhandari1/forest-prediction-final;1.0;['xgboost', 'sklearn'];['ner', 'ai', 'cv', 'rl', 'ml', 'nn', 'ann'];['machine learning', 'regression', 'train', 'fitting', 'model', 'label', 'gradient boosting', 'predict', 'understanding', 'random forest'];https://www.kaggle.com/c/forest-cover-type-prediction;0.614;0.268;2020-12-12 20:01:44;Forest Cover Type Prediction;[];Forest_Prediction_Final;Python notebook;569.0;7;0.81005;0.81005
2017-05-02 15:10:36;PART I (Being a newbie would love to have your suggestions on improving it)Link to PART II https://www.kaggle.com/nitin007/forest-cover-type-prediction/forest-cover-type-prediction-complete-part-ii/;Apache 2.0;https://www.kaggle.com/nitin007/forest-cover-type-prediction-complete-part-i;1.0;['sklearn'];['ai', 'rl', 'ml', 'cv'];['gru', 'filter', 'test data', 'train', 'model', 'support vector machines', 'label', 'predict', 'classification'];https://www.kaggle.com/c/forest-cover-type-prediction;0.747;0.367;2020-12-12 20:01:44;Forest Cover Type Prediction;[];Forest Cover Type Prediction (Complete) Part I;Python notebook;9621.0;20;;
2017-05-02 14:03:00;PART IILink to PART I https://www.kaggle.com/nitin007/forest-cover-type-prediction/forest-cover-type-prediction-complete-part-i;Apache 2.0;https://www.kaggle.com/nitin007/forest-cover-type-prediction-complete-part-ii;1.0;['xgboost', 'sklearn'];['ai', 'rl', 'cv'];['gru', 'filter', 'test data', 'train', 'model', 'label', 'predict', 'random forest'];https://www.kaggle.com/c/forest-cover-type-prediction;0.692;0.253;2020-12-12 20:01:44;Forest Cover Type Prediction;[];Forest Cover Type Prediction (Complete) Part II;Python notebook;2549.0;6;;
2016-10-08 09:12:53;<....Work in progress...> Thank you for opening this script! I have made all efforts to document each and every step involved in the prediction process so that this notebook acts as a good starting point for new Kagglers and new machine learning enthusiasts. Please upvote this kernel so that it reaches the top of the chart and is easily locatable by new users. Your comments on how we can improve this kernel is welcome. Thanks.  Layout of the documentThe prediction process is divided into two notebooks. Part 1 : Covers data statistics, data visualization, and feature selection : https://www.kaggle.com/sharmasanthosh/forest-cover-type-prediction/exploratory-study-on-feature-selection This notebook : Covers prediction using various algorithms  Data statistics Shape Datatypes Description Skew Class distribution  Data Interaction Correlation Scatter plot  Data Visualization Box and density plots Grouping of one hot encoded attributes  Data Cleaning Remove unnecessary columns  Data Preparation Original Delete rows or impute values in case of missing StandardScaler MinMaxScaler Normalizer  Feature selection ExtraTreesClassifier GradientBoostingClassifier RandomForestClassifier XGBClassifier RFE SelectPercentile PCA PCA + SelectPercentile Feature Engineering  Evaluation, prediction, and analysis LDA (Linear algo) LR (Linear algo) KNN (Non-linear algo) CART (Non-linear algo) Naive Bayes (Non-linear algo) SVC (Non-linear algo) Bagged Decision Trees (Bagging) Random Forest (Bagging) Extra Trees (Bagging) AdaBoost (Boosting) Stochastic Gradient Boosting (Boosting) Voting Classifier (Voting) MLP (Deep Learning) XGBoost;Apache 2.0;https://www.kaggle.com/sharmasanthosh/exploratory-study-of-ml-algorithms;1.0;['tensorflow', 'xgboost', 'sklearn', 'keras'];['ner', 'ai', 'cv', 'ml', 'nn', 'ann'];['filter', 'relu', 'predict', 'machine learning', 'train', 'epoch', 'classification', 'naive bayes', 'model', 'layer', 'loss', 'rank', 'decision tree', 'test data', 'regression', 'deep learning', 'label', 'gradient boosting', 'random forest'];https://www.kaggle.com/c/forest-cover-type-prediction;0.757;0.467;2020-12-12 20:01:44;Forest Cover Type Prediction;[];Exploratory study of ML algorithms;Python notebook;12340.0;65;;
2016-10-13 04:03:02;Thank you for opening this script! I have made all efforts to document each and every step involved in the prediction process so that this notebook acts as a good starting point for new Kagglers and new machine learning enthusiasts. Please upvote this kernel so that it reaches the top of the chart and is easily locatable by new users. Your comments on how we can improve this kernel is welcome. Thanks. My other exploratory studies can be accessed here : https://www.kaggle.com/sharmasanthosh/kernels  Layout of the documentThe prediction process is divided into two notebooks. This notebook : Covers data statistics, data visualization, and feature selection Part 2 : Covers prediction using various algorithms : https://www.kaggle.com/sharmasanthosh/forest-cover-type-prediction/exploratory-study-of-ml-algorithms  Data statistics Shape Datatypes Description Skew Class distribution  Data Interaction Correlation Scatter plot  Data Visualization Box and density plots Grouping of one hot encoded attributes  Data Cleaning Remove unnecessary columns  Data Preparation Original Delete rows or impute values in case of missing StandardScaler MinMaxScaler Normalizer  Feature selection ExtraTreesClassifier GradientBoostingClassifier RandomForestClassifier XGBClassifier RFE SelectPercentile PCA PCA + SelectPercentile Feature Engineering  Evaluation, prediction, and analysis LDA (Linear algo) LR (Linear algo) KNN (Non-linear algo) CART (Non-linear algo) Naive Bayes (Non-linear algo) SVC (Non-linear algo) Bagged Decision Trees (Bagging) Random Forest (Bagging) Extra Trees (Bagging) AdaBoost (Boosting) Stochastic Gradient Boosting (Boosting) Voting Classifier (Voting) MLP (Deep Learning) XGBoost;Apache 2.0;https://www.kaggle.com/sharmasanthosh/exploratory-study-on-feature-selection;1.0;['pattern', 'xgboost', 'sklearn'];['ai', 'rl', 'cv', 'nn', 'ml'];['filter', 'machine learning', 'regression', 'random forest', 'train', 'model', 'deep learning', 'label', 'gradient boosting', 'predict', 'rank', 'decision tree', 'classification', 'naive bayes'];https://www.kaggle.com/c/forest-cover-type-prediction;0.801;0.54;2020-12-12 20:01:43;Forest Cover Type Prediction;[];Exploratory study on feature selection;Python notebook;47932.0;177;;
2019-11-25 02:57:40;Kaggle Forest Cover Type PredictionLogistic regression, Random Forest, and LightGBM;Apache 2.0;https://www.kaggle.com/shreeharjoshi/classifying-the-type-of-forest;1.0;['lightgbm', 'sklearn'];['cv', 'ai', 'ml', 'gbm'];['regression', 'train', 'model', 'label', 'logistic regression', 'predict', 'random forest'];https://www.kaggle.com/c/forest-cover-type-prediction;0.578;0.236;2020-12-12 20:01:44;multiple data sources;[];Classifying the type of forest;Python notebook;312.0;5;;
2016-11-22 17:26:59;This kernel uses Support Vector Machines to classify the forest cover type;Apache 2.0;https://www.kaggle.com/vsmolyakov/svm-classifier;1.0;['sklearn'];['ai', 'cv'];['test data', 'train', 'fitting', 'model', 'support vector machines', 'predict'];https://www.kaggle.com/c/forest-cover-type-prediction;0.667;0.236;2020-12-12 20:01:44;Forest Cover Type Prediction;[];SVM classifier;Python notebook;1511.0;5;;
2018-06-04 00:20:47;"OverviewAs I am new to deep learning and my background is more ""classic"" machine learning, I decided to start with random forest (RF) / xgboost (xgb) / logistic regression and then learn how to use neural nets. I started with skimming through articles on musical instrument detection and making a list of important features, coding these features and using these features as an input into RF and xgb. Training both classifiers on the whole dataset and averaging outputs using geometric mean gave 0.844 on the leaderboard, which was already great. Next I started to learn how to use CNNs. ""Learn from what is there"" they say, so I checked what was already done and came across kernel by Zafar - Beginner's Guide to Audio Data, which was a great starting point. Next I did some studying by listening to course by Andrew Ng links from here and played with hyperparameter optimization. As I had dataset for training RF/xgb, I decided to use that dataset along with dataset for CNN as two distinct inputs into one NN which gave good improvement to mapk. Currently I have around 0.92 on the leaderboard. Next steps are to study amazing input done by daisukelab which can be found here. Things I will try:  augmentaions oversampling other NN architectures re-sampling audio at 16k or 24k using RNN or 1d CNN as suggested by Zafar (or time-dependent approach by daisukelab) sequential learning / pseudo-labelling (e.g. definitely it is possible to label all test data in 2-3 days: add to train predictions with highest probability, train, etc.)  What I have noticed  Cross-validated mapk is way more lower then the one on the leaderboard Geometric mean works, arithmetic doesn't (for ensembling) Training classifers on all data can help (cross-validate to tune parameters, then re-train on all data) Ensembling helps TWO SUBMITS IS NOT ENOUGH :D  I will try to share more insights and ideas with the time.";Apache 2.0;https://www.kaggle.com/agehsbarg/audio-challenge-cnn-with-concatenated-inputs;1.0;['tensorflow', 'xgboost', 'sklearn', 'keras'];['ner', 'ai', 'cnn', 'gan', 'rl', 'nn', 'rnn'];['unlabeled', 'filter', 'logistic regression', 'predict', 'relu', 'ground truth', 'machine learning', 'train', 'epoch', 'labeled', 'model', 'neural network', 'layer', 'loss', 'test data', 'regression', 'deep learning', 'label', 'random forest'];https://www.kaggle.com/c/freesound-audio-tagging;0.689;0.327;2020-12-12 20:04:19;multiple data sources;[];Audio challenge: CNN with concatenated inputs;Python notebook;2395.0;13;;
2018-08-01 15:43:13;Freesound Dataset Kaggle 2018 SolutionThis is private 0.917 / public 0.950 solution.;Apache 2.0;https://www.kaggle.com/daisukelab/freesound-dataset-kaggle-2018-solution;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'rl', 'nn'];['filter', 'training data', 'test data', 'generation', 'train', 'model', 'epoch', 'layer', 'vgg', 'loss', 'label', 'alexnet', 'predict', 'relu', 'resnet', 'labeled'];https://www.kaggle.com/c/freesound-audio-tagging;0.734;0.421;2020-12-12 20:04:19;multiple data sources;[];Freesound Dataset Kaggle 2018 Solution ;Python notebook;6825.0;37;;
2019-08-24 08:53:07;Part 2 - Extracting Audio FeaturesEu Jin Lok Kernel post for Speech Accent Archive on Kaggle 20 January 2019 IntroductionTo understand the various features we can extract from audio, and use it to predict gender and accentsIn part 2 of this series, I'll introduce the various types of features from audio and we can see how these features differ when we compare between genders and accent types. I'm hoping one of these features will be distinctive enough that we could use it for predictive modelling in the next part. I would also like to acknowledge 2 people whom I've learnt alot from:  Jayesh Saita, whose blog I really liked and helped me understand audio features and MFCCs in the early stages of my journey    Zafarullah Mahmood, whose Kaggle Kernel basically became the canvas for all audio work that I do at work and outside work. Please do check out his kernels whom I've drawn lots of inspiration from!   This part 2 kernel will cover quite a few items so I'll provide a brief agenda:  Core concepts in Audio Time domain features  1. Audio wave   Frequency domain features 2. MFCC 3. Log Mel-spectogram 4. Harmonic-percussive source separation (HPSS) 5. Chroma   Final thoughts  Again, thanks to the awesome Kaggle community, and the broader data science community. Without further ado, lets begin!;Apache 2.0;https://www.kaggle.com/ejlok1/part-2-extracting-audio-features;1.0;['pattern'];['ner', 'ai', 'dl', 'rl', 'cv'];['filter', 'machine learning', 'train', 'model', 'deep learning', 'label', 'gradient boosting', 'predict', 'understanding', 'random forest'];https://www.kaggle.com/c/freesound-audio-tagging;0.711;0.367;2020-12-12 20:04:19;multiple data sources;[];Part 2 - Extracting Audio Features;Python notebook;3927.0;20;;
2018-04-12 07:41:33;Freesound General-Purpose Audio Tagging Challenge Freesound is a collaborative database of Creative Commons Licensed sounds. The aim of this competition is to classify audio files that cover real-world sounds from musical instruments, humans, animals, machines, etc. Few of the labels are: Trumpet, Squeak, Meow, Applause and Finger_sapping.  One of the challenges is that not all labels are manually verified. A creative solution should be able to partially rely on these weak annotations. Let's take a tour of the data visualization and model building through this kernel. If you like this work, please show your support by upvotes. Happy Kaggling! Contents Exploratory Data Analysis Loading data Distribution of Categories Reading Audio Files Audio Length   Building a Model using Raw Wave Model Discription Configuration DataGenerator class Normalization Training 1D Conv Ensembling 1D Conv Predictions   Introduction to MFCC Generating MFCC using Librosa   Building a Model using MFCC Preparing Data Normalization Training 2D Conv on MFCC Ensembling 2D Conv Predictions   Ensembling 1D Conv and 2D Conv Predictions Results and Conclusion   1. Exploratory Data Analysis;Apache 2.0;https://www.kaggle.com/fizzbuzz/beginner-s-guide-to-audio-data;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ann'];['generation', 'train', 'model', 'epoch', 'deep learning', 'layer', 'validation data', 'loss', 'label', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/freesound-audio-tagging;0.816;0.609;2020-12-12 20:04:19;multiple data sources;['beginner, data visualization, deep learning, +1 morecnn'];Beginner's Guide to Audio Data;Python notebook;80268.0;522;0.86476;0.89590
2018-10-04 14:49:37;Show a few example spectrogramsWe can see what sort of patterns the model should be looking for;Apache 2.0;https://www.kaggle.com/kmader/spectrogram-classifier-mobilenet;1.0;['pattern', 'tensorflow', 'sklearn', 'keras'];['ai', 'dl', 'cnn', 'rl', 'nn'];['test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/freesound-audio-tagging;0.675;0.268;2020-12-12 20:04:19;multiple data sources;['gpu'];Spectrogram Classifier MobileNet;Python notebook;1810.0;7;;
2018-05-05 18:12:04;Freesound Kaggle PresentationMatt PotmaMay 3, 2018This notebook has been written for a presentation happening at approximately 6:30pm PDT today, May 3rd. A link to the livestream will be posted here shortly before it begins, so anyone can view it. Without watching the presentation, and even with, the flow of the notebook may be a bit awkward, but the presentation will be left up on YouTube to be viewed at any time. At some point, I may edit this notebook to provide more context, but will be left as-is for now. Unfortunately, despite the notebook running from scratch on my laptop in about 2 hours, trying to Commit & Run the notebook ran out of time. I've added two flags at the beginning of the second code cell, cache and run_full_notebook. Both are set to False in this notebook, hoping that it can fully execute on this kernel. The cache flag saves intermediate results and calculates spectral features on audio files with silence trimmed off, and run_full_notebook trains a couple of extra LGBM models. By setting both of those flags to True and running the notebook locally, the last submission file is good for 0.836 on the Public Leaderboard, with lots that can be improved upon. A link to my presentation where I go through this notebook can be seen here https://www.youtube.com/watch?v=3CtPuwok7Nw;Apache 2.0;https://www.kaggle.com/mpotma/learndatascience-presentation-lgbm-lb-0-836;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'nn'];['training data', 'test data', 'train', 'model', 'neural network', 'layer', 'loss', 'label', 'predict'];https://www.kaggle.com/c/freesound-audio-tagging;0.674;0.357;2020-12-12 20:04:19;Freesound General-Purpose Audio Tagging Challenge;[];LearnDataScience Presentation, LGBM LB=0.836;Python notebook;1745.0;18;0.79278;0.82115
2018-07-25 08:48:55;Freesound General-Purpose Audio Tagging Challenge Freesound is a collaborative database of Creative Commons Licensed sounds. The aim of this competition is to classify audio files that cover real-world sounds from musical instruments, humans, animals, machines, etc. Few of the labels are: Trumpet, Squeak, Meow, Applause and Finger_sapping.  One of the challenges is that not all labels are manually verified. A creative solution should be able to partially rely on these weak annotations. Let's take a tour of the data visualization and model building through this kernel. If you like this work, please show your support by upvotes. Happy Kaggling! Contents Exploratory Data Analysis Loading data Distribution of Categories Reading Audio Files Audio Length   Building a Model using Raw Wave Model Discription Configuration DataGenerator class Normalization Training 1D Conv Ensembling 1D Conv Predictions   Introduction to MFCC Generating MFCC using Librosa   Building a Model using MFCC Preparing Data Normalization Training 2D Conv on MFCC Ensembling 2D Conv Predictions   Ensembling 1D Conv and 2D Conv Predictions Results and Conclusion   1. Exploratory Data Analysis;Apache 2.0;https://www.kaggle.com/nafisur/beginner-s-guide-to-audio-data-90b7f7;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ann'];['generation', 'train', 'model', 'epoch', 'deep learning', 'layer', 'validation data', 'loss', 'label', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/freesound-audio-tagging;0.666;0.302;2020-12-12 20:04:19;multiple data sources;[];Beginner's Guide to Audio Data;Python notebook;1491.0;10;0.86476;0.89590
2019-09-14 20:59:30;Freesound General-Purpose Audio Tagging Challenge Aim: To build a general-purpose automatic audio tagging system using a dataset of audio files covering a wide range of real-world environments.;Apache 2.0;https://www.kaggle.com/saitanya/audio-recognition;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['training data', 'test data', 'train', 'model', 'neural network', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/freesound-audio-tagging;0.63;0.281;2020-12-12 20:04:19;multiple data sources;['gpu'];Audio Recognition;Python notebook;749.0;8;;
2019-05-13 14:52:32;Free Sound Cloud Audio Classification Challange  Project ModelInput file : Audio Wave file Output file : Label;Apache 2.0;https://www.kaggle.com/ashishpatel26/feature-extraction-from-audio;1.0;['sklearn'];['ai'];['filter', 'train', 'model', 'label', 'classification'];https://www.kaggle.com/c/freesound-audio-tagging-2019;0.751;0.403;2020-12-12 20:05:18;Freesound Audio Tagging 2019;['gpu'];Feature Extraction From Audio;Python notebook;10740.0;30;;
2019-04-24 20:27:13;Birectional LSTM model for audio labeling with Keras;Apache 2.0;https://www.kaggle.com/carlolepelaars/bidirectional-lstm-for-audio-labeling-with-keras;1.0;['vocabulary', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'rl', 'nn'];['machine learning', 'training data', 'train', 'model', 'neural network', 'epoch', 'layer', 'relu', 'loss', 'label', 'lstm', 'predict', 'rank', 'classification', 'labeled', 'ground truth'];https://www.kaggle.com/c/freesound-audio-tagging-2019;0.753;0.494;2020-12-12 20:05:18;Freesound Audio Tagging 2019;['deep learning, classification, lstm, +1 moreaudio data'];Bidirectional LSTM for audio labeling with Keras;Python notebook;11197.0;93;0.38889;0.38889
2019-04-16 11:46:20;"CNN 2D Basic Solution #2.5This is 2nd version of https://www.kaggle.com/daisukelab/cnn-2d-basic-solution-powered-by-fast-ai.  Based on fast.ai library, solving issue as image multi-label classification. Using mel-spectrogram preprocessing. Using preprocessed dataset additionally. https://www.kaggle.com/daisukelab/fat2019_prep_mels1  What's new in 14-Apr version Smaller subset of noisy training data was added; The best 50s. (I should call random 50 actually...) Training uses both curated and this subset of noisy data.  Important notice for final submissionThis kernel is not preprocessing test set, then this doesn't work for final submission. We should be ready for preprocessing new test set used in re-evaluation after deadline: ""Note, as this competition is a Kernels-only, two-stage competition, following the final submission deadline for the competition, your kernel code will be re-run on a privately-held test set that is not provided to you. It is your model's score against this private test set that will determine your ranking on the private leaderboard and final standing in the competition. The leaderboard will be updated in the days following the competition's completion, and our team will announce that the re-run has been completed and leaderboard finalized with an announcement made on the competition forums."" Link: https://www.kaggle.com/c/freesound-audio-tagging-2019/overview/timeline";Apache 2.0;https://www.kaggle.com/daisukelab/cnn-2d-basic-2-preprocessed-dataset-noisy;1.0;['pytorch', 'sklearn'];['ner', 'ai', 'dl', 'cnn', 'nn', 'ann'];['filter', 'training data', 'test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'rank', 'resnet', 'classification'];https://www.kaggle.com/c/freesound-audio-tagging-2019;0.696;0.4;2020-12-12 20:05:18;multiple data sources;['gpu'];CNN 2D Basic #2, Preprocessed Dataset, Noisy;Python notebook;2814.0;29;;
2019-05-01 00:27:59;CNN 2D Basic Solution Powered by fast.aiThis kernel explains basic solution that I've used in the last competition and many of top competitors also. It's CNN, even ImageNet pretrained model works fine with audio 2D image like data. Will show:  Converting audio to 2D image like array, so that we can simply exploit strong CNN classifier. fast.ai to build fast and strong multi-label classifier model. Unlike normal use, we need to train from scratch to comply competition rule. (Though if we use ImageNet pretrained model, it converges super fast...) With simple codes.  Update 30-Apr, 2019 Now fast.ai library ready to use lwlrap as metric: https://colab.research.google.com/drive/1AgPdhSp7ttY18O3fEoHOQKlt_3HJDLi8 And TTA! https://github.com/fastai/fastai/blob/master/fastai/vision/tta.py --> Oops, it might not be effective for this problem. Now planning to update one more...  Update 28-Apr, 2019 Removed EasyDict dependency. Training steps improved, tuned by running lr_find() and fit_one_cycle() iteratively.;Apache 2.0;https://www.kaggle.com/daisukelab/cnn-2d-basic-solution-powered-by-fast-ai;1.0;['pytorch', 'sklearn'];['ner', 'ai', 'dl', 'cnn', 'ml', 'nn', 'ann'];['filter', 'training data', 'test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'rank', 'resnet', 'classification'];https://www.kaggle.com/c/freesound-audio-tagging-2019;0.77;0.542;2020-12-12 20:05:18;Freesound Audio Tagging 2019;['gpu, cnn'];CNN 2D Basic Solution Powered by fast.ai;Python notebook;18133.0;182;;
2019-04-29 18:04:21;Code to create FAT2019 Preprocessed Mel-spectrogram DatasetThis is the code to create FAT2019 Preprocessed Mel-spectrogram Dataset. Creating noisy set is commented out due to kernel memory restriction. You can fully run in your local environment. No GPU used.;Apache 2.0;https://www.kaggle.com/daisukelab/creating-fat2019-preprocessed-data;1.0;['pytorch'];['ann', 'ai', 'nn', 'ml'];['train', 'label'];https://www.kaggle.com/c/freesound-audio-tagging-2019;0.734;0.496;2020-12-12 20:05:18;multiple data sources;[];Creating FAT2019 Preprocessed Data;Python notebook;6833.0;95;;
2019-04-05 18:49:37;To classify audio, you first need present it somehow to the classifier. You may notice everyone is talking about spectrogram, FFT, STFT, MFCC, but why don't we just use audio? What does it all stand for? Here comes a little explanation!tip: most interesting things are marked as QUESTION;Apache 2.0;https://www.kaggle.com/davids1992/audio-representation-what-it-s-all-about;1.0;['sklearn'];['ai', 'nn', 'ann', 'rl'];['speech recognition', 'filter', 'train', 'recognition', 'label', 'classification'];https://www.kaggle.com/c/freesound-audio-tagging-2019;0.701;0.452;2020-12-12 20:05:18;Freesound Audio Tagging 2019;[];Audio representation - what it's all about;Python notebook;3160.0;54;;
2019-04-26 18:00:32;This is my quick implementation of SpecAugment paper here, without time warping. It works regardless of PyTorch or Tensorflow. You set percentage of frames to mask so should work with long and short segments. Let's test it:;Apache 2.0;https://www.kaggle.com/davids1992/specaugment-quick-implementation;1.0;['pytorch', 'tensorflow'];['ai', 'dl'];['train'];https://www.kaggle.com/c/freesound-audio-tagging-2019;0.704;0.437;2020-12-12 20:05:18;Freesound Audio Tagging 2019;[];SpecAugment quick implementation;Python notebook;3357.0;45;;
2019-05-31 15:40:59;This notebook is a clone of an excellent introduction to audio guide by Robert Bracco. I learnt a lot from Robert's guide. I hope it will also help other beginners like me. Big Thank you to Robert Bracco !;Apache 2.0;https://www.kaggle.com/deepaksinghrawat/in-depth-introduction-to-audio-for-beginners;1.0;['pytorch'];['ner', 'ai', 'rl', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'train', 'recognition', 'model', 'deep learning', 'label', 'predict', 'understanding', 'classification'];https://www.kaggle.com/c/freesound-audio-tagging-2019;0.711;0.429;2020-12-12 20:05:18;Freesound Audio Tagging 2019;['beginner, audio data'];In-depth introduction to audio for beginners;Python notebook;3957.0;41;;
2019-05-02 04:16:23;Freesound Audio Tagging 2019  updated May.02  @fizzbuzz's awesome kernel from previous competition would be a great introduction for beginners, including me :) ( https://www.kaggle.com/fizzbuzz/beginner-s-guide-to-audio-data ) Here I posted the modified kernel for this competition ( though not perfect ).  Also some top solutions in previous competition will help us.  1st solution : https://storage.googleapis.com/kaggle-forum-message-attachments/365414/9991/Jeong_COCAI_task2.pdf  4th solution : https://www.kaggle.com/c/freesound-audio-tagging/discussion/62634#latest-367166  8th solution : https://www.kaggle.com/c/freesound-audio-tagging/discussion/64262#latest-376395  11th solution : http://dcase.community/documents/workshop2018/proceedings/DCASE2018Workshop_Wei_100.pdf    DCASE_2018 proceedings : http://dcase.community/workshop2018/proceedings   And more... Planet Understanding the Amazon from Space was a multi-labeled image classification competition. https://www.kaggle.com/c/planet-understanding-the-amazon-from-space 1st place solution had been written in Kaggle blog by @bestfitting. http://blog.kaggle.com/2017/10/17/planet-understanding-the-amazon-from-space-1st-place-winners-interview/ Most interesting part for me is the way to consider co-occurence. In this solution, Ridge regression was used to do it (please read the above material for more detail).  NOTE : This notebook used only curated wav files, and did not consider multi-labeled records in train. For supplement, I have also posted the kernel to explore multi-label audio data. https://www.kaggle.com/maxwell110/explore-multi-labeled-data Contents Exploratory Data Analysis Loading data Distribution of Categories Reading Audio Files Audio Length   Building a Model using Raw Wave Model Discription Configuration DataGenerator class Normalization Training 1D Conv Ensembling 1D Conv Predictions   Introduction to MFCC Generating MFCC using Librosa   Building a Model using MFCC Preparing Data Normalization Training 2D Conv on MFCC Ensembling 2D Conv Predictions   Ensembling 1D Conv and 2D Conv Predictions   1. Exploratory Data Analysis;Apache 2.0;https://www.kaggle.com/maxwell110/beginner-s-guide-to-audio-data-2;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ann'];['image classification', 'filter', 'regression', 'generation', 'train', 'fitting', 'model', 'epoch', 'deep learning', 'layer', 'validation data', 'loss', 'label', 'predict', 'relu', 'understanding', 'classification', 'labeled'];https://www.kaggle.com/c/freesound-audio-tagging-2019;0.768;0.535;2020-12-12 20:05:18;Freesound Audio Tagging 2019;['gpu'];Beginner's Guide to Audio Data 2;Python notebook;17163.0;164;;
2019-05-13 19:00:28;You know, StratifiedKFold of scikit-learn cannot deal with multi-label data. So, here I would like to get stratified folds using the randomized algorithm.;Apache 2.0;https://www.kaggle.com/osciiart/multilabel-stratifiedkfold-by-randomized-algorithm;1.0;['sklearn'];['ann', 'ai', 'nn', 'ml'];['train', 'model', 'label', 'filter'];https://www.kaggle.com/c/freesound-audio-tagging-2019;0.681;0.425;2020-12-12 20:05:18;Freesound Audio Tagging 2019;[];Multilabel StratifiedKfold by Randomized Algorithm;Python notebook;2018.0;39;;
2019-04-19 10:58:29;1 sample ごとの計算正解ラベルが1つの場合。クラスがA,B,Cの3種類とする。 正解ラベル = A, 予測 = (A: 0.7, B: 0.1, 0.2)の場合を例として考える。 まず予測をランク化 (値の大きい順に数字を振る) する。 -> 予測 = (A: 1, B: 3, C:2) Score = 1～正解ラベルのランクまでの正解数/正解ラベルのランク と計算される。 この場合、 正解ラベルのランク = 1 1～正解ラベルのランクまでの正解数 = ランク1～1までの正解数 = 1 なので、 Score = 1/1 = 1.0 となる。;Apache 2.0;https://www.kaggle.com/osciiart/understanding-lwlrap-sorry-it-s-in-japanese;1.0;['sklearn'];['dl'];['rank', 'label'];https://www.kaggle.com/c/freesound-audio-tagging-2019;0.689;0.442;2020-12-12 20:05:18;Freesound Audio Tagging 2019;[];understanding LwLRAP (sorry it's in Japanese);Python notebook;2432.0;48;;
2019-05-19 06:59:35;"Introductionsee V56 for the best result of LB632 -- Finally I beat the current best public kernel using Keras :) -- This probably be my last update on this kernel -- If you find this kernel helpful, please upvote Version upto V60 have a silly bug of 'if <-- elif' so that model selection is wrong  This is my effort to do a Keras replication with comparable baseline to the great kernel of @mhiro2 https://www.kaggle.com/mhiro2/simple-2d-cnn-classifier-with-pytorch (and further improved by @peining), which in turns use the excellent pre-processed data of @daisukelab https://www.kaggle.com/daisukelab/creating-fat2019-preprocessed-data) -- Note that to inference to the private data in stage-2, you have to preprocess data yourself. One change I made in a Keras version, in addition to a simple conv net, we can also use a pre-defined architectures [trained from scratch] MobileNetV2, InceptionV3 and Xception where you can choose in the kernel. Also, many ideas borrow from a nice kernel of @voglinio https://www.kaggle.com/voglinio/keras-2d-model-5-fold-log-specgram-curated-only , I also borrow the SoftMax+BCE loss & TTA ideas from Giba's kernel (BTW, we all know Giba without having to mention his user :). I apologize that my code is not at all clean; some of the pytorch code is still here albeit not used. Major Updates V1 [CV680, LB574] V4 [CV66x, LB576] V5 [] Add image augmentation module V9 [CV679] Add lwlrap TF metric (credit @rio114 : https://www.kaggle.com/rio114/keras-cnn-with-lwlrap-evaluation ) V11 [] Employ list of augmentations mentioned in https://github.com/sainathadapa/kaggle-freesound-audio-tagging/blob/master/approaches_all.md V16 [] Add BCEwithLogits (use only with ACTIVATION = 'linear') V17 add SimpleCNN similar to the pytorch baseline V22 add Curated-Only, Train-augment options V23 add CRNN model V30 LB598 with shallow CNN in 400s, set iteration to 150 V39 LB608 with CoarseDropout Augmentation V40 Simple Snapshot (Checkpoint) Ensemble V52 [CV811, LB616] MixUp+CoarseDropout : credit https://www.kaggle.com/mathormad/resnet50-v2-keras-focal-loss-mix-up  V56 [CV830, LB632] Change Architecture to get the best result  V61 fix silly bugs on model selection";Apache 2.0;https://www.kaggle.com/ratthachat/fat19-mixup-keras-on-preprocesseddata-lb632;1.0;['pytorch', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'nn', 'rnn', 'ann'];['gru', 'filter', 'training data', 'test data', 'generation', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'lstm', 'predict', 'rank', 'resnet', 'relu'];https://www.kaggle.com/c/freesound-audio-tagging-2019;0.754;0.485;2020-12-12 20:05:18;multiple data sources;['gpu, beginner, deep learning'];FAT19: MixUp Keras on PreProcessedData LB632;Python notebook;11612.0;82;;
2019-05-25 00:56:55;"Fork from mhiro, https://www.kaggle.com/mhiro2/simple-2d-cnn-classifier-with-pytorch . Single model resnet18 with curated subset, to get the LB 0.634. commit V4 is for model training and commit V5 is for prediction and submission. Added:  Predefined NNs such as resnet18, resnet 34, alexnet, vgg; Data augmentation mixup() added for the train data; Optimizers, lr schedules (CyclicLR, ReduceLROnPlateau, CosineAnnealingLR) can be selected; loss function weighted_BCEWithLogits added;  Model change can increase the lb to 0.65+. Feel free to check the code, setup and discuss here. My confusion: Several guys report local lwlrap around 0.86 with LB around 0.7. https://www.kaggle.com/c/freesound-audio-tagging-2019/discussion/91881#latest-535068 However for mine: With resnet18, local lwlrap is about 0.7324, while LB is 0.634. While with a self private model, almost same train setup, add ""k-fold averaging"", LB can be 0.7+ with local lwlrap around 0.76.";Apache 2.0;https://www.kaggle.com/sailorwei/fat2019-2d-cnn-with-mixup-lb-0-673;1.0;['pytorch', 'sklearn'];['ner', 'ai', 'dl', 'cnn', 'nn', 'ann'];['train', 'model', 'epoch', 'vgg', 'loss', 'label', 'alexnet', 'predict', 'rank', 'resnet', 'relu'];https://www.kaggle.com/c/freesound-audio-tagging-2019;0.69;0.403;2020-12-12 20:05:18;multiple data sources;['gpu'];FAT2019 2d-cnn with mixup, LB 0.634;Python notebook;2479.0;30;;
2019-04-05 07:01:00;based on :  https://www.kaggle.com/CVxTz/keras-cnn-starter https://www.kaggle.com/jmourad100/keras-eda-and-cnn-starter  || Loading Packages;Apache 2.0;https://www.kaggle.com/shujian/keras-cnn-starter-curated-training-data-only;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'nn'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/freesound-audio-tagging-2019;0.696;0.439;2020-12-12 20:05:18;Freesound Audio Tagging 2019;['gpu'];Keras CNN Starter [curated training data only];Python notebook;2780.0;46;0.12283;0.12283
2019-04-24 04:47:19;In this notebook I present the basic keypoints of my attempt to tackle the problem. I hope you all find it helpfull. The key-points are:  I choose a np.log version of scipy.signal.spectrogram to transform 1-D audio signal to 2-D imaging. The model uses softmax activation function. During training I select random 1-seconds parts from the audio signals (see DataGenerator). I use a stratified version of k-fold based on the first class. That means that for stratification purposes I choose one of the many classes (see dictionary first_labels_set)  I calculate out-of-fold predictions (oof_y) which I use to estimate the lwlrap score. The test set is evaluated and averaged k=5 times. The evaluation is done using TestDataGenerator hence introducing some randomness and non-determinism (res_Y = model.predict_generator(test_gen, verbose=1)) The training process is optimizing categorical_crossentropy and monitors categorical_accuracy for termination. By using early stopping in each fold I implicitly introduce some overfitting on the validation set. I expect more stable estimation by using fixed number of iterations, but is is not my style :)  The whole kernel takes ~2 hours to train and a couple of minutes for inference if you use the pretrained weights I already attach.  (GIBA) Increased Window time to 1.5 * 44100 (GIBA) Added TTA at test time;Apache 2.0;https://www.kaggle.com/titericz/giba-keras-2-folds-from-scratch-lb-0-501;1.0;['pattern', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cnn', 'rl', 'nn', 'ann'];['activation function', 'generation', 'train', 'fitting', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'rank', 'relu', 'labeled'];https://www.kaggle.com/c/freesound-audio-tagging-2019;0.686;0.423;2020-12-12 20:05:18;multiple data sources;['gpu'];Giba Keras, 5-fold, log_specgram, curated only;Python notebook;2268.0;38;0.50263;0.50263
2019-04-17 13:42:46;In this notebook I present the basic keypoints of my attempt to tackle the problem. I hope you all find it helpfull. The key-points are:  I choose a np.log version of scipy.signal.spectrogram to transform 1-D audio signal to 2-D imaging. The model uses softmax activation function. During training I select random 1-seconds parts from the audio signals (see DataGenerator). I use a stratified version of k-fold based on the first class. That means that for stratification purposes I choose one of the many classes (see dictionary first_labels_set)  I calculate out-of-fold predictions (oof_y) which I use to estimate the lwlrap score. The test set is evaluated and averaged k=5 times. The evaluation is done using TestDataGenerator hence introducing some randomness and non-determinism (res_Y = model.predict_generator(test_gen, verbose=1)) The training process is optimizing categorical_crossentropy and monitors categorical_accuracy for termination. By using early stopping in each fold I implicitly introduce some overfitting on the validation set. I expect more stable estimation by using fixed number of iterations, but is is not my style :)  The whole kernel takes ~2 hours to train and a couple of minutes for inference if you use the pretrained weights I already attach.;Apache 2.0;https://www.kaggle.com/voglinio/keras-2d-model-5-fold-log-specgram-curated-only;1.0;['pattern', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cnn', 'rl', 'nn', 'ann'];['activation function', 'generation', 'train', 'fitting', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'rank', 'relu', 'labeled'];https://www.kaggle.com/c/freesound-audio-tagging-2019;0.694;0.418;2020-12-12 20:05:18;multiple data sources;['gpu'];Keras 2D model, 5-fold, log_specgram, curated only;Python notebook;2706.0;36;0.49530;0.49530
2018-12-14 17:01:49;General informationThis kernel is dedicated to EDA of Google Analytics Customer Revenue Prediction  competition as well as feature engineering. For now basic data is used and not data from BigQuery. In this dataset we can see customers which went to Google Merchandise Store, info about them and their transactions. We need to predict the natural log of the sum of all transactions per user. A continuation of this kernel can be found in this one it has more features, CV calculation and other things.;Apache 2.0;https://www.kaggle.com/artgor/eda-on-basic-data-and-lgb-in-progress;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'nn', 'ann'];['filter', 'regression', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/ga-customer-revenue-prediction;0.756;0.533;2020-12-12 20:08:17;Google Analytics Customer Revenue Prediction;['data visualization, exploratory data analysis, feature engineering'];EDA on basic data and LGB (in progress);Python notebook;12152.0;160;;
2018-10-11 11:34:27;"IntroductionKaggle describes this competition as follows: In this competition, you’re challenged to analyze a Google Merchandise Store (also known as GStore, where Google swag is sold) customer dataset to predict revenue per customer. Hopefully, the outcome will be more actionable operational changes and a better use of marketing budgets for those companies who choose to use data analysis on top of GA data. For each fullVisitorId in the test set, you must predict the natural log of their total revenue. Submissions are scored on the root mean squared error (RMSE).  This kernel contains an EDA, a Baseline LightGBM model, and also Screenshots of the app. Since I am familiar with Google Analytics and also have the Google Mechandising store setup as a property in my personal environment, I though it would be good to start with some screen shots of the actual application. In the comments, the question was raised ""how I did this"". Well, actually this is pretty easy to setup, and you can find out how to do that through this link: Learn by experimenting with data from the Google Merchandise Store.. However, once I really got started with the EDA, I increasingly found the large screenshots to become a bit distracting and I decided to separate these from the EDA and move them to an Appendix. To go straight to the screenshots: Appendix: Screenshots. Table of contents 1. Loading libraries and data  2. EDA  2.1 Missing data 2.2 The response variable; transactionRevenue 2.3 Time series and grouping by workday and by month 2.3.1 Time series of sessions and revenues by Date 2.3.2 Sessions and revenues by Workday 2.3.3 Sessions and revenues by Month   2.4 Channel grouping and the source/medium dimension 2.4.1 Channel grouping 2.4.2 The source/medium dimension   2.5 Operating system, browser and device category 2.5.1 Device category 2.5.2 Operating system 2.5.3 Browser   2.6 Pageviews, Bounces and Hits 2.6.1 Pageviews; all sessions. 2.6.2 Pageviews; only sessions with any transaction revenue. 2.6.3 Pageviews versus percent transactions 2.6.4 Bounces 2.6.5 Hits   2.7 Sessions, revenues and transactions by country   3. LightGBM Model  Appendix: Screenshots of the app";Apache 2.0;https://www.kaggle.com/erikbruin/google-analytics-eda-lightgbm-screenshots;1.0;['pattern', 'lightgbm'];['ner', 'ai', 'dl', 'gbm', 'gan', 'rl', 'ml', 'nn', 'ann'];['filter', 'test data', 'regression', 'train', 'model', 'label', 'predict', 'labeled'];https://www.kaggle.com/c/ga-customer-revenue-prediction;0.794;0.582;2020-12-12 20:08:17;Google Analytics Customer Revenue Prediction;['exploratory data analysis'];Google Analytics EDA + LightGBM + Screenshots;R notebook;37496.0;333;;
2018-09-25 13:14:09;LGBM (RF) starteraknowledgment: a quick hello at Olivier to whom I borrowed many lines of code;Apache 2.0;https://www.kaggle.com/fabiendaniel/lgbm-starter;1.0;['lightgbm', 'sklearn'];['ai', 'dl', 'gan', 'gbm', 'cv', 'rl'];['regression', 'train', 'model', 'label', 'predict', 'random forest'];https://www.kaggle.com/c/ga-customer-revenue-prediction;0.745;0.491;2020-12-12 20:08:17;Google Analytics Customer Revenue Prediction;[];LGBM starter;Python notebook;9162.0;89;0.00000;0.00000
2018-10-20 20:16:40;2.  Quick study: LGBM, XGB and Catboost  Hi, and welcome!  In this short kernel, we will: 1) run  baseline versions of LightGBM, XGBoost and Catboost  over the Google Analytics Customer Revenue Prediction Challenge dataset, 2)  present the offline rmse, the running time and the public score of each of them and 3) create a trivial linear ensemble obtaining a 1.6677 score in the public leaderboard.     Model Rounds Train RMSE Validation RMSE Train time Public Score     LightGBM 5000 1.505 1.60372  7min 48s 1.6717   XGBoost 2000 1.568 1.64924 54min 54s  1.6946   Catboost 1000 1.52184 1.61231 2min 24s 1.6722   Ensemble -- -- -- -- 1.6677    Result table from Conclusions section. This kernel is strongly based on these previous work:  LGBM (RF) starter [LB: 1.70] - Preprocessing is taken as-is from this awesome kernel by FabienDaniel. LightGBM + XGBoost + Catboost - LGBM, XGBoost and Catboost functions taken and ligerely adapted from this other awesome kernel by Samrat P.  The notebook has the following sections:  Preprocessing Models 2.1. LightGBM 2.2. XGBoost 2.3. Catboost   Ensemble and submissions Conclusions References;Apache 2.0;https://www.kaggle.com/julian3833/2-quick-study-lgbm-xgb-and-catboost-lb-1-66;1.0;['catboost', 'xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'dl', 'gbm', 'rl', 'nn', 'ml'];['filter', 'machine learning', 'regression', 'test data', 'train', 'fitting', 'model', 'label', 'gradient boosting', 'predict', 'decision tree'];https://www.kaggle.com/c/ga-customer-revenue-prediction;0.747;0.487;2020-12-12 20:08:17;Google Analytics Customer Revenue Prediction;['beginner, gradient boosting'];2 - Quick study: LGBM, XGB and Catboost [LB: 1.66];Python notebook;9530.0;85;;
2018-11-05 13:41:52;If you want see another interesting Kernels please check here https://www.kaggle.com/kabure/kernels Please, don't forget to upvote this Kernel to keep me motivated !;Apache 2.0;https://www.kaggle.com/kabure/exploring-the-consumer-patterns-ml-pipeline;1.0;['pattern', 'sklearn'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nn', 'ann'];['test data', 'train', 'model', 'layer', 'label', 'predict', 'understanding'];https://www.kaggle.com/c/ga-customer-revenue-prediction;0.787;0.596;2020-12-12 20:08:16;Google Analytics Customer Revenue Prediction;['data visualization, finance, e-commerce services'];Exploring the Consumer Patterns + ML Pipeline ;Python notebook;29604.0;419;;
2018-10-07 19:51:01;IntroductionNot much here except very simple features that build on the fact we know the future... In all time series competition where you're allowed to use future events the best features are time to next session for a given visitor. This competition is no exception. I left part of the features I already tested and don't seem to generalize... but what can we really trust here ?;Apache 2.0;https://www.kaggle.com/ogrellier/i-have-seen-the-future;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'gan', 'rl', 'nn', 'ann'];['train', 'model', 'filter', 'predict'];https://www.kaggle.com/c/ga-customer-revenue-prediction;0.752;0.531;2020-12-12 20:08:17;multiple data sources;[];I_have_seen_the_future;Python notebook;11029.0;155;;
2018-10-01 06:33:52;IntroductionIn this kernel I demonstrate how to create predictions at Session level and then use them at User level so that LighGBM can learn how to better sum individual session prediction. It is sort of mini stacker and to avoid leakage, we use GroupKFold strategy.;Apache 2.0;https://www.kaggle.com/ogrellier/teach-lightgbm-to-sum-predictions;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'gan', 'rl', 'nn', 'ann'];['train', 'model', 'filter', 'predict'];https://www.kaggle.com/c/ga-customer-revenue-prediction;0.764;0.545;2020-12-12 20:08:17;multiple data sources;[];Teach_LightGBM_to_Sum_Predictions;Python notebook;15167.0;190;;
2018-10-05 17:37:42;"IntroductionI believe the main issue we have in this challenge is not to predict revenues but more to get these zeros right since less than 1.3 % of the sessions have a non-zero revenue. The idea in this kernel is to classify non-zero transactions first and use that to help our regressor get better results. The kernel only presents one way of doing it. No special feature engineering or set of hyperparameters, just a code shell/structure ;-)";Apache 2.0;https://www.kaggle.com/ogrellier/using-classification-for-predictions;1.0;['lightgbm', 'sklearn'];['ai', 'dl', 'gbm', 'rl', 'nn', 'ann'];['filter', 'train', 'model', 'loss', 'label', 'predict', 'classification'];https://www.kaggle.com/c/ga-customer-revenue-prediction;0.744;0.5;2020-12-12 20:08:17;multiple data sources;[];using_classification_for_predictions;Python notebook;8830.0;100;0.00000;0.00000
2019-09-11 18:28:40;"Google Analytics Customer Revenue Prediction - Simple Exploration + LGBM Model LB 1.291Problem StatementThe 80/20 rule has proven true for many businesses–only a small percentage of customers produce most of the revenue. As such, marketing teams are challenged to make appropriate investments in promotional strategies. GStoreRStudio, the developer of free and open tools for R and enterprise-ready products for teams to scale and share work, has partnered with Google Cloud and Kaggle to demonstrate the business impact that thorough data analysis can have. In this kaggle competition,we are challenged to analyze a Google Merchandise Store (also known as GStore, where Google swag is sold) customer dataset to predict revenue per customer. File Descriptions train.csv - the training set - contains the same data as the BigQuery rstudio_train_set. test.csv - the test set - contains the same data as the BigQuery rstudio_test_set. sampleSubmission.csv - a sample submission file in the correct format. Contains all fullVisitorIds in test.csv.  Data Fields fullVisitorId- A unique identifier for each user of the Google Merchandise Store. channelGrouping - The channel via which the user came to the Store. date - The date on which the user visited the Store. device - The specifications for the device used to access the Store. geoNetwork - This section contains information about the geography of the user. sessionId - A unique identifier for this visit to the store. socialEngagementType - Engagement type, either ""Socially Engaged"" or ""Not Socially Engaged"". totals - This section contains aggregate values across the session. trafficSource - This section contains information about the Traffic Source from which the session originated. visitId - An identifier for this session. This is part of the value usually stored as the _utmb cookie. This is only unique to the user. For a completely unique ID, we should use a combination of fullVisitorId and visitId. visitNumber - The session number for this user. If this is the first session, then this is set to 1. visitStartTime - The timestamp (expressed as POSIX time).";Apache 2.0;https://www.kaggle.com/pavansanagapati/google-analytics-simple-exploration;1.0;['pattern', 'lightgbm', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'rl', 'nn', 'ann'];['filter', 'test data', 'regression', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/ga-customer-revenue-prediction;0.758;0.532;2020-12-12 20:08:17;Google Analytics Customer Revenue Prediction;['beginner, data visualization, exploratory data analysis, +1 moredata cleaning'];Google Analytics - Simple Exploration;Python notebook;12835.0;157;;
2018-09-14 18:17:19;Google Analytics Customer Revenue PredictionContents of this Kernel Problem Statement   Dataset Understanding   Exploration   Visitor Profile   Baseline Model    1. Problem StatementIn this competition, the aim is to analyze a Google Merchandise Store (also known as GStore, where Google swag is sold) customer dataset to predict revenue per customer. The results of predictions and analysis might lead to more actionable operational changes and a better use of marketing budgets for those companies who choose to use data analysis on top of GA data. This is the starter baseline kernel, I will be updating it frequently. As the first step, lets load the required libraries.;Apache 2.0;https://www.kaggle.com/shivamb/exploratory-analysis-ga-customer-revenue;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'gan', 'rl', 'nn', 'ann'];['filter', 'test data', 'regression', 'generation', 'train', 'model', 'label', 'predict', 'understanding'];https://www.kaggle.com/c/ga-customer-revenue-prediction;0.752;0.524;2020-12-12 20:08:17;Google Analytics Customer Revenue Prediction;['beginner, data visualization, exploratory data analysis'];Exploratory Analysis - GA Customer Revenue;Python notebook;10875.0;140;0.00000;0.00000
2018-12-16 10:37:33;Kernel Headlines Introduction and Crisp Methodology Data Analysis  imports Reading Data Features Descriptions ChannelGrouping_barchart date and visitStartTime_describe device_barchart geoNetwork_barchart socialEngagement_describe totals_line_violin visitNumber_line_violin_hist trafficSource_barchart fullVisitorId_qpercentile   Compound Features  Churn Rate and Conversion Rate revenue_datetime device_revenue   Basic Regression Preparing for More Evaluations and Tests Investigation of Feature Importance;Apache 2.0;https://www.kaggle.com/smasar/tutorial-preprocessing-processing-evaluation;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['regression', 'train', 'model', 'understanding', 'epoch', 'label', 'predict', 'recommend', 'resnet'];https://www.kaggle.com/c/ga-customer-revenue-prediction;0.751;0.496;2020-12-12 20:08:17;Google Analytics Customer Revenue Prediction;['beginner, exploratory data analysis'];Tutorial (Preprocessing, Processing, Evaluation);Python notebook;10610.0;95;;
2018-09-25 14:47:46;Objective of the notebook: In this notebook, let us explore the given dataset and make some inferences along the way. Also finally we will build a baseline light gbm model to get started. Objective of the competition: In this competition, we a’re challenged to analyze a Google Merchandise Store (also known as GStore, where Google swag is sold) customer dataset to predict revenue per customer.;Apache 2.0;https://www.kaggle.com/sudalairajkumar/simple-exploration-baseline-ga-customer-revenue;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'gan', 'rl', 'nn', 'ann'];['training data', 'test data', 'regression', 'train', 'model', 'validation data', 'label', 'predict'];https://www.kaggle.com/c/ga-customer-revenue-prediction;0.822;0.646;2020-12-12 20:08:16;Google Analytics Customer Revenue Prediction;['data visualization, exploratory data analysis'];Simple Exploration+Baseline - GA Customer Revenue;Python notebook;100366.0;1008;;
2020-09-21 11:15:50;Galaxies Morphology Classification Using CNNUsing the Galaxy-Zoo dataset available on kaggle: https://www.kaggle.com/c/galaxy-zoo-the-galaxy-challenge/data, we will exploit a Convolutional Neural Network to train a model for galaxy morphology classification.;Apache 2.0;https://www.kaggle.com/atogni85/galaxy-convnet;1.0;['tensorflow', 'keras'];['ner', 'ai', 'cnn', 'rl', 'nn', 'ml'];['neuron', 'train', 'model', 'neural network', 'epoch', 'layer', 'label', 'loss', 'relu', 'decision tree', 'classification', 'labeled', 'convolutional neural network', 'hidden layer'];https://www.kaggle.com/c/galaxy-zoo-the-galaxy-challenge;0.577;0.0;2020-12-12 20:08:34;multiple data sources;[];galaxy_convnet;Python notebook;307.0;0;;
2019-02-13 08:51:25;Research topic Name : Entity Coreference Resolutions - NLU Task   Note : Here, I have tried to giving full insight about this topic as much as possible.I have gather all information by research from the internet. so if I missed something suggest.   For this topic I will explaied here some basic so It will make it clear more to understand this topic   Index :1 .What is Coreference? | 2. Types of Coreference | 3.What is Coreference Resolutions? | 4. Research Paper Summary  1 .What is Coreference?  In Simple word, When two or more expression in the text refer to the same person or thing. they have same Coreference.;Apache 2.0;https://www.kaggle.com/ashishpatel26/research-summary-with-co-reference-resolutions;1.0;['pattern'];['ner', 'ai', 'nlu', 'dl', 'rl', 'ml', 'nlp', 'nn', 'ann'];['filter', 'machine learning', 'chatbot', 'training data', 'train', 'model', 'validation data', 'natural language processing', 'layer', 'reward', 'label', 'labeled', 'predict', 'understanding', 'natural language'];https://www.kaggle.com/c/gendered-pronoun-resolution;0.709;0.472;2020-12-12 20:09:27;multiple data sources;[];🇬.Research Summary with Co-reference Resolutions.🇬;Python notebook;3744.0;70;;
2019-03-24 06:16:09;Looks like Matei Ionita beated me to it. Check out his kernel here. I haven't read his kernel carefully yet, but it seems we have basically the same model design. However, his kernel uses Tensorflow and this one uses PyTorch. Since Matei Ionita alread did a great job explaining the workflow, I won't repeat the same thing here. I'll just let the code do the speaking and comment when necessary.;Apache 2.0;https://www.kaggle.com/ceshine/pytorch-bert-baseline-public-score-0-54;1.0;['pytorch', 'tensorflow'];['ai', 'nn', 'ml', 'rl'];['test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'labeled'];https://www.kaggle.com/c/gendered-pronoun-resolution;0.718;0.458;2020-12-12 20:09:27;Gendered Pronoun Resolution;['gpu, nlp'];[PyTorch] BERT Baseline (Public Score ~ 0.54);Python notebook;4664.0;58;;
2019-03-23 17:29:01;2019/03/23 Update:  Inspired by hanxiao/bert-as-service, the hidden states (context vectors) of the second-to-last layer is used instead of the ones from the last layer. Q: Why not the last hidden layer? Why second-to-last? A: The last layer is too closed to the target functions (i.e. masked language model and next sentence prediction) during pre-training, therefore may be biased to those targets. If you question about this argument and want to use the last hidden layer anyway, please feel free to set pooling_layer=-1.;Apache 2.0;https://www.kaggle.com/ceshine/pytorch-bert-endpointspanextractor-kfold;1.0;['pytorch', 'spacy', 'sklearn', 'nltk'];['ai', 'rl', 'ml', 'nlp', 'nn', 'ann'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'labeled', 'hidden layer'];https://www.kaggle.com/c/gendered-pronoun-resolution;0.704;0.435;2020-12-12 20:09:27;Gendered Pronoun Resolution;['gpu'];[PyTorch] BERT + EndpointSpanExtractor + KFold;Python notebook;3372.0;44;0.00000;0.00000
2019-04-04 06:25:26;The basic idea is from my kernel (https://www.kaggle.com/chanhu/bert-score-layer-lb-0-475). In this kernel, I had changed several points below.  keras -> pytorch(this is my second kernel wrote in pytorch) use pretrain Bert, EndpointSpanExtractor, and weight decay. (similar to Lee's work https://www.kaggle.com/ceshine/pytorch-bert-endpointspanextractor-kfold)  use kfold to get a robust score.(according to the comment from Matei Ionita, and huiqin. Thanks!)  P.S: the best I can get is 0.486.;Apache 2.0;https://www.kaggle.com/chanhu/bert-score-layer-kfold-weightdecay-0-486;1.0;['nltk', 'sklearn', 'pytorch', 'tensorflow', 'spacy', 'keras'];['ai', 'rl', 'nlp', 'nn', 'ml'];['test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/gendered-pronoun-resolution;0.69;0.352;2020-12-12 20:09:27;multiple data sources;['gpu, beginner, classification'];Bert+Score Layer+Kfold+WeightDecay(0.486);Python notebook;2434.0;17;;
2019-03-26 04:19:12;In this kernel, I try to use Pretrain Bert Model and Feed Forword Network. ※I am just starter for deep learning. If there are some mistakes, please comment.  used code from the kernel below to get word Embedding from pretrain Bert mode. https://www.kaggle.com/mateiionita/taming-the-bert-a-baseline  Inspired by https://arxiv.org/pdf/1805.04893v1.pdf and https://cs.stanford.edu/people/kevclark/resources/clark-manning-emnlp2016-deep.pdf. I assume that FFNN reduce A, B, Pronoun dimensions(from Bert)  and  only  keep  information relevant to coreference decisions.;Apache 2.0;https://www.kaggle.com/chanhu/bert-score-layer-lb-0-475;1.0;['spacy', 'tensorflow', 'sklearn', 'keras'];['ai', 'dl', 'cnn', 'rl', 'ml', 'nlp', 'nn', 'ann'];['train', 'model', 'epoch', 'deep learning', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/gendered-pronoun-resolution;0.722;0.467;2020-12-12 20:09:27;multiple data sources;['gpu, beginner, classification'];Bert +  Score Layer (LB 0.475);Python notebook;5108.0;65;;
2019-04-01 23:16:11;This is not my work.  It was forked from the pytorch bert baseline with .54 score. I have messed around with epochs, weight decay, and adding another fully connected layer in the head.;Apache 2.0;https://www.kaggle.com/gdoteof/pytorch-bert-baseline-wd-epochs-cnn-lstm;1.0;['pytorch'];['ai', 'nn', 'ml', 'rl'];['test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'labeled'];https://www.kaggle.com/c/gendered-pronoun-resolution;0.709;0.375;2020-12-12 20:09:27;Gendered Pronoun Resolution;['gpu'];[PyTorch] BERT Baseline +wd +epochs +layers;Python notebook;3729.0;22;;
2019-04-14 11:39:54;Here we simply run logistic regression with BERT embeddings. Code for building BERT embeddings for A, B, and pronoun is taken from this great Matei's Kernel.;Apache 2.0;https://www.kaggle.com/kashnitsky/simple-logistic-regression-bert-0-27-lb;1.0;['sklearn'];['ai'];['regression', 'train', 'model', 'layer', 'loss', 'label', 'logistic regression', 'predict'];https://www.kaggle.com/c/gendered-pronoun-resolution;0.738;0.462;2020-12-12 20:09:27;Gendered Pronoun Resolution;['gpu, nlp, logistic regression'];Simple logistic regression & BERT [0.27 LB];Python notebook;7578.0;61;;
2019-02-25 05:02:34;This kernel implements 4 DL models for coreference resolution. All the model in this kernel are Non-RNN Based DL models. Features extraction used in this kernel follows Clark and Mannings work: https://nlp.stanford.edu/pubs/clark2016improving.pdf If you are interested in RNN based End2End coreference solution model, please check this kernel: https://www.kaggle.com/keyit92/end2end-coref-resolution-by-attention-rnn.;Apache 2.0;https://www.kaggle.com/keyit92/coref-by-mlp-cnn-coattention;1.0;['nltk', 'theano', 'tensorflow', 'spacy', 'keras'];['ner', 'ai', 'dl', 'cnn', 'rl', 'ml', 'nlp', 'nn', 'rnn', 'ann'];['filter', 'train', 'model', 'epoch', 'layer', 'loss', 'predict', 'relu', 'natural language'];https://www.kaggle.com/c/gendered-pronoun-resolution;0.735;0.501;2020-12-12 20:09:27;multiple data sources;['deep learning, classification, neural networks'];Coref By MLP, CNN, Coattention;Python notebook;7082.0;102;0.00000;0.00000
2019-03-02 18:59:00;This Kernel implements a modified version of a state-of-art end-to-end neural correference resolution model published in 2017: https://www.aclweb.org/anthology/D17-1018. This completition only focus on a specific case of  the generic reference resolution problem, and we only need pick out the correct mention from two candidates, which simplifies the model implementation. You can compare the result of this model  with the result by other non-RNN based DL models implemented in another kernel: https://www.kaggle.com/keyit92/coreference-resolution-by-mlp-cnn-coattention-nn.;Apache 2.0;https://www.kaggle.com/keyit92/end2end-coref-resolution-by-attention-rnn;1.0;['nltk', 'theano', 'tensorflow', 'spacy', 'vocabulary', 'keras'];['ner', 'ai', 'dl', 'cnn', 'rl', 'ml', 'nlp', 'nn', 'rnn', 'ann'];['gru', 'test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'lstm', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/gendered-pronoun-resolution;0.698;0.416;2020-12-12 20:09:27;multiple data sources;['deep learning, neural networks, multiclass classification, +1 morernn'];End2End Coref Resolution By Attention RNN;Python notebook;2907.0;35;0.00000;0.00000
2019-03-02 10:51:13;Coreference resolution with fast.aiIn this notebook, we will explore ULMFiT approach to solve this task. With proper fine-tuning, you can get decent results in a matter of 20 minutes. Some 15 epochs of fine-tuning will get you up to 20-ish place. Changes in this version:  More civilized approach to validation. The model uses the representation of the last token of the entity instead of the first token. With a unidirectional encoder, this might be the right thing to do.  I will be grateful for any suggestions, especially about converting two logits/probabilities into the three classes without the need for an additional layer. Collect the data;Apache 2.0;https://www.kaggle.com/mamamot/fastai-awd-lstm-solution-0-71-lb;1.0;['spacy', 'sklearn'];['ner', 'ai', 'dl', 'nlp', 'nn', 'rnn'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'lstm', 'predict', 'relu', 'classification', 'hidden layer'];https://www.kaggle.com/c/gendered-pronoun-resolution;0.701;0.367;2020-12-12 20:09:27;Gendered Pronoun Resolution;['gpu, nlp, neural networks'];Fastai (AWD-LSTM) solution (~0.71 LB);Python notebook;3117.0;20;0.00000;0.00000
2019-03-06 17:18:55;"In this kernel, I'm trying to obtain a baseline for the following model:  Use a pre-trained version for the BERT transformer model to obtain contextual word embeddings for the 3 target words in each passage: A, B and Pronoun. Feed this into a multi-layer perceptron (MLP), which learns to solve the coreference resolution problem as a supervised classification task.  I'm using the GitHub repo for the BERT project  to obtain the pre-trained model. See also the BERT paper by Devlin et al. The idea for the architecture (1-2 above) comes from the paper ""What do you learn from context? Probing for sentence structure in contextualized word representations"" by Tenney et al. For coreference resolution, they use the OntoNotes and Definite Pronoun Resolution datasets, but not GAP. As such, the MLP hyperparameters they use may not be the best for our current task. The hyperparameters I use below are quite different from theirs. The data I'm using comes from the 3 GAP files available here. The gap-development file contains the same data as the test_stage_1 file that we're trying to make predictions on. Of course, gap-development also contains the true labels, but I'm not using these when making predictions. I only use the true labels to evaluate the predictions made by my model. The other two files, gap-test and gap-validation, are used for training the model. Updates V7: In the previous version, I was a little worried by the large variance of the model. The current version uses a much smaller MLP for the supervised classification problem, with more regularization. This achieves the same mean CV score, with lower variance. Specifically, the current MLP has:  only one hidden layer of size 37, down from two hidden layers of sizes [59,31] dropout rate of 0.6 in the hidden layer, up from 0.5 L2 regularization in the output layer of 0.1, up from 0.05  Ceshine Lee independently published a kernel with a very neat PyTorch implementation of the same idea. You can check it out here.";Apache 2.0;https://www.kaggle.com/mateiionita/taming-the-bert-a-baseline;1.0;['pytorch', 'tensorflow', 'sklearn', 'keras'];['ai', 'rl', 'cv', 'nn', 'ml'];['test data', 'train', 'model', 'output layer', 'neural network', 'epoch', 'validation data', 'layer', 'loss', 'label', 'predict', 'relu', 'classification', 'hidden layer', 'propagation'];https://www.kaggle.com/c/gendered-pronoun-resolution;0.763;0.531;2020-12-12 20:09:27;Gendered Pronoun Resolution;['gpu'];Taming the BERT - a baseline;Python notebook;14650.0;154;0.00000;0.00000
2019-03-10 22:06:56;"I've been wondering how far one can get in this competition using an unsupervised learning approach. So I decided to play with the contextual embeddings I obtained from BERT in my previous kernel, and try to make predictions without having a training set with ground truth labels. Spoiler alert: I didn't get very far, the best score I could get was around 0.93. Still, I think it's instructive to visualize some of the output of BERT. Specifically, I'm looking at:  The Euclidean distance d(A,P) between the embeddings of the Pronoun and the target word A. The Euclidean distance d(B,P). The Euclidean distance d(A,B) between the two target words.  This is low-dimensional information that you can plot, and then use to make predictions for the coreference resolution problem. The simplest approach would be:  If d(A,B) is large compared to d(A,P) and d(B,P), in a sense that will be made precise later, classify the data as ""Neither"". Otherwise, if d(A,P) < d(B,P), classify the data as ""A"". If d(A,P) > d(B,P), classify the data as ""B"".  This is more or less what I do below. To obtain class probabilities, I pass the distances through a softmax function.";Apache 2.0;https://www.kaggle.com/mateiionita/visualizing-bert-plus-an-unsupervised-solution;1.0;['sklearn'];['ai', 'nn', 'ml'];['train', 'model', 'supervised learning', 'loss', 'label', 'predict', 'unsupervised learning', 'classification', 'ground truth'];https://www.kaggle.com/c/gendered-pronoun-resolution;0.688;0.397;2020-12-12 20:09:27;multiple data sources;[];Visualizing BERT, plus an unsupervised solution;Python notebook;2352.0;28;0.00000;0.00000
2019-04-11 02:28:16;A non-neural baselineIn this kernel I match the baseline introduced here. Unlike in my previous kernel, I use spaCy for parsing, whose data structures are very easy to work with. Besides the parsing step, the model is completely non-neural and doesn't rely on word embeddings. As expected, it does not come close to the performance of modern deep transfer learning approaches. However, with some tweaking I was able to reach 0.57 log loss. Model architecture Build a global list of candidates using an entity recognizer and make sure both provided candidates are in there. Disqualify some candidates using well-understood grammatical constraints on coreference. Divide remaining candidates into 3 groups A, B, N based on what entity they are likely an instance of. For each group, compute some features based on testing its instances on metrics like prominence, locality, etc. Feed those features into a standard ensemble classifier.  Two take-aways: A major problem is the cascading effect of misparses. Obviously this is an inherent danger of using intermediate representations like dependency parses, and not directly training on the task at hand. A zillion manual tweaks are possible, and some have elegant spaCy implementations, but the return given the effort is rather slim. The thing the model did worst on is detecting cases where neither suggested candidate was correct. I wonder if that is specific to the approach here or if everyone is finding that to some extent.;Apache 2.0;https://www.kaggle.com/pheell/look-ma-no-embeddings;1.0;['spacy', 'xgboost', 'sklearn'];['ai', 'gan', 'rl', 'ml', 'nlp', 'nn', 'ann'];['filter', 'train', 'model', 'loss', 'label', 'predict', 'bayesian'];https://www.kaggle.com/c/gendered-pronoun-resolution;0.648;0.39;2020-12-12 20:09:27;Gendered Pronoun Resolution;[];Look ma, no embeddings!;Python notebook;1057.0;26;0.00000;0.00000
2019-02-18 05:22:10;Coreference visualization for jupyter notebooks (Code repository: https://github.com/sattree/gpr_pub) AllenNLP style highlighting of mention clusters (https://demo.allennlp.org/coreference-resolution/NjA2MjY3**) extended to stanford corenlp, huggingface, and pronoun resolutions  This notebook demonstrates two contributions made to the gpr visualization task:  Extend the visualization code logic for rendering in jupyter notebooks - allennlp functionality provides these visualizations only through a web app interface and is natively built in js. Extend the visualization api to cover and provide a uniform interface for stanford and huggingface coref apis, and to also handle pronoun resolution labels.  Visualization renderer has a displacy (spacy) style api interface, again aimed at maintaining uniformity in interfaces. I found allennlp entity highlighting and linking type of visualizations to be better suited for longer text snippets as opposed to the spacy dependency style visualizations offered by huggingface. This kernel is the first in a tri-series of self-contained installments to introduce the GPR problem.  Coref visualization Reproducing GAP results - achieves a logloss score of 0.84 A better baseline - without any training  By no means am I implying that this series is a comprehensive coverage of the problem. There are numerous wonderful kernels available in the competition to that effect. The aim of this series is to provide a good starting point for fellow participants to hit the ground running.;Apache 2.0;https://www.kaggle.com/sattree/1-coref-visualization-jupyter-allenlp-stanford;1.0;['vocabulary', 'nltk', 'mxnet', 'pytorch', 'spacy', 'pattern'];['ner', 'ai', 'dl', 'cnn', 'rl', 'ml', 'nlp', 'nn', 'rnn', 'ann'];['filter', 'train', 'model', 'layer', 'loss', 'label', 'lstm', 'predict', 'relu', 'ground truth'];https://www.kaggle.com/c/gendered-pronoun-resolution;0.705;0.421;2020-12-12 20:09:27;Gendered Pronoun Resolution;['data visualization, exploratory data analysis'];1. Coref visualization jupyter allenlp stanford...;Python notebook;3396.0;37;;
2019-04-06 16:13:32;I use the code from Introducing BERT with Tensorflow;Apache 2.0;https://www.kaggle.com/wochidadonggua/bert-finetuning-classifier;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'rl', 'nn'];['train', 'model', 'epoch', 'layer', 'label', 'loss'];https://www.kaggle.com/c/gendered-pronoun-resolution;0.668;0.357;2020-12-12 20:09:27;Gendered Pronoun Resolution;['gpu'];bert-finetuning-classifier;Python notebook;1561.0;18;;
2019-07-18 06:33:49;General informationThis is an unique competition: the first Kaggle competition with GAN! I have trained GANs only while going through courses, so I'm excited to try this!  The kernel is heavily based by this official tutorial: https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html;Apache 2.0;https://www.kaggle.com/artgor/dcgan-baseline;1.0;['pytorch'];['ner', 'ai', 'gan', 'ml', 'nn', 'ann'];['predict', 'train', 'model', 'epoch', 'label', 'loss', 'relu'];https://www.kaggle.com/c/generative-dog-images;0.716;0.463;2020-12-12 20:11:09;Generative Dog Images;['gpu'];DCGAN baseline;Python notebook;4416.0;62;;
2019-08-17 07:03:07;Pretrained Big GAN 128 - Scores LB 12In this kernel, we load Pretrained Big GAN 128 and have fun generating some dog images. It's amazing how accurate Big GAN generated dogs appear. Big GAN 128 was trained on the same set of dogs that we are using in Kaggle's Dog Competition. (Stanford Dogs are a subset of ImageNet Dogs). If we were allowed more than 9 hours to train, we could train Big GAN 128 in a Kaggle notebook/kernel and submit it as our competition solution!! Big GAN 128 scores an amazing LB 12!! (Since we need to turn on internet to download pretrained network weights, the outputted images from this notebook/kernel cannot be submitted). Big GAN 128 can produce 1000 different classes of images. A full list is here. For example class 472 is a canoe and class 71 is a scorpion. Try changing the code below to see images besides dogs. Furthermore you can do latent walks between different classes. As an example I morph dogs into cats below. Dogs are classes 151 thru 280 and cats are 281 thru 293. You can read a blog about Big GAN here. A paper descibing Big GAN is here. We download Big GAN from GitHub here;Apache 2.0;https://www.kaggle.com/cdeotte/big-gan-128-lb-12;1.0;['pytorch', 'tensorflow'];['ner', 'ai', 'dl', 'gan', 'rl', 'nn', 'ann'];['generation', 'train', 'model', 'reward', 'layer', 'predict'];https://www.kaggle.com/c/generative-dog-images;0.686;0.453;2020-12-12 20:11:09;multiple data sources;['gpu'];Big GAN 128 - [LB 12];Python notebook;2234.0;55;;
2019-07-23 17:21:33;"Dog AutoencoderIn this kernel, we learn about autoencoders. By understanding autoencoders, we will better understand GANs (Generative Adversarial Networks) and VAEs (Variational Autoencoders). We will also learn how to use an autoencoder to generate images of dogs.  Kaggle's ""Generative Dog Images"" competition asks us to generate dog images using generative methods. It is unclear whether we must use GANs. If we must use GANs, then this kernel's output is not a valid competition submission. Load Data and AugmentWe will randomly crop the original 20,000 images and make 500,000 new training images.";Apache 2.0;https://www.kaggle.com/cdeotte/dog-autoencoder;1.0;['tensorflow', 'keras'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml'];['autoencoder', 'predict', 'training data', 'generation', 'train', 'model', 'epoch', 'layer', 'loss', 'relu', 'understanding', 'generative adversarial network'];https://www.kaggle.com/c/generative-dog-images;0.741;0.493;2020-12-12 20:11:09;Generative Dog Images;['gpu'];Dog Autoencoder;Python notebook;8178.0;92;;
2019-08-16 19:09:08;"Conditional Dog Breed GANThis kernel is a A-C-Ra-LS-DC-GAN. Whoa that's a lot of letters! The A if for Auxiliary Classifier. The C is for Conditional GAN. The Ra is for Relativistic Average GAN. The LS is for Least Squares GAN. The DC is for Deep Convolutional GAN!  Conditional GANs are fun! When we train our GAN, we can associate each image (and seed) with one or more labels (classes). Afterwards, we can request our Generator to draw a dog with certain labels. For example, we can label every training image as either ""facing left"", ""facing center"", or ""facing right"". This is categorical feature one. Next we label every training image as either ""short hair"", ""long hair"", or ""no hair"". This is categorical feature two. Then we can ask our Generator to draw a dog that is ""facing left"" and has ""long hair"". Fun, right?! In this kernel, we will use one categorial feature, namely breed. After training our GAN, we can ask our Generator to draw a specific breed of dog! Keep in mind that this kernel is a work in progress. The GAN architecture and/or hyperparameters are not neccessarily optimal. Similar to most of you, I'm learning this stuff too. I encourage everyone to fork this kernel and improve it. UPDATE v17Kernel version 16 scores LB 100. This version scores LB 52. In addition to small changes, the following big changes were made:  Crop original images with square inside bounding box plus padding (80x80) Use data augmentation, random crops (64x64) Use dense layer of 121 sigmoid units before output unit Compute classification error on dense layer and add to discriminator's loss Compile training loop as tf.function for 2x speedup  Load and Crop Images";Apache 2.0;https://www.kaggle.com/cdeotte/dog-breed-acgan-lb-52;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nn', 'ann'];['generation', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/generative-dog-images;0.716;0.475;2020-12-12 20:11:09;multiple data sources;['gpu'];Dog Breed ACGAN - [LB 52];Python notebook;4382.0;72;;
2019-07-06 16:06:07;Dog Memorizer GANDISCLAIMER: This may not be a valid comp solutionIn this kernel we attempt to create a new kind of semi-supervised GAN. (Typical GAN design is presented in Nanashi's great tutorial here). Instead of having the Generator and Discriminator learn at the same time, we will first train the Discriminator to memorize all the training images. Next the Discriminator will teach the images to the Generator. We give the Generator poor memory (with a bottleneck) in hopes that it will learn to generalize. For our Kaggle submission, we will ask this Generator to output a mixture of (the generalized) images it has learned. Since the images are stored in a conv net, we hope to get a generalized conceptual mixture (versus a pixel blend). (This kernel is inspired by the tutorial here and by my previous kernels here and here).  A GAN consists of a Generator and Discriminator. After being trained, a Generator is a robot artist that draws dog images. During training the Discriminator teaches the Generator how to draw a dog. (And typically the G teaches the D to disguish real from fake dogs). The Generator never sees any images of dogs. Instead it continually attempts to draw a dog and is coached by the Discriminator. In this kernel, the Memorizer Generator is coached to memorize images from the training set. (We hope generalization arises from poor memory). In contrast, a Generalizing Generator is coached to generalize images! Load and Crop Images;Apache 2.0;https://www.kaggle.com/cdeotte/dog-memorizer-gan;1.0;['tensorflow', 'keras'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nn', 'ann'];['predict', 'training data', 'generation', 'train', 'model', 'epoch', 'layer', 'loss', 'generative adversarial network'];https://www.kaggle.com/c/generative-dog-images;0.767;0.553;2020-12-12 20:11:09;multiple data sources;['gpu'];Dog Memorizer GAN;Python notebook;16300.0;214;;
2019-07-11 06:00:25;Supervised Generative Dog NetworkDo GANs (Generative Adversarial Networks) memorize images or generalize images? This is a heavily debated question and it's hard to determine what a GAN is actually doing. If a GAN memorizes images, then choosing random seeds in latent space creates basic blends of training images. If a GAN generalizes images, then choosing random seeds produces exciting images that utilize patterns and components from training images but are not simple blend images. In this kernel, using supervision, we force a Generative Network (half a GAN) to memorize images. (A full Memorizing GAN is posted here). We then demonstrate that moving in a straight line through latent space produces a sequence of basic blended images instead of producing a sequence of exciting generalized images. (Exciting latent walk images can be seen here). (More information about latent walks can be found here in section 6.1) Load and Crop ImagesThank you Paulo Pinto for posting code to retrieve bounding box info here. Using bounding box information, we can crop dogs from the images. Below we can either create crops with dogs only or randomly crop full images using boolean DogsOnly = True.;Apache 2.0;https://www.kaggle.com/cdeotte/supervised-generative-dog-net;1.0;['pattern', 'tensorflow', 'keras'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nn', 'ann'];['autoencoder', 'predict', 'training data', 'generation', 'train', 'model', 'epoch', 'layer', 'loss', 'generative adversarial network'];https://www.kaggle.com/c/generative-dog-images;0.763;0.558;2020-12-12 20:11:09;Generative Dog Images;['gpu, computer vision'];Supervised Generative Dog Net;Python notebook;14587.0;230;;
2019-07-23 15:00:10;DCGAN (Deep convolutional generative adversarial networks)  Estable version V50;Apache 2.0;https://www.kaggle.com/jesucristo/introducing-dcgan-dogs-images;1.0;['tensorflow'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['activation function', 'filter', 'regression', 'generation', 'train', 'model', 'input layer', 'output layer', 'neural network', 'epoch', 'layer', 'gradient descent', 'loss', 'label', 'predict', 'relu', 'generative adversarial network'];https://www.kaggle.com/c/generative-dog-images;0.73;0.483;2020-12-12 20:11:09;Generative Dog Images;['gpu'];Introducing DCGAN Dogs Images;Python notebook;6218.0;80;;
2019-07-12 07:09:57;"Memorizer CGAN for dummies You're going to see:  GANs and CGANs How to destroy the FID metric. Best FID MiFID Penalization     How Supervised GANs work and how to improve it. Discriminator memory test. Tricks to avoid MiFID Penalization.    From a noob point of view ;) This kernel is obviously based on: Dog Memorizer GAN , is pure knowledge so please upvote it, and the post Memorization GAN Explained As you can check here: Rules clarification on Generative Models this method is allowed.  If you are interested in these kind of explanations, I can publish a kernel about my Private LB simulation (Private Dataset and Private NN). So, if this helps you, don't forget to upvote   :)";Apache 2.0;https://www.kaggle.com/jesucristo/memorizer-cgan-for-dummies;1.0;['tensorflow', 'keras'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nn', 'ann'];['training data', 'generation', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'generative adversarial network'];https://www.kaggle.com/c/generative-dog-images;0.724;0.491;2020-12-12 20:11:09;multiple data sources;['gpu'];Memorizer CGAN for dummies;Python notebook;5394.0;89;;
2019-08-12 13:07:07;"Pytorch Rals-C-SAGAN Ra - Relativistic Average; Ls - Least Squares; C - Conditional; SA - Self-Attention; DCGAN - Deep Convolutional Generative Adversarial Network   References:  https://www.kaggle.com/speedwagon/ralsgan-dogs https://www.kaggle.com/cdeotte/dog-breed-cgan https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/cgan/cgan.py https://github.com/voletiv/self-attention-GAN-pytorch/blob/master/sagan_models.py";Apache 2.0;https://www.kaggle.com/mpalermo/pytorch-rals-c-sagan;1.0;['pytorch', 'tensorflow'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nn', 'ann'];['train', 'model', 'epoch', 'layer', 'label', 'loss', 'relu', 'recommend', 'generative adversarial network'];https://www.kaggle.com/c/generative-dog-images;0.702;0.435;2020-12-12 20:11:09;Generative Dog Images;['gpu'];Pytorch RaLS-C-SAGAN;Python notebook;3197.0;44;131.18994;82.54667
2019-08-15 23:21:03;"Imagine if we had access to the true data distribution Pdata(x) we could sample from that distribution in order to generate new samples, however there is no direct way to do this as typically this distribution is complex and high-dimensional. What if we could instead sample from a random noise (e.g. Normal distribution) and then learn to transform that to Pdata(x). Neural networks are a prime candidate to capture functions with high complexity and we can use to to capture this transformation. This is exactly what the do. They train the transformer network or Generator along with another network, called the Discriminator, in a game theoretic way. Going back to our image generation example: The Generator network (G), tries to fool the discriminator in thinking that the generated images are real,meaning that they are taken from Pdata, and The Discriminator network (D), tries to differentiate between real (x∼Pdata) and fake images. Random noise is fed into the Generator that transforms it into a ""fake image"". The Discriminator is fed both from the training set images (pdata(x)) and the fake images coming from the Generator and it has to tell them apart. The idea behind GAN, is to train both of these networks alternatively to do the best they can in generating and discriminating images. The intuition is that by improving one of these networks, in this game theoretic manner, the other network has to do a better job to win the game, and that in turn improves its performance and this loop continues.";Apache 2.0;https://www.kaggle.com/roydatascience/introduction-to-generative-adversarial-networks;1.0;['tensorflow', 'keras'];['ner', 'ai', 'gan', 'rl', 'ml', 'nn', 'ann'];['filter', 'training data', 'generation', 'train', 'model', 'neural network', 'epoch', 'layer', 'loss', 'predict', 'relu', 'generative adversarial network'];https://www.kaggle.com/c/generative-dog-images;0.741;0.504;2020-12-12 20:11:09;Generative Dog Images;['gpu'];Introduction to Generative Adversarial Networks;Python notebook;8132.0;106;;
2019-07-13 13:13:16;Architecture was taken from https://github.com/ozanciga/gans-with-pytorch  UPD: corrected loss function as was mentioned here;Apache 2.0;https://www.kaggle.com/speedwagon/ralsgan-dogs;1.0;['pytorch'];['ner', 'ai', 'gan', 'nn', 'ann'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/generative-dog-images;0.738;0.504;2020-12-12 20:11:09;Generative Dog Images;['gpu, deep learning, gan'];RaLSGAN dogs;Python notebook;7586.0;106;158.08668;81.60226
2016-11-12 08:59:04;This is a fun Halloween competition. We have some characteristics of monsters and the goal is to predict the type of monsters: ghouls, goblins or ghosts. At first I do data exploration to get some insights. Then I try various models for prediction.;Apache 2.0;https://www.kaggle.com/artgor/eda-and-models-score-0-74291;1.0;['xgboost', 'sklearn'];['ai', 'dl', 'cv', 'nn', 'ann'];['regression', 'train', 'model', 'loss', 'label', 'logistic regression', 'predict', 'rank', 'recommend'];https://www.kaggle.com/c/ghouls-goblins-and-ghosts-boo;0.704;0.362;2020-12-12 20:12:33;Ghouls, Goblins, and Ghosts... Boo!;[];EDA and models. Score 0.74291;Python notebook;3353.0;19;;
2016-11-10 04:53:54;How Standardization improves prediction with Logistic Regression - 11/09/2016;Apache 2.0;https://www.kaggle.com/lilyelizabethjohn/standardization-using-standardscaler;1.0;['sklearn'];['ai', 'nn', 'cv'];['test data', 'regression', 'train', 'model', 'validation data', 'logistic regression', 'predict'];https://www.kaggle.com/c/ghouls-goblins-and-ghosts-boo;0.772;0.357;2020-12-12 20:12:33;Ghouls, Goblins, and Ghosts... Boo!;[];Standardization using StandardScaler;Python notebook;19266.0;18;;
2018-08-13 11:08:16;Hi, this is my first notebook. I'm trying to help newbies like myself to get started with machine learning and simple classifications problems. Let's start by importing the dataset, and verify if there is any column with missing values.;Apache 2.0;https://www.kaggle.com/netopedro/nn-approach-to-ghouls-goblins-and-ghosts;1.0;['sklearn'];['ai', 'dl', 'cv', 'rl', 'nn', 'ml'];['machine learning', 'train', 'model', 'neural network', 'layer', 'label', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/ghouls-goblins-and-ghosts-boo;0.599;0.236;2020-12-12 20:12:33;Ghouls, Goblins, and Ghosts... Boo!;['beginner, classification, feature engineering'];"NN Approach to ""Ghouls, Goblins, and Ghosts """;Python notebook;438.0;5;;
2016-11-12 15:19:48;Monsters First CompThis is my first notebook on Kaggle.  I am creating it to explore the Kaggle environment.  Newcomers to Kaggle follow along with me as I learn how to use a Kaggle notebook.  I am also very new to machine learning and this looked like a fairly easy data set to start with So I am going to play with a few different classifiers. I found it very cool how SciKit Learn works and how easy it is to plug in a different classifier.;Apache 2.0;https://www.kaggle.com/quadmx08/monsters-first-submission;1.0;['sklearn'];['ai', 'nn', 'ml', 'rl'];['machine learning', 'random forest', 'train', 'model', 'neural network', 'predict', 'decision tree', 'classification'];https://www.kaggle.com/c/ghouls-goblins-and-ghosts-boo;0.639;0.253;2020-12-12 20:12:33;Ghouls, Goblins, and Ghosts... Boo!;[];Monsters First Submission;Python notebook;891.0;6;;
2018-12-10 07:57:11;Here is a simple MachineLearning notebook for beginners. The notebook includes: #### Feature Engineering #### Visualization #### Voting Classifier;Apache 2.0;https://www.kaggle.com/samratp/machine-learning-with-ghouls-goblins-and-ghosts;1.0;['sklearn'];['ner', 'ai', 'cv', 'rl', 'nn', 'ann'];['filter', 'training data', 'regression', 'test data', 'train', 'model', 'label', 'predict', 'classification'];https://www.kaggle.com/c/ghouls-goblins-and-ghosts-boo;0.724;0.427;2020-12-12 20:12:33;Ghouls, Goblins, and Ghosts... Boo!;['beginner, data visualization, exploratory data analysis, +1 moreclassification'];Machine Learning With Ghouls, Goblins and Ghosts;Python notebook;5371.0;40;0.72967;0.72967
2016-11-09 12:42:15;Let us explore the given data in this notebook through various visualisations.;Apache 2.0;https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-1;1.0;['sklearn'];['ai'];['train', 'label', 'test data'];https://www.kaggle.com/c/ghouls-goblins-and-ghosts-boo;0.622;0.281;2020-12-12 20:12:33;Ghouls, Goblins, and Ghosts... Boo!;[];Simple Exploration Notebook;Python notebook;658.0;8;;
2016-11-08 22:27:14;Yoann Boj5th November 2016My first notebook for this competition has reasonable results but they could be much better if I'd improve classification of Goblins. Let's see why it's so difficult to classify them !;Apache 2.0;https://www.kaggle.com/yoyocm/why-goblins-classification-is-so-weak;1.0;['pattern', 'sklearn'];['ai', 'nn', 'ann'];['regression', 'train', 'model', 'logistic regression', 'predict', 'rank', 'classification'];https://www.kaggle.com/c/ghouls-goblins-and-ghosts-boo;0.667;0.319;2020-12-12 20:12:33;Ghouls, Goblins, and Ghosts... Boo!;[];Why goblins classification is so weak !?;Python notebook;1532.0;12;;
2020-07-29 17:21:35;Improve on the state of the art in credit scoring by predicting the probability that somebody will experience financial distress in the next two years.The goal of this analysis is to build a model that borrowers can use to help make the best financial decisions.;Apache 2.0;https://www.kaggle.com/aashishbidap/credit-defaulter-probability;1.0;['xgboost', 'sklearn'];['ner', 'ai', 'dl', 'rl', 'nn'];['test data', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/GiveMeSomeCredit;0.523;0.152;2020-12-12 20:13:55;Give Me Some Credit;[];Credit Defaulter Probability;Python notebook;139.0;2;;
2020-07-18 03:41:04;Give me Some Credit: Predicting DefaultNote: There are certain improvisations which needs to be done and is in my mind but I have tried this as my 1st version of notebook. Also, please upvote this kernel since it will also help my enthusiasm to provide more learning to the larger group and deeply understand the nuances of predicting a default;Apache 2.0;https://www.kaggle.com/akshayjhawar/predicting-default-deep-learning-0-82-auc;1.0;['xgboost', 'lightgbm', 'theano', 'sklearn', 'tensorflow', 'keras'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'logistic regression', 'predict', 'relu', 'machine learning', 'train', 'epoch', 'classification', 'model', 'neural network', 'layer', 'loss', 'rank', 'understanding', 'decision tree', 'test data', 'regression', 'fitting', 'deep learning', 'label', 'gradient boosting', 'random forest'];https://www.kaggle.com/c/GiveMeSomeCredit;0.577;0.214;2020-12-12 20:13:55;multiple data sources;['deep learning, finance, banking'];Predicting Default | Deep Learning ~ 0.82 AUC;Python notebook;307.0;4;;
2020-04-18 16:50:25;Exploratory Data Analysis - Preparing for one of the top performing modelsIn this notebook, an exploratory data analysis is performed on Give Me Some Credit's training set and preprocessing steps will be listed. These preprocessing steps will be the preparatory work for training a XGBoost model on the dataset, which is able to attain private and public scores of 0.86756 and 0.86104 respectively. The private and public scores are ranked top 100 and top 130 respectively (at the point of time of submitting this notebook). More comprehensive README and Python scripts can be found at https://github.com/nicholaslaw/kaggle-credit-scoring Table of Contents Import Packages Import Data EDA Preprocessing Suggestions References;Apache 2.0;https://www.kaggle.com/nicholasgah/eda-credit-scoring-top-100-on-leaderboard;1.0;['xgboost'];['dl', 'ai', 'nn', 'rl'];['rank', 'model', 'train'];https://www.kaggle.com/c/GiveMeSomeCredit;0.709;0.397;2020-12-12 20:13:55;Give Me Some Credit;[];EDA - Credit Scoring, Top 100 on Leaderboard;Python notebook;3786.0;28;;
2020-09-28 10:55:53;*Mostly copied from https://www.kaggle.com/orange90/credit-scorecard-example and https://zhuanlan.zhihu.com/p/148102950. Thank orange90 for sharing. It is very helpful for a rookie in the area of credit risk management.;Apache 2.0;https://www.kaggle.com/qizhengqi/give-me-some-credit-qizhengqi;1.0;['xgboost', 'sklearn'];['ner', 'ai', 'dl', 'rl', 'nn'];['regression', 'train', 'model', 'label', 'predict', 'classification'];https://www.kaggle.com/c/GiveMeSomeCredit;0.503;0.152;2020-12-12 20:13:55;Give Me Some Credit;[];Give_Me_Some_Credit_qizhengqi;Python notebook;105.0;2;;
2020-04-28 09:29:59;Problem statement    -Predicting the probability that somebody will experience financial distress in the next two years.which can make banks a       guess at the probability of default, are use to determine whether or not a loan should be granted.;Apache 2.0;https://www.kaggle.com/sainikhilesh/give-me-some-credit-classification;1.0;['tensorflow', 'xgboost', 'sklearn'];['ai', 'dl', 'cv', 'rl', 'nn', 'ann'];['filter', 'test data', 'train', 'model', 'label', 'predict', 'random forest'];https://www.kaggle.com/c/GiveMeSomeCredit;0.616;0.214;2020-12-12 20:13:55;multiple data sources;[];Give Me Some Credit-Classification;Python notebook;589.0;4;;
2020-05-14 05:22:30;"Credit Scoring  First of all, Thank you for your interest in my notebook. If you feel useful please upvote for me. Thank you for your consideration. Introduction"" A credit score is a numerical expression based on a level analysis of a person's credit files, to represent the creditworthiness of an individual. A credit score is primarily based on a credit report, information typically sourced from credit bureaus.Lenders, such as banks and credit card companies, use credit scores to evaluate the potential risk posed by lending money to consumers and to mitigate losses due to bad debt. Lenders use credit scores to determine who qualifies for a loan, at what interest rate, and what credit limits. Lenders also use credit scores to determine which customers are likely to bring in the most revenue. The use of credit or identity scoring prior to authorizing access or granting credit is an implementation of a trusted system.Credit scoring is not limited to banks. Other organizations, such as mobile phone companies, insurance companies, landlords, and government departments employ the same techniques. Digital finance companies such as online lenders also use alternative data sources to calculate the creditworthiness of borrowers. "" 1  Overview of my solution  OutlineI. Preprocess 1,1. Replace mising value 1.2. Split data 1.3. Robust transform  II. Visualization 2.1. Heat map  2.2. Boxplot  III. OUTLIER-DETECTION 3.1. Why do we use Tukey's method ? 3.2. TUKEY’S METHOD  IV. Algorithm 4.1. Classifiers (Knn, Logistic regression, Naive Bayes, Random Forest, Decision Tree) 4.2. Random Undersampling 4.3. Random Oversampling 4.4. Lightgbm";Apache 2.0;https://www.kaggle.com/sentrankim/85-5-roc-auc-private-test;1.0;['tensorflow', 'lightgbm', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['training data', 'random forest', 'regression', 'train', 'fitting', 'model', 'understanding', 'loss', 'label', 'logistic regression', 'predict', 'decision tree', 'classification', 'naive bayes'];https://www.kaggle.com/c/GiveMeSomeCredit;0.6;0.152;2020-12-12 20:13:55;Give Me Some Credit;[];85.5% ROC_AUC Private Test;Python notebook;448.0;2;;
2018-12-06 06:03:06;Math 154: Group Data Project     Give Me Some Credit Kaggle Competition      Seena Huang, Cecelia Sanborn, Harry Bendekgey, Simon Posada Fishman;Apache 2.0;https://www.kaggle.com/simonpfish/comp-stats-group-data-project-final;1.0;['sklearn'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ml'];['regression', 'train', 'model', 'neural network', 'k-nearest neighbor', 'predict', 'random forest'];https://www.kaggle.com/c/GiveMeSomeCredit;0.747;0.433;2020-12-12 20:13:55;Give Me Some Credit;[];Comp Stats Group Data Project - Final ;Python notebook;9480.0;43;;
2020-07-25 19:31:58;GIVE ME SOME CREDITThis notebook is created 9 years after this competition ended. The main aim of this project is to predict the probabily whether a customer will default in the future given his record present in the dataset. We will be using predict_proba to determine the delinquency probabilities of the customer. The Highlights of the notebook are:  Exploratory Data Analysis **Outlier Analysis **Null Handling **Distribution Analysis **Skewness Reduction (using Box Cox Transformation)   Feature Engineering LightGBM using RandomizedSearchCV (Classification) Evaluation Metrics Mean Squared Error Root Mean Squared Error Mean Absolute Error Mean Squared Logarithmic Error Root Mean Square Logarithmic Error Accuracy on Training Set Accuracy on Test Set F-Beta Score (Beta = 2) F1 Score Precision Recall Confusion Matrix AUC Curve   Probability Prediction on Validation Sets Delinquency Prediction on Validation Sets Feature Importances Summary Plot SHAP Analysis     XGBoost using RandomizedSearchCV (Classification) Evaluation Metrics Mean Squared Error Root Mean Squared Error Mean Absolute Error Mean Squared Logarithmic Error Root Mean Square Logarithmic Error Accuracy on Training Set Accuracy on Test Set F-Beta Score (Beta = 2) F1 Score Precision Recall Confusion Matrix AUC Curve   Probability Prediction on Validation Sets Delinquency Prediction on Validation Sets Feature Importances Summary Plot SHAP Analysis      Let's begin with importing the libraries we will be requiring for this notebook;Apache 2.0;https://www.kaggle.com/uditnagar5/give-me-some-credit-eda-xgboost-lightgbm-shap;1.0;['catboost', 'xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'training data', 'test data', 'train', 'model', 'label', 'predict', 'classification'];https://www.kaggle.com/c/GiveMeSomeCredit;0.63;0.268;2020-12-12 20:13:55;Give Me Some Credit;['data visualization, exploratory data analysis, classification, +1 morefeature engineering'];Give Me Some Credit: EDA, XGBoost, LightGBM & SHAP;Python notebook;762.0;7;;
2020-06-17 20:51:48;Introduction Banks play a crucial role in market economies. They decide who can get financing and on what terms and can make or stop investment decisions. For markets and society to function, individuals and companies need access to credit. Credit scoring algorithms, which predict the probability of default, are the method used by banks to determine whether or not a loan should be granted.. objective Creation of a model in which he can try to predict the probability of the customer being able to repay the requested loan to the bank About Dataset  History of approx. 250,000 customers in which it was divided between training and test dataset Variable Name Description Type  Variable Description   SeriousDlqin2yrs Person experienced 90 days past due delinquency or worse Y/N   RevolvingUtilizationOfUnsecuredLines Total balance on credit cards and personal lines of credit except real estate and no installment debt like car loans divided by the sum of credit limits percentage   Age Age of borrower in years integer   NumberOfTime3059DaysPastDueNotWorse Number of times borrower has been 30-59 days past due but no worse in the last 2 years. integer   DebtRatio Monthly debt payments, alimony,living costs divided by monthy gross income percentage   MonthlyIncome Monthly income real   NumberOfOpenCreditLinesAndLoans Number of Open loans (installment like car loan or mortgage) and Lines of credit (e.g. credit cards) integer   NumberOfTimes90DaysLate Number of times borrower has been 90 days or more past due. integer   NumberRealEstateLoansOrLines Number of mortgage and real estate loans including home equity lines of credit integer   NumberOfTime60-89DaysPastDueNotWorse Number of times borrower has been 60-89 days past due but no worse in the last 2 years. integer   NumberOfDependents  Number of dependents in family excluding themselves (spouse, children etc.) integer;Apache 2.0;https://www.kaggle.com/vermillionz/hyperopt-lgbmclassifier-86-roc-auc-simple-eda;1.0;['tensorflow', 'lightgbm', 'sklearn'];['ai', 'dl', 'gbm', 'cv', 'rl', 'nn'];['filter', 'test data', 'random forest', 'train', 'model', 'loss', 'label', 'predict', 'classification'];https://www.kaggle.com/c/GiveMeSomeCredit;0.702;0.292;2020-12-12 20:13:55;Give Me Some Credit;[];Hyperopt + LGBMClassifier,Simple EDA;Python notebook;3188.0;9;;
2020-06-28 18:01:08;"General information To get large and accurate data about wheat fields worldwide, plant scientists use image detection of ""wheat heads""—spikes atop the plant containing grain. These images are used to estimate the density and size of wheat heads in different varieties. Farmers can use the data to assess health and maturity when making management decisions in their fields. However, accurate wheat head detection in outdoor field images can be visually challenging. There is often overlap of dense wheat plants, and the wind can blur the photographs. Both make it difficult to identify single heads. Additionally, appearances vary due to maturity, color, genotype, and head orientation. Finally, because wheat is grown worldwide, different varieties, planting densities, patterns, and field conditions must be considered. In this competition we detect wheat heads on images and return coordinates of bboxes and their confidence. You can see a repository with code (can be run as a script) here: https://github.com/Erlemar/wheat The metric is IoU:  It is calculated at at different thresholds from 0.5 to 0.75 with a step size of 0.05. My kernel is based on official tutorial: https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html and could intersect with this cool kernel by Peter: https://www.kaggle.com/pestipeti/pytorch-starter-fasterrcnn-train But this kernel I want to show you how to use Pytorch-Lightning framework for deep learning. I like the concept of this library and hope you will also find it useful. UPD: code updated for pytorch-lightning 0.7.6 Version 8: update pytorch-lightning to 0.8.1 and add various small fixes.";Apache 2.0;https://www.kaggle.com/artgor/object-detection-with-pytorch-lightning;1.0;['pytorch', 'albumentations', 'sklearn', 'pattern'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'test data', 'object detection', 'train', 'model', 'epoch', 'deep learning', 'loss', 'label', 'predict', 'rank', 'resnet'];https://www.kaggle.com/c/global-wheat-detection;0.761;0.526;2020-12-12 20:14:55;Global Wheat Detection;['gpu, deep learning'];Object Detection with Pytorch-Lightning;Python notebook;13983.0;145;;
2020-05-17 05:08:44;Awesome AugmentationIn this notebook I am going to share an agumentation resource for object detection that I found from this awesome project. It has a variety of selection to play. We can tweak around with it to get a very high score. I hope this notebook will save someone's time.;Apache 2.0;https://www.kaggle.com/nvnnghia/awesome-augmentation;1.0;['pytorch', 'albumentations', 'sklearn'];['ner', 'ai', 'cnn', 'cv', 'rl', 'nn'];['test data', 'object detection', 'train', 'model', 'epoch', 'label', 'predict', 'resnet'];https://www.kaggle.com/c/global-wheat-detection;0.748;0.535;2020-12-12 20:14:55;multiple data sources;['gpu'];Awesome Augmentation;Python notebook;9663.0;164;0.6435;0.7143
2020-05-09 13:31:57;# ** FasterRCNN Pseudo LabelingIn this nodebook, I am going to test the pseudo labeling for this dataset. The training data is small, therefore more data usually help.  I use a published fasterRCNN model and then continue train it for 3 more epochs with pseudo labeling.  By using this technique, I improve the LB from 0.6687 to 0.6937  You can find the train notebook here Inference notebook here The weights are available here  I also published 2 notebooks of centernet training and inference Centernet Training notebook ** Centernet Inference notebook Your upvotes will be my motivation to upgrade those notenote as I make improvements;Apache 2.0;https://www.kaggle.com/nvnnghia/fasterrcnn-pseudo-labeling;1.0;['pytorch', 'albumentations'];['ner', 'ai', 'cnn', 'cv', 'nn'];['predict', 'training data', 'test data', 'train', 'model', 'epoch', 'label', 'loss', 'resnet'];https://www.kaggle.com/c/global-wheat-detection;0.757;0.543;2020-12-12 20:14:55;Global Wheat Detection;[]; FasterRCNN Pseudo Labeling;Python notebook;12323.0;185;;
2020-05-05 16:04:02;Pytorch starter - FasterRCNN Inference You can find the train notebook here The weights are available here;Apache 2.0;https://www.kaggle.com/pestipeti/pytorch-starter-fasterrcnn-inference;1.0;['pytorch', 'albumentations'];['ner', 'ai', 'cnn', 'cv', 'nn'];['train', 'resnet', 'model', 'predict'];https://www.kaggle.com/c/global-wheat-detection;0.769;0.554;2020-12-12 20:14:55;multiple data sources;['gpu, computer vision'];Pytorch Starter - FasterRCNN Inference;Python notebook;17404.0;217;0.5975;0.6687
2020-05-05 16:19:56;Pytorch starter - FasterRCNN TrainIn this notebook I enabled the GPU and the Internet access (needed for the pre-trained weights). We can not use Internet during inference, so I'll create another notebook for commiting. Stay tuned! You can find the inference notebook here  FasterRCNN from torchvision Use Resnet50 backbone Albumentation enabled (simple flip for now);Apache 2.0;https://www.kaggle.com/pestipeti/pytorch-starter-fasterrcnn-train;1.0;['pytorch', 'albumentations'];['ner', 'ai', 'cnn', 'cv', 'nn'];['predict', 'train', 'model', 'epoch', 'label', 'loss', 'resnet'];https://www.kaggle.com/c/global-wheat-detection;0.795;0.608;2020-12-12 20:14:55;Global Wheat Detection;['gpu, computer vision'];Pytorch Starter - FasterRCNN Train;Python notebook;38528.0;514;;
2020-05-28 18:19:14;Scikit-Opt of WBF params for EfficientDetHi everyone! My name is Alex Shonenkov, I am DL/NLP/CV/TS research engineer. Especially I am in Love with NLP & DL. Recently I have created kernels for this competition:  WBF approach for ensemble [Training] EfficientDet [Inference] EfficientDet [OOF-Evaluation][Mixup] EfficientDet  Thank you all, my friends, for your support, I appreciate it.;Apache 2.0;https://www.kaggle.com/shonenkov/bayesian-optimization-wbf-efficientdet;1.0;['pytorch', 'albumentations', 'sklearn'];['ai', 'dl', 'cv', 'rl', 'nlp', 'nn', 'ml'];['train', 'model', 'label', 'predict', 'recommend', 'bayesian'];https://www.kaggle.com/c/global-wheat-detection;0.76;0.544;2020-12-12 20:14:55;multiple data sources;['gpu'];[Bayesian optimization WBF] EfficientDet;Python notebook;13690.0;187;0.6334;0.7375
2020-05-28 08:49:27;Inference EfficientDetHi everyone! My name is Alex Shonenkov, I am DL/NLP/CV/TS research engineer. Especially I am in Love with NLP & DL. Recently I have created kernel for this competition about Weighted Boxes Fusion:  WBF approach for ensemble  I hope it is useful for you, my friends! If you didn't read this kernel, don't forget to do it! :) Here I would like to share with you inference part for my training kernel:  [Training] EfficientDet;Apache 2.0;https://www.kaggle.com/shonenkov/inference-efficientdet;1.0;['pytorch', 'albumentations'];['nlp', 'ai', 'dl', 'cv'];['train', 'model', 'label', 'predict'];https://www.kaggle.com/c/global-wheat-detection;0.764;0.568;2020-12-12 20:14:55;multiple data sources;['gpu, deep learning, computer science, +1 moreresearch'];[Inference] EfficientDet;Python notebook;15030.0;270;0.6292;0.7193
2020-05-24 00:00:16;Out of fold evaluation for EfficientDetHi everyone! My name is Alex Shonenkov, I am DL/NLP/CV/TS research engineer. Especially I am in Love with NLP & DL. Recently I have created kernels for this competition:  WBF approach for ensemble [Training] EfficientDet [Inference] EfficientDet;Apache 2.0;https://www.kaggle.com/shonenkov/oof-evaluation-mixup-efficientdet;1.0;['pytorch', 'albumentations', 'sklearn'];['ai', 'dl', 'cv', 'rl', 'nlp', 'nn'];['train', 'model', 'epoch', 'label', 'predict', 'recommend'];https://www.kaggle.com/c/global-wheat-detection;0.762;0.542;2020-12-12 20:14:55;multiple data sources;['gpu, deep learning, computer science'];[OOF-Evaluation][Mixup] EfficientDet;Python notebook;14367.0;181;0.6462;0.7318
2020-05-26 20:24:50;Really good training pipeline for pytorch EfficientDetHi everyone! My name is Alex Shonenkov, I am DL/NLP/CV/TS research engineer. Especially I am in Love with NLP & DL. Recently I have created kernel for this competition about Weighted Boxes Fusion:  WBF approach for ensemble  I hope it is useful for you, my friends! If you didn't read this kernel, don't forget to do it! :) Today I would like to share really good training pipeline for this competition using SOTA EfficientDet: Scalable and Efficient Object Detection;Apache 2.0;https://www.kaggle.com/shonenkov/training-efficientdet;1.0;['pytorch', 'albumentations', 'sklearn'];['ai', 'dl', 'cv', 'nlp', 'nn', 'ann'];['filter', 'object detection', 'train', 'model', 'epoch', 'layer', 'label', 'loss'];https://www.kaggle.com/c/global-wheat-detection;0.801;0.621;2020-12-12 20:14:55;multiple data sources;['gpu, deep learning, computer science, +2 morecomputer vision, research'];[Training] EfficientDet;Python notebook;46636.0;647;;
2020-05-13 23:55:39;How to make stable ensemble in object detectionHi everyone! My name is Alex Shonenkov, I am DL/NLP/CV/TS research engineer. Especially I am in Love with NLP & DL. Today I would like to share with you, my friends, super easy technique for bbox postprocessing and making ensemble in object detection tasks. I spied this idea from really good russian competitions grandmaster Roman Solovyev ZFTurbo in this repository that I used in this kernel as dataset. original paper: Weighted Boxes Fusion: ensembling boxes for object detection models;Apache 2.0;https://www.kaggle.com/shonenkov/wbf-approach-for-ensemble;1.0;['pytorch', 'albumentations', 'sklearn'];['ner', 'ai', 'dl', 'cnn', 'cv', 'nlp', 'nn'];['object detection', 'train', 'fitting', 'model', 'label', 'predict', 'resnet', 'ground truth'];https://www.kaggle.com/c/global-wheat-detection;0.758;0.562;2020-12-12 20:14:55;multiple data sources;['gpu, deep learning'];WBF approach for ensemble;Python notebook;12716.0;244;0.5949;0.6735
2020-06-07 12:38:59;WBF approach over TTA for single model EfficientDetHi everyone! Thank you all, my friends, for reading my kernels about this competition:  WBF approach for ensemble [Training] EfficientDet [Inference] EfficientDet [OOF-Evaluation][Mixup] EfficientDet [Bayesian optimization WBF] EfficientDet  All of them have got golden zone! It is crazy :) thank you! It means that kernels are useful for you, my friends! Welcome!;Apache 2.0;https://www.kaggle.com/shonenkov/wbf-over-tta-single-model-efficientdet;1.0;['pytorch', 'albumentations'];['ai', 'rl', 'cv'];['object detection', 'train', 'model', 'label', 'predict', 'understanding', 'bayesian'];https://www.kaggle.com/c/global-wheat-detection;0.737;0.526;2020-12-12 20:14:55;multiple data sources;['gpu'];[WBF over TTA][Single Model] EfficientDet;Python notebook;7422.0;145;0.6473;0.7294
2020-07-01 15:09:13;About this NotebookObject Detection is a problem which is not only a bit complex but also computationally expensive, due to the number of components to it. I always wanted to learn it and I got really excited when I saw a Kaggle competition on it , although I was not able to fully concentrate on it due to other competitions up untill now. While I was learning all the different concepts in Object Detection , I came across Facebook's Detection tranformer DETR , launched in April 2020 . It's still quite new but the resuts are astonishing and the model itself is very fast . In this notebook, I explore this new architecture,its working and fine tune it for Wheat Detection competition Dataset. Note that for now this is just a baseline to demonstrate the architecture and its working ,it does not aim at getting very good results on lb,this will be a work in progress,and I will soon update with full training and a separate;Apache 2.0;https://www.kaggle.com/tanulsingh077/end-to-end-object-detection-with-transformers-detr;1.0;['pytorch', 'albumentations', 'sklearn', 'detectron'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'nlp', 'nn'];['filter', 'object detection', 'generation', 'train', 'model', 'understanding', 'epoch', 'deep learning', 'loss', 'label', 'predict', 'recommend', 'resnet', 'classification', 'ground truth'];https://www.kaggle.com/c/global-wheat-detection;0.759;0.573;2020-12-12 20:14:55;Mean Average Precision;['gpu, deep learning'];End to End Object Detection with Transformers:DETR;Python notebook;13164.0;291;;
2020-07-31 16:54:57;Global Wheat Detection - Pseudo-labelingYou can get the training scripts here.  YOLOv3 from GluonCV Use Darknet53 backbone Use WBF over TTA Use multi-rounds pseudo-labeling technique;Apache 2.0;https://www.kaggle.com/ufownl/global-wheat-detection-pseudo-labaling;1.0;['mxnet'];['ner', 'ai', 'cv'];['predict', 'train', 'model', 'epoch', 'label', 'loss'];https://www.kaggle.com/c/global-wheat-detection;0.774;0.522;2020-12-12 20:14:55;multiple data sources;['gpu'];global-wheat-detection-pseudo-labaling;Python notebook;20513.0;137;;
2018-07-28 23:08:29;Analysis between New and Old Open Image Dataset;Apache 2.0;https://www.kaggle.com/aldrin644/analysis-between-new-and-old-open-image-dataset;1.0;['pillow'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'nn', 'ann'];['train', 'label'];https://www.kaggle.com/c/google-ai-open-images-object-detection-track;0.65;0.281;2020-12-12 20:15:53;multiple data sources;[];Analysis between New and Old Open Image Dataset;Python notebook;1088.0;8;;
2018-08-16 21:25:31;This is a baseline kernel, the purpose of this kernel to provide the insight of the competition. It is using Faster RCNN Inception Resnet v2 pretrained model on Old Open Image Dataset that contains 545 classes similar to New Open Image Dataset. I have done some analysis between old and new dataset's classes, checkout this kernel. I have used Model Zoo's utility files for object detection purpose.;Apache 2.0;https://www.kaggle.com/aldrin644/bounding-box-prediction-using-faster-rcnn-resnet;1.0;['tensorflow'];['ai', 'dl', 'cnn', 'cv', 'rl', 'nn'];['r-cnn', 'object detection', 'train', 'model', 'label', 'predict', 'resnet'];https://www.kaggle.com/c/google-ai-open-images-object-detection-track;0.757;0.379;2020-12-12 20:15:53;multiple data sources;['deep learning, image data, neural networks, +1 moretransfer learning'];Bounding box prediction using Faster RCNN Resnet;Python notebook;12571.0;23;;
2020-03-17 15:26:53;Object Detection using YOLOV3 This is a starter kernel, mainly for learning purposes and getting started. There is so much to learn more and improve. I am using YOLOv3 model for object classification and detection using a pretrained model. References: The ideas presented in this notebook came primarily from the two YOLO papers. The implementation here also took significant inspiration and used many components from Allan Zelener's github repository. The pretrained weights used in this exercise came from the official YOLO website. Check the speed of detection using YOLO! This detection algorithm will need some fine tuning if you want to run for large number of images. Goal is to demonstrate how YOLO3 performs object detection Joseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi - You Only Look Once: Unified, Real-Time Object Detection (2015) Joseph Redmon, Ali Farhadi - YOLO9000: Better, Faster, Stronger (2016) Allan Zelener - YAD2K: Yet Another Darknet 2 Keras The official YOLO website (https://pjreddie.com/darknet/yolo/);Apache 2.0;https://www.kaggle.com/kraisin/object-detection-using-yolov3;1.0;['tensorflow', 'keras'];['ner', 'ai', 'cv', 'ml', 'nn', 'ann'];['filter', 'object detection', 'train', 'model', 'neural network', 'layer', 'label', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/google-ai-open-images-object-detection-track;0.544;0.0;2020-12-12 20:15:53;Google AI Open Images - Object Detection Track;[];Object Detection using YOLOV3;Python notebook;188.0;0;;
2018-07-05 17:54:54;Detectors for Object detectionIn this problem, We are asked to do object detection on very large datasets (Open Image V4), here we have 1.7M images and annotations and have 100k images in test set. For doing computation on such a large datasets one will need multiple GPUs. I am listing some of the models that can be used for start working on this problem. The lastest model I am providing link to is of late 2016 and I hope better models are available openly. I will be providing links to following models -  Single Shot Multibox Yolo Faster RCNN;Apache 2.0;https://www.kaggle.com/maheshdadhich/detectors-for-object-detection;1.0;['py-faster-rcnn', 'caffe', 'tensorflow', 'keras'];['ner', 'ai', 'cnn', 'rl', 'nn', 'ann'];['train', 'model', 'classification', 'object detection'];https://www.kaggle.com/c/google-ai-open-images-object-detection-track;0.747;0.383;2020-12-12 20:15:53;Google AI Open Images - Object Detection Track;[];Detectors for Object detection;Python notebook;9533.0;24;;
2018-07-05 00:53:01;This is a baseline kernel. Dataset labels are checked for similarity with ImageNet labels followed by prediction with InceptionNet_v3 model. If a class is predicted with high (>0.5) probabiltly we make an assumtion that in the center of image there is object belonging to that class.;Apache 2.0;https://www.kaggle.com/mihaskalic/classifier-as-a-bounding-box-predictor;1.0;['tensorflow', 'keras', 'pillow'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'train', 'model', 'epoch', 'layer', 'label', 'predict'];https://www.kaggle.com/c/google-ai-open-images-object-detection-track;0.781;0.507;2020-12-12 20:15:53;multiple data sources;['gpu'];Classifier as a bounding-box predictor;Python notebook;25265.0;111;;
2018-07-09 08:34:15;Base line model to show how to use tf with Object detection API for inference on the open images datasetOverviewThis is my very first Kaggle kernel! So happy.... This kernel is a proof of concept for using the tf object detection api on the data. I have noticed that many people are detered by Kaggle inability to access the outside world (like colab) so they are not using pre-trained models. The way to do that is to upload the pre trained models as private dataset. In this case I used the goodle trained model from their zoo. It is exptremely slow (44 seconds per image) so on the test set would take.... would take... mmmm very long time. Data used in this kernelLabels for the open images dataset from https://github.com/tensorflow/models/blob/master/research/object_detection/data/oid_bbox_trainable_label_map.pbtxt) Models from: http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_resnet_v2_atrous_oid_14_10_2017.tar.gz http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_resnet_v2_atrous_oid_2018_01_28.tar.gz (I thought there were problems with the newer model but it turned out to be my mistake. The 2017 model is frcnn.pb, the 2018 is frcnn2.pb) I have also uploaded the tf models git as a dataset but haven't played with it directly. The model is faster rcnn with inception v2 as base. It is a very slow process but you can see how it performs on the leaderboard (with few tweaks) currently number 4;Apache 2.0;https://www.kaggle.com/moshel/baseline-object-detection-tf-faster-rcnn-pub;1.0;['tensorflow'];['ai', 'dl', 'cnn', 'cv', 'rl', 'nn'];['object detection', 'train', 'model', 'label', 'resnet'];https://www.kaggle.com/c/google-ai-open-images-object-detection-track;0.715;0.34;2020-12-12 20:15:53;multiple data sources;['gpu'];Baseline object detection tf faster rcnn pub;Python notebook;4334.0;15;;
2019-02-10 19:15:45;Object Detection using ImageAI - Resnet50 This is is starter kernel, mainly for learning purposes and getting started. There is so much to learn more and improve. I am using imageai package along with resnet50 pretrained model. For the baseline model, one can refer to a great kernel shared by Miha Skalic: Classifier as a bounding-box predictor;Apache 2.0;https://www.kaggle.com/muhammedfathi/objects-bounding-boxes-using-resnet50-my;1.0;['tensorflow', 'keras', 'pillow'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'nn', 'ann'];['object detection', 'train', 'model', 'label', 'predict', 'resnet'];https://www.kaggle.com/c/google-ai-open-images-object-detection-track;0.618;0.099;2020-12-12 20:15:53;multiple data sources;[];Objects + Bounding Boxes using Resnet50-my;Python notebook;606.0;1;;
2018-07-25 08:54:03;This is a baseline kernel. Dataset labels are checked for similarity with ImageNet labels followed by prediction with InceptionNet_v3 model. If a class is predicted with high (>0.5) probabiltly we make an assumtion that in the center of image there is object belonging to that class.;Apache 2.0;https://www.kaggle.com/nafisur/classifier-as-a-bounding-box-predictor;1.0;['tensorflow', 'keras', 'pillow'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'train', 'model', 'epoch', 'layer', 'label', 'predict'];https://www.kaggle.com/c/google-ai-open-images-object-detection-track;0.623;0.214;2020-12-12 20:15:53;multiple data sources;['gpu'];Classifier as a bounding-box predictor;Python notebook;664.0;4;;
2018-08-01 03:46:36;Object Detection using YOLOV3 This is a starter kernel, mainly for learning purposes and getting started. There is so much to learn more and improve. I am using YOLOv3 model for object classification and detection using a pretrained model. References: The ideas presented in this notebook came primarily from the two YOLO papers. The implementation here also took significant inspiration and used many components from Allan Zelener's github repository. The pretrained weights used in this exercise came from the official YOLO website. Check the speed of detection using YOLO! This detection algorithm will need some fine tuning if you want to run for large number of images. Goal is to demonstrate how YOLO3 performs object detection Joseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi - You Only Look Once: Unified, Real-Time Object Detection (2015) Joseph Redmon, Ali Farhadi - YOLO9000: Better, Faster, Stronger (2016) Allan Zelener - YAD2K: Yet Another Darknet 2 Keras The official YOLO website (https://pjreddie.com/darknet/yolo/);Apache 2.0;https://www.kaggle.com/sajinpgupta/object-detection-using-yolov3;1.0;['tensorflow', 'keras', 'pillow'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'object detection', 'train', 'model', 'neural network', 'layer', 'label', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/google-ai-open-images-object-detection-track;0.788;0.433;2020-12-12 20:15:53;multiple data sources;[];Object Detection using YOLOV3;Python notebook;31205.0;43;;
2018-07-11 05:15:54;Object Detection using YOLOV2 This is a starter kernel, mainly for learning purposes and getting started. There is so much to learn more and improve. I am using YOLOv2 model for object classification and detection using a pretrained model. I could not consolidate all the functions into a dataset and import in the Notebook so i had to put all the code here! Sorry about that. I am still new to Kaggle! Goal is to get an idea on how YOLO algorithm works in detail step by step. Hope this helps :-) References: The ideas presented in this notebook came primarily from the two YOLO papers. The implementation here also took significant inspiration and used many components from Allan Zelener's github repository. The pretrained weights used in this exercise came from the official YOLO website. Check the speed of detection using YOLO! Joseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi - You Only Look Once: Unified, Real-Time Object Detection (2015) Joseph Redmon, Ali Farhadi - YOLO9000: Better, Faster, Stronger (2016) Allan Zelener - YAD2K: Yet Another Darknet 2 Keras The official YOLO website (https://pjreddie.com/darknet/yolo/);Apache 2.0;https://www.kaggle.com/sajinpgupta/object-detection-yolov2;1.0;['tensorflow', 'keras'];['ner', 'ai', 'dl', 'nn', 'ann'];['filter', 'object detection', 'generation', 'train', 'model', 'layer', 'loss', 'label', 'predict', 'relu', 'classification', 'ground truth'];https://www.kaggle.com/c/google-ai-open-images-object-detection-track;0.767;0.379;2020-12-12 20:15:53;multiple data sources;['gpu'];Object Detection YOLOV2;Python notebook;16711.0;23;;
2018-08-03 01:37:16;This notebook is exact replica of sban's kernel Objects + Bounding Boxes using Resnet50 - ImageAI Only difference is that imageai now outputs bounding box points for detected objects in the image. This kernel reflects this update in the prediction string Many thanks to @sban;Apache 2.0;https://www.kaggle.com/shirishr/objects-bb-resnet50-imageai-thanks-to-sban;1.0;['tensorflow', 'keras', 'pillow'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'nn', 'ann'];['train', 'model', 'label', 'predict', 'resnet'];https://www.kaggle.com/c/google-ai-open-images-object-detection-track;0.671;0.236;2020-12-12 20:15:53;multiple data sources;['gpu, deep learning, image data'];Objects + BB + Resnet50 - ImageAI (thanks to sban);Python notebook;1667.0;5;;
2018-07-06 20:25:25;Object Detection using ImageAI - Resnet50 This is is starter kernel, mainly for learning purposes and getting started. There is so much to learn more and improve. I am using imageai package along with resnet50 pretrained model. For the baseline model, one can refer to a great kernel shared by Miha Skalic: Classifier as a bounding-box predictor;Apache 2.0;https://www.kaggle.com/shivamb/objects-bounding-boxes-using-resnet50-imageai;1.0;['tensorflow', 'keras', 'pillow'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'nn', 'ann'];['object detection', 'train', 'model', 'label', 'predict', 'resnet'];https://www.kaggle.com/c/google-ai-open-images-object-detection-track;0.79;0.491;2020-12-12 20:15:53;multiple data sources;['deep learning, image data, transfer learning'];Objects + Bounding Boxes using Resnet50 - ImageAI ;Python notebook;32545.0;89;;
2018-08-17 16:39:22;TensorFlow Object Detection API + Apache SparkThe goal of this notebook is to utilize TensorFlow Object Detection API [1] and provide insight on how to prepare the training files using Apache Spark [2]. TensorFlow Object Detection API is a research library maintained by Google that contains multiple pretrained, ready for transfer learning object detectors that provide different speed vs accuracy tradeoffs [3]. Examples include Faster R-CNN, YOLO and SSD.;Apache 2.0;https://www.kaggle.com/vsmolyakov/tensorflow-object-detection-api-apache-spark;1.0;['tensorflow', 'skimage'];['ner', 'ai', 'dl', 'cnn', 'rl', 'ml', 'nn', 'ann'];['r-cnn', 'filter', 'object detection', 'train', 'model', 'label', 'understanding', 'ground truth'];https://www.kaggle.com/c/google-ai-open-images-object-detection-track;0.756;0.403;2020-12-12 20:15:53;multiple data sources;['deep learning'];TensorFlow Object Detection API + Apache Spark;Python notebook;12132.0;30;;
2020-03-05 10:29:39;In this kernel I'm working with data from Google Cloud & NCAA® ML Competition 2019-Men's Challenge. We'll try to predict winners of NCAA based on previous tournaments! We have a lot of data, so let's start with EDA and then build a baseline model.;Apache 2.0;https://www.kaggle.com/artgor/march-madness-2020-ncaam-eda-and-baseline;1.0;['xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'training data', 'test data', 'train', 'model', 'loss', 'label', 'predict', 'rank', 'classification'];https://www.kaggle.com/c/google-cloud-ncaa-march-madness-2020-division-1-mens-tournament;0.722;0.492;2020-12-12 20:18:13;Google Cloud & NCAA® ML Competition 2020-NCAAM;['beginner, data visualization, exploratory data analysis, +1 moreclassification'];March Madness 2020 NCAAM EDA and baseline;Python notebook;5104.0;90;0.67377;0.67377
2020-03-04 11:21:45;2020 NCAA Men's and Women's Exploratory Data Analysis, All files explainedMarch Madness  is the collegiate men's and women's basketball tournaments in US, held by NCAA (National Collegiate Athletic Association). We will build a prediction model to predict which team wins for all combination of possible matchup. Large amount of historical data about college basketball games and teams are provided. This is 2 stage competition:  Stage 1 - You should submit predicted probabilities for every possible matchup in the past 5 NCAA® tournaments (seasons 2015-2019). Stage 2 - You should submit predicted probabilities for every possible matchup before the 2020 tournament begins.  I will also demonstrate how to get logloss=0 score for stage1. [Update] I wrote following kernels too, please check it as well!   2020 NCAAM: Fast data loading with feather  2020 NCAAW: Fast data loading with feather;Apache 2.0;https://www.kaggle.com/corochann/2020-ncaa-eda-all-files-explained;1.0;['catboost', 'xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'dl', 'gbm', 'gan', 'rl', 'ml', 'nn', 'ann'];['train', 'model', 'layer', 'loss', 'predict', 'rank', 'understanding', 'ground truth'];https://www.kaggle.com/c/google-cloud-ncaa-march-madness-2020-division-1-mens-tournament;0.681;0.408;2020-12-12 20:18:13;Google Cloud & NCAA® ML Competition 2020-NCAAM;['beginner, data visualization, exploratory data analysis'];2020 NCAA EDA: ALL files explained;Python notebook;2020.0;32;;
2020-02-15 10:17:11;overviewThis kernel is based on last year's Basic Starter Kernel.I added total score feature calculated on a yearly basis :);Apache 2.0;https://www.kaggle.com/hiromoon166/2020-basic-starter-kernel;1.0;['sklearn'];['ai', 'rl', 'cv', 'nn', 'ml'];['predict', 'training data', 'regression', 'test data', 'train', 'model', 'loss'];https://www.kaggle.com/c/google-cloud-ncaa-march-madness-2020-division-1-mens-tournament;0.676;0.416;2020-12-12 20:18:13;Google Cloud & NCAA® ML Competition 2020-NCAAM;[];2020 Basic Starter Kernel;Python notebook;1834.0;35;0.54999;0.54999
2020-02-25 06:01:25;NCAAM2020: XGBoost + LightGBM K-Fold Ensemble (Baseline);Apache 2.0;https://www.kaggle.com/khoongweihao/ncaam2020-xgboost-lightgbm-k-fold-baseline;1.0;['catboost', 'xgboost', 'sklearn', 'lightgbm'];['ai', 'gbm', 'cv', 'rl', 'nn', 'ml'];['training data', 'regression', 'train', 'model', 'loss', 'label', 'lstm', 'predict'];https://www.kaggle.com/c/google-cloud-ncaa-march-madness-2020-division-1-mens-tournament;0.718;0.446;2020-12-12 20:18:13;Google Cloud & NCAA® ML Competition 2020-NCAAM;[];NCAAM2020: XGBoost + LightGBM K-Fold (Baseline);Python notebook;4632.0;50;;
2020-02-24 20:34:45;Team power ranking idea and code is due to @raddar https://www.kaggle.com/raddar/team-power-rankings KenPom data is from @paulorzp https://www.kaggle.com/paulorzp/kenpom-scraper-2020;Apache 2.0;https://www.kaggle.com/latimerb/2020-model-comparison-no-leak-submission;1.0;['statsmodels', 'sklearn'];['ai', 'nn', 'ml'];['regression', 'train', 'model', 'layer', 'loss', 'logistic regression', 'predict', 'rank', 'random forest'];https://www.kaggle.com/c/google-cloud-ncaa-march-madness-2020-division-1-mens-tournament;0.659;0.371;2020-12-12 20:18:13;multiple data sources;[];2020 NCAAM Model Comparison;Python notebook;1306.0;21;0.50761;0.50761
2020-02-29 19:44:41;The goal of this notebook is to explore the data of both the Men's and Women's competitions and answering the following questions:  How did the game evolved over the years? What stats are most useful to predict the outcome of a game? What are the differences between the Men's and Women's competitions?  To do so, we need to produce some aggregated statistics. The next few hidden cells have all the functions to do just that.;Apache 2.0;https://www.kaggle.com/lucabasa/are-men-s-and-women-s-tournaments-different;1.0;['pattern', 'sklearn'];['ner', 'ai', 'cv', 'rl', 'ml', 'nn', 'ann'];['generation', 'train', 'model', 'loss', 'label', 'predict', 'rank'];https://www.kaggle.com/c/google-cloud-ncaa-march-madness-2020-division-1-mens-tournament;0.662;0.421;2020-12-12 20:18:13;multiple data sources;[];Are Men's and Women's tournaments different?;Python notebook;1383.0;37;;
2020-03-06 16:31:44;overviewThis kernel is based on last year's Basic Starter Kernel.I added total score feature calculated on a yearly basis :);Apache 2.0;https://www.kaggle.com/ratan123/march-madness-2020-ncaam-simple-lightgbm-on-kfold;1.0;['lightgbm', 'sklearn'];['ai', 'gbm', 'cv', 'rl', 'nn', 'ml'];['training data', 'regression', 'train', 'model', 'loss', 'label', 'predict'];https://www.kaggle.com/c/google-cloud-ncaa-march-madness-2020-division-1-mens-tournament;0.699;0.481;2020-12-12 20:18:13;Google Cloud & NCAA® ML Competition 2020-NCAAM;['beginner, classification, utility script'];March Madness 2020 NCAAM:Simple Lightgbm on KFold;Python notebook;2989.0;78;0.00000;0.00000
2020-03-17 21:39:54;Google Cloud & NCAA® ML Competition 2020-NCAAM;Apache 2.0;https://www.kaggle.com/vbmokin/mm-ncaam-no-leaks-lgb-xgb-logreg;1.0;['tensorflow', 'xgboost', 'sklearn', 'lightgbm'];['ai', 'gbm', 'gan', 'cv', 'rl', 'ml', 'nlp', 'nn', 'ann'];['filter', 'training data', 'regression', 'train', 'model', 'loss', 'label', 'logistic regression', 'predict'];https://www.kaggle.com/c/google-cloud-ncaa-march-madness-2020-division-1-mens-tournament;0.734;0.475;2020-12-12 20:18:13;Google Cloud & NCAA® ML Competition 2020-NCAAM;['classification, feature engineering'];MM NCAAM [No leaks]: LGB, XGB, LogReg;Python notebook;6801.0;72;0.56028;0.56028
2020-02-19 10:09:49;Welcome back to my kernel! This is my 'naive' approach for the Google Cloud & NCAA® ML Competition 2020-NCAAW  And as usual, if my work can make you feel excited, help me to upvote this kernel on the right corner 💖💖  P/s: I come from Vietnam, so please ignore my English grammar mistakes through out this notebook 😊😊;Apache 2.0;https://www.kaggle.com/warkingleo2000/eda-with-sparse-matrix;1.0;['pattern', 'catboost', 'lightgbm', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'gan', 'cv', 'nn', 'ml'];['filter', 'test data', 'train', 'model', 'loss', 'label', 'gradient boosting', 'predict', 'ground truth'];https://www.kaggle.com/c/google-cloud-ncaa-march-madness-2020-division-1-mens-tournament;0.673;0.403;2020-12-12 20:18:13;Google Cloud & NCAA® ML Competition 2020-NCAAM;['beginner, data visualization, exploratory data analysis'];EDA with sparse matrix 🐱;Python notebook;1711.0;30;0.17355;0.17355
2020-02-15 12:06:28;overviewThis kernel is based on hiromu 2020 Starter Kernel Women.I improve it using Random Forest RegressorPlease don't forget to upvote original kernel :);Apache 2.0;https://www.kaggle.com/a45632/2020-starter-kernel-women-improved;1.0;['sklearn'];['ai', 'nn', 'cv'];['filter', 'training data', 'test data', 'train', 'model', 'predict', 'random forest'];https://www.kaggle.com/c/google-cloud-ncaa-march-madness-2020-division-1-womens-tournament;0.615;0.292;2020-12-12 20:19:12;Google Cloud & NCAA® ML Competition 2020-NCAAW;['beginner, data visualization'];2020 Starter Kernel Women Improved;Python notebook;582.0;9;0.40199;0.40199
2020-02-21 13:20:11;OverviewThis kernel is based on 2020 Starter Kernel WomenI added my GBDT (+NN) pipelines to see the feature importance from LGB and CatBoost.Also see my starter for mens' games: https://www.kaggle.com/code1110/ncaam20-eda-and-lgb-catb-starter;Apache 2.0;https://www.kaggle.com/code1110/ncaaw20-eda-and-nn-lgb-catb-starter;1.0;['xgboost', 'lightgbm', 'catboost', 'sklearn', 'tensorflow', 'keras'];['ner', 'ai', 'gbm', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'regression', 'neuron', 'train', 'fitting', 'model', 'epoch', 'layer', 'relu', 'loss', 'label', 'predict', 'rank', 'classification', 'bayesian'];https://www.kaggle.com/c/google-cloud-ncaa-march-madness-2020-division-1-womens-tournament;0.66;0.34;2020-12-12 20:19:12;Google Cloud & NCAA® ML Competition 2020-NCAAW;[];[NCAAW20] EDA and NN+LGB+CatB starter;Python notebook;1322.0;15;0.22229;0.22229
2020-02-24 01:37:50;OverviewAs it has been pointed out in the discussion (e.g. https://www.kaggle.com/c/google-cloud-ncaa-march-madness-2020-division-1-mens-tournament/discussion/131028), most of the high scoring public kernels have a leak. That includes mine, apparently. The main cause of this is that they (intentionally or not) ignore the chronological order of the data. In this case you end up with having many cases where the future data are used by a model to predict the past, causing a leak. One way to avoid such situations is apparently to use only the past data to predict the future, like using only ~2018 to predict 2019. Here I implemented such a validation strategy. The log_loss in the end should be around 0.5 if you are truely successful, as is always the case with the winners in the past competitions.;Apache 2.0;https://www.kaggle.com/code1110/ncaaw20-finally-no-leak-starter-with-lgb;1.0;['xgboost', 'lightgbm', 'catboost', 'sklearn', 'tensorflow', 'keras'];['ner', 'ai', 'gbm', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'regression', 'train', 'fitting', 'model', 'layer', 'loss', 'label', 'predict', 'rank', 'classification', 'bayesian'];https://www.kaggle.com/c/google-cloud-ncaa-march-madness-2020-division-1-womens-tournament;0.615;0.319;2020-12-12 20:19:12;Google Cloud & NCAA® ML Competition 2020-NCAAW;[];[NCAAW20] (finally) no-leak starter with LGB;Python notebook;582.0;12;0.48157;0.48157
2020-02-29 15:11:24;OverviewThis kernel is based on 2020 Starter Kernel WomenI added my GBDT (+NN) pipelines to see the feature importance from LGB and CatBoost.Also see my starter for mens' games: https://www.kaggle.com/code1110/ncaam20-eda-and-lgb-catb-starter;Apache 2.0;https://www.kaggle.com/darwinwin/ncaaw20-eda-and-nn-lgb-catb-starter-7c65f8;1.0;['xgboost', 'lightgbm', 'catboost', 'sklearn', 'tensorflow', 'keras'];['ner', 'ai', 'gbm', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'regression', 'neuron', 'train', 'fitting', 'model', 'epoch', 'layer', 'relu', 'loss', 'label', 'predict', 'rank', 'classification', 'bayesian'];https://www.kaggle.com/c/google-cloud-ncaa-march-madness-2020-division-1-womens-tournament;0.529;0.236;2020-12-12 20:19:12;Google Cloud & NCAA® ML Competition 2020-NCAAW;[];[NCAAW20] EDA and NN+LGB+CatB starter 7c65f8;Python notebook;151.0;5;0.20489;0.20489
2020-02-29 15:24:19;Overview Objective of this kernel is to illustrate the impact the number of folds have on the public scores in NCAAW 2020 Folds to be illustrated: 10, 50, 100, 250, 500, 1000 Built-upon from kernels in NCAAM2020 & NCAAW2020: https://www.kaggle.com/code1110/ncaaw20-eda-and-nn-lgb-catb-starter https://www.kaggle.com/khoongweihao/ncaam2020-xgboost-lightgbm-k-fold-baseline https://www.kaggle.com/vbmokin/mm-2020-ncaam-lgb-xgb-linreg-tuning https://www.kaggle.com/ratan123/march-madness-2020-ncaam-simple-lightgbm-on-kfold https://www.kaggle.com/artgor/march-madness-2020-ncaam-eda-and-baseline   Warning: This kernel uses historical data, and its sole purpose is stated above. Do not use for scoring!;Apache 2.0;https://www.kaggle.com/darwinwin/ncaaw2020-lightgbm-k-fold-on-fire-viz;1.0;['xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'gbm', 'cv', 'rl', 'nn'];['filter', 'regression', 'train', 'fitting', 'model', 'loss', 'label', 'predict', 'rank', 'classification', 'bayesian'];https://www.kaggle.com/c/google-cloud-ncaa-march-madness-2020-division-1-womens-tournament;0.568;0.236;2020-12-12 20:19:12;Google Cloud & NCAA® ML Competition 2020-NCAAW;[];[NCAAW2020] LightGBM: K-fold on Fire (Viz);Python notebook;270.0;5;0.17343;0.17343
2020-02-21 19:29:04;OverviewThis kernel is based on 2020 Starter Kernel WomenI added my GBDT (+NN) pipelines to see the feature importance from LGB and CatBoost.Also see my starter for mens' games: https://www.kaggle.com/code1110/ncaam20-eda-and-lgb-catb-starter;Apache 2.0;https://www.kaggle.com/hamditarek/ncaaw20-eda-and-nn-lgb-catb-starter-7c65f8;1.0;['xgboost', 'lightgbm', 'catboost', 'sklearn', 'tensorflow', 'keras'];['ner', 'ai', 'gbm', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'regression', 'neuron', 'train', 'fitting', 'model', 'epoch', 'layer', 'relu', 'loss', 'label', 'predict', 'rank', 'classification', 'bayesian'];https://www.kaggle.com/c/google-cloud-ncaa-march-madness-2020-division-1-womens-tournament;0.611;0.311;2020-12-12 20:19:12;Google Cloud & NCAA® ML Competition 2020-NCAAW;[];[NCAAW20] EDA and NN+LGB+CatB starter 7c65f8;Python notebook;540.0;11;0.20404;0.20404
2020-02-15 10:33:13;overviewThis kernel is based on last year's Basic Starter Kernel.I added total score feature calculated on a yearly basis :);Apache 2.0;https://www.kaggle.com/hiromoon166/2020-women-s-starter-kernel;1.0;['sklearn'];['ai', 'rl', 'cv', 'nn', 'ml'];['predict', 'training data', 'regression', 'test data', 'train', 'model', 'loss'];https://www.kaggle.com/c/google-cloud-ncaa-march-madness-2020-division-1-womens-tournament;0.627;0.357;2020-12-12 20:19:12;Google Cloud & NCAA® ML Competition 2020-NCAAW;[];2020 Starter Kernel Women;Python notebook;711.0;18;0.44527;0.44527
2020-02-17 19:52:01;Neural Network Starter for NCAA March Madness Credits - https://www.kaggle.com/hiromoon166/2020-women-s-starter-kernel;Apache 2.0;https://www.kaggle.com/immvab/nn-starter-tensorflow;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'nn', 'ml'];['training data', 'train', 'model', 'neural network', 'epoch', 'layer', 'loss', 'label', 'predict', 'rank', 'relu'];https://www.kaggle.com/c/google-cloud-ncaa-march-madness-2020-division-1-womens-tournament;0.587;0.281;2020-12-12 20:19:12;Google Cloud & NCAA® ML Competition 2020-NCAAW;['gpu'];NN Starter Tensorflow;Python notebook;363.0;8;0.44785;0.44785
2020-02-23 04:30:11;Overview Objective of this kernel is to illustrate the impact the number of folds have on the public scores in NCAAW 2020 Folds to be illustrated: 10, 50, 100, 250, 500, 1000 Built-upon from kernels in NCAAM2020 & NCAAW2020: https://www.kaggle.com/code1110/ncaaw20-eda-and-nn-lgb-catb-starter https://www.kaggle.com/khoongweihao/ncaam2020-xgboost-lightgbm-k-fold-baseline https://www.kaggle.com/vbmokin/mm-2020-ncaam-lgb-xgb-linreg-tuning https://www.kaggle.com/ratan123/march-madness-2020-ncaam-simple-lightgbm-on-kfold https://www.kaggle.com/artgor/march-madness-2020-ncaam-eda-and-baseline   Warning: This kernel uses historical data, and its sole purpose is stated above. Do not use for scoring!;Apache 2.0;https://www.kaggle.com/khoongweihao/ncaaw2020-lightgbm-k-fold-on-fire-viz;1.0;['xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'gbm', 'cv', 'rl', 'nn'];['filter', 'regression', 'train', 'fitting', 'model', 'loss', 'label', 'predict', 'rank', 'classification', 'bayesian'];https://www.kaggle.com/c/google-cloud-ncaa-march-madness-2020-division-1-womens-tournament;0.679;0.34;2020-12-12 20:19:12;Google Cloud & NCAA® ML Competition 2020-NCAAW;[];[NCAAW2020] LightGBM: K-fold on Fire (Viz);Python notebook;1957.0;15;;
2020-05-01 01:43:02;Madness at Home and on the Court - Part 2Authors: Emilien Etchevers, Kieran Janin, Michael Karpe, Remi Le Thai, Haley Wohlever ContentsIn the first notebook  Introduction  NCAA March Madness Data Analysis Seeding and Entertainment Madness through Unpredictability Entertainment due to Closeness of Games    In this notebook  Tweets on NCAA Data Analysis Temporal Evolution of Engagement Team Mentions Count in Tweets Sentiment Analysis for Tweets on NCAA   Conclusion  3. Tweets on NCAA DataAfter thoroughly exploring the NCAA data, we decided to extend our analysis by studying relevant tweets published during the 2015 to 2019 NCAA March Madness tournaments. We built a database of 1.6 million tweets containing the word NCAA, using the GetOldTweets3 library. The dataset we built with this library is available here (as well as a processed version here to avoid memory issues). The purpose of this second part of our analysis is to identify trends in tweets published during and related to the competition. As discussed in Part 1, we want to distinguish an objective madness, explainable by match and player data, from a subjective madness that can be observed in the public sentiment surrounding the games. 3.1. Temporal Evolution of EngagementWe first study engagement on Twitter. Engagement on Twitter is defined by three types of actions: retweets, replies, and favorites (or likes). We plot the evolution of the number of each of these actions over the 21 days of the competition for each season, as well as the evolution of the number of tweets. While we can see that the number of tweets including the word NCAA tends to slightly decrease over the years (or at least remains constant), we can observe an increase in the number of retweets and replies over the years. We also note an even higher increase in the number of favorites, this latest observation showing that people tend to express themselves more and more using the favorites feature on Twitter.;Apache 2.0;https://www.kaggle.com/mika30/madness-at-home-and-on-the-court-part-2;1.0;['statsmodels', 'xgboost', 'sklearn', 'nltk'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['train', 'model', 'layer', 'loss', 'label', 'predict', 'rank', 'sentiment analysis', 'classification'];https://www.kaggle.com/c/google-cloud-ncaa-march-madness-2020-division-1-womens-tournament;0.618;0.302;2020-12-12 20:19:12;multiple data sources;[];Madness at Home and on the Court - Part 2;Python notebook;610.0;10;;
2020-03-09 12:36:20;Part 1 : Understanding the data March brings one of the most awaited events for sports fans in the US — The NCAA Women’s and Men’s Division 1 Tournament aka March madness. This brings the sport of basketball into the spotlight and many basketball fanatics get into the work of predicting the winners and rooting for their favorites. Basketball is a fairly popular game in the US and is ranked second to American football. However, for a person like me, who is born in India, my familiarity with March madness is on a lower side. Things would have been different if this were a competition for predicting IPL winners. The Indian Premier League (IPL) is a professional Twenty20 cricket league in India contested during March or April and May of every year by eight teams representing eight different cities in India. So, before exploring the dataset, I shall first explain the whole concept of NCAA March Madness and how the format is designed. Hopefully, this will help the people to actually understand a large amount of dataset and not be daunted by it. NCAA Division I Basketball Tournament This tournament is a knockout tournament where the loser is immediately eliminated from the tournament. Since it is mostly played in march, hence it has been accorded the title of March Madness. The first edition took place in 1939 and has been regularly held since then. the Women’s Championship was inaugurated in the 1981–82 season. FormatThe male edition tournament comprises of 68 teams that compete in 7 rounds for the National Championship Title. However, the number of Teams in the Women’s edition is 64.   SelectionThe selection procedure takes place by two methods:  1. Automatic32 Teams get selected in this way.  Men’s Division 1 Team comprises of 353 Teams.    Each one of those teams belongs to 32 conferences.    Each of those conferences conducts a tournament and if a time wins the tournament, they get selected for the NCAA.  2. At LargeThe second selection process is called ‘At Large’ where The NCAA selection committee convenes at the final days of the regular season and decides which 36 teams which are not the Automatic qualifiers can be sent to the playoffs. This selection is based on multiple stats and rankings.  Selection SundayThese “at-large” teams are announced in a nationally televised event on the Sunday preceding the “First Four” play-in games. This Sunday is called ‘Selection Sunday and is on March 15. SeedingAfter all the 68(64 in case of Women), have been decided, the selection committee ranks them in a process called seeding where each team gets a ranking from 1 to 68. Then First Four play-in games are contested between teams holding the four lowest-seeded automatic bids and the four lowest-seeded at-large bids. The Teams are then split into 4 regions of 16 Teams each. Each team is now ranked from 1 to 16 in each region. After the First Four, the tournament occurs during the course of three weekends, at pre-selected neutral sites across the United States. Here, the first round matches are determined by pitting the top team in the region with the lowest-seeded team in that region and so on. This ranking is the team’s seed. March Madness Begins First RoundThe First round consisting of 64 teams playing in 32 games over the course of a week. From here 32 teams emerge as winners and go on to the second round. Sweet SixteenNext, the sweet sixteen round takes place, which sees the elimination of 16 teams. Rest of the 16 teams move forward. Elite EightThe next fight is for the Elite Eight as only 8 teams remain in the competition. Final Four The penultimate round of the tournament where the 4 teams contest to reserve a place in the finals. Four teams, one from each region (East, South, Midwest, and West), compete in a preselected location for the national championship.  Who are Cinderellas?Upsets do happen in the tournament and sometimes the underdogs, who are seeded low, deliver an unexpected. They are called Cinderellas. So, this was a background behind the NCAA Baskerball tournament. Now let's have a look at the datasets provided.I shall be analysing the NCAA Division I Women's Basketball Tournament data. I assume the Men's tournament data should also be on the same lines.;Apache 2.0;https://www.kaggle.com/parulpandey/decoding-march-madness;1.0;['sklearn'];['ner', 'ai', 'rl', 'nn', 'ann'];['regression', 'train', 'model', 'validation data', 'layer', 'loss', 'label', 'logistic regression', 'predict', 'rank', 'understanding'];https://www.kaggle.com/c/google-cloud-ncaa-march-madness-2020-division-1-womens-tournament;0.682;0.411;2020-12-12 20:19:12;multiple data sources;['beginner, exploratory data analysis'];Decoding March Madness ;Python notebook;2081.0;33;;
2020-03-17 21:41:59;Google Cloud & NCAA® ML Competition 2020-NCAAW;Apache 2.0;https://www.kaggle.com/vbmokin/mm-ncaaw-lgb-xgb-regr;1.0;['tensorflow', 'xgboost', 'sklearn', 'lightgbm'];['ai', 'gbm', 'cv', 'ml', 'nlp', 'nn', 'ann'];['filter', 'training data', 'regression', 'train', 'model', 'loss', 'label', 'logistic regression', 'predict'];https://www.kaggle.com/c/google-cloud-ncaa-march-madness-2020-division-1-womens-tournament;0.644;0.327;2020-12-12 20:19:12;Google Cloud & NCAA® ML Competition 2020-NCAAW;['data visualization, classification, feature engineering'];MM NCAAW - LGB, XGB & Regr;Python notebook;978.0;13;0.48155;0.48155
2020-01-12 05:12:51;Since I received great response from the community for my Original BERT kernel in the TF QA Competition and even some people reached out asking me to do a similar kernel for the Google QUEST competition  (as they are kinda similar as well), I was really motivated and here I am with another BERT for Humans thing, hope you enjoy it.;Apache 2.0;https://www.kaggle.com/abhinand05/bert-for-humans-tutorial-baseline-version-2;1.0;['vocabulary', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'rl', 'ml', 'nlp', 'nn', 'rnn', 'ann'];['recognition', 'natural language processing', 'predict', 'machine learning', 'training data', 'train', 'epoch', 'recommend', 'classification', 'labeled', 'model', 'layer', 'loss', 'understanding', 'named entity recognition', 'output layer', 'deep learning', 'label', 'computer vision', 'natural language'];https://www.kaggle.com/c/google-quest-challenge;0.743;0.548;2020-12-12 20:20:08;multiple data sources;['gpu, beginner, nlp'];BERT for Humans: Tutorial+Baseline (Version 2);Python notebook;8511.0;199;;
2019-11-29 18:54:49;If you like the kernel, consider upvoting it and the associated datasets:https://www.kaggle.com/abhishek/transformers https://www.kaggle.com/abhishek/sacremoses https://www.kaggle.com/abhishek/distilbertbaseuncased;Apache 2.0;https://www.kaggle.com/abhishek/distilbert-use-features-oof;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'rl'];['train', 'model', 'epoch', 'layer', 'loss', 'predict', 'rank', 'understanding'];https://www.kaggle.com/c/google-quest-challenge;0.773;0.582;2020-12-12 20:20:08;multiple data sources;['gpu'];DistilBERT + USE + Features + OOF;Python notebook;19374.0;336;0.33272;0.36707
2020-07-26 19:26:13;"Bert-base TensorFlow 2.0This kernel does not explore the data. For that you could check out some of the great EDA kernels: introduction, getting started & another getting started. This kernel is an example of a TensorFlow 2.0 Bert-base implementation, using TensorFow Hub Huggingface transformer.   Update 1 (Commit 7):  removing penultimate dense layer; now there's only one dense layer (output layer) for fine-tuning using BERT's sequence_output instead of pooled_output as input for the dense layer   Update 2 (Commit 8):  adjusting _trim_input() --- now have a q_max_len and a_max_len, instead of 'keeping the ratio the same' while trimming. importantly: now also includes question_title for the input sequence   Update 3 (Commit 9) A lot of experiments can be made with the title + body + answer sequence. Feel free to look into e.g. (1) inventing new tokens (add it to '../input/path-to-bert-folder/assets/vocab.txt'), (2) keeping [SEP] between title and body but modify _get_segments(), (3) using the [PAD] token, or (4) merging title and body without any kind of separation. In this commit I'm doing (2). I also tried (3) offline, and they both perform better than in commit 8, in terms of validation rho.  ignoring first [SEP] token in _get_segments().   Update 4 (Commit 11)  Now using Huggingface transformer instead of TFHub (note major changes in the code). This creates the possibility to easily try out different architectures like XLNet, Roberta etc. As well as easily outputting the hidden states of the transformer. two separate inputs (title+body and answer) for BERT removed snapshot average (now only using last (third) epoch). This will likely decrease performance, but it's not feasible to use ~ 5 x 4 models for a single bert prediction in practice.  only training for 2 epochs instead of 3 (to manage 2h limit)   Update 5 (Commit 12)  transformers now available in 'Latest Available' Docker reducing input size";Apache 2.0;https://www.kaggle.com/akensert/quest-bert-base-tf2-0;1.0;['tensorflow', 'sklearn', 'keras'];['ai'];['predict', 'train', 'model', 'output layer', 'epoch', 'layer', 'loss', 'understanding'];https://www.kaggle.com/c/google-quest-challenge;0.794;0.595;2020-12-12 20:20:08;multiple data sources;[];[QUEST] Bert-base TF2.0;Python notebook;37652.0;413;;
2019-12-01 10:17:19;Pytorch approachIn this kernel I work with data from Google QUEST Q&A Labeling competition. In this challenge we work with... opinions. This could help Q&A systems, so let's try! Code will, of course, be in Pytorch Change log V25: Adding USE like in https://www.kaggle.com/ldm314/universal-sentence-encoder-keras-nn/ V26: changing preprocessing V32: reverting to previous preprocessing approach. Use more models for predictions. v33: fixed model paths it doesn't work, so revert to previous version. V37: adding bert embeddings (not using bert itself for training) like in this kernel: https://www.kaggle.com/abhishek/distilbert-use-features-oof V40: limit the number of epochs for training (due to 2h limit). Use some preprocessed embeddings instead of creating them in kernel.;Apache 2.0;https://www.kaggle.com/artgor/pytorch-approach;1.0;['nltk', 'gensim', 'sklearn', 'pytorch', 'tensorflow', 'spacy', 'keras'];['ner', 'ai', 'gbm', 'rl', 'nlp', 'nn', 'rnn', 'ann'];['activation function', 'gru', 'regression', 'train', 'model', 'epoch', 'loss', 'label', 'lstm', 'predict', 'rank', 'understanding', 'relu'];https://www.kaggle.com/c/google-quest-challenge;0.742;0.509;2020-12-12 20:20:08;multiple data sources;['beginner, deep learning, classification, +1 moredata cleaning'];Pytorch approach;Python notebook;8391.0;114;0.29385;0.32468
2019-12-24 02:15:54;More To Come. Stay Tuned. !!If there are any suggestions/changes you would like to see in the Kernel please let me know :). Appreciate every ounce of help! This notebook will always be a work in progress. Please leave any comments about further improvements to the notebook! Any feedback or constructive criticism is greatly appreciated!. If you like it or it helps you , you can upvote and/or leave a comment :).;Apache 2.0;https://www.kaggle.com/codename007/start-from-here-quest-complete-eda-fe;1.0;['sklearn', 'nltk'];['ner', 'ai', 'gan', 'rl', 'ml', 'nn', 'ann'];['training data', 'test data', 'train', 'layer', 'label', 'predict', 'understanding', 'bayesian'];https://www.kaggle.com/c/google-quest-challenge;0.744;0.545;2020-12-12 20:20:08;Google QUEST Q&A Labeling;['beginner, exploratory data analysis, feature engineering, +2 moredata cleaning, nlp'];Start From Here : QUEST Complete EDA + FE ✓✓;Python notebook;8837.0;189;;
2019-11-23 10:54:07;Google QUEST Q&A LabelingImproving automated understanding of complex question answer content Computers are really good at answering questions with single, verifiable answers. But, humans are often still better at answering questions about opinions, recommendations, or personal experiences. ... In this competition, you’re challenged to use this new dataset to build predictive algorithms for different subjective aspects of question-answering.   The competition is Notebook-only competition. Your Notebook will re-run automatically against an unseen test set. This competition data is small, only made of 6079 rows of train dataset. So I think this competition is easy for beginners to participate in terms of computational resource (unless you use BERT or any other heavy models to get good score), compared to the past competition hosted by Google like Open Image Challenges which requires a lot of GPU resources to train the model.;Apache 2.0;https://www.kaggle.com/corochann/google-quest-first-data-introduction;1.0;['xgboost', 'lightgbm', 'catboost', 'sklearn', 'pattern'];['ner', 'ai', 'gbm', 'rl', 'nn', 'ml'];['training data', 'test data', 'train', 'model', 'understanding', 'label', 'predict', 'recommend'];https://www.kaggle.com/c/google-quest-challenge;0.702;0.514;2020-12-12 20:20:08;Google QUEST Q&A Labeling;['beginner, data visualization, exploratory data analysis, +1 morefeature engineering'];Google QUEST: First data introduction;Python notebook;3223.0;122;;
2020-02-20 11:57:32;Google Quest Q&A Labeling  1st place solution  by Dmitriy Danevskiy, Oleg Yaroshevskiy, Yury Kashnitsky, and Dmitriy Abulkhanov The purpose of this competition is to analyze StackExchange questions & answers predicting whether the question is interesting, whether the answer is helpful or misleading etc. So in theory, top solutions can help Q&A systems in getting more human-like. In a nutshell, our team trained 4 models: 2 BERT ones, one RoBERTa, and one BART. Key ideas are:  pretraining language models with StackExchange data and auxiliary targets pseudo-labeling postprocessing predictions  Details are outlined in this post, code is shared in this repository.;Apache 2.0;https://www.kaggle.com/ddanevskyi/1st-place-solution;1.0;['tensorflow'];['ai'];['training data', 'train', 'model', 'epoch', 'label', 'predict'];https://www.kaggle.com/c/google-quest-challenge;0.752;0.538;2020-12-12 20:20:08;multiple data sources;['gpu'];1st-place-solution;Python notebook;10958.0;172;0.43100;0.46233
2020-02-06 04:35:57;Welcome to my new Kernel to NLP tasksI'm starting to focus on NLP tasks and I decided to find for good challenges on Kaggle, and for luck, I discovered this competition. I hope it can be useful to the other fellows I'm sure that I will learn a lot in this amazing world of NLP. Come with me and let's discover some interesting questions about this data.;Apache 2.0;https://www.kaggle.com/kabure/qa-eda-and-nlp-modelling-insights-vis-bert;1.0;['nltk', 'gensim', 'sklearn', 'pytorch', 'tensorflow', 'spacy', 'textblob', 'pattern', 'keras'];['ner', 'ai', 'gan', 'rl', 'ml', 'nlp', 'nn', 'ann'];['training data', 'test data', 'train', 'model', 'understanding', 'epoch', 'natural language processing', 'layer', 'loss', 'label', 'labeled', 'predict', 'rank', 'recommend', 'sentiment analysis', 'natural language'];https://www.kaggle.com/c/google-quest-challenge;0.724;0.502;2020-12-12 20:20:08;multiple data sources;['data visualization, exploratory data analysis, nlp, +1 moretext data'];QA EDA and NLP Modelling - Insights&Vis&Bert ;Python notebook;5297.0;103;0.34930;0.36465
2020-01-18 01:10:33;Implementing RoBERTa with fastai and HuggingFace 🤗Transformers;Apache 2.0;https://www.kaggle.com/melissarajaram/roberta-fastai-huggingface-transformers;1.0;['pytorch', 'vocabulary', 'pattern'];['ner', 'ai', 'dl', 'rl', 'ml', 'nlp', 'nn', 'rnn', 'ann'];['training data', 'test data', 'train', 'model', 'epoch', 'natural language processing', 'layer', 'loss', 'label', 'text classification', 'predict', 'rank', 'understanding', 'classification', 'natural language'];https://www.kaggle.com/c/google-quest-challenge;0.756;0.464;2020-12-12 20:20:08;multiple data sources;['gpu, beginner'];RoBERTa [fastai, HuggingFace 🤗Transformers];Python notebook;12090.0;63;0.31888;0.35287
2019-12-22 09:04:56;What is in this kernel?This kenel is dedicated for doing Exploratory data analysis on Google Q&A competition data.We will be exploring various aspects of the data given which hopefully will be helpful for our fellow kagglers. please UPVOTE the kernel if you find it helpful;Apache 2.0;https://www.kaggle.com/mobassir/jigsaw-google-q-a-eda;1.0;['nltk', 'gensim', 'sklearn', 'tensorflow', 'vocabulary', 'keras'];['ner', 'ai', 'dl', 'gan', 'rl', 'nn'];['filter', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'understanding'];https://www.kaggle.com/c/google-quest-challenge;0.733;0.525;2020-12-12 20:20:08;multiple data sources;['gpu'];Jigsaw Google Q&A EDA;Python notebook;6645.0;142;0.35602;0.38521
2020-03-22 15:35:15;This notebook is an update of this work. Just added my own pretrained weights.If it is useful, please consider your upvote.;Apache 2.0;https://www.kaggle.com/nxrprime/bert-base-pretrained-models;1.0;['nltk', 'gensim', 'sklearn', 'tensorflow', 'vocabulary', 'keras'];['ner', 'ai', 'dl', 'gan', 'rl', 'nn', 'ml'];['filter', 'train', 'model', 'epoch', 'layer', 'loss', 'predict', 'understanding'];https://www.kaggle.com/c/google-quest-challenge;0.72;0.463;2020-12-12 20:20:08;multiple data sources;['gpu'];Bert-base Pretrained Models;Python notebook;4894.0;62;;
2019-11-26 13:49:44;"Competition DetailsComputers are really good at answering questions with single, verifiable answers. But, humans are often still better at answering questions about opinions, recommendations, or personal experiences. Humans are better at addressing subjective questions that require a deeper, multidimensional understanding of context - something computers aren't trained to do well…yet.. Questions can take many forms - some have multi-sentence elaborations, others may be simple curiosity or a fully developed problem. They can have multiple intents, or seek advice and opinions. Some may be helpful and others interesting. Some are simple right or wrong. Unfortunately, it’s hard to build better subjective question-answering algorithms because of a lack of data and predictive models. That’s why the CrowdSource team at Google Research, a group dedicated to advancing NLP and other types of ML science via crowdsourcing, has collected data on a number of these quality scoring aspects. In this competition, you’re challenged to use this new dataset to build predictive algorithms for different subjective aspects of question-answering. The question-answer pairs were gathered from nearly 70 different websites, in a ""common-sense"" fashion. Our raters received minimal guidance and training, and relied largely on their subjective interpretation of the prompts. As such, each prompt was crafted in the most intuitive fashion so that raters could simply use their common-sense to complete the task. By lessening our dependency on complicated and opaque rating guidelines, we hope to increase the re-use value of this data set. What you see is what you get! Demonstrating these subjective labels can be predicted reliably can shine a new light on this research area. Results from this competition will inform the way future intelligent Q&A systems will get built, hopefully contributing to them becoming more human-like.";Apache 2.0;https://www.kaggle.com/phoenix9032/get-started-with-your-questions-eda-model-nn;1.0;['nltk', 'theano', 'sklearn', 'tensorflow', 'spacy', 'keras'];['ner', 'ai', 'cnn', 'gan', 'cv', 'rl', 'ml', 'nlp', 'nn', 'rnn', 'ann'];['gru', 'filter', 'regression', 'train', 'model', 'understanding', 'epoch', 'layer', 'relu', 'loss', 'label', 'lstm', 'predict', 'rank', 'recommend', 'classification'];https://www.kaggle.com/c/google-quest-challenge;0.735;0.498;2020-12-12 20:20:08;multiple data sources;['gpu'];Get Started with Your Questions-EDA+ Model NN;Python notebook;6920.0;98;0.27772;0.28869
2020-01-14 12:56:12;This is mostly a copy of Aditya Soni's kernel with some small changes . This is nothing complicated . I just wanted to learn BERT and played around with the basics . The training was done in colab . If you want to use the Kernel for training , just change the last parameter to True in Pipeline Config . This was taken from Combat-Wombat team in Toxicity .;Apache 2.0;https://www.kaggle.com/phoenix9032/pytorch-bert-plain;1.0;['pytorch', 'tensorflow'];['ner', 'ai', 'gan', 'rl', 'nn', 'ml'];['regression', 'generation', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'understanding', 'classification'];https://www.kaggle.com/c/google-quest-challenge;0.735;0.464;2020-12-12 20:20:08;multiple data sources;['gpu'];Pytorch Bert -Plain ;Python notebook;6925.0;63;0.34641;0.37678
2019-12-13 06:00:28;"1. This notebook is about ""Splitting and CV""Good day everybody! In this competition, one important aspect is that ""Public LB is based on 13% of total test data, which is only 476 examples"". So it is intuitively clear that our own CV score is more reliable than public LB, e.g. if we do 5-folds split, we will have 20% of training data, around 1200 examples. Moreover, we can average over 5-folds and get even more reliable number, right? It seems to me that in this imbalance-multi-label problem (explained below), splitting is not easy. So in this notebook, we will investigate and compare 3 splitting approaches which I know of:  KFold GroupKFold MultilabelStratifiedKFold  The goal of this notebook is to compare CV from these methods among themselves, and also to Public LB. Since this notebook is not about optimizing LB, we will save time by using a very fast model training from @abhishek's kernel which in turn originated from @abazdyrev's kernel. We will see that this same model will have different CV behaviors depending on splitting methods. Therefore, when talking about CV vs. LB, it's important to understand this different behaviors. In particular, when teaming up with other people, be sure that different CV calculation (if any) will not mislead your team. Note that this is all I know about splitting. At the end of the article, if anybody know a better method, or have better insights, and would like to share in the comment section, it will be very much appreciate!!";Apache 2.0;https://www.kaggle.com/ratthachat/quest-cv-analysis-on-different-splitting-methods;1.0;['pytorch', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'nlu', 'dl', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['linear regression', 'training data', 'test data', 'regression', 'generation', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'rank', 'understanding', 'bayesian'];https://www.kaggle.com/c/google-quest-challenge;0.732;0.479;2020-12-12 20:20:08;multiple data sources;['gpu'];QUEST : CV analysis on Different Splitting Methods;Python notebook;6442.0;76;;
2016-08-13 03:15:06;"The methods used to generate the filter terms involved looking at the most frequent words/client names for clues about what types of establishments were mentioned in this data set. Developing the filters took a fair amount of ""human"" sleuthing while looking at TF-IDF scores, frequency counts of Client names, as well as just general knowledge of common Spanish words used to refer to certain establishment types. Especially with all the noise provided by the Clients referred to only by a proper name, the filtered data is a proportionally small figure- but, significant.";Apache 2.0;https://www.kaggle.com/abbysobh/classifying-client-type-using-client-names;1.0;['sklearn'];['ner', 'ai', 'cv', 'rl', 'nn', 'ml'];['train', 'test data', 'model', 'filter'];https://www.kaggle.com/c/grupo-bimbo-inventory-demand;0.719;0.397;2020-12-12 20:39:03;Grupo Bimbo Inventory Demand;[];Classifying Client Type using Client Names;Python notebook;4694.0;28;;
2016-06-16 00:51:16;a simple product aggregate. Kaggle computing power allows us to only calculate 1-2 fields at a time.;Apache 2.0;https://www.kaggle.com/vykhand/exploring-products;1.0;['sklearn', 'nltk'];['ner', 'ai', 'dl', 'gan', 'rl', 'nn', 'ann'];['rank', 'model', 'train'];https://www.kaggle.com/c/grupo-bimbo-inventory-demand;0.787;0.527;2020-12-12 20:39:03;Grupo Bimbo Inventory Demand;[];Exploring products;Python notebook;30331.0;146;;
2020-06-15 21:18:24;6.2.20 UPDATE - this notebook explored Halite in its initial form, and has not been updated to reflect the latest changes in Kaggle environments or Halite gameplay rules;Apache 2.0;https://www.kaggle.com/ajeffries/obsolete-halite-v0-starter-notebook;1.0;['pytorch'];['ner', 'ai', 'rl', 'nn', 'ann'];['train', 'reward', 'layer'];https://www.kaggle.com/c/halite;0.738;0.462;2020-12-12 20:40:17;Halite by Two Sigma;[];[Obsolete] Halite v0 Starter Notebook;Python notebook;7577.0;61;;
2020-06-27 23:35:38;Designing game AI with Reinforcement learning;Apache 2.0;https://www.kaggle.com/basu369victor/designing-game-ai-with-reinforcement-learning;1.0;['pattern', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'nn'];['unlabeled', 'machine learning', 'train', 'model', 'neural network', 'reward', 'deep learning', 'layer', 'relu', 'loss', 'label', 'reinforcement learning', 'predict', 'unsupervised learning', 'recommend', 'supervised learning', 'labeled', 'propagation'];https://www.kaggle.com/c/halite;0.736;0.503;2020-12-12 20:40:17;Halite by Two Sigma;['deep learning, video games, reinforcement learning, +1 moresimulations'];Designing game AI with Reinforcement learning;Python notebook;7255.0;105;;
2020-08-03 21:51:36;Version HistoryThis is a kernel that shows how to run reinforcement learning algorithms in Halite IV. A colleague of mine asked me to provide something so he could get started so I decided to make it publicly available. I think I will see how far I can push this kernel in terms of usefulness. Currently it is really just a toy example and  meant to be minimal Version 1 (03. Aug 2020)This is a first sketch of a simple DQN baseline. It has:  replay buffer target network simple reward function self play  A couple convolutional layers  ReferencesThere is plenty of good resources out there. First and foremost checkout a couple other notebooks in this competition since there is other RL starter notebooks.  Simple Reinforcement Learning with Tensorflow - Arthur Juliani Official Pytorch: Reinforcement Learning (DQN) Tutorial - Adam Paszke Couple of good ipynb notebooks for various rainbow DQN features higgsfield/RL-Adventure Pytorch Examples on Github;Apache 2.0;https://www.kaggle.com/hsperr/halite-iv-dqn-example-pytorch;1.0;['pytorch', 'tensorflow'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['train', 'model', 'neural network', 'epoch', 'reward', 'layer', 'loss', 'reinforcement learning', 'predict', 'relu'];https://www.kaggle.com/c/halite;0.68;0.413;2020-12-12 20:40:17;Halite by Two Sigma;['reinforcement learning'];Halite IV - DQN example - PyTorch;Python notebook;1998.0;34;;
2020-03-22 21:56:05;create data.csvLink for understand data and create data.csv;Apache 2.0;https://www.kaggle.com/drobchak1988/herbarium-2020-fgvc7-create-tfrecords-tensorflow;1.0;['pattern', 'tensorflow'];['ai', 'dl', 'rl', 'nn', 'ann'];['train', 'label'];https://www.kaggle.com/c/herbarium-2020-fgvc7;0.622;0.236;2020-12-12 20:41:48;multiple data sources;[];Herbarium 2020 - FGVC7 create tfrecords Tensorflow;Python notebook;651.0;5;;
2020-04-17 00:12:36;Herbarium via ResNet50 and 3-step classificationOur data consists out of input images of Herbariums, each of which belongs to one of 309 families, one of 3,677 geni and one of 32,093 categories. Thus it is a good idea to first guess an images family, then its genus and finally infer from this its category. In this notebook, we  crop the input images, because Herbariums seem to show pathologic margins that do not contain useful information, use ResNet50 in order to 'preprocess' our input images, use a Dense Neural Network after that to first make a guess for the family of the input, then make a guess for the genus of the input via another Dense layer whose inputs are the guessed family and the ResNet50 output, finally guess the category of the input via another Dense layer, whose inputs are the guessed family and genus as well as the output of ResNet50, activate training for genus and category, only after the network is trained well on for the family, then genus, and only in the end start to train inference of category.;Apache 2.0;https://www.kaggle.com/jullang/herbarium-via-resnet50-and-3-step-classification;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'rl', 'ml', 'nn', 'ann'];['train', 'model', 'neural network', 'epoch', 'layer', 'loss', 'predict', 'resnet', 'classification'];https://www.kaggle.com/c/herbarium-2020-fgvc7;0.655;0.253;2020-12-12 20:41:48;Herbarium 2020 - FGVC7;['gpu'];Herbarium via ResNet50 and 3-step classification;Python notebook;1199.0;6;;
2020-03-11 20:41:44;"The New York Botanical Garden (NYBG) herbarium contains more than 7.8 million plant and fungal specimens. Herbaria are a massive repository of plant diversity data. These collections not only represent a vast amount of plant diversity, but since herbarium collections include specimens dating back hundreds of years, they provide snapshots of plant diversity through time. The integrity of the plant is maintained in herbaria as a pressed, dried specimen; a specimen collected nearly two hundred years ago by Darwin looks much the same as one collected a month ago by an NYBG botanist. All specimens not only maintain their morphological features but also include collection dates and locations, and the name of the person who collected the specimen. This information, multiplied by millions of plant collections, provides the framework for understanding plant diversity on a massive scale and learning how it has changed over time.";Apache 2.0;https://www.kaggle.com/rsingh99/getting-started-with-herbarium-2020;1.0;['pytorch'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ann'];['machine learning', 'training data', 'object detection', 'generation', 'train', 'recognition', 'model', 'neural network', 'epoch', 'deep learning', 'layer', 'loss', 'label', 'predict', 'computer vision', 'understanding', 'resnet', 'classification'];https://www.kaggle.com/c/herbarium-2020-fgvc7;0.694;0.362;2020-12-12 20:41:48;Herbarium 2020 - FGVC7;['gpu, beginner, deep learning'];Getting Started with Herbarium 2020;Python notebook;2669.0;19;;
2020-03-17 02:39:09;PeekThis notebook is here to just unify the dataset into one. I will perform further analysis and the Deep Learning algorithm in a future kernel. If you like this kernel, or forked this version, please upvote. First step, we peek at the data paths:;Apache 2.0;https://www.kaggle.com/seraphwedd18/herbarium-consolidating-the-details;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cnn', 'ml', 'nn', 'ann'];['test data', 'train', 'model', 'output layer', 'epoch', 'deep learning', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/herbarium-2020-fgvc7;0.719;0.481;2020-12-12 20:41:48;Herbarium 2020 - FGVC7;[];Herbarium - Consolidating the Details;Python notebook;4691.0;78;0.00000;0.00000
2020-04-01 15:21:57;Firstly, I'd like to say that I'm novice in machine learning and don't know how this problem can be resolved. However I'm just curious how to work with such amount of data and if I can create something working. Here I'm going to build ML model using Keras. Just to save your time. I have managed to create model which achieved 0.0022% of accuracy after 8 hours of learning.;Apache 2.0;https://www.kaggle.com/sergey55/herbarium-2020-notebook;1.0;['tensorflow', 'keras'];['ner', 'ai', 'dl', 'ml', 'nn', 'ann'];['machine learning', 'train', 'fitting', 'model', 'epoch', 'layer', 'loss', 'relu', 'resnet'];https://www.kaggle.com/c/herbarium-2020-fgvc7;0.606;0.152;2020-12-12 20:41:48;Herbarium 2020 - FGVC7;[];Herbarium 2020 - notebook;Python notebook;495.0;2;;
2020-05-04 19:12:11;What is a herbarium?  A herbarium is a collection of preserved plants stored, catalogued and arranged systematically for study by both professional taxonomists (scientists who name and identify plants), botanists and amateurs. The creation of a herbarium specimen involves the pressing and drying of plants between sheets of paper, a practice that has changed very little since the beginning, 500 years ago. Thanks to this simple technique, most of the characteristics of living plants are visible on the dried plant. The few that are not (e.g. flower colour, scent, height of a tree, vegetation type) are written on the collection label by the collector. Most importantly, the label should tell us where and when the specimen was collected. A working reference collection A herbarium acts like a plant library or vast catalogue with each of our three million specimens providing unique information – where it was found, when it flowered, what it looks like and it’s DNA, which remains intact for many years. DNA is now routinely extracted from herbarium specimens. The most important specimens are called 'types'. The type specimen, chosen by the author of the species name, becomes the physical reference for the new species. This unique working reference collection brings species from all over the world together into one place to be discovered, described and compared. The work is disseminated through the writing of Floras (a description of all the plants in a country or region), monographs (a description of plants or fungi within a group, such as a family) and scientific papers. This fundamental research provides an essential baseline for other plant-based research and helps inform conservation practices. Click here for further details.;Apache 2.0;https://www.kaggle.com/shaunthesheep/fgvc7-herbarium-2020-data-viz;1.0;['sklearn'];['ai', 'dl', 'rl', 'nn', 'ann'];['train', 'model', 'label', 'loss'];https://www.kaggle.com/c/herbarium-2020-fgvc7;0.537;0.099;2020-12-12 20:41:48;Herbarium 2020 - FGVC7;['beginner, classification'];FGVC7- Herbarium 2020 - Data Viz;Python notebook;168.0;1;;
2020-04-12 06:45:38;PeekThis notebook is here to just unify the dataset into one. I will perform further analysis and the Deep Learning algorithm in a future kernel. If you like this kernel, or forked this version, please upvote. First step, we peek at the data paths:;Apache 2.0;https://www.kaggle.com/tathagatbanerjee/herbarium;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'nn', 'ann'];['machine learning', 'test data', 'object detection', 'generation', 'train', 'recognition', 'model', 'output layer', 'neural network', 'epoch', 'deep learning', 'layer', 'loss', 'label', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/herbarium-2020-fgvc7;0.607;0.188;2020-12-12 20:41:48;Herbarium 2020 - FGVC7;[];Herbarium ;Python notebook;502.0;3;;
2020-12-12 18:12:09;"TESTING with version 17 if export is saved and measure output at the end of session.Version is saved and output is there. but I don't know how to ""rollback"" or access them inside or ""continue"" nam saying.";Apache 2.0;https://www.kaggle.com/thejravichandran/herbarium-2020-competition;1.0;['pytorch'];['ner', 'ai', 'dl', 'cnn', 'rl', 'ml', 'nn', 'ann'];['filter', 'predict', 'training data', 'test data', 'train', 'model', 'epoch', 'loss', 'understanding', 'resnet'];https://www.kaggle.com/c/herbarium-2020-fgvc7;0.512;0.214;2020-12-12 20:41:48;multiple data sources;['gpu'];Herbarium 2020 competition;Python notebook;118.0;4;;
2020-11-10 15:39:16;For the first time, load data;Apache 2.0;https://www.kaggle.com/tkm123456/notebook-mykaggle;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'rl', 'nn', 'ann'];['test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/herbarium-2020-fgvc7;0.51;0.0;2020-12-12 20:41:48;Herbarium 2020 - FGVC7;[];notebook_myKaggle;Python notebook;115.0;0;;
2020-03-17 00:26:45;About this notebook PyTorch Resnet18 starter code train kernel -> inference kernel  If this notebook is helpful, feel free to upvote :);Apache 2.0;https://www.kaggle.com/yasufuminakama/herbarium-2020-pytorch-resnet18-inference;1.0;['pytorch', 'albumentations', 'sklearn'];['ai', 'dl', 'cv', 'nn', 'ann'];['train', 'model', 'label', 'predict', 'resnet'];https://www.kaggle.com/c/herbarium-2020-fgvc7;0.663;0.327;2020-12-12 20:41:48;multiple data sources;['gpu'];Herbarium 2020 PyTorch Resnet18 [inference];Python notebook;1408.0;13;0.05334;0.06949
2020-03-16 18:56:41;About this notebook PyTorch Resnet18 starter code single fold 1 epochs  If this notebook is helpful, feel free to upvote :);Apache 2.0;https://www.kaggle.com/yasufuminakama/herbarium-2020-pytorch-resnet18-train;1.0;['pytorch', 'albumentations', 'sklearn'];['ai', 'dl', 'cv', 'nn', 'ann'];['train', 'model', 'epoch', 'label', 'loss', 'resnet'];https://www.kaggle.com/c/herbarium-2020-fgvc7;0.701;0.302;2020-12-12 20:41:48;Herbarium 2020 - FGVC7;['gpu'];Herbarium 2020 PyTorch Resnet18 [train] ;Python notebook;3134.0;10;;
2020-08-06 16:10:00;Higgs Boson Clustering | t-SNE + UMAP [RAPIDS];Apache 2.0;https://www.kaggle.com/imeintanis/identifying-higgs-boson-t-sne-umap-rapids;1.0;['xgboost', 'lightgbm', 'sklearn', 'pillow', 'tensorflow', 'pattern', 'keras'];['ner', 'ai', 'nlu', 'dl', 'gbm', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'relu', 'predict', 'gru', 'training data', 'train', 'clustering', 'classification', 'labeled', 'propagation', 'model', 'layer', 'loss', 'rank', 'bayesian', 'test data', 'regression', 'generation', 'label'];https://www.kaggle.com/c/higgs-boson;0.569;0.152;2020-12-12 20:42:09;multiple data sources;['gpu'];Identifying Higgs Boson | t-SNE+UMAP [RAPIDS];Python notebook;274.0;2;;
2019-06-22 18:47:47;IntroductionThis notebook provides solution to Histopathologic Cancer Detection challenge on Kaggle. This is a perfect Computer Vision problem where we are tasked with the detection of cancer by identifying metastatic tissue in histopathologic scans of lymph nodes using Deep Learning.  1. Understanding the Problem:Our goal is to create an algorithm to identify metastatic cancer in small image patches taken from larger digital pathology scans. Obviously I don't know biology to understand this problem right away, here is what I found online about histopathology. Histopathology is the study of the signs of the disease using the microscopic examination of a biopsy or surgical specimen that is processed and fixed onto glass slides. To visualize different components of the tissue under a microscope, the sections are dyed with one or more stains.  Motivation:Lymph nodes are small glands that filter the fluid in the lymphatic system and they are the first place a breast cancer is likely to spread. Histological assessment of lymph node metastases is part of determining the stage of breast cancer in TNM classification which is a globally recognized standard for classifying the extent of spread of cancer. The diagnostic procedure for pathologists is tedious and time-consuming as a large area of tissue has to be examined and small metastases can be easily missed.  That makes using Machine Learning a great choice both in terms of accuracy and ease of usability. It could bring a great change altogether. 2. Understanding the Data:The train data we have here contains 220,025 images and the test set contains 57,468 images. It is important to take into account that this data is only a subset of the original PCam dataset which in the end is derived from the Camelyon16 Challenge dataset, which contains 400 H&E stained whole slide images of sentinel lymph node sections that were acquired and digitized at 2 different centers using a 40x objective. The PCam's dataset including this one uses 10x undersampling to increase the field of view, which gives the resultant pixel resolution of 2.43 microns. Here's what Kaggle says, The original PCam dataset contains duplicate images due to its probabilistic sampling, however, the version presented on Kaggle does not contain duplicates. We have otherwise maintained the same data and splits as the PCam benchmark.  Our training data has a class distribution of 60:40 negative and positive samples which is not bad. I also found that these data were obtained as a result of routine clinical practices and similar to how a trained pathologist would examine similar images for identifying metastases. However, some relevant information about the surroundings might be left out with these small-sized image samples (I guess). 3. Understanding the ImagesYou are predicting the labels for the images in the test folder. A positive label indicates that the center 32x32px region of a patch contains at least one pixel of tumor tissue. Tumor tissue in the outer region of the patch does not influence the label. This outer region is provided to enable fully-convolutional models that do not use zero-padding, to ensure consistent behavior when applied to a whole-slide image.  This from the competition's description means that the centers of the images are the ones that really matter. As you might already know, this is a binary classification problem. 4. Understanding the Evaluation MetricThe evaluation metric is the Area Under ROC Curve which is also called AU-ROC/AOC Curve. It is one of the most important evaluation metrics for checking any classification model’s performance. AUC - ROC curve is a performance measurement for classification problem at various thresholds settings. ROC is a probability curve and AUC represents degree or measure of separability. It tells how much model is capable of distinguishing between classes. Higher the AUC, better the model is at predicting 0s as 0s and 1s as 1s. By analogy, higher the AUC (close to 1), better the model is at distinguishing between patients with disease and no disease. The curve is plotted with True Positive Rates Vs the False Positive Rates along the x and y axes respectively.   ROC AUC;Apache 2.0;https://www.kaggle.com/abhinand05/histopathologic-cancer-detection-using-cnns;1.0;['pytorch', 'sklearn'];['ai', 'cnn', 'cv', 'rl', 'nn', 'ann'];['filter', 'relu', 'predict', 'machine learning', 'training data', 'train', 'epoch', 'classification', 'image classification', 'model', 'neural network', 'layer', 'loss', 'understanding', 'test data', 'deep learning', 'label', 'computer vision', 'convolutional neural network'];https://www.kaggle.com/c/histopathologic-cancer-detection;0.719;0.427;2020-12-12 20:43:30;Histopathologic Cancer Detection;['gpu'];Histopathologic Cancer Detection using CNNs;Python notebook;4752.0;40;0.9318;0.9562
2019-03-24 17:16:43;General informationThere are many frameworks for Deep Learning. Recently I started using Pytorch and liked it, but sometimes it requires too much coding, so I started looking for wrappers over Pytorch. Recently a new library emerged: Kekas https://github.com/belskikh/kekas It provides a simple API for training neural nets for images and good visualizations of training process. There are also nice tricks from fast.ai - learning rate finder, one cycle policy and others. In this kernel I'll show what this library can do. At first I'll take a small subset of data and demonstrate the general functionality, after this we'll try training model on the full data.  Sadly, kaggle kernels have some problems currently, so I won't be able to show everything.;Apache 2.0;https://www.kaggle.com/artgor/cancer-detection-with-kekas;1.0;['pytorch', 'albumentations', 'sklearn'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ann'];['test data', 'train', 'model', 'neural network', 'epoch', 'deep learning', 'layer', 'loss', 'label', 'predict'];https://www.kaggle.com/c/histopathologic-cancer-detection;0.734;0.446;2020-12-12 20:43:30;Histopathologic Cancer Detection;['gpu, beginner, deep learning, +1 moreclassification'];Cancer detection with kekas;Python notebook;6876.0;50;0.9628;0.9664
2019-03-24 18:33:39;General informationIn this kernel I'll work with data from Histopathologic Cancer Detection Challenge. Our task is to identify metastatic cancer in small image patches taken from larger digital pathology scans. Or to be more precise - to classify 32x32 center crops as having cancer or not.;Apache 2.0;https://www.kaggle.com/artgor/simple-eda-and-model-in-pytorch;1.0;['pytorch', 'albumentations', 'sklearn'];['ner', 'ai', 'cnn', 'cv', 'nn', 'ann'];['train', 'model', 'epoch', 'label', 'loss', 'relu', 'resnet'];https://www.kaggle.com/c/histopathologic-cancer-detection;0.741;0.472;2020-12-12 20:43:30;Histopathologic Cancer Detection;['deep learning, classification, binary classification'];Simple EDA and model in pytorch;Python notebook;8137.0;70;0.8914;0.9257
2019-02-15 09:42:36;For now I only did standard stuff and used the new suggested learning rate methods of the 1 cycle learning policy as described here:  blog post by Sylvain Gugger summarizing the following papers original papers by leslie smith on hyperparameter tuning   and Superconvergence, the 1 cycle policy learning  Next things I planned would be to properly crop the images so it only includes the 32x32 sized patch that is the important part of the image, and check the augmentation settings. I already set up some functionality to use hyperopt to optimiize the hyperparameters of the one cycle parameters, this will come in another kernel. I also still need to check how many augmentation in the TTA  as used here I would also like check how the accuracy (or in this case ROC-AUC) changes with the different resnet18/34/50;Apache 2.0;https://www.kaggle.com/dromosys/fastai-v1-densenet201;1.0;['pytorch', 'sklearn'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'train', 'model', 'epoch', 'validation data', 'loss', 'label', 'predict', 'resnet'];https://www.kaggle.com/c/histopathologic-cancer-detection;0.685;0.367;2020-12-12 20:43:30;Histopathologic Cancer Detection;['gpu'];fastai v1 Densenet201;Python notebook;2215.0;20;0.9553;0.9710
2018-11-26 18:16:04;Baseline Keras CNN with 160k samplesHeavily inspired by https://www.kaggle.com/hrmello/cnn-classification-80-accuracy Thanks to @Marsh for https://www.kaggle.com/vbookshelf/cnn-how-to-use-160-000-images-without-crashing;Apache 2.0;https://www.kaggle.com/fmarazzi/baseline-keras-cnn-roc-fast-10min-0-925-lb;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cnn', 'rl', 'nn'];['filter', 'test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/histopathologic-cancer-detection;0.752;0.462;2020-12-12 20:43:30;Histopathologic Cancer Detection;['gpu, beginner, deep learning, +1 morecnn'];Baseline Keras CNN - ROC - FAST (10min) (0.925 LB);Python notebook;10768.0;61;0.8357;0.8796
2019-01-23 21:19:07;AcknowledgementsThis kernel contains excerpts from and was inspired by the following other kernels:  https://www.kaggle.com/qitvision/a-complete-ml-pipeline-fast-ai https://www.kaggle.com/CVxTz/cnn-starter-nasnet-mobile-0-9709-lb https://www.kaggle.com/fmarazzi/baseline-keras-cnn-roc-fast-10min-0-925-lb https://www.kaggle.com/artgor/simple-eda-and-model-in-pytorch  IntroductionThis kernel is an exemplary presentation of a simple exploratory data analysis (EDA) and a tutorial on creating your first model for this challenge. It is targeted at beginners. Running it you will be able to  take a look at the data for the challenge and its features train a basic convolutional neural network on all of the data (many of the other kernels only train on parts of the data) create your first submission ( LB ~0.93)  Contents Useful python modules The challenge and the data Loading the data EDA Creating a simple keras model Training and validating the model Creating a submission;Apache 2.0;https://www.kaggle.com/gomezp/complete-beginner-s-guide-eda-keras-lb-0-93;1.0;['pytorch', 'tensorflow', 'keras'];['ner', 'ai', 'cnn', 'cv', 'rl', 'ml', 'nn', 'ann'];['activation function', 'filter', 'training data', 'test data', 'train', 'model', 'neural network', 'epoch', 'deep learning', 'layer', 'loss', 'label', 'predict', 'relu', 'classification', 'labeled', 'convolutional neural network'];https://www.kaggle.com/c/histopathologic-cancer-detection;0.72;0.421;2020-12-12 20:43:30;Histopathologic Cancer Detection;['beginner, data visualization, classification'];Complete beginner's guide [EDA, Keras, LB 0.93];Python notebook;4865.0;37;0.9254;0.9113
2018-12-19 00:30:28;Check out corresponding Medium article: Histopathologic Cancer Detector - Machine Learning in Medicine;Apache 2.0;https://www.kaggle.com/greg115/histopathologic-cancer-detector-lb-0-958;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'generation', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict'];https://www.kaggle.com/c/histopathologic-cancer-detection;0.732;0.416;2020-12-12 20:43:30;Histopathologic Cancer Detection;['gpu'];Histopathologic Cancer Detector (LB 0.958);Python notebook;6424.0;35;0.9239;0.9448
2019-01-27 14:07:08;This model is based on fastai 0.7 because thats what we get in kaggle, as soon as pytorch v1 is released and the kernels are updated I'll adjust for the changes I guess. For now I only did standard stuff and used the new suggested learning rate methods of the 1 cycle learning policy as described here:  blog post by Sylvain Gugger summarizing the following papers original papers by leslie smith on hyperparameter tuning   and Superconvergence, the 1 cycle policy learning  Next things I planned would be to properly crop the images so it only includes the 32x32 sized patch that is the important part of the image, and check the augmentation settings. I already set up some functionality to use hyperopt to optimiize the hyperparameters of the one cycle parameters, this will come in another kernel. I also still need to check how many augmentation in the TTA  as used here I would also like check how the accuracy (or in this case ROC-AUC) changes with the different resnet18/34/50;Apache 2.0;https://www.kaggle.com/guntherthepenguin/fastai-v1-densenet169;1.0;['pytorch', 'sklearn'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'train', 'model', 'epoch', 'validation data', 'loss', 'label', 'predict', 'resnet'];https://www.kaggle.com/c/histopathologic-cancer-detection;0.725;0.408;2020-12-12 20:43:30;Histopathologic Cancer Detection;['gpu'];[fastai v1] Densenet169;Python notebook;5466.0;32;0.9443;0.9522
2018-11-22 01:17:50;Introduction In this kernel I'll show how to get the data in the proper format to use it on a CNN and make the classification. First let's import the necessary libraries.;Apache 2.0;https://www.kaggle.com/hrmello/base-cnn-classification-from-scratch;1.0;['sklearn', 'tensorflow', 'pattern', 'keras', 'skimage'];['ai', 'dl', 'cnn', 'cv', 'rl', 'nn'];['filter', 'training data', 'train', 'model', 'epoch', 'deep learning', 'layer', 'computer vision', 'loss', 'label', 'relu', 'predict', 'rank', 'resnet', 'classification'];https://www.kaggle.com/c/histopathologic-cancer-detection;0.718;0.383;2020-12-12 20:43:30;Histopathologic Cancer Detection;['gpu'];Base CNN classification from scratch ;Python notebook;4615.0;24;0.8545;0.8963
2019-03-25 21:13:48;This notebook tried to show that doing test time augumentation and take mean of all your predictions could boosting your score a lot. I used the same data augumentation transform in train, validation and test.;Apache 2.0;https://www.kaggle.com/jionie/tta-power-densenet169;1.0;['albumentations', 'sklearn', 'opencv-python', 'pillow'];['ai', 'dl', 'cv', 'nn', 'ann'];['train', 'model', 'epoch', 'layer', 'label', 'predict', 'relu'];https://www.kaggle.com/c/histopathologic-cancer-detection;0.69;0.39;2020-12-12 20:43:30;multiple data sources;['gpu'];TTA Power(Densenet169);Python notebook;2461.0;26;0.9791;0.9744
2019-03-06 10:29:34;Sections of this kernel  Project understanding Data understanding Data visualization Baseline model (Fastai v1) Validation and analysis Metrics Prediction and activation visualizations ROC & AUC   Submit Deploy (example)    Section: Data visualization Section: Prediction and activation visualizations           Project understandingWhat exactly is the problem?Binary image classification problem. Identify the presence of metastases from 96 x 96px digital histopathology images. One key challenge is that the metastases can be as small as single cells in a large area of tissue. How would a solution look like?Our evaluation metric is area under the ROC curve. The ROC curve is a plot of True positive rate against False positive rate at various thresholds and the area under the curve (AUC) is equal to the probability that a classifier will rank a randomly chosen positive instance higher than a randomly chosen negative one. The best possible solution would yield an AUC of 1 which means we would classify all positive samples correctly without getting any false positives.   ROC curve from a previous run of this kernel What is known about the domain?The histopathological images are glass slide microscope images of lymph nodes that are stained with hematoxylin and eosin (H&E). This staining method is one of the most widely used in medical diagnosis and it produces blue, violet and red colors. Dark blue hematoxylin binds to negatively charged substances such as nucleic acids and pink eosin to positively charged substances like amino-acid side chains (most proteins). Typically nuclei are stained blue, whereas cytoplasm and extracellular parts in various shades of pink.   Low-resolution Mid-resolution High-resolution             Example of a metastatic region in lymph nodes, CHAMELYON17  Lymph nodes are small glands that filter the fluid in the lymphatic system and they are the first place a breast cancer is likely to spread. Histological assessment of lymph node metastases is part of determining the stage of breast cancer in TNM classification which is a globally recognized standard for classifying the extent of spread of cancer. The diagnostic procedure for pathologists is tedious and time-consuming as a large area of tissue has to be examined and small metastases can be easily missed. Useful links for background knowledge  Patch Camelyon (PCam) Hematoxylin and eosin staining of tissue and cell sections H&E-stained sentinel lymph node sections of breast cancer patients: the CAMELYON dataset CAMELYON16 - background CAMELYON17 - background TNM classification;Apache 2.0;https://www.kaggle.com/qitvision/a-complete-ml-pipeline-fast-ai;1.0;['pytorch', 'sklearn', 'pattern'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'ml', 'nn', 'ann'];['image classification', 'filter', 'test data', 'train', 'fitting', 'model', 'understanding', 'epoch', 'deep learning', 'layer', 'loss', 'label', 'predict', 'rank', 'recommend', 'resnet', 'classification', 'labeled'];https://www.kaggle.com/c/histopathologic-cancer-detection;0.809;0.601;2020-12-12 20:43:30;Histopathologic Cancer Detection;['gpu, data visualization, computer vision'];A complete ML pipeline (Fast.ai);Python notebook;61101.0;459;0.9505;0.9622
2019-03-29 14:41:01;One Cycle Policy with KerasHighly inspired by following paper:  A disciplined approach to neural network hyper-parameters: Part 1 -- learning rate, batch size, momentum, and weight decay (Leslie N. Smith)  I have implemented the One Cycle Policy algorithm developed by Leslie N. Smith into the Keras Callback class. Leslie Smith suggests in this paper a slight modification of cyclical learning rate policy for super convergence using one cycle that is smaller than the total number of iterations/epochs and allow the learning rate todecrease several orders of magnitude less than the initial learning rate for the remaining miterations. In his experiments this policy allows the accuracy to plateau before the training ends. This approach (among others) helped me to improve my score.;Apache 2.0;https://www.kaggle.com/robotdreams/one-cycle-policy-with-keras;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ann'];['train', 'model', 'neural network', 'epoch', 'validation data', 'layer', 'label', 'loss', 'resnet'];https://www.kaggle.com/c/histopathologic-cancer-detection;0.728;0.39;2020-12-12 20:43:30;Histopathologic Cancer Detection;['gpu'];One Cycle Policy with Keras;Python notebook;5825.0;26;;
2019-03-25 02:41:22;A single model without WSIs. Preparing libraries;Apache 2.0;https://www.kaggle.com/seefun/you-really-need-attention-pytorch;1.0;['sklearn', 'opencv-python', 'pillow', 'pytorch', 'albumentations', 'pytorchcv'];['ai', 'cv', 'rl', 'ml', 'nn', 'ann'];['train', 'model', 'epoch', 'label', 'loss', 'relu', 'resnet'];https://www.kaggle.com/c/histopathologic-cancer-detection;0.705;0.375;2020-12-12 20:43:30;Histopathologic Cancer Detection;['gpu'];You Really Need Attention;Python notebook;3429.0;22;0.9767;0.9738
2019-01-08 10:07:04;"TL;DRThis is a simple classifier based on an Imagenet-trained Resnet18. It's inspired by Iafoss's kernels in other competititions. UpdateJust realized Densnet121 is way better, so let's switch to that for now!";Apache 2.0;https://www.kaggle.com/suicaokhoailang/wip-densenet121-baseline-with-fastai;1.0;['pytorch', 'sklearn', 'pillow'];['ner', 'ai', 'nn'];['predict', 'train', 'model', 'epoch', 'label', 'loss', 'resnet'];https://www.kaggle.com/c/histopathologic-cancer-detection;0.725;0.452;2020-12-12 20:43:30;Histopathologic Cancer Detection;['gpu'];[WIP] Densenet121 baseline with Fastai;Python notebook;5419.0;54;0.9467;0.9621
2018-11-22 16:05:34;Introduction In this kernel I will describe a workflow that  allows 160,000 full size images to be used without crashing the kaggle kernel. This is made possible by setting up a directory structure and then using generators to feed the data into the model for training, validation and for prediction. We will train the model using 144,000 images and validate on 16,000 images.;Apache 2.0;https://www.kaggle.com/vbookshelf/cnn-how-to-use-160-000-images-without-crashing;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cnn', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/histopathologic-cancer-detection;0.764;0.499;2020-12-12 20:43:30;Histopathologic Cancer Detection;['gpu'];CNN - How to use 160,000 images without crashing;Python notebook;15108.0;99;0.9102;0.9528
2018-07-24 22:56:57;Home Credit Default Risk Extensive EDA Content Introduction  Load the data  Check the data Data model  Glimpse the data  Check missing data  Check data unbalance   Explore the data Application data Bureau data Previous application data  Contract type    References;Apache 2.0;https://www.kaggle.com/gpreda/home-credit-default-risk-extensive-eda;1.0;['statsmodels'];['ner', 'ai', 'dl', 'gan', 'nn', 'ann'];['filter', 'test data', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/home-credit-default-risk;0.796;0.572;2020-12-12 20:47:32;Home Credit Default Risk;['beginner, data visualization, exploratory data analysis, +1 morefinance'];Home Credit Default Risk Extensive EDA;Python notebook;40670.0;284;;
2018-08-24 15:03:07;Basic end-to-end training of a LightGBM modelFeatures that are illustrated in this kernel:  data reading with memory footprint reduction a bit of feature engineering adding estimated credit length, which boosts AUC ROC by 0.015 on PLB and by 0.035 in local CV categorical feature encoding using one-hot-encoding (OHE) internal category weighting by LightGBM was tuned and no need of resampling is shown gradient-boosted decision trees using LightGBM package early stopping in LightGBM model training to avoid overtraining learning rate decay in LightGBM model training to improve convergence to the minimum hyperparameter optimisation of the model using random search in cross validation submission preparation The main goal is to provide an example of how those features can be used. High ROC AUC score is not the purpose here This kernel inherited ideas and SW solutions from other public kernels and in such cases I will post direct references to the original product, that that you can get some additional insights from the source.;Apache 2.0;https://www.kaggle.com/mlisovyi/lightgbm-hyperparameter-optimisation-lb-0-761;1.0;['pattern', 'lightgbm', 'sklearn'];['ai', 'gbm', 'cv', 'rl', 'nn', 'ann'];['train', 'fitting', 'model', 'predict', 'decision tree'];https://www.kaggle.com/c/home-credit-default-risk;0.808;0.539;2020-12-12 20:47:32;Home Credit Default Risk;['classification, gradient boosting, sampling'];LightGBM hyperparameter optimisation (LB: 0.761);Python notebook;60257.0;174;;
2018-06-14 08:44:05;Feature selecture using target permutationThe notebook uses a procedure described in this article. Feature selection process using target permutation tests actual importance significance against the distribution of feature importances when fitted to noise (shuffled target). The notebook implements the following steps  :  Create the null importances distributions : these are created fitting the model over several runs on a shuffled version of the target. This shows how the model can make sense of a feature irrespective of the target. Fit the model on the original target and gather the feature importances. This gives us a benchmark whose significance can be tested against the Null Importances Distribution for each feature test the actual importance: Compute the probabability of the actual importance wrt the null distribution. I will use a very simple estimation using occurences while the article proposes to fit known distribution to the gathered data. In fact here I'll compute 1 - the proba so that things are in the right order. Simply compare the actual importance to the mean and max of the null importances. This will give sort of a feature importance that allows to see major features in the dataset. Indeed the previous method may give us lots of ones.    For processing time reasons, the notebook will only cover application_train.csv but you can extend it as you wish.;Apache 2.0;https://www.kaggle.com/ogrellier/feature-selection-with-null-importances;1.0;['lightgbm', 'sklearn'];['cv', 'ai', 'rl', 'gbm'];['filter', 'train', 'fitting', 'model', 'label', 'predict'];https://www.kaggle.com/c/home-credit-default-risk;0.822;0.619;2020-12-12 20:47:32;Home Credit Default Risk;[];Feature Selection with Null Importances;Python notebook;98897.0;621;;
2018-06-10 15:56:11;DNN classifier in TensorflowThis kernel will build a DNN classifier for the Home Credit Default Risk competition. The challenge here (as always!) is to try and match the performance of the LightGBM/XGBoost classifiers which always seems tricky for NNs for this kind of problem. A lot of the feature engineering going into the model is from my previous kernel here, so I will focus more on the NN graph development here. Contents Load and process data Check nulls Identify categoricals Scaling   Building the graph Training the NN Analysis and submission;Apache 2.0;https://www.kaggle.com/shep312/deep-learning-in-tf-with-upsampling-lb-758;1.0;['tensorflow', 'xgboost', 'sklearn', 'lightgbm'];['ai', 'gan', 'gbm', 'rl', 'nn', 'ann'];['training data', 'test data', 'train', 'fitting', 'model', 'epoch', 'layer', 'gradient descent', 'loss', 'label', 'predict', 'relu', 'hidden layer'];https://www.kaggle.com/c/home-credit-default-risk;0.761;0.531;2020-12-12 20:47:32;Home Credit Default Risk;['deep learning, classification, feature engineering'];Deep learning in TF with upsampling [LB: .758];Python notebook;13965.0;155;;
2018-06-27 04:00:27;Home Credit Default Risk - Exploration + Baseline ModelMany people struggle to get loans due to insufficient or non-existent credit histories. And, unfortunately, this population is often taken advantage of by untrustworthy lenders. Home Credit strives to broaden financial inclusion for the unbanked population by providing a positive and safe borrowing experience. In order to make sure this underserved population has a positive loan experience, Home Credit makes use of a variety of alternative data--including telco and transactional information--to predict their clients' repayment abilities. While Home Credit is currently using various statistical and machine learning methods to make these predictions, they're challenging Kagglers to help them unlock the full potential of their data. Doing so will ensure that clients capable of repayment are not rejected and that loans are given with a principal, maturity, and repayment calendar that will empower their clients to be successful. This is a simple notebook on exploration and baseline model of home credit default risk data Contents 1. Dataset Preparation 2. Exploration - Applications Train      2.1 Snapshot - Application Train      2.2 Distribution of Target Variable      2.3 Applicant's Gender Type      2.4 Family Status of Applicants who takes the loan      2.5 Does applicants own Real Estate or Car      2.6 Suite Type and Income Type of Applicants      2.7 Applicants Contract Type      2.8 Education Type and Occupation Type      2.9 Organization Type and Occupation Type      2.10 Walls Material, Foundation and House Type      2.11 Amount Credit Distribution      2.12 Amount Annuity Distribution - Distribution      2.13 Amount Goods Price - Distribution      2.14 Amount Region Population Relative      2.15 Days Birth - Distribution      2.16 Days Employed - Distribution      2.17 Distribution of Num Days Registration      2.18 Applicants Number of Family Members      2.19 Applicants Number of Children 3. Exploration - Bureau Data      3.1 Snapshot - Bureau Data 4. Exploration - Bureau Balance Data      4.1 Snapshot - Bureau Balance Data 5. Exploration - Credit Card Balance Data      5.1 Snapshot - Credit Card Balance Data 6. Exploration - POS Cash Balance Data      6.1 Snapshot - POS Cash Balance Data 7. Exploration - Previous Application Data      7.1 Snapshot - Previous Application Data      7.2 Contract Status Distribution - Previous Applications      7.3 Suite Type Distribution - Previous Application      7.4 Client Type Distribution  - Previous Application      7.5 Channel Type Distribution - Previous Applications 8. Exploration - Installation Payments      8.1 Snapshot of Installation Payments 9. Baseline Model      9.1 Dataset Preparation      9.2 Handelling Categorical Features      9.3 Create Flat Dataset      9.4 Validation Sets Preparation      9.5 Model Fitting      9.6 Feature Importance      9.7 Prediction 1. Dataset Preparation;Apache 2.0;https://www.kaggle.com/shivamb/homecreditrisk-extensive-eda-baseline-0-772;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'gan', 'rl', 'nn', 'ann'];['filter', 'machine learning', 'training data', 'test data', 'train', 'fitting', 'model', 'label', 'predict'];https://www.kaggle.com/c/home-credit-default-risk;0.779;0.555;2020-12-12 20:47:32;Home Credit Default Risk;['beginner, data visualization, exploratory data analysis, +1 moreclassification'];HomeCreditRisk: Extensive EDA + Baseline [0.772];Python notebook;23162.0;221;;
2018-06-30 20:43:23;Prepare  Feature Selection 1. Filter 1.1 Pearson Correlation 1.2 Chi-2   2. Wrapper 3. Embeded 3.1 Logistics Regression L1 3.2 Random Forest 3.3 LightGBM     Summary;Apache 2.0;https://www.kaggle.com/sz8416/6-ways-for-feature-selection;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'gbm', 'gan', 'ml', 'nn', 'ann'];['filter', 'regression', 'train', 'fitting', 'model', 'label', 'random forest'];https://www.kaggle.com/c/home-credit-default-risk;0.796;0.536;2020-12-12 20:47:32;Home Credit Default Risk;['feature engineering'];6 Ways for Feature Selection;Python notebook;39953.0;165;;
2018-06-29 16:07:48;Step 1: parameters to be tunedNote: values for parameters should make sense, e.g.: 'num_leaves' needs to be a integer and 'feature_fraction' should between 0 and 1;Apache 2.0;https://www.kaggle.com/sz8416/simple-bayesian-optimization-for-lightgbm;1.0;['lightgbm', 'sklearn'];['cv', 'ai', 'rl', 'gbm'];['train', 'label', 'filter', 'bayesian'];https://www.kaggle.com/c/home-credit-default-risk;0.78;0.538;2020-12-12 20:47:32;Home Credit Default Risk;['gradient boosting, bayesian statistics'];Simple Bayesian Optimization for LightGBM;Python notebook;24233.0;171;;
2018-06-17 02:21:22;Introduction: Automated Feature Engineering BasicsIn this notebook, we will walk through applying automated feature engineering to the Home Credit Default Risk dataset using the featuretools library. Featuretools is an open-source Python package for automatically creating new features from multiple tables of structured, related data. It is ideal tool for problems such as the Home Credit Default Risk competition where there are several related tables that need to be combined into a single dataframe for training (and one for testing). Feature EngineeringThe objective of feature engineering is to create new features (alos called explantory variables or predictors) to represent as much information from an entire dataset in one table.  Typically, this process is done by hand using pandas operations such as groupby, agg, or merge and can be very tedious. Moreover, manual feature engineering is limited both by human time constraints and imagination: we simply cannot conceive of every possible feature that will be useful. (For an example of using manual feature engineering, check out part one and part two applied to this competition). The importance of creating the proper features cannot be overstated because a machine learning model can only learn from the data we give to it. Extracting as much information as possible from the available datasets is crucial to creating an effective solution. Automated feature engineering aims to help the data scientist with the problem of feature creation by automatically building hundreds or thousands of new features from a dataset. Featuretools - the only library for automated feature engineering at the moment - will not replace the data scientist, but it will allow her to focus on more valuable parts of the machine learning pipeline, such as delivering robust models into production. Here we will touch on the concepts of automated feature engineering with featuretools and show how to implement it for the Home Credit Default Risk competition. We will stick to the basics so we can get the ideas down and then build upon this foundation in later work when we customize featuretools. We will work with a subset of the data because this is a computationally intensive job that is outside the capabilities of the Kaggle kernels. I took the work done in this notebook and ran the methods on the entire dataset with the results available here. At the end of this notebook, we'll look at the features themselves, as well as the results of modeling with different combinations of hand designed and automatically built features. If you are new to this competition, I suggest checking out this post to get started. For a good take on why features are so important, here's a blog post by one of the developers of Featuretools.;Apache 2.0;https://www.kaggle.com/willkoehrsen/automated-feature-engineering-basics;1.0;['lightgbm'];['ner', 'ai', 'dl', 'gbm', 'gan', 'rl', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'training data', 'train', 'model', 'validation data', 'label', 'gradient boosting', 'predict', 'understanding', 'classification'];https://www.kaggle.com/c/home-credit-default-risk;0.801;0.58;2020-12-12 20:47:32;multiple data sources;['beginner, feature engineering'];Automated Feature Engineering Basics ;Python notebook;47035.0;324;;
2018-07-09 02:20:48;Introduction: Automated Hyperparameter TuningIn this notebook, we will talk through a complete example of using automated hyperparameter tuning to optimize a machine learning model. In particular, we will use Bayesian Optimization and the Hyperopt library to tune the hyperparameters of a gradient boosting machine. Additional Notebooks If you haven't checked out my other work on this problem, here is a complete list of the notebooks I have completed so far:  A Gentle Introduction Manual Feature Engineering Part One Manual Feature Engineering Part Two Introduction to Automated Feature Engineering Advanced Automated Feature Engineering Feature Selection Intro to Model Tuning: Grid and Random Search Automated Model Tuning  There are four approaches to tuning the hyperparameters of a machine learning model  Manual: select hyperparameters based on intuition/experience/guessing, train the model with the hyperparameters, and score on the validation data. Repeat process until you run out of patience or are satisfied with the results. Grid Search: set up a grid of hyperparameter values and for each combination, train a model and score on the validation data. In this approach, every single combination of hyperparameters values is tried which can be very inefficient! Random search: set up a grid of hyperparameter values and select random combinations to train the model and score. The number of search iterations is set based on time/resources. Automated Hyperparameter Tuning: use methods such as gradient descent, Bayesian Optimization, or evolutionary algorithms to conduct a guided search for the best hyperparameters.  These are listed in general order of least to most efficient. While we already conquered 2 and 3 in this notebook (we didn't even try method 1), we have yet to take on automated hyperparameter tuning. There are a number of methods to do this including genetic programming, Bayesian optimization, and gradient based methods. Here we will focus only on Bayesian optimization, using the Tree Parzen Esimator (don't worry, you don't need to understand this in detail) in the Hyperopt open-source Python library. For a little more background (we'll cover everything you need below), here is an introductory article on Bayesian optimization, and here is an article on automated hyperparameter tuning using Bayesian optimization. Here we'll get right into automated hyperparameter tuning, so for the necessary background on model tuning, refer to this kernel Bayesian Optimization PrimerThe problem with grid and random search is that these are uninformed methods because they do not use the past results from different values of hyperparameters in the objective function (remember the objective function takes in the hyperparameters and returns the model cross validation score). We record the results of the objective function for each set of hyperparameters, but the algorithms do not select the next hyperparameter values from this information. Intuitively, if we have the past results, we should  use them to reason about what hyperparameter values work the best and choose the next values wisely to try and spend more iterations evaluating promising values. Evaluating hyperparameters in the objective function is very time-consuming, and the concept of Bayesian optimization is to limit calls to the evaluation function by choosing the next hyperparameter values based on the previous results. This allows the algorithm to spend more time evaluating promising hyperparameter values and less time in low-scoring regions of the hyperparameter space. For example, consider the image below:  If you were choosing the next number of trees to try for the random forest, where would you concentrate your search? Probably around 100 trees because that is where the lowest errors have tended to occur (imagine this is a problem where we want to minimize the error). In effect, you have just done Bayesian hyperparameter optimization in your head! You formed a probability model of the error as a function of the hyperparameters and then selected the next hyperparameter values by maximizing the probability of a low error. Bayesian optimization works by building a surrogate function (in the form of a probability model) of the objective function P(score|hyperparameters. The surrogate function is much cheaper to evaluate than the objective, so the algorithm chooses the next values to try in the objective based on maximizing a criterion on the surrogate (usually expected improvement), exactly what you would have done with respect to the image above. The surrogate function is based on past evaluation results - pairs of (score, hyperparameter) records - and is continually updated with each objective function evaluation. Bayesian optimization therefore uses Bayesian reasoning: form an initial model (called a prior) and then update it with more evidence. The idea is that as the data accumulates, the surrogate function gets closer and closer to the objective function, and the hyperparameter values that are the best in the surrogate function will also do the best in the objective function. Bayesian optimization methods differ in the algorithm used to build the surrogate function and choose the next hyperparameter values to try. Some of the common choices are Gaussian Process (implemented in Spearmint), Random Forest Regression (in SMAC), and the Tree Parzen Estimator (TPE) in Hyperopt (technical details can be found in this article, although they won't be necessary to use the methods). Four Part of Bayesian OptimizationBayesian hyperparameter optimization requires the same four parts as we implemented in grid and random search:  Objective Function: takes in an input (hyperparameters) and returns a score to minimize or maximize (the cross validation score) Domain space: the range of input values (hyperparameters) to evaluate Optimization Algorithm: the method used to construct the surrogate function and choose the next values to evaluate Results: score, value pairs that the algorithm uses to build the surrogate function  The only differences are that now our objective function will return a score to minimize (this is just convention in the field of optimization), our domain space will be probability distributions rather than a hyperparameter grid, and the optimization algorithm will be an informed method that uses past results to choose the next hyperparameter values to evaluate. HyperoptHyperopt is an open-source Python library the implements Bayesian Optimization using the Tree Parzen Estimator algorithm to construct the surrogate function and select the next hyperparameter values to evaluate in the objective function. There are a number of other libraries such as Spearmint (Guassian process surrogate function) and SMAC (random forest regression surrogate function) sharing the same problem structure. The four parts of an optimization problem that we develop here will apply to all the libraries with only a change in syntax. Morevoer, the optimization methods as applied to the Gradient Boosting Machine will translate to other machine learning models or any problem where we have to minimize a function. Gradient Boosting MachineWe will use the gradient booosting machine (GBM) as our model to tune in the LightGBM library. The GBM is our choice of model because it performs extremely well for these types of problems (as shown on the leaderboard) and because the performance is heavily dependent on the choice of hyperparameter values. For more details of the Gradient Boosting Machine (GBM), check out this high-level blog post, or this in depth technical article. Cross Validation with Early StoppingAs with random and grid search, we will evaluate each set of hyperparameters using 5 fold cross validation on the training data. The GBM model will be trained with early stopping, where estimators are added to the ensemble until the validation score has not decrease for 100 iterations (estimators added). Cross validation and early stopping will be implemented using the LightGBM cv function. We will use 5 folds and 100 early stopping rounds. Dataset and ApproachAs before, we will work with a limited section of the data - 10000 observations for training and 6000 observations for testing. This will allow the optimization within the notebook to finish in a reasonable amount of time. Later in the notebook, I'll present results from 1000 iterations of Bayesian hyperparameter optimization on the reduced dataset and we then will see if these results translate to a full dataset (from this kernel). The functions developed here can be taken and run on any dataset, or used with any machine learning model (just with minor changes in the details) and working with a smaller dataset will allow us to learn all of the concepts. I am currently running 500 iterations of Bayesian hyperparameter optimization on a complete dataset and will make the results available when the search is completed.;Apache 2.0;https://www.kaggle.com/willkoehrsen/automated-model-tuning;1.0;['pattern', 'lightgbm', 'sklearn'];['ner', 'ai', 'gbm', 'cv', 'rl', 'nn', 'ann'];['machine learning', 'training data', 'regression', 'automated machine learnin', 'train', 'test data', 'model', 'validation data', 'gradient descent', 'loss', 'label', 'gradient boosting', 'predict', 'random forest', 'bayesian'];https://www.kaggle.com/c/home-credit-default-risk;0.792;0.576;2020-12-12 20:47:32;multiple data sources;[];Automated Model Tuning;Python notebook;34754.0;304;;
2018-07-17 16:03:16;"Introduction: Hyperparameter Tuning using Grid and Random SearchIn this notebook, we will explore two methods for hyperparameter tuning a machine learning model. In contrast to model parameters which are learned during training, model hyperparameters are set by the data scientist ahead of training and control implementation aspects of the model. The weights learned during training of a linear regression model are parameters while the number of trees in a random forest is a model hyperparameter because this is set by the data scientist. Hyperparameters can be thought of as model settings. These settings need to be tuned for each problem because the best model hyperparameters for one particular dataset will not be the best across all datasets. The process of hyperparameter tuning (also called hyperparameter optimization) means finding the combination of hyperparameter values for a machine learning model that performs the best - as measured on a validation dataset - for a problem. (Quick Note: a lot of data scientists use the terms parameters and hyperparameters interchangeably to refer to the model settings. While this is technically incorrect, it's pretty common practice and it's usually possible to tell when they are referring to parameters learned during training versus hyperparameters. I'll try to stick to using model hyperparameters or model settings and I'll  point out when I'm talking about a parameter that is learned during training. If you're still confused, this article may help you out!) Additional Notebooks If you haven't checked out my other work on this problem, here is a complete list of the notebooks I have completed so far:  A Gentle Introduction Manual Feature Engineering Part One Manual Feature Engineering Part Two Introduction to Automated Feature Engineering Advanced Automated Feature Engineering Feature Selection Intro to Model Tuning: Grid and Random Search Automated Model Tuning  There are several approaches to hyperparameter tuning  Manual: select hyperparameters based on intuition/experience/guessing, train the model with the hyperparameters, and score on the validation data. Repeat process until you run out of patience or are satisfied with the results.  Grid Search: set up a grid of hyperparameter values and for each combination, train a model and score on the validation data. In this approach, every single combination of hyperparameters values is tried which can be very inefficient! Random search: set up a grid of hyperparameter values and select random combinations to train the model and score. The number of search iterations is set based on time/resources.  Automated Hyperparameter Tuning: use methods such as gradient descent, Bayesian Optimization, or evolutionary algorithms to conduct a guided search for the best hyperparameters.  (This Wikipedia Article provides a good high-level overview of tuning options with links for more details) In this notebook, we will implement approaches 2 and 3 for a Gradient Boosting Machine Learning Model. In a future notebook, we will implement automated hyperparameter tuning using Bayesian optimization, specifically the Hyperopt library. If you want to get an idea of how automated hyperparameter tuning is done, check out this article. Model: Gradient Boosting MachineThe Gradient Boosting Machine (GBM) has recently emerged as one of the top machine learning models. The GBM is extremely effective on structured data - where the information is in rows and columns - and medium sized datasets - where there are at most a few million observations. We will focus on this model because it is currently the top performing method for most competitions on Kaggle and because the performance is highly dependent on the hyperparameter choices. The basics you need to know about the GBM are that it is an ensemble method that works by training many individual learners, almost always decision trees. However, unlike in a random forest where the trees are trained in parallel, in a GBM, the trees are trained sequentially with each tree learning from the mistakes of the previous ones. The hundreds or thousands of weak learners are combined to make a single strong ensemble learner with the contributions of each individual learned during training using Gradient Descent (the weights of the individual trees would therefore be a model parameter). The GBM has many hyperparameters to tune that control both the overall ensemble (such as the learning rate) and the individual decision trees (such as the number of leaves in the tree or the maximum depth of the tree). It is difficult to know which combination of hyperparameters will work best based only on theory because there are complex interactions between hyperparameters. Hence the need for hyperparameter tuning: the only way to find the optimal hyperparameter values is to try many different combinations on a dataset! We will use the implementation of the Gradient Boosting Machine in the LightGBM library. This is a much faster (and some say more accurate) implementation than that available in Scikit-Learn. For more details of the Gradient Boosting Machine (GBM), check out this high-level blog post, or this in depth technical article. Getting StartedWith the necessary background out of the way, let's get started. For this notebook, we will work with a subset of the data consisting of 10000 rows. Hyperparameter tuning is extremely computationally expensive and working with the full dataset in a Kaggle Kernel would not be feasible for more than a few search iterations. However, the same ideas that we will implement here can be applied to the full dataset and while this notebook is specifically aimed at the GBM, the methods can be applied for any machine learning model. To ""test"" the tuning results, we will save some of the training data, 6000 rows, as a separate testing set. When we do hyperparameter tuning, it's crucial to not tune the hyperparameters on the testing data. We can only use the testing data a single time when we evaluate the final model that has been tuned on the validation data. To actually test our methods from this notebook, we would need to train the best model on all of the training data, make predictions on the actual testing data, and then submit our answers to the competition.";Apache 2.0;https://www.kaggle.com/willkoehrsen/intro-to-model-tuning-grid-and-random-search;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'ml', 'nn', 'ann'];['linear regression', 'machine learning', 'training data', 'regression', 'test data', 'train', 'fitting', 'model', 'neural network', 'validation data', 'gradient descent', 'loss', 'label', 'gradient boosting', 'predict', 'decision tree', 'random forest', 'bayesian'];https://www.kaggle.com/c/home-credit-default-risk;0.82;0.582;2020-12-12 20:47:32;multiple data sources;['beginner, data visualization, classification'];Intro to Model Tuning: Grid and Random Search;Python notebook;93369.0;335;;
2018-06-22 03:21:28;Introduction: Feature SelectionIn this notebook we will apply feature engineering to the manual engineered features built in two previous kernels. We will reduce the number of features using several methods and then we will test the performance of the features using a fairly basic gradient boosting machine model. The main takeaways from this notebook are:  Going from 1465 total features to 536 and an AUC ROC of 0.783 on the public leaderboard A further optional step to go to 342 features and an AUC ROC of 0.782  The full set of features was built in Part One and Part Two of Manual Feature Engineering We will use three methods for feature selection:  Remove collinear features Remove features with greater than a threshold percentage of missing values Keep only the most relevant features using feature importances from a model  We will also take a look at an example of applying PCA although we will not use this method for feature reduction.;Apache 2.0;https://www.kaggle.com/willkoehrsen/introduction-to-feature-selection;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'gan', 'cv', 'rl', 'nn', 'ann'];['linear regression', 'filter', 'machine learning', 'regression', 'training data', 'train', 'fitting', 'model', 'validation data', 'label', 'gradient boosting', 'predict', 'understanding', 'random forest'];https://www.kaggle.com/c/home-credit-default-risk;0.798;0.567;2020-12-12 20:47:32;multiple data sources;[];Feature Selection;Python notebook;42978.0;264;0.78414;0.78205
2018-08-01 01:50:27;Introduction: Manual Feature EngineeringIf you are new to this competition, I highly suggest checking out this notebook to get started. In this notebook, we will explore making features by hand for the Home Credit Default Risk competition. In an earlier notebook, we used only the application data in order to build a model. The best model we made from this data achieved a score on the leaderboard around 0.74. In order to better this score, we will have to include more information from the other dataframes. Here, we will look at using information from the bureau and bureau_balance data. The definitions of these data files are:  bureau: information about client's previous loans with other financial institutions reported to Home Credit. Each previous loan has its own row. bureau_balance: monthly information about the previous loans. Each month has its own row.  Manual feature engineering can be a tedious process (which is why we use automated feature engineering with featuretools!) and often relies on domain expertise. Since I have limited domain knowledge of loans and what makes a person likely to default, I will instead concentrate of getting as much info as possible into the final training dataframe. The idea is that the model will then pick up on which features are important rather than us having to decide that. Basically, our approach is to make as many features as possible and then give them all to the model to use! Later, we can perform feature reduction using the feature importances from the model or other techniques such as PCA. The process of manual feature engineering will involve plenty of Pandas code, a little patience, and a lot of great practice manipulation data. Even though automated feature engineering tools are starting to be made available, feature engineering will still have to be done using plenty of data wrangling for a little while longer.;Apache 2.0;https://www.kaggle.com/willkoehrsen/introduction-to-manual-feature-engineering;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'rl', 'nn', 'ann'];['filter', 'machine learning', 'training data', 'test data', 'train', 'model', 'validation data', 'label', 'gradient boosting', 'predict', 'random forest'];https://www.kaggle.com/c/home-credit-default-risk;0.818;0.623;2020-12-12 20:47:32;Home Credit Default Risk;['beginner, feature engineering'];Introduction to Manual Feature Engineering;Python notebook;86473.0;669;;
2018-08-25 04:00:06;Introduction: Home Credit Default Risk CompetitionThis notebook is intended for those who are new to machine learning competitions or want a gentle introduction to the problem. I purposely avoid jumping into complicated models or joining together lots of data in order to show the basics of how to get started in machine learning! Any comments or suggestions are much appreciated. In this notebook, we will take an initial look at the Home Credit default risk machine learning competition currently hosted on Kaggle. The objective of this competition is to use historical loan application data to predict whether or not an applicant will be able to repay a loan. This is a standard supervised classification task:  Supervised: The labels are included in the training data and the goal is to train a model to learn to predict the labels from the features Classification: The label is a binary variable, 0 (will repay loan on time), 1 (will have difficulty repaying loan)  DataThe data is provided by Home Credit, a service dedicated to provided lines of credit (loans) to the unbanked population. Predicting whether or not a client will repay a loan or have difficulty is a critical business need, and Home Credit is hosting this competition on Kaggle to see what sort of models the machine learning community can develop to help them in this task. There are 7 different sources of data:  application_train/application_test: the main training and testing data with information about each loan application at Home Credit. Every loan has its own row and is identified by the feature SK_ID_CURR. The training application data comes with the TARGET indicating 0: the loan was repaid or 1: the loan was not repaid.  bureau: data concerning client's previous credits from other financial institutions. Each previous credit has its own row in bureau, but one loan in the application data can have multiple previous credits. bureau_balance: monthly data about the previous credits in bureau. Each row is one month of a previous credit, and a single previous credit can have multiple rows, one for each month of the credit length.  previous_application: previous applications for loans at Home Credit of clients who have loans in the application data. Each current loan in the application data can have multiple previous loans. Each previous application has one row and is identified by the feature SK_ID_PREV.  POS_CASH_BALANCE: monthly data about previous point of sale or cash loans clients have had with Home Credit. Each row is one month of a previous point of sale or cash loan, and a single previous loan can have many rows. credit_card_balance: monthly data about previous credit cards clients have had with Home Credit. Each row is one month of a credit card balance, and a single credit card can have many rows. installments_payment: payment history for previous loans at Home Credit. There is one row for every made payment and one row for every missed payment.   This diagram shows how all of the data is related:  Moreover, we are provided with the definitions of all the columns (in HomeCredit_columns_description.csv) and an example of the expected submission file. In this notebook, we will stick to using only the main application training and testing data. Although if we want to have any hope of seriously competing, we need to use all the data, for now we will stick to one file which should be more manageable. This will let us establish a baseline that we can then improve upon. With these projects, it's best to build up an understanding of the problem a little at a time rather than diving all the way in and getting completely lost! Metric: ROC AUCOnce we have a grasp of the data (reading through the column descriptions helps immensely), we need to understand the metric by which our submission is judged. In this case, it is a common classification metric known as the Receiver Operating Characteristic Area Under the Curve (ROC AUC, also sometimes called AUROC). The ROC AUC may sound intimidating, but it is relatively straightforward once you can get your head around the two individual concepts. The Reciever Operating Characteristic (ROC) curve graphs the true positive rate versus the false positive rate:  A single line on the graph indicates the curve for a single model, and movement along a line indicates changing the threshold used for classifying a positive instance. The threshold starts at 0 in the upper right to and goes to 1 in the lower left. A curve that is to the left and above another curve indicates a better model. For example, the blue model is better than the red model, which is better than the black diagonal line which indicates a naive random guessing model. The Area Under the Curve (AUC) explains itself by its name! It is simply the area under the ROC curve. (This is the integral of the curve.) This metric is between 0 and 1 with a better model scoring higher. A model that simply guesses at random will have an ROC AUC of 0.5. When we measure a classifier according to the ROC AUC, we do not generation 0 or 1 predictions, but rather a probability between 0 and 1. This may be confusing because we usually like to think in terms of accuracy, but when we get into problems with inbalanced classes (we will see this is the case), accuracy is not the best metric. For example, if I wanted to build a model that could detect terrorists with 99.9999% accuracy, I would simply make a model that predicted every single person was not a terrorist. Clearly, this would not be effective (the recall would be zero) and we use more advanced metrics such as ROC AUC or the F1 score to more accurately reflect the performance of a classifier. A model with a high ROC AUC will also have a high accuracy, but the ROC AUC is a better representation of model performance. Not that we know the background of the data we are using and the metric to maximize, let's get into exploring the data. In this notebook, as mentioned previously, we will stick to the main data sources and simple models which we can build upon in future work. Follow-up Notebooks For those looking to keep working on this problem, I have a series of follow-up notebooks:  Manual Feature Engineering Part One Manual Feature Engineering Part Two Introduction to Automated Feature Engineering Advanced Automated Feature Engineering Feature Selection Intro to Model Tuning: Grid and Random Search Automated Model Tuning Model Tuning Results  I'll add more notebooks as I finish them! Thanks for all the comments!;Apache 2.0;https://www.kaggle.com/willkoehrsen/start-here-a-gentle-introduction;1.0;['xgboost', 'lightgbm', 'sklearn', 'tensorflow', 'pattern'];['ner', 'ai', 'dl', 'gbm', 'gan', 'rl', 'nn', 'ann'];['filter', 'machine learning', 'regression', 'generation', 'train', 'fitting', 'model', 'training data', 'understanding', 'test data', 'validation data', 'label', 'logistic regression', 'gradient boosting', 'predict', 'recommend', 'classification', 'random forest'];https://www.kaggle.com/c/home-credit-default-risk;0.85;0.698;2020-12-12 20:47:32;Home Credit Default Risk;['beginner, exploratory data analysis, classification'];Start Here: A Gentle Introduction;Python notebook;309934.0;2911;;
2019-08-30 21:21:58;Amar Shaw Computer Science Engineering,(August, 2019);Apache 2.0;https://www.kaggle.com/shawamar/product-recommendation-system-for-e-commerce;1.0;['pattern', 'sklearn'];['ai', 'dl', 'cv', 'nn', 'ml'];['filter', 'fitting', 'model', 'clustering', 'k-means', 'predict', 'recommend'];https://www.kaggle.com/c/home-depot-product-search-relevance;0.779;0.437;2020-12-12 20:56:51;multiple data sources;[];Product Recommendation System for e-commerce;Python notebook;23227.0;45;;
2016-12-21 18:31:15;Predict the Relevance of Search Results on HomeDepot.com;Apache 2.0;https://www.kaggle.com/tennissuperstar/data-exploration-1;1.0;['pattern', 'caffe', 'h2o', 'pillow'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'ml', 'nn', 'rnn', 'ann'];['unlabeled', 'gru', 'filter', 'training data', 'test data', 'generation', 'train', 'fitting', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'rank', 'relu', 'labeled'];https://www.kaggle.com/c/home-depot-product-search-relevance;0.732;0.253;2020-12-12 20:56:51;Home Depot Product Search Relevance;[];Data Exploration;Python notebook;6558.0;6;;
2018-03-05 09:20:23;"HOW MUCH DID IT RAIN ?For agriculture, it is extremely important to know how much it rained on a particular field. However, rainfall is variable in space and time and it is impossible to have rain gauges everywhere. Therefore, remote sensing instruments such as radar are used to provide wide spatial coverage. Rainfall estimates drawn from remotely sensed observations will never exactly match the measurements that are carried out using rain gauges, due to the inherent characteristics of both sensors. Currently, radar observations are ""corrected"" using nearby gauges and a single estimate of rainfall is provided to users who need to know how much it rained. The Challenge is to solve this in probabilistic manner.Knowing the full probabilistic spread of rainfall amounts can be very useful to drive hydrological and agronomic models -- much more than a single estimate of rainfall.  Unlike a conventional Doppler radar, a polarimetric radar transmits radio wave pulses that have both horizontal and vertical orientations. Because rain drops become flatter as they increase in size and because ice crystals tend to be elongated vertically, whereas liquid droplets tend to be flattened, it is possible to infer the size of rain drops and the type of hydrometeor from the differential reflectivity of the two orientations. We are given polarimetric radar values and derived quantities at a location over the period of one hour. You will need to produce a probabilistic distribution of the hourly rain gauge total. ABOUT POLAMETRIC RADAR MEASUREMNTSPolarimetric radar offers the promise of being able to better infer drop-sizes and thus improve rainfall estimates since smaller drops evaporate more and of being able to distinguish between echoes due to bioscatter and echoes due to weather.  The US National Weather Service's weather radar network (called NEXRAD) was recently upgraded to polarimetry, and it is the polarimetric radar data collected after the upgrade that you are provided. This is an kaggle competition and you can download the dataset from the link given below: https://www.kaggle.com/c/how-much-did-it-rain/data LET'S START OUR JOURNEYBefore understanding the data set I will be importing the python libraries that will be used later";Apache 2.0;https://www.kaggle.com/suchith0312/predicting-rainfall;1.0;['xgboost', 'sklearn'];['ner', 'ai', 'dl', 'rl', 'nn', 'ann'];['filter', 'test data', 'regression', 'random forest', 'train', 'model', 'label', 'predict', 'rank', 'understanding', 'classification'];https://www.kaggle.com/c/how-much-did-it-rain;0.711;0.188;2020-12-12 21:16:25;How Much Did It Rain?;[];Predicting rainfall;Python notebook;3900.0;3;;
2019-02-12 07:09:00;Forked from https://www.kaggle.com/ilya16/lstm-models?scriptVersionId=10420679 with refactoring, simplification and some changes to the model Data Preprocessing and Deep LSTM model are inspired by the top solution described here:  http://simaaron.github.io/Estimating-rainfall-from-weather-radar-readings-using-recurrent-neural-networks/;Apache 2.0;https://www.kaggle.com/andkul/deep-lstm-to-predict-rainfall;1.0;['tensorflow', 'keras'];['ai', 'nn', 'rl'];['predict', 'train', 'model', 'epoch', 'layer', 'lstm', 'loss'];https://www.kaggle.com/c/how-much-did-it-rain-ii;0.705;0.268;2020-12-12 21:25:17;How Much Did It Rain? II;['gpu'];Deep LSTM to predict rainfall;Python notebook;3400.0;7;24.73192;23.71420
2019-02-10 16:11:37;Note: Data Preprocessing and Deep LSTM model are inspired by the top solution described here:  http://simaaron.github.io/Estimating-rainfall-from-weather-radar-readings-using-recurrent-neural-networks/;Apache 2.0;https://www.kaggle.com/ilya16/lstm-models;1.0;['tensorflow', 'keras'];['ai', 'nn', 'rl'];['predict', 'train', 'model', 'epoch', 'layer', 'lstm', 'loss'];https://www.kaggle.com/c/how-much-did-it-rain-ii;0.686;0.357;2020-12-12 21:25:17;How Much Did It Rain? II;['gpu, lstm'];LSTM models;Python notebook;2278.0;18;24.73595;23.71913
2018-10-30 22:27:49;Shoutout to @Vladimir Iglovikov for providing us this amazing image augmentation library! Heres how you can apply it to this competition.;Apache 2.0;https://www.kaggle.com/alexanderliao/image-augmentation-demo-with-albumentation;1.0;['albumentations', 'opencv-python', 'pillow'];['ai', 'nn', 'ann', 'cv'];['train'];https://www.kaggle.com/c/human-protein-atlas-image-classification;0.749;0.471;2020-12-12 21:26:51;Human Protein Atlas Image Classification;[];Image Augmentation Demo with albumentation;Python notebook;10136.0;69;;
2019-07-12 14:17:33;Welcome to the Human Protein Atlas Competition!I started this kernel notebook to explore the data and build a simple baseline model to play with. I have never mind that the results are useful for many kagglers that like to start with the competition but need some starter code or some inspiration. Thank you for pushing this kernel that far! :-) If you have just found this kernel, here is a short summary of what you can find:  Encoding of binary target labels out of the given multilabel list per image, Visual analysis of target protein distribution in the train set, A simple image generator that yields images of a target-protein-wishlist. Each sample that has at least one match with this list is returned. Some ideas on validation. A baseline model build with keras that is supported by: A modelparameter class that holds all parameters that are necessary to build the model, to load the data and to preprocess the images. A data generator that can be used with CPU/GPU computing to perform training and validation. An image preprocessor that rescales, reshapes and normalizes the images for feeding into the model.   Ideas on how to improve the baseline model by tracking loss with a keras callback.  Some ideas on how to proceed. (coming soon);Apache 2.0;https://www.kaggle.com/allunia/protein-atlas-exploration-and-baseline;1.0;['sklearn', 'tensorflow', 'pattern', 'keras', 'skimage'];['ner', 'ai', 'dl', 'cnn', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'predict', 'relu', 'training data', 'neuron', 'train', 'epoch', 'clustering', 'classification', 'propagation', 'model', 'neural network', 'layer', 'loss', 'test data', 'generation', 'fitting', 'validation data', 'deep learning', 'gradient descent', 'label'];https://www.kaggle.com/c/human-protein-atlas-image-classification;0.81;0.632;2020-12-12 21:26:50;multiple data sources;['gpu, beginner, exploratory data analysis'];Protein Atlas - Exploration and Baseline;Python notebook;63871.0;789;;
2018-12-24 14:19:57;"Which proteins come together?Take a look at this wonderful image of an animal cell provided by LadyofHats (Mariana Ruiz) in the public domain via Wikimedia Commons. We can see some of our target proteins and may conclude that some of them are likely to occur together. In our images all of them should be present but only one of them are stained in the green channel. Now let's assume that staining is sometimes not that easy and it happens that multible organelles are likely to be stained together. If this is true we could expect groupings - some targets may be likely to be one-hot at the same time over a broader range of image samples in our data set. As the target distribution and dependencies are an entry point to setup an objective or loss function, it could be worth it to dive into dive with me into target group analysis using a latent variable model. If you like my kernel you can make be very happy with an upvote and/or comment ;-)! The motivation I gain out of your feedback pushes me to share my ideas instead of hiding them. Thank you!";Apache 2.0;https://www.kaggle.com/allunia/uncover-target-correlations-with-bernoulli-mixture;1.0;['pattern', 'tensorflow', 'sklearn'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nn', 'ann'];['filter', 'train', 'model', 'clustering', 'loss', 'label', 'k-means', 'predict'];https://www.kaggle.com/c/human-protein-atlas-image-classification;0.736;0.522;2020-12-12 21:26:50;Human Protein Atlas Image Classification;['data visualization, clustering, advanced'];Uncover target correlations with Bernoulli Mixture;Python notebook;7120.0;136;;
2018-12-23 16:49:18;"OverviewThe goal of this competition is classification of mixed protein patterns. However, unlike most image labeling tasks, where binary or multiclass labeling is considered, in this competition each image can have multiple labels. Multiclass multilabel task has its own specific affecting the design of the model and the loss function. Moreover, the classified images are quite different from ImageNet; therefore, despite usage of a pretrained model is quite helpful, a substantial retraining of entire model is needed. An additional challenge is 4-chanel input to the model (RGBY), which is different from ones used in most of pretrained models (RGB input). In this kernel I will show how to handle the above challenges and get started with this competition. I will begin with using a light ResNet34 model and low-resolution images to have a baseline that can be used later to select higher end models and explore the effect of image resolution on the prediction accuracy. The validation F1 score of the model is ~0.65-0.7, and I was able to get 0.460 public LB score in V11 of the kernel (0.453 after reset of the LB). Though reuslts are slightly different from one run to another because F1 macro metric is unstable, and sevral items of rear classes contribute in the same way as as thousands items of common classes, 1/28. The problem of low public LB score of the model, which mentioned in the first versions of the kernel, is resulted by a bug in the evaluation metric (https://www.kaggle.com/c/human-protein-atlas-image-classification/discussion/69366#409041) that relies on the order of records in the submission file rather than IDs.";Apache 2.0;https://www.kaggle.com/iafoss/pretrained-resnet34-with-rgby-0-460-public-lb;1.0;['pytorch', 'pillow', 'sklearn', 'pattern'];['ner', 'ai', 'dl', 'gan', 'cv', 'ml', 'nn', 'ann'];['image segmentation', 'filter', 'train', 'fitting', 'model', 'output layer', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'recommend', 'resnet', 'classification'];https://www.kaggle.com/c/human-protein-atlas-image-classification;0.81;0.61;2020-12-12 21:26:50;multiple data sources;['gpu, deep learning, classification, +2 morecnn, multiclass classification'];pretrained ResNet34 with RGBY (0.460 public LB);Python notebook;63717.0;530;;
2018-10-26 22:12:09;Sliding window source image breakdownThe input images are fairly large. Certainly larger then will fit into GPU memory with any modern image processing NN. One obvious way to solve that problem is to resize them. However, that loses a lot of information. One interesting feature of these images though, is that they contain lot of similar elements (multiple cells per image). That means, if we cut them into pieces, we will still have lot of relevant info. This notebook slices each 512x512 image into 4 299x299 images and feeds them to InceptionV3 network. This results in decent improvement at the expence of multiplying training time by 4.**;Apache 2.0;https://www.kaggle.com/iluxave/inceptionv3-with-sliding-window-image-breakdown;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cv', 'rl', 'nn', 'ann'];['filter', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/human-protein-atlas-image-classification;0.702;0.383;2020-12-12 21:26:51;multiple data sources;['gpu, deep learning, classification'];InceptionV3 with sliding window image breakdown;Python notebook;3227.0;24;0.40079;0.39173
2018-10-04 15:25:35;OverviewHere we use a pretrained model and transfer learning to try and identify the different types of proteins present in the image. BeyondThe model currently just uses the green channel of the image (arbitrary) and includes all labels although some are exceedingly rare, better image usage and stratification would definitely help;Apache 2.0;https://www.kaggle.com/kmader/transfer-learning-for-human-protein-submission;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'rl', 'nn', 'ann'];['test data', 'train', 'model', 'epoch', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'resnet'];https://www.kaggle.com/c/human-protein-atlas-image-classification;0.73;0.444;2020-12-12 21:26:51;Human Protein Atlas Image Classification;['gpu, multiclass classification, transfer learning'];Transfer Learning for Human Protein Submission;Python notebook;6125.0;49;0.02203;0.02130
2018-10-13 20:28:02;"IntroductionLet's try to understand how to use channels in learning. First variant is combine them all together like here In our case we will use two branch of network - first one is about data and second one is about ""The protein of interest"". We will get 2 images from 4 sources:  Yellow, blue and red channel - we create RGB image (yellow channel will be in fact green color now); Source green channel will be grayscale image but with 3 equal channel (condition for using Imagenet weights)  Let's start from imports and data loading:";Apache 2.0;https://www.kaggle.com/kwentar/two-branches-xception-lb-0-3;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'gan', 'nn', 'ann'];['filter', 'train', 'model', 'output layer', 'epoch', 'layer', 'loss', 'label', 'predict'];https://www.kaggle.com/c/human-protein-atlas-image-classification;0.719;0.44;2020-12-12 21:26:51;Human Protein Atlas Image Classification;['gpu, beginner, multiclass classification'];Two branches Xception LB ~ 0.3;Python notebook;4735.0;47;0.25873;0.28009
2018-10-08 02:00:34;IntroductionThe hypothesis: if we visualize a few examples for each class, we will get the visual patterns for each class. Also, we will get the method for merge channels into one image;Apache 2.0;https://www.kaggle.com/kwentar/visualization-examples-of-each-class-in-rgb;1.0;['pattern'];['ai', 'dl', 'gan', 'nn', 'ann'];['train', 'label'];https://www.kaggle.com/c/human-protein-atlas-image-classification;0.693;0.418;2020-12-12 21:26:51;Human Protein Atlas Image Classification;[];Visualization examples of each class in RGB;Python notebook;2606.0;36;;
2019-02-01 15:39:16;This is the first competition I've entered.  No illusions of placing top 3 out of the gate, but gaining some experience and learning a thing or two are high on the priority list.  Plus if some of my code can help, that's always a bonus. Here's what I've got so far...;Apache 2.0;https://www.kaggle.com/mickeypvx/actually-this-is-my-first-rodeo;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'training data', 'test data', 'train', 'fitting', 'model', 'neural network', 'epoch', 'deep learning', 'layer', 'loss', 'label', 'predict', 'relu', 'recommend', 'resnet', 'classification', 'convolutional neural network'];https://www.kaggle.com/c/human-protein-atlas-image-classification;0.712;0.397;2020-12-12 21:26:51;multiple data sources;['gpu, beginner, deep learning'];Actually, this IS my first rodeo;Python notebook;4046.0;28;;
2018-10-05 10:34:15;Aim of the CompitionAnalyse the Protein cell from the biomedical image and find the pattern to accelerate the understanding of human cells behaviour and optimise disease [such as breast cancer, prostate cancer, colon cancer, diabetes, autoimmune diseases, ovarian cancer and renal failure].;Apache 2.0;https://www.kaggle.com/nikitpatel/best-tutorial-for-beginner;1.0;['pattern'];['ner', 'ai', 'nn', 'gan'];['understanding', 'predict'];https://www.kaggle.com/c/human-protein-atlas-image-classification;0.722;0.403;2020-12-12 21:26:51;Human Protein Atlas Image Classification;['beginner'];Best Tutorial for Beginner;Python notebook;5036.0;30;;
2018-10-19 22:57:36;You might notice, that binary crossentropy loss is not performing very well. Let's study, why's that and look for other possibilities.;Apache 2.0;https://www.kaggle.com/rejpalcz/best-loss-function-for-f1-score-metric;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'nn', 'ann'];['train', 'model', 'layer', 'loss', 'label', 'predict', 'relu', 'recommend', 'classification', 'ground truth'];https://www.kaggle.com/c/human-protein-atlas-image-classification;0.802;0.522;2020-12-12 21:26:50;Human Protein Atlas Image Classification;['optimization'];Best loss function for F1-score metric;Python notebook;48745.0;137;;
2018-10-29 19:59:35;Using in KerasLet's try to test the multi_processing.;Apache 2.0;https://www.kaggle.com/rejpalcz/cnn-128x128x4-keras-from-scratch-lb-0-328;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cnn', 'cv', 'rl', 'nn', 'ann'];['train', 'model', 'epoch', 'validation data', 'layer', 'loss', 'label', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/human-protein-atlas-image-classification;0.765;0.513;2020-12-12 21:26:50;Human Protein Atlas Image Classification;['gpu, deep learning, cnn, +1 moremulticlass classification'];CNN 128x128x4, Keras from scratch [LB 0.328];Python notebook;15583.0;120;0.33409;0.32499
2018-11-03 22:23:24;Using in KerasLet's try to test the multi_processing.;Apache 2.0;https://www.kaggle.com/rejpalcz/gapnet-pl-lb-0-385;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'nn', 'ann'];['train', 'model', 'epoch', 'validation data', 'layer', 'loss', 'label', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/human-protein-atlas-image-classification;0.73;0.4;2020-12-12 21:26:51;Human Protein Atlas Image Classification;['gpu'];GapNet-PL [LB 0.385];Python notebook;6167.0;29;0.38106;0.37545
2018-12-19 19:02:06;"TL;DR: Download up to 70328 additional labeled fluorescent microscopy samples with these 5 images per sample:";Apache 2.0;https://www.kaggle.com/therealpythonman/get-350k-additional-hpa-images;1.0;['skimage'];['ai', 'dl', 'gan', 'rl', 'ml', 'nn', 'ann'];['train', 'label', 'training data', 'labeled'];https://www.kaggle.com/c/human-protein-atlas-image-classification;0.672;0.4;2020-12-12 21:26:51;Human Protein Atlas Image Classification;[];Get >350k Additional HPA Images;Python notebook;1681.0;29;;
2018-10-25 02:19:39;"OverviewThe goal of this competition is classification of mixed protein patterns. However, unlike most image labeling tasks, where binary or multiclass labeling is considered, in this competition each image can have multiple labels. Multiclass multilabel task has its own specific affecting the design of the model and the loss function. Moreover, the classified images are quite different from ImageNet; therefore, despite usage of a pretrained model is quite helpful, a substantial retraining of entire model is needed. An additional challenge is 4-chanel input to the model (RGBY), which is different from ones used in most of pretrained models (RGB input). In this kernel I will show how to handle the above challenges and get started with this competition. I will begin with using a light ResNet34 model and low-resolution images to have a baseline that can be used later to select higher end models and explore the effect of image resolution on the prediction accuracy. The validation F1 score of the model is ~0.5-0.6, and I was able to get 0.437 public LB score by using a model produced in an earlier version of the kernel after I did adjustment of thresholds according to https://www.kaggle.com/c/human-protein-atlas-image-classification/discussion/68678#404591. The problem of low public LB score of the model, which mentioned in the previous version of the kernel, is resulted by a bug in the evaluation metric (https://www.kaggle.com/c/human-protein-atlas-image-classification/discussion/69366#409041) that relies on the order of records in the submission file rather than IDs.";Apache 2.0;https://www.kaggle.com/zhugds/resnet34-with-rgby-fast-ai-fork;1.0;['pytorch', 'sklearn', 'pattern'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'nn', 'ann'];['image segmentation', 'train', 'fitting', 'model', 'output layer', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'recommend', 'resnet', 'classification'];https://www.kaggle.com/c/human-protein-atlas-image-classification;0.716;0.397;2020-12-12 21:26:51;Human Protein Atlas Image Classification;['gpu'];ResNet34 with RGBY (fast.ai) Fork;Python notebook;4375.0;28;;
2019-02-05 20:49:55;General informationIn this kernel I'll build a CNN in Pytorch to identify Whales. The first attempt was done by using a simple CNN from scratch, but it didn't work well, so I'll use pre-trained nets.;Apache 2.0;https://www.kaggle.com/artgor/pytorch-whale-identifier;1.0;['pytorch', 'albumentations', 'keras', 'sklearn'];['ner', 'ai', 'dl', 'cnn', 'cv', 'nn', 'ann'];['filter', 'test data', 'train', 'model', 'epoch', 'layer', 'label', 'loss', 'relu', 'resnet'];https://www.kaggle.com/c/humpback-whale-identification;0.743;0.483;2020-12-12 21:28:20;Humpback Whale Identification;['data visualization, deep learning, classification, +2 morecomputer vision, multiclass classification'];Pytorch Whale identifier;Python notebook;8583.0;80;;
2019-01-21 09:57:35;Comprehensive Guide of Object Detection Algorithms(Computer Vision)  Zero to Hero Guide of Object Detection Part-1 Object Detection 1.1 What is Object Detection? 1.2 Object Localization 1.3 Maths Behind Object Localization 1.4 Object Localization Regression 1.5 Comparing bounding box prediction accuracy  Part-2 Algorithm of Object Detection HOG RCNN 2.1 Understanding of RCNN 2.2 Problems with RCNN   SPP-NET FastRCNN 2.3 Understanding Fast RCNN 2.4 Problems with Fast RCNN   FasterRCNN 2.5 Understanding Faster RCNN 2.6 Problems with Faster RCNN   Summary of the Algorithms covered;Apache 2.0;https://www.kaggle.com/ashishpatel26/comprehensive-guide-of-object-detection-algorithms;1.0;['caffe'];['ner', 'ai', 'cnn', 'gan', 'cv', 'rl', 'nn', 'ml'];['filter', 'recognition', 'vgg', 'predict', 'ground truth', 'object detection', 'train', 'alexnet', 'recommend', 'linear regression', 'classification', 'propagation', 'image classification', 'model', 'neural network', 'layer', 'loss', 'understanding', 'resnet', 'r-cnn', 'regression', 'deep learning', 'computer vision', 'convolutional neural network'];https://www.kaggle.com/c/humpback-whale-identification;0.699;0.421;2020-12-12 21:28:20;multiple data sources;[];Comprehensive Guide of Object Detection Algorithms;Python notebook;2964.0;37;;
2018-12-02 04:33:28;Triplet Model for Hampback Whole Prediction Outline of the Notebook  1.Introduction 2.Data Description 3.Evaluation 4.Submission Format 5.Required Packages 6.Define Parameter 7.Helping Function 8.Introduction to Triplet Loss 9.Model Design 10.Model Training 11.Image Generator 12.Predict Result;Apache 2.0;https://www.kaggle.com/ashishpatel26/triplet-loss-network-for-humpback-whale-prediction;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cnn', 'cv', 'rl', 'nn'];['filter', 'training data', 'train', 'recognition', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'understanding', 'resnet', 'labeled'];https://www.kaggle.com/c/humpback-whale-identification;0.75;0.458;2020-12-12 21:28:20;Humpback Whale Identification;['deep learning, classification, cnn, +1 moreindia'];Triplet Loss Network for Humpback Whale Prediction;Python notebook;10319.0;58;0.22299;0.22211
2018-12-06 19:37:51;Working with images is pretty memory consuming, especially if you read and preprocess all of them at the same time. The following approach avoids this problem in Keras, leaving more space in memory to use augmentation and/or loading pre-trained models. I hope this helps Kagglers to work on their networks in Kaggle kernels without worrying (or at least worrying less) with the 14GB of memory provided using GPU environment. I tried to comment the comment the code as clearer as I could, but if some part was not well-explained or if you have doubts, ask on the comments :) Contents  (Very) brief data exploration Training models using generators and flow_from_dataframe;Apache 2.0;https://www.kaggle.com/hrmello/flow-from-dataframe-a-memory-friendly-approach;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cnn', 'cv', 'rl', 'nn'];['unlabeled', 'filter', 'training data', 'test data', 'train', 'model', 'epoch', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'classification', 'labeled'];https://www.kaggle.com/c/humpback-whale-identification;0.7;0.418;2020-12-12 21:28:20;Humpback Whale Identification;['gpu'];Flow_from_dataframe: A memory-friendly approach ;Python notebook;3094.0;36;;
2019-02-18 03:47:18;"OverviewThe goal of this competition is identifying individual whales in images. Despite several whales are well represented in images, most of whales are unique or shown only in a few pictures. In particular, the train dataset includes 25k images and 5k unique whale ids. In addition, ~10k of images show unique whales ('new_whale' label). Checking public kernels suggests that a classical approach for classification problems based on softmax prediction for all classes is working quite well for this particular problem. However, strong class imbalance, handling labels represented by just several images, and 'new_whale' label deteriorates this approach. In addition, form the using this model for production, the above approach doesn't sound right since expansion of the model to identify new whales not represented in the train dataset would require retraining the model with increased softmax size. Meanwhile, the task of this competition could be reconsidered as checking similarities that suggests one-shot based learning algorithm to be applicable. This approach is less susceptible to data imbalance in this competition, can naturally handle 'new_whale' class, and is scalable in terms of a model for production (new classes can be added without retraining the model). There are several public kernels targeted at using similarity based approach. First of all, it is an amazing kernel posted by Martin Piotte, which discusses Siamese Neural Network architecture in details. A fork of this kernel reports 0.822 public LB score after training for 400 epochs. There is also a quite interesting public kernel discussing Triplet Neural Network architecture, which is supposed to overperform Siamese architecture (check links in this discussion). Since both positive and negative examples are provided, the gradients are appeared to be more stable, and the network is not only trying to get away from negative or get close to positive example but arranges the prediction to fulfil both. In this kernel I provide an example of a network inspired by Triplet architecture that is capable to reach ~0.81 public LB score after training within the kernel time limit in my preliminary test. Training for more epochs is supposed to improve the prediction even further. The main trick of this kernel is using batch all loss. If the forward pass is completed for all images in a batch, why shouldn't I compare all of them when calculate the loss function? why should I limit myself by just several triplets? I have designed a loss function in such a way that allows performing all vs. all comparison within each batch, in other words for a batch of size 32 instead of comparing 32 triplets or 64 pairs the network performs processing of 9216 pairs of images at the same time. If training is done on multiple GPUs, the number of compared pares could be boosted even further since it it proportional to bs^2. Such a huge number of processed pairs further stabilizes gradients in comparison with triplet loss and allows more effective mapping of the input into the embedding space since not only pairs or triplets but entire picture is seen at the same time. This approach also allows effective search for hard negative examples at the later stage of training since each image is compared with all images in a batch. I tried to boost the search of the most difficult negative examples even further by selection of most similar negative examples to an anchor image when build triplets. Moreover, I added metric learning that boosts the performance of the model really a lot. In my preliminary test for V2 setup I got 0.606->0.655 improvement after I started calculating distance as d^2 = (v1-v2).T x A x (v1-v2) instead of Euclidian (v1-v2).T x (v1-v2), where A is a trainable matrix parameter. It can be considered as a trainable deformation of the space. However, the above form of the metric is quite slow at the inference time when distances for all image pairs are calculated. Also, it is quite difficult to impose a constrain on A during training to make it positive semi defined. Therefore, I use an alternative approximation formulation for distance calculation that is much faster at the inference time, symmetric and always positive, and have similar (or slightly better) performance with accounting for nonlinear coordinate transformations. To prevent predictions being spread too much in the embedding space, which deteriorates generalization, I added a compactificcation term to the loss that boosted the score from 0.74 to ~0.771 (V9). When I switched from ResNeXt50 to DenseNet169 backbone I got 0.771 -> ~0.81 improvement, and it appeared that DenseNet121 works a little bit better. I switched to using cropped rescaled square images since they work better. The idea behind rectangular images generated without distortion of images, which I used in the first versions of the kernel, is the following. Since bounding boxes have different aspect ratio, each image has different degree of distortion when rescaled to square one, which could negatively affect training. However, it looks that the setup when the tail is occupying approximately the same area in the image, no matter what is its orientation and distortion, works better. Looking at the produced images I really do not understand why. In my preliminary test for V7 I could get a boost from ~0.70 to ~0.75 public LB after this modification. In the current setup, the images are cropped according to bounding boxes (thanks to this fork and to Martin Piotte for posting the original kernel) and rescaled to 224x224 square images. Milestones of the kernel score improvement and corresponding modifications are summorized in this discussion. This kernel is written with using fast.ai 0.7 since a newer version of fast.ai doesn't work well in kaggle: using more than one core for data loading leads to bus error ""DataLoader worker (pid 137) is killed by signal: Bus error"". Therefore, when I tried to write similar kernel with fast.ai 1.0, it appeared to be much slower, more than 1 hour per epoch vs. 20-30 min with this kernel if ResNet34 and images of size 576x192 are used. People interested in fast.ai 1.0 could check an example of Siamese network here. Also since fast.ai 0.7 is not really designed to build Siamese and Triplet networks, some parts are a little bit far away from a standard usage of the library. Highlights: Batch all loss, metric learning, mining hard negative examples";Apache 2.0;https://www.kaggle.com/iafoss/similarity-densenet121-0-805lb-kernel-time-limit;1.0;['pytorch', 'sklearn', 'pillow'];['ner', 'ai', 'dl', 'cnn', 'cv', 'nn', 'ann'];['filter', 'train', 'fitting', 'model', 'neural network', 'epoch', 'validation data', 'layer', 'loss', 'label', 'predict', 'relu', 'resnet', 'classification'];https://www.kaggle.com/c/humpback-whale-identification;0.777;0.538;2020-12-12 21:28:20;multiple data sources;['gpu, deep learning, classification, +2 moreimage data, cnn'];Similarity DenseNet;Python notebook;22394.0;170;0.84228;0.80557
2019-01-16 16:34:16;We all like to play around with data and get things done. In this kernel I'll show you how you can do it yourself. Full Video Explanation of this NotebookKAGGLE KERNELS 2019 I also have a full explanation on how to work with large Image datasets ( like this one :D )  How to Deal with Large Image Datasets and you can check out the Kernel Notebook Content Resources Some libraries we need to get things done How to load the dataset Looking at 5 random beauties Preprocessing the data   5.1 Using python OpenCV   5.2 Using torchvision Cleaning the Data Encoding Handling the dataset Building a very simple sequential model Conclusion;Apache 2.0;https://www.kaggle.com/jhonatansilva31415/whales-a-simple-guide;1.0;['pytorch', 'keras'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'ml', 'nn', 'ann'];['train', 'model', 'neural network', 'epoch', 'deep learning', 'layer', 'label', 'loss', 'computer vision', 'convolutional neural network'];https://www.kaggle.com/c/humpback-whale-identification;0.734;0.468;2020-12-12 21:28:20;Humpback Whale Identification;['data visualization, exploratory data analysis, deep learning, +2 moreclassification, data cleaning'];Whales. A Simple Guide!;Python notebook;6862.0;66;;
2019-01-20 23:16:27;Whale GANAn attempt to generate fake whale images for testing. Also for learning GAN networks. Based on code from:  Bounding Box Model Whale Classification Model;Apache 2.0;https://www.kaggle.com/ldm314/whale-gan;1.0;['tensorflow', 'keras'];['ner', 'ai', 'dl', 'gan', 'cv', 'nn', 'ann'];['generation', 'train', 'model', 'epoch', 'layer', 'loss', 'predict', 'relu', 'classification', 'ground truth'];https://www.kaggle.com/c/humpback-whale-identification;0.702;0.416;2020-12-12 21:28:20;multiple data sources;['gpu'];Whale GAN;Python notebook;3188.0;35;;
2018-12-01 00:31:46;Humpback Whale Identification - CNN with KerasThis kernel is based on Anezka Kolaceke's awesome work: CNN with Keras for Humpback Whale ID;Apache 2.0;https://www.kaggle.com/pestipeti/keras-cnn-starter;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'nn', 'cnn', 'rl'];['filter', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/humpback-whale-identification;0.757;0.507;2020-12-12 21:28:20;Humpback Whale Identification;['gpu, computer vision'];Keras CNN starter;Python notebook;12343.0;111;0.30220;0.28881
2018-12-07 15:58:32;Reference  Awesome Kernel, thanks @martinpiotte : https://www.kaggle.com/martinpiotte/bounding-box-model cropping.model: https://www.kaggle.com/martinpiotte/bounding-box-model/output Data: https://www.kaggle.com/c/humpback-whale-identification/data;Apache 2.0;https://www.kaggle.com/phhasian0710/create-bounding-box-images-whale-recognition;1.0;['tensorflow', 'keras'];['ai'];['train', 'recognition', 'model', 'predict'];https://www.kaggle.com/c/humpback-whale-identification;0.709;0.416;2020-12-12 21:28:20;multiple data sources;['gpu'];Create bounding box images - Whale Recognition;Python notebook;3774.0;35;;
2018-12-29 15:17:14;"Updated TL;DRI am just using the pretrained weights from  @martinpiotte. Thanks to @suicaokhoailang for creating the updated kernel. I think the important steps to improve to 0.9 are:  Get rid of lapjv dependency. It really slows down training/trying different ideas. Load images as RGB (and retrain). I can't find where, but the current first place wrote that it helps by ~0.1.  Interesting: The mpiotte-bootstrap-model only scored 0.697. Though, it was better on the playgroud competition.  TL;DRI tried to refactor @martinpiotte's original kernel here. I changed almost nothing beside commenting out the latter 380 epochs since it can't fit into a kernel. I also generated the new bounding boxes in my kernel here and saved it as a .csv instead of pickle for readability. A few things to point out:  Training more will probably improve your score, maybe as many as 500 epochs. We only train for 20 epochs in this kernel.  You may try to improve your training time by applying this technique (thanks Brian): https://www.kaggle.com/c/humpback-whale-identification/discussion/74402#444476 .  Consider using a pretrained model(s), good for blending.";Apache 2.0;https://www.kaggle.com/seesee/siamese-pretrained-0-822;1.0;['tensorflow', 'keras'];['ner', 'ai', 'cv', 'nn', 'ann'];['filter', 'train', 'model', 'neural network', 'epoch', 'layer', 'loss', 'predict', 'relu'];https://www.kaggle.com/c/humpback-whale-identification;0.794;0.571;2020-12-12 21:28:20;multiple data sources;['gpu'];Siamese (pretrained) 0.822;Python notebook;38064.0;279;0.84094;0.82297
2018-12-09 06:59:15;Reference  Awesome Kernel, thanks @martinpiotte : https://www.kaggle.com/martinpiotte/bounding-box-model cropping.model: https://www.kaggle.com/martinpiotte/bounding-box-model/output Data: https://www.kaggle.com/c/humpback-whale-identification/data;Apache 2.0;https://www.kaggle.com/suicaokhoailang/generating-whale-bounding-boxes;1.0;['tensorflow', 'keras'];['ai', 'nn', 'ann', 'cv'];['train', 'model', 'predict'];https://www.kaggle.com/c/humpback-whale-identification;0.733;0.446;2020-12-12 21:28:20;multiple data sources;['gpu'];Generating whale bounding boxes.;Python notebook;6642.0;50;;
2018-12-13 07:53:38;To wrap up, I take this kernel by @asanakoev and combine it with my idea here about a better classification method to see if it really works. Results:  Better training time (since we only used 68% of data): 5509s vs 8196s.'  A bit better accuracy, the threshold wasn't fine-tuned, it was taken from my original resnet18 kernel, so it can get better.;Apache 2.0;https://www.kaggle.com/suicaokhoailang/resnet50-bounding-boxes-0-628-lb;1.0;['pytorch', 'sklearn', 'pillow'];['ner', 'ai', 'cv', 'nn', 'ml'];['training data', 'train', 'recognition', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'resnet', 'classification'];https://www.kaggle.com/c/humpback-whale-identification;0.737;0.455;2020-12-12 21:28:20;multiple data sources;['gpu'];Resnet50 + Bounding Boxes [0.628 LB];Python notebook;7321.0;56;;
2019-02-20 09:59:36;"Most voted kernelIn this competition one of the most voted kernels is Siamese (pretrained) 0.822 by See--. Unfortunatelly for me I realized that by the end of the competition. Mostly I was working on porting Dlib metric learning paradigm to this competition.  However by reading original kernel Martin discloses something realy important in the Ensmble section The assembly strategy consist in compute a score matrix (or dimension test by train) that is a linear combination of the standard and bootstrap model. Generation of the submission using the score matrix is unchanged. Trial and error suggest a weight of 0.45 for the standard model and 0.55 for the bootstrap model. The resulting ensemble as an accuracy of 0.78563 using a threshold of 0.92.  So I did that....And used both weights provided using the weighting Martin suggested and I really hit on a good starting point. The rest of  this kernel code is just the same as See-- originally posted. I believe now that this is the starting point of the competion (at least for those working on Siameze networks). Hope that this may help come people with their mergings. Updated TL;DRI am just using the pretrained weights from  @martinpiotte. Thanks to @suicaokhoailang for creating the updated kernel. I think the important steps to improve to 0.9 are:  Get rid of lapjv dependency. It really slows down training/trying different ideas. Load images as RGB (and retrain). I can't find where, but the current first place wrote that it helps by ~0.1.  Interesting: The mpiotte-bootstrap-model only scored 0.697. Though, it was better on the playgroud competition.  TL;DRI tried to refactor @martinpiotte's original kernel here. I changed almost nothing beside commenting out the latter 380 epochs since it can't fit into a kernel. I also generated the new bounding boxes in my kernel here and saved it as a .csv instead of pickle for readability. A few things to point out:  Training more will probably improve your score, maybe as many as 500 epochs. We only train for 20 epochs in this kernel.  You may try to improve your training time by applying this technique (thanks Brian): https://www.kaggle.com/c/humpback-whale-identification/discussion/74402#444476 .  Consider using a pretrained model(s), good for blending.";Apache 2.0;https://www.kaggle.com/voglinio/siamese-two-pretrained-weights-0-855;1.0;['tensorflow', 'keras'];['ner', 'ai', 'dl', 'cv', 'nn', 'ann'];['filter', 'generation', 'train', 'model', 'neural network', 'epoch', 'layer', 'loss', 'predict', 'relu'];https://www.kaggle.com/c/humpback-whale-identification;0.719;0.456;2020-12-12 21:28:20;multiple data sources;['gpu'];Siamese (two pretrained weights) 0.855;Python notebook;4679.0;57;0.86838;0.85538
2019-09-03 04:24:55;General informationIn this kernel I work with IEEE Fraud Detection competition. EEE-CIS works across a variety of AI and machine learning areas, including deep neural networks, fuzzy systems, evolutionary computation, and swarm intelligence. Today they’re partnering with the world’s leading payment service company, Vesta Corporation, seeking the best solutions for fraud prevention industry, and now you are invited to join the challenge. We have a binary classification problem with a heavy imbalance which is an inherent property of such problems. At first I'll explore the data and try to find valuable insights, maybe I'll do some feature engineering and then it wil be time to build models.  Work in progress;Apache 2.0;https://www.kaggle.com/artgor/eda-and-models;1.0;['xgboost', 'lightgbm', 'catboost', 'sklearn', 'tensorflow'];['ner', 'ai', 'gbm', 'cv', 'rl', 'ml'];['machine learning', 'filter', 'regression', 'training data', 'train', 'test data', 'model', 'neural network', 'loss', 'label', 'predict', 'rank', 'classification'];https://www.kaggle.com/c/ieee-fraud-detection;0.823;0.646;2020-12-12 21:40:27;IEEE-CIS Fraud Detection;['data visualization, exploratory data analysis, classification, +1 morefeature engineering'];EDA and models;Python notebook;104741.0;1005;;
2020-02-02 00:12:36;"XGB Fraud with Magic scores LB 0.96This model is part of the 1st place solution to Kaggle's ""IEEE-CIS Fraud Detection"" competition. When this model is ensembled together with Konstantin's CatBoost and LGBM models, the result achieves public LB 0.9677 and private LB 0.9459 taking first place here In this kernel, we build two XGB models. The first model does not use the magic features and achieves LB 0.95. The second model uses the magic features and achieves LB 0.96. In the appendix, we demonstrate how to increase LB further with post processing. Reading one million rows of data from disk and engineering features takes 5 minutes using Pandas and CPU. Alternatively if we use RAPIDS cuDF and GPU, it takes only 20 seconds! CPU times are displayed beneath code blocks below and GPU 15x speed up is demonstrated here.";Apache 2.0;https://www.kaggle.com/cdeotte/xgb-fraud-with-magic-0-9600;1.0;['catboost', 'xgboost', 'sklearn'];['cv', 'ai', 'rl', 'gbm'];['training data', 'train', 'model', 'label', 'predict', 'decision tree'];https://www.kaggle.com/c/ieee-fraud-detection;0.789;0.587;2020-12-12 21:40:28;multiple data sources;['gpu'];XGB Fraud with Magic - [0.9600];Python notebook;32184.0;361;0.934084;0.961812
2019-09-01 17:03:38;About this kernelHey, everyone! This was my first solution to this competition. There is nothing revolutionary here as this is my first competition and I'm trying to learn with all the public kernels. I decided to share this solution to help people that are beginners like me, to at least give them an idea of what to do and where to begin. Later, I'll add a cell with all the advice people gave me in the discussions so we can talk more about it here. I'll also add a reference to the kernels I used here. Please, give me some feedback if you can. I would love to hear what you believe could be improved in this kernel. Hope you are enjoying this competition as much as I am. Good luck and I hope you like this kernel. [UPDATE] In the comments section, @cebeci told me the merging process was wrong and it really was. I'm sorry about it, merging is now correct. Also in the comments, @lftuwujie told me the GPU makes almost no difference to LGBM. I tested it and he was (as expected) correct, so this was also changed. Thank you for all the feedback and support. It's been really nice to learn with all of you.;Apache 2.0;https://www.kaggle.com/davidcairuz/feature-engineering-lightgbm;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'gbm', 'rl', 'nn'];['filter', 'test data', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/ieee-fraud-detection;0.777;0.566;2020-12-12 21:40:28;IEEE-CIS Fraud Detection;['classification, feature engineering, data cleaning'];Feature Engineering & LightGBM;Python notebook;22312.0;262;;
2019-07-18 09:27:34;"IEEE Fraud Detection    Why fraud detection? Fraud is a billion-dollar business and it is increasing every year. The PwC global economic crime survey of 2018[1] found that half (49 percent) of the 7,200 companies they surveyed had experienced fraud of some kind. This is an increase from the PwC 2016 study in which slightly more than a third of organizations surveyed (36%) had experienced economic crime.  This competition is a binary classification problem - i.e. our target variable is a binary attribute (Is the user making the click fraudlent or not?) and our goal is to classify users into ""fraudlent"" or ""not fraudlent"" as well as possible. Unlike metrics such as LogLoss, the AUC score only depends on how well you well you can separate the two classes. In practice, this means that only the order of your predictions matter, as a result of this, any rescaling done to your model's output probabilities will have no effect on your score. click here to read more about AUC-ROC  Content Data exploration Missing Data. Imbalanced problem.   Plots Distribution plots Count plots Unique values Groups     Memory reduction  PCA    Models XGBoost Model. LGBM    Remember the upvote button is next to the fork button, and it's free too! ;)  References: https://www.kaggle.com/artgor/eda-and-models/data https://www.kaggle.com/artkulak/ieee-fraud-simple-baseline-0-9383-lb https://www.kaggle.com/robikscube/ieee-fraud-detection-first-look-and-eda https://www.kaggle.com/mjbahmani/reducing-memory-size-for-ieee";Apache 2.0;https://www.kaggle.com/jesucristo/fraud-complete-eda;1.0;['xgboost', 'lightgbm', 'catboost', 'sklearn', 'pattern'];['ai', 'dl', 'gan', 'gbm', 'cv', 'rl', 'nn'];['filter', 'test data', 'train', 'model', 'loss', 'label', 'predict', 'classification'];https://www.kaggle.com/c/ieee-fraud-detection;0.789;0.595;2020-12-12 21:40:27;IEEE-CIS Fraud Detection;['gpu, beginner, data visualization, +1 moreexploratory data analysis'];Fraud complete EDA;Python notebook;31916.0;413;;
2019-08-08 03:28:43;Feature Engineering~Almost~ all features of IEEE fraud detectetion datasetPurpose of the kernel:In the last week I worked in all features trying to improve my model. I've worked in almost all features and I decided to share with the kaggle fellows. NOTE: Maybe not all features could be useful, but I think that this work could help other kagglers in Data manipulation or to create another interesting feature;Apache 2.0;https://www.kaggle.com/kabure/almost-complete-feature-engineering-ieee-data;1.0;['xgboost', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'nn', 'ml'];['training data', 'regression', 'train', 'fitting', 'model', 'loss', 'label', 'logistic regression', 'predict', 'recommend'];https://www.kaggle.com/c/ieee-fraud-detection;0.744;0.551;2020-12-12 21:40:28;IEEE-CIS Fraud Detection;['beginner, feature engineering, data cleaning'];~Almost~ complete Feature Engineering IEEE data;Python notebook;8886.0;208;0.875381;0.918045
2019-08-06 17:21:19;As my other kernel has running very slow because the interactive plots, I decided to start again using only Seaborn and matplotlib.You can visit here:  Interactive IEEE Fraud Detection  Also, I worked in all features of this dataset and you can access the Kernel here:   ~Almost~ complete Feature Engineering IEEE data;Apache 2.0;https://www.kaggle.com/kabure/extensive-eda-and-modeling-xgb-hyperopt;1.0;['pattern', 'xgboost', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'nn', 'ml'];['training data', 'regression', 'train', 'fitting', 'model', 'loss', 'label', 'logistic regression', 'predict', 'recommend'];https://www.kaggle.com/c/ieee-fraud-detection;0.806;0.639;2020-12-12 21:40:27;IEEE-CIS Fraud Detection;['beginner, exploratory data analysis, finance'];Extensive EDA and Modeling XGB Hyperopt;Python notebook;56609.0;883;0.892536;0.926184
2019-09-01 01:47:11;SummaryI'll try to make a small summary for this blend baseline: Step: 0. EDA (missing kernel here, I'll post later) Step: 1. Minify Data https://www.kaggle.com/kyakovlev/ieee-data-minification  Step: 2. Make ground baseline with no fe: https://www.kaggle.com/kyakovlev/ieee-ground-baseline and  https://www.kaggle.com/kyakovlev/ieee-ground-baseline-deeper-learning  Step: 3. Make a small FE and see I you can understand data you have https://www.kaggle.com/kyakovlev/ieee-ground-baseline-make-amount-useful-again and  https://www.kaggle.com/kyakovlev/ieee-gb-2-make-amount-useful-again  Step: 4. Find good CV strategy https://www.kaggle.com/kyakovlev/ieee-cv-options and same with gap to compare results (gap in values is what we have in test set) https://www.kaggle.com/kyakovlev/ieee-cv-options-with-gap  Step: 4(1). Groupkfold (by timeblocks) application https://www.kaggle.com/kyakovlev/ieee-lgbm-with-groupkfold-cv  Step: 5. Try different set of features https://www.kaggle.com/kyakovlev/ieee-experimental  Step: 6. Make deeper FE (brute force option) https://www.kaggle.com/kyakovlev/ieee-fe-with-some-eda  Step: 7. Features selection (missing kernel here, I'll post later) Step: 8. Hyperopt (missing kernel here, I'll post later) Step: 9. Try other models (XGBoost, CatBoost, NN - missing kernel here, I'll post later) CatBoost (with categorical transformations)  https://www.kaggle.com/kyakovlev/ieee-catboost-baseline-with-groupkfold-cv  Step: 10. Try blending and stacking (missing kernel here, I'll post later)  (Utils) Some tricks that where used in fe kernel https://www.kaggle.com/kyakovlev/ieee-small-tricks  Part of EDA (Just few things) https://www.kaggle.com/kyakovlev/ieee-check-noise and https://www.kaggle.com/kyakovlev/ieee-simple-eda   https://www.kaggle.com/c/ieee-fraud-detection/discussion/104142;Apache 2.0;https://www.kaggle.com/kyakovlev/ieee-internal-blend;1.0;['catboost', 'xgboost'];['ner', 'ai', 'gbm', 'cv', 'nn'];['model', 'filter'];https://www.kaggle.com/c/ieee-fraud-detection;0.764;0.547;2020-12-12 21:40:28;multiple data sources;[];IEEE - Internal Blend;Python notebook;15212.0;196;0.928489;0.951826
2019-09-17 11:49:32;In this kernel I will do my EDA on the dataset, make some visualizations, try to find any insights and create some new features. Join me, it promises to be a thrilling adventure. Some tricks being used:  card1 count encoding Covariate Shift features interaction data relaxation  New engineered features:  Number of NaNs TransactionAmt and it's decimal part;Apache 2.0;https://www.kaggle.com/nroman/eda-for-cis-fraud-detection;1.0;['lightgbm', 'sklearn'];['cv', 'ai', 'gbm'];['filter', 'train', 'model', 'label', 'gradient boosting', 'predict', 'decision tree'];https://www.kaggle.com/c/ieee-fraud-detection;0.768;0.564;2020-12-12 21:40:28;IEEE-CIS Fraud Detection;[];EDA for CIS Fraud Detection;Python notebook;17218.0;254;;
2019-08-02 22:20:53;Let's take a look how similar train and test sets are.;Apache 2.0;https://www.kaggle.com/tunguz/adversarial-ieee;1.0;['xgboost', 'sklearn', 'lightgbm'];['ai', 'rl', 'nn', 'gbm'];['train', 'model', 'label', 'filter'];https://www.kaggle.com/c/ieee-fraud-detection;0.745;0.532;2020-12-12 21:40:28;multiple data sources;[];Adversarial IEEE;Python notebook;9092.0;157;;
2019-08-04 17:20:49;IEEE Fraud Detection - Bayesian optimization - LGBVincent Lugat July 2019;Apache 2.0;https://www.kaggle.com/vincentlugat/ieee-lgb-bayesian-opt;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'nn', 'ml'];['filter', 'train', 'model', 'label', 'predict', 'bayesian'];https://www.kaggle.com/c/ieee-fraud-detection;0.759;0.546;2020-12-12 21:40:28;IEEE-CIS Fraud Detection;['classification'];IEEE - LGB + Bayesian opt.;Python notebook;13092.0;192;;
2019-07-24 17:32:38;"About this kernelBefore I get started, I just wanted to say: huge props to Inversion! The official starter kernel is AWESOME; it's so simple, clean, straightforward, and pragmatic. It certainly saved me a lot of time wrangling with data, so that I can directly start tuning my models (real data scientists will call me lazy, but hey I'm an engineer I just want my stuff to work). I noticed two tiny problems with it:  It takes a lot of RAM to run, which means that if you are using a GPU, it might crash as you try to fill missing values. It takes a while to run (roughly 3500 seconds, which is more than an hour; again, I'm a lazy guy and I don't like waiting).  With this kernel, I bring some small changes:  Decrease RAM usage, so that it won't crash when you change it to GPU. I simply changed when we are deleting unused variables. Decrease running time from ~3500s to ~40s (yes, that's almost 90x faster), at the cost of a slight decrease in score. This is done by adding a single argument.  Again, my changes are super minimal (cause Inversion's kernel was already so awesome), but I hope it will save you some time and trouble (so that you can start working on cool stuff). ChangelogV4  Change some wording Prints XGBoost version Add random state to XGB for reproducibility";Apache 2.0;https://www.kaggle.com/xhlulu/ieee-fraud-xgboost-with-gpu-fit-in-40s;1.0;['xgboost', 'sklearn'];['ai', 'nn', 'rl'];['train', 'fitting', 'model', 'label', 'predict'];https://www.kaggle.com/c/ieee-fraud-detection;0.754;0.553;2020-12-12 21:40:28;IEEE-CIS Fraud Detection;['gpu, beginner, classification, +1 morexgboost'];IEEE Fraud: XGBoost with GPU (Fit in 40s);Python notebook;11340.0;212;0.901162;0.938102
2018-04-11 08:18:24;I believe it is many people (including me) first time to deal with multilabel classification. I spent some time struggling converting the label columns to the matrix, after which I found out a much simpler, easier and faster way for the conversion.;Apache 2.0;https://www.kaggle.com/anqitu/for-starter-json-to-multilabel-in-24-seconds;1.0;['sklearn'];['ner', 'ai', 'rl', 'ml', 'nn', 'ann'];['filter', 'test data', 'train', 'validation data', 'label', 'recommend', 'classification'];https://www.kaggle.com/c/imaterialist-challenge-fashion-2018;0.694;0.39;2020-12-12 21:47:00;iMaterialist Challenge (Fashion) at FGVC5;[];For Starter: JSON to MultiLabel in 24 seconds;Python notebook;2680.0;26;;
2018-05-22 02:30:00;OverviewInput: training data with image urls and labels Goal: generate the prediction of labels of each test set image Key steps of my strategy Rank the google labels of training images by frequency. Filter out labels that are not indicative or not having strong correlation with wish.com labels.  For each google label, extract all training images containing that label and corresponding wish.com labels. Aggregate those wish.com labels and rank them according to frequency. Filter out labels with frequency less than a certain threshold. My hypothesis is that the frequent wish.com labels are correlated with google label, so we can use google labels as an indicator of wish.com labels.  Detect the google labels of each test image, and assign corresponding wish.com to each test image. Cluster training images, and extract frequent labels of each cluster. My hypothesis is that for images in each cluster, they should have some labels in common. Use google labels to detect which cluster each test image belongs to. Add common labels of that cluster to the test image. Remove duplicate wish.com labels of each test image.  Full strategy with details: Use Google Vision API to detect the labels of 10,000 images in training set. Aggregate all labels together and rank them by frequency. Filter out top 10 most frequent labels as they are not indicative in this circumstance. Also, filter out labels with frequency less than a threshold. I will name the table generated in this step as “ranking table”.  For each label in “ranking table”, identify training images containing that label, and aggregate corresponding wish.com labels together. Then aggregate those wish.com labels and rank them according to frequency. Filter out wish.com labels with frequency lower than a threshold. My hypothesis is that the frequent wish.com labels are correlated with google label, so we can use google labels as an indicator of wish.com labels. After this step, a table indicating the matching relationship will be generated, and I will name this table as “matching table”.  Use Google Vision API to detect the labels of each image in test set. For each Google label of the image, append the matching wish.com labels from the matching table. After this step, a table named “prediction table” will be generated. The column “predicted labels” is super long and there are many duplicate labels, I will remove duplicate labels later.  Use k-means clustering method to assign 10,000 training set images into 60 clusters. For each cluster, select training set images belonging to that cluster and aggregate all corresponding wish.com labels. Rank those labels by frequency and select top 5 most frequent labels as representative labels of that cluster. After this step, a table indicating the representative labels of each cluster will be generated, and I will name this table as “clusters table”.  For each test set image, identify which cluster it belongs to. For each test set image, if predicted labels contain three or more representative labels of a cluster, then I would say the image belongs to that cluster, and I will assign other representative labels to that label.  Remove duplicate labels of each test set image, as I found that duplicate labels will affect the f-score of prediction.   Flow chart;Apache 2.0;https://www.kaggle.com/disenwang1994/matching-clustering;1.0;['sklearn'];['ner', 'ai', 'rl', 'nn', 'ann'];['filter', 'training data', 'test data', 'train', 'model', 'validation data', 'clustering', 'label', 'k-means', 'predict', 'rank', 'labeled'];https://www.kaggle.com/c/imaterialist-challenge-fashion-2018;0.684;0.302;2020-12-12 21:47:00;multiple data sources;[];Matching + Clustering;Python notebook;2152.0;10;;
2018-04-22 08:37:35;Extensive EDA of iMaterialist (Fashion) Dataset with Object Detection and Color AnalysisThis notebook contains the exploration of iMaterialist Challenge (Fashion) at FGVC5 dataset About the iMaterialist (Fashion) Competition - As shoppers move online, it would be a dream come true to have products in photos classified automatically. But, automatic product recognition is tough because for the same product, a picture can be taken in different lighting, angles, backgrounds, and levels of occlusion. Meanwhile different fine-grained categories may look very similar, for example, royal blue vs turquoise in color. Many of today’s general-purpose recognition machines simply cannot perceive such subtle differences between photos, yet these differences could be important for shopping decisions. Tackling issues like this is why the Conference on Computer Vision and Pattern Recognition (CVPR) has put together a workshop specifically for data scientists focused on fine-grained visual categorization called the FGVC5 workshop. As part of this workshop, CVPR is partnering with Google, Wish, and Malong Technologies to challenge the data science community to help push the state of the art in automatic image classification. In this competition, FGVC workshop organizers with Wish and Malong Technologies challenge you to develop algorithms that will help with an important step towards automatic product detection – to accurately assign attribute labels for fashion images. Individuals/Teams with top submissions will be invited to present their work live at the FGVC5 workshop. Contents 1. Descriptive Statistics 1.1 Counts of Images and Labels   1.2 Top Labels in the dataset   1.3 Most Common Co-occuring Labels   1.4 Images with maxium Labels   1.5 Images with single Label   1.6 Freq Dist of Images in different label count buckets     2. Colors Used in the Images 2.1 Top Average Color of the images 2.2 Dominant Colors present in the images 2.3 Common Color Palletes   3. Object Detection 3.1 Top Colors Detected in the images 3.2 Top Objects Detected in the images;Apache 2.0;https://www.kaggle.com/djuuuu/imaterialist-object-detection-colors-eda;1.0;['pattern', 'tensorflow'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['image classification', 'training data', 'test data', 'object detection', 'train', 'recognition', 'model', 'validation data', 'label', 'computer vision', 'classification'];https://www.kaggle.com/c/imaterialist-challenge-fashion-2018;0.631;0.099;2020-12-12 21:47:00;multiple data sources;[];iMaterialist: Object Detection + Colors + EDA;Python notebook;769.0;1;;
2018-05-06 11:57:42;Extensive EDA of iMaterialist (Fashion) Dataset with Object Detection and Color AnalysisThis notebook contains the exploration of iMaterialist Challenge (Fashion) at FGVC5 dataset About the iMaterialist (Fashion) Competition - As shoppers move online, it would be a dream come true to have products in photos classified automatically. But, automatic product recognition is tough because for the same product, a picture can be taken in different lighting, angles, backgrounds, and levels of occlusion. Meanwhile different fine-grained categories may look very similar, for example, royal blue vs turquoise in color. Many of today’s general-purpose recognition machines simply cannot perceive such subtle differences between photos, yet these differences could be important for shopping decisions. Tackling issues like this is why the Conference on Computer Vision and Pattern Recognition (CVPR) has put together a workshop specifically for data scientists focused on fine-grained visual categorization called the FGVC5 workshop. As part of this workshop, CVPR is partnering with Google, Wish, and Malong Technologies to challenge the data science community to help push the state of the art in automatic image classification. In this competition, FGVC workshop organizers with Wish and Malong Technologies challenge you to develop algorithms that will help with an important step towards automatic product detection – to accurately assign attribute labels for fashion images. Individuals/Teams with top submissions will be invited to present their work live at the FGVC5 workshop. Contents 1. Descriptive Statistics       1.1 Counts of Images and Labels          1.2 Top Labels in the dataset          1.3 Most Common Co-occuring Labels          1.4 Images with maxium Labels          1.5 Images with single Label          1.6 Freq Dist of Images in different label count buckets 2. Colors Used in the Images          2.1 Top Average Color of the images          2.2 Dominant Colors present in the images          2.3 Common Color Palletes 3. Object Detection          3.1 Top Colors Detected in the images          3.2 Top Objects Detected in the images;Apache 2.0;https://www.kaggle.com/shivamb/imaterialist-fashion-eda-object-detection-colors;1.0;['pattern', 'tensorflow'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['image classification', 'training data', 'test data', 'object detection', 'train', 'recognition', 'model', 'validation data', 'label', 'computer vision', 'classification'];https://www.kaggle.com/c/imaterialist-challenge-fashion-2018;0.777;0.541;2020-12-12 21:47:00;multiple data sources;['beginner, data visualization, image data'];iMaterialist(Fashion): EDA+Object Detection+Colors;Python notebook;22406.0;180;;
2019-05-17 20:22:12;This kernel is U-Net Baseline written by PyTorchIn this kernel, there are many places that are simplified now. So, you should fix these bad points. U-Net web site U-Net paper I reference this blog post in U-Net installation. Thank you awesome this blog post. This is my EDA. If you don't know this competition rule and data, this EDA might help you.;Apache 2.0;https://www.kaggle.com/go1dfish/u-net-baseline-by-pytorch-in-fgvc6-resize;1.0;['pytorch'];['ner', 'ai', 'dl', 'cv', 'nn', 'ann'];['train', 'epoch', 'label', 'loss', 'relu', 'u-net'];https://www.kaggle.com/c/imaterialist-fashion-2019-FGVC6;0.738;0.485;2020-12-13 11:35:56;iMaterialist (Fashion) 2019 at FGVC6;['gpu'];U-Net Baseline by PyTorch in FGVC6 resize;Python notebook;7483.0;82;0.00127;0.00153
2019-05-02 14:00:48;Let's segment a variety of clothing types!import modules and define utils;Apache 2.0;https://www.kaggle.com/go1dfish/updated4-29-fgvc6-simple-eda;1.0;['pattern'];['ner', 'ai', 'gan', 'cv', 'rl', 'nn', 'ann'];['rank', 'label', 'train', 'predict'];https://www.kaggle.com/c/imaterialist-fashion-2019-FGVC6;0.714;0.456;2020-12-13 11:35:56;iMaterialist (Fashion) 2019 at FGVC6;[];[Updated4/29] FGVC6 simple EDA!;Python notebook;4163.0;57;;
2019-04-30 11:49:30;Fine-grained segmentation task for fashion and appareliMaterialist (Fashion) 2019 at FGVC6 with dataset Designers know what they are creating, but what, and how, do people really wear their products? What combinations of products are people using? In this competition, we challenge you to develop algorithms that will help with an important step towards automatic product detection – to accurately assign segmentations and attribute labels for fashion images. Visual analysis of clothing is a topic that has received increasing attention in recent years. Being able to recognize apparel products and associated attributes from pictures could enhance the shopping experience for consumers, and increase work efficiency for fashion professionals. We present a new clothing dataset with the goal of introducing a novel fine-grained segmentation task by joining forces between the fashion and computer vision communities. The proposed task unifies both categorization and segmentation of rich and complete apparel attributes, an important step toward real-world applications.;Apache 2.0;https://www.kaggle.com/hyeonho/imaterialist-fashion-2019-at-fgvc6-eda;1.0;['pattern'];['ner', 'ai', 'gan', 'cv', 'rl'];['test data', 'filter', 'train', 'label', 'computer vision'];https://www.kaggle.com/c/imaterialist-fashion-2019-FGVC6;0.674;0.34;2020-12-13 11:35:56;iMaterialist (Fashion) 2019 at FGVC6;[];iMaterialist (Fashion) 2019 at FGVC6 - EDA;Python notebook;1742.0;15;;
2019-05-03 18:40:03;This is a work in progress. Training set is sampled at 5% and image size is set far smaller than optimal in order to run in a reasonable amount of time. Code to generate appropriate RLE output for submission is not ready yet, I will add it when it is.;Apache 2.0;https://www.kaggle.com/interneuron/fastai-custom-rle;1.0;['pytorch', 'pytorchcv'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'nn', 'ml'];['train', 'model', 'epoch', 'loss', 'label', 'predict', 'computer vision', 'resnet', 'labeled', 'ground truth'];https://www.kaggle.com/c/imaterialist-fashion-2019-FGVC6;0.681;0.311;2020-12-13 11:35:56;iMaterialist (Fashion) 2019 at FGVC6;['gpu'];fastai custom RLE;Python notebook;2029.0;11;;
2019-05-06 07:44:25;In this kernel I use the incredible repo https://github.com/qubvel/segmentation_models.pytorch along with catalyst. Most of the code here is adapted from qubvel's camvid example notebook in the segmentation models repo, I adapted it to work with these data.;Apache 2.0;https://www.kaggle.com/interneuron/segmentation-models-pytorch-catalyst;1.0;['opencv-python', 'pillow', 'pytorch', 'albumentations', 'tensorflow', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['test data', 'train', 'model', 'neural network', 'epoch', 'loss', 'label', 'predict', 'resnet'];https://www.kaggle.com/c/imaterialist-fashion-2019-FGVC6;0.725;0.352;2020-12-13 11:35:56;iMaterialist (Fashion) 2019 at FGVC6;['gpu'];segmentation models pytorch+ catalyst;Python notebook;5517.0;17;;
2019-06-13 08:00:46;สวัสดีครับ ขอต้อนรับทุกท่านเข้าสู่อีก workshop นึง ของ ThAIKeras ใน workshop นี้ เราจะมาลองทำ image segmentation กัน บนข้อมูล iMaterialist - Fashion 2019 ซึ่งเป็นข้อมูลที่ใช้ในการแข่งขันของ Kaggle ที่เพิ่งจะจบไปไม่นานนี้เองครับ;Apache 2.0;https://www.kaggle.com/pednoi/image-segmentation;1.0;['pytorch', 'tensorflow', 'sklearn', 'keras'];['ai', 'dl', 'cnn', 'gan', 'cv', 'rl', 'nn', 'ann'];['filter', 'predict', 'ground truth', 'autoencoder', 'object detection', 'train', 'epoch', 'classification', 'model', 'neural network', 'layer', 'loss', 'resnet', 'image segmentation', 'r-cnn', 'test data', 'regression', 'label', 'computer vision'];https://www.kaggle.com/c/imaterialist-fashion-2019-FGVC6;0.787;0.253;2020-12-13 11:35:56;iMaterialist (Fashion) 2019 at FGVC6;['gpu'];เรียนรู้การทำ Image Segmentation กับงานด้านแฟชั่น;Python notebook;30121.0;6;;
2019-05-22 17:15:08;Welcome to the world where fashion meets computer vision! This is a starter kernel that applies Mask R-CNN with COCO pretrained weights to the task of iMaterialist (Fashion) 2019 at FGVC6.;Apache 2.0;https://www.kaggle.com/pednoi/training-mask-r-cnn-to-be-a-fashionista-lb-0-07;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'dl', 'cnn', 'cv', 'rl', 'nn', 'ann'];['image segmentation', 'r-cnn', 'filter', 'test data', 'train', 'model', 'epoch', 'deep learning', 'layer', 'validation data', 'loss', 'label', 'predict', 'computer vision', 'resnet', 'classification', 'u-net'];https://www.kaggle.com/c/imaterialist-fashion-2019-FGVC6;0.775;0.536;2020-12-13 11:35:56;iMaterialist (Fashion) 2019 at FGVC6;['gpu'];Training Mask R-CNN to be a Fashionista (LB≈0.07);Python notebook;21073.0;166;;
2020-07-27 12:44:46;Welcome to the world where fashion meets computer vision! This is a starter kernel that applies Mask R-CNN with COCO pretrained weights to the task of iMaterialist (Fashion) 2019 at FGVC6.;Apache 2.0;https://www.kaggle.com/prabhavsingh/training-mask-r-cnn-to-be-a-fashionista-lb-dfc5f0;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'dl', 'cnn', 'cv', 'rl', 'nn', 'ann'];['image segmentation', 'r-cnn', 'filter', 'test data', 'train', 'model', 'epoch', 'deep learning', 'layer', 'validation data', 'loss', 'label', 'predict', 'computer vision', 'resnet', 'classification', 'u-net'];https://www.kaggle.com/c/imaterialist-fashion-2019-FGVC6;0.552;0.152;2020-12-13 11:35:56;iMaterialist (Fashion) 2019 at FGVC6;['gpu'];Training Mask R-CNN to be a Fashionista (LB dfc5f0;Python notebook;209.0;2;;
2020-08-26 06:44:17;Welcome to the world where fashion meets computer vision! This is a starter kernel that applies Mask R-CNN with COCO pretrained weights to the task of iMaterialist (Fashion) 2019 at FGVC6.;Apache 2.0;https://www.kaggle.com/satyamsharma/mask-rcnn-attribute-prediction;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'cnn', 'cv', 'rl', 'nn', 'ann'];['r-cnn', 'filter', 'test data', 'train', 'model', 'epoch', 'validation data', 'layer', 'loss', 'label', 'predict', 'computer vision', 'resnet', 'classification'];https://www.kaggle.com/c/imaterialist-fashion-2019-FGVC6;0.544;0.152;2020-12-13 11:35:56;multiple data sources;[];Mask RCNN Attribute Prediction;Python notebook;188.0;2;;
2019-10-17 18:38:10;I'm currently doing the fastai practical deep learning course. An option for lesson 3's homework was to try out a segmentation problem, so this seemed like a good opportunity to do that. To keep things simple I kept it to just the 27 main apparel items (no apparel parts or attributes), and I converted run-encoded pixels to png images to feed into the standard SegmentationItemList. Improvement areas:  Create a custom SegmentationItemList that takes the run length enconded masks directly (as is done in internueron's kernel) Use more data, currently limited to ~10% of the training images (5k) to save time Use larger images, currently using 224x224 images to save time  I may work on the above, but for now am going to continue with the course. Maybe this kernel helps others.;Apache 2.0;https://www.kaggle.com/solpaul/fastai-factory-approach-using-mask-images;1.0;['pytorch'];['ner', 'ai', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['train', 'model', 'epoch', 'deep learning', 'label', 'loss', 'resnet'];https://www.kaggle.com/c/imaterialist-fashion-2019-FGVC6;0.691;0.311;2020-12-13 11:35:56;iMaterialist (Fashion) 2019 at FGVC6;['gpu'];Fastai factory approach using mask images;Python notebook;2512.0;11;;
2020-04-27 21:20:19;Welcome to the world where fashion meets computer vision! This is a starter kernel that applies Mask R-CNN with COCO pretrained weights to the task of iMaterialist (Fashion) 2019 at FGVC6.;Apache 2.0;https://www.kaggle.com/adityamehndiratta/training-mask-r-cnn-to-be-a-fashionista-lb-0-07;1.0;['pattern', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'nn', 'ann'];['image segmentation', 'r-cnn', 'filter', 'machine learning', 'test data', 'train', 'model', 'epoch', 'deep learning', 'layer', 'validation data', 'loss', 'label', 'predict', 'computer vision', 'resnet', 'classification', 'u-net'];https://www.kaggle.com/c/imaterialist-fashion-2020-fgvc7;0.6;0.099;2020-12-13 11:37:41;multiple data sources;[];Training Mask R-CNN to be a Fashionista (LB≈0.07);Python notebook;446.0;1;;
2020-03-26 03:12:17;"""developed by : aipythoner@gmail.com"" I'm a tensorflow(keras) user and try to learn how fastai library work, but prefer to do it on realworld datasets Developed model and results can be found on my Github";Apache 2.0;https://www.kaggle.com/aipythoner/fashion-segmentation-preprocessing;1.0;['tensorflow', 'skimage', 'keras'];['ner', 'ai', 'rl', 'cv'];['train', 'model', 'label', 'filter'];https://www.kaggle.com/c/imaterialist-fashion-2020-fgvc7;0.621;0.188;2020-12-13 11:37:41;iMaterialist (Fashion) 2020 at FGVC7;['beginner, deep learning, image data'];Fashion Segmentation Preprocessing;Python notebook;644.0;3;;
2020-04-15 19:06:43;Step 1: Using 4 MaskRCNN Models for SuperCategory Prediction;Apache 2.0;https://www.kaggle.com/akshatag10/kernel14be54d714;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cnn', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['r-cnn', 'filter', 'object detection', 'train', 'model', 'neural network', 'epoch', 'validation data', 'layer', 'loss', 'label', 'predict', 'relu', 'resnet', 'ground truth'];https://www.kaggle.com/c/imaterialist-fashion-2020-fgvc7;0.494;0.099;2020-12-13 11:37:42;multiple data sources;['gpu'];kernel14be54d714;Python notebook;93.0;1;;
2020-04-16 14:29:13;Step 1: Using 4 MaskRCNN Models for SuperCategory Prediction;Apache 2.0;https://www.kaggle.com/akshatag10/kernel29563efe5f;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cnn', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['r-cnn', 'filter', 'object detection', 'train', 'model', 'neural network', 'epoch', 'validation data', 'layer', 'loss', 'label', 'predict', 'relu', 'resnet', 'ground truth'];https://www.kaggle.com/c/imaterialist-fashion-2020-fgvc7;0.509;0.099;2020-12-13 11:37:42;multiple data sources;['gpu'];kernel29563efe5f;Python notebook;114.0;1;;
2020-04-15 19:50:40;Step 1: Using 4 MaskRCNN Models for SuperCategory Prediction;Apache 2.0;https://www.kaggle.com/akshatag10/kernel7e5fb61efd;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cnn', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['r-cnn', 'filter', 'object detection', 'train', 'model', 'neural network', 'epoch', 'validation data', 'layer', 'loss', 'label', 'predict', 'relu', 'resnet', 'ground truth'];https://www.kaggle.com/c/imaterialist-fashion-2020-fgvc7;0.464;0.099;2020-12-13 11:37:42;multiple data sources;['gpu'];kernel7e5fb61efd;Python notebook;63.0;1;;
2020-05-22 16:14:09;Dataloader tutorial How to show PIL Image in ipython notebook Dataloader for semantic segmentation;Apache 2.0;https://www.kaggle.com/doranlyong/data-loader-for-pytorch;1.0;['pytorch', 'detectron', 'pattern'];['ai', 'dl', 'cnn', 'gan', 'rl', 'nn', 'ann'];['train', 'label', 'object detection', 'validation data'];https://www.kaggle.com/c/imaterialist-fashion-2020-fgvc7;0.523;0.0;2020-12-13 11:37:42;iMaterialist (Fashion) 2020 at FGVC7;[];Data loader for PyTorch;Python notebook;138.0;0;;
2020-04-03 19:58:51;Image size analysis in training dataset;Apache 2.0;https://www.kaggle.com/kaushal2896/imaterialist-2020-starter-eda-mask-rcnn;1.0;['pattern', 'tensorflow', 'sklearn', 'keras'];['ai', 'dl', 'cnn', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'training data', 'train', 'model', 'epoch', 'layer', 'label', 'loss', 'resnet'];https://www.kaggle.com/c/imaterialist-fashion-2020-fgvc7;0.729;0.446;2020-12-13 11:37:41;iMaterialist (Fashion) 2020 at FGVC7;['gpu'];iMaterialist 2020: Starter EDA + Mask RCNN;Python notebook;6056.0;50;;
2020-04-07 09:29:38;lets open the file train.csv ,label.csv and describe submission.csv;Apache 2.0;https://www.kaggle.com/mulbajjasha/my-first-kernel;1.0;['pytorch', 'albumentations', 'pattern'];['ner', 'ai', 'dl', 'cnn', 'gan', 'rl', 'ml', 'nn', 'ann'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'resnet'];https://www.kaggle.com/c/imaterialist-fashion-2020-fgvc7;0.595;0.188;2020-12-13 11:37:41;iMaterialist (Fashion) 2020 at FGVC7;[];EDA + MaskR-CNN, LB = 0.23;Python notebook;412.0;3;;
2020-04-27 09:40:52;lets open the file train.csv ,label.csv and describe submission.csv;Apache 2.0;https://www.kaggle.com/snagerashish/eda-maskr-cnn-lb-0-23;1.0;['pytorch', 'albumentations', 'pattern'];['ner', 'ai', 'dl', 'cnn', 'gan', 'rl', 'ml', 'nn', 'ann'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'resnet'];https://www.kaggle.com/c/imaterialist-fashion-2020-fgvc7;0.588;0.0;2020-12-13 11:37:42;iMaterialist (Fashion) 2020 at FGVC7;[];EDA + MaskR-CNN, LB = 0.23;Python notebook;370.0;0;;
2020-04-13 16:58:02;Image size analysis in training dataset;Apache 2.0;https://www.kaggle.com/tathagatbanerjee/eda-mask-rcnn-visualization;1.0;['pattern', 'tensorflow', 'sklearn', 'keras'];['ai', 'dl', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['train', 'model', 'label', 'training data'];https://www.kaggle.com/c/imaterialist-fashion-2020-fgvc7;0.613;0.236;2020-12-13 11:37:41;iMaterialist (Fashion) 2020 at FGVC7;[];EDA + Mask RCNN Visualization;Python notebook;563.0;5;;
2020-11-12 22:14:42;Image size analysis in training dataset;Apache 2.0;https://www.kaggle.com/tejaskhandwekar/imaterialist-2020-starter-eda-mask-rcnn;1.0;['pattern', 'tensorflow', 'sklearn', 'keras'];['ai', 'dl', 'cnn', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'training data', 'train', 'model', 'epoch', 'layer', 'label', 'loss', 'resnet'];https://www.kaggle.com/c/imaterialist-fashion-2020-fgvc7;0.39;0.0;2020-12-13 11:37:42;iMaterialist (Fashion) 2020 at FGVC7;[];iMaterialist 2020: Starter EDA + Mask RCNN;Python notebook;26.0;0;;
2020-05-15 11:00:45;Take a look at the data;Apache 2.0;https://www.kaggle.com/yanastamenova/imaterialist-segmentation-task;1.0;['caffe', 'sklearn', 'tensorflow', 'pattern', 'keras'];['ner', 'ai', 'dl', 'cnn', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'training data', 'test data', 'train', 'model', 'epoch', 'validation data', 'layer', 'label', 'loss', 'resnet'];https://www.kaggle.com/c/imaterialist-fashion-2020-fgvc7;0.643;0.236;2020-12-13 11:37:41;multiple data sources;['beginner, deep learning, computer vision'];iMaterialist - Segmentation task;Python notebook;957.0;5;;
2019-06-01 14:27:39;Simple example of transfer learning from pretrained model using Keras and Efficientnet (https://pypi.org/project/efficientnet/).  Loss: Focal loss Metrics: f2_score;Apache 2.0;https://www.kaggle.com/ateplyuk/efficientnet-keras-s75-b200-e20;1.0;['tensorflow', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/imet-2019-fgvc6;0.636;0.352;2020-12-13 11:40:08;multiple data sources;['gpu'];Efficientnet (Keras s75_b200_e20);Python notebook;840.0;17;;
2019-04-12 07:44:00;Simple example of transfer learning from pretrained model using Keras.  Loss: Focal loss Metrics: f2_score;Apache 2.0;https://www.kaggle.com/ateplyuk/keras-starter;1.0;['tensorflow', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'resnet'];https://www.kaggle.com/c/imet-2019-fgvc6;0.733;0.493;2020-12-13 11:40:08;multiple data sources;['gpu, deep learning, classification'];Keras Starter;Python notebook;6717.0;91;0.423;0.423
2019-04-25 17:55:14;"Don't skip the analysis!!!Updated on 21 AprWhen it comes to image data, people tend to skip the data understanding step and goes straight into using powerful models for transfer learning or feature extractions. This is alright, but wouldn't you want to understand what goes on under the hood? In this kernel, I attempt to understand the data in a conventional data analysis approach (on the raw image metadata etc) and highlight interesting observations which can help your pre-processing pipeline and feature engineering. What is covered & what I plan to do over the next few weeks (or whenever I have time):  Image Shape (done!) Understanding Target Variable (done!) <---------------------------- NEW!!!! RGB Pixel Statistics (done!) <--------------------------------------- NEW!!!! Edge Detection Pixel Statistics (done!) <-------------------------- NEW!!!! Intensity Histogram Correlations of the above with Target Variable  TL;DR - Summary of Insights Super long images exist in the dataset Highly imbalanced dataset, over 1000 labels, with 90% images having less than 5 labels Similar target classes (e.g. men, women, portraits, human figures) RGB pixel statistics - normal distribution with different mean";Apache 2.0;https://www.kaggle.com/chewzy/eda-weird-images-with-new-updates;1.0;['pattern'];['ner', 'ai', 'cnn', 'rl', 'nn', 'ann'];['filter', 'train', 'model', 'label', 'predict', 'understanding'];https://www.kaggle.com/c/imet-2019-fgvc6;0.727;0.527;2020-12-13 11:40:08;multiple data sources;['beginner, data visualization, exploratory data analysis'];EDA - Weird Images with New Updates!;Python notebook;5712.0;146;;
2019-04-12 21:34:44;iMet Collection 2019 - FGVC6 Recognize artwork attributes from The Metropolitan Museum of Art  In this competition we are charged to build models to add fine-grained attributes to aid in the visual understanding of the museum objects, from the 1.5M objects, 200k were digitized, and are provided here.In this notebook I will be using a basic deep learning convolutional model to create a baseline.;Apache 2.0;https://www.kaggle.com/dimitreoliveira/imet-collection-2019-eda-keras;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cv', 'nn'];['filter', 'train', 'model', 'epoch', 'deep learning', 'layer', 'loss', 'label', 'predict', 'relu', 'understanding'];https://www.kaggle.com/c/imet-2019-fgvc6;0.648;0.379;2020-12-13 11:40:08;iMet Collection 2019 - FGVC6;['data visualization, exploratory data analysis, deep learning, +2 moreclassification, computer vision'];iMet Collection 2019 - EDA & Keras;Python notebook;1056.0;23;;
2019-04-02 23:49:38;Problem descriptionIn this kernel, we are going to use Densenet121 pretrained model with Pytorch.;Apache 2.0;https://www.kaggle.com/hidehisaarai1213/imet-pytorch-starter;1.0;['pytorch', 'sklearn'];['ner', 'ai', 'dl', 'ml', 'nn', 'ann'];['test data', 'train', 'model', 'epoch', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'resnet', 'classification'];https://www.kaggle.com/c/imet-2019-fgvc6;0.718;0.439;2020-12-13 11:40:08;multiple data sources;['gpu, deep learning'];iMet Pytorch Starter;Python notebook;4667.0;46;0.474;0.474
2019-05-12 11:39:26;IntroductionModified from https://www.kaggle.com/mathormad/pretrained-resnet50-focal-loss/notebook?scriptVersionId=12746542 (we have tried to catch up the Pytorch :) To see all my personal modification, please use diff from the original kernel to the latest version. The best score is at version 17. But that version used ResNet50 instead of 'should-be-better' ResNet50V2 In the current version, I try to improve the performance by change back from DenseNet121 to ResNet50. For the previous DenseNet version with Acknowledgement, please take a look at version 9. Modification listResNet50 Change LOG V13 [LB553, CV546] PixSize224, LR1e-4, Batch64, 2048Dense-Head, 30Epochs V14 [LB, CV549] Try VALID_SPLIT0.1, 29Epochs V15 Try batch96 << runtime exceed, from LOG file, there is a memory issue that degrades performance too V16 [CV528] Batch32, Epoch24 << finish too early & final LR too small V17 [CV551, LB560] Batch88, Epoch27  V18 [CV Bad] gamma=3 V19 [CV Bad] gamma=4 V20 [CV 524] change back to gamma=1 and use ResNetV2 weights -- thanks @mathormad again! V21[CV 381!] change Hyperparameter V22[CV526] batch64, LR1e-4 V23[CV511] batch48, LR8e-5 V24 Fix bugs on f2, my_f2 functions, try a bit deeper head to digest more information at the end V25-27 try V17 again [FAILED] V28 [] make a 'variable-size' input augmentation modification (resize later) - ResNetV1 V28-34 Bugs V34 Bug Fixed [V2] V35-36[CV558 / 531] increase LR, adjust ReduceOnPlateau for both V1&V2 -- After play around with Lopuhin's great kernel on pytorch, I try to make a learning process converge faster and better << Better results V37-38 increase LR a bit more to force the network to converge earlier   ToDo  Deal with this issue : http://blog.datumbox.com/the-batch-normalization-layer-of-keras-is-broken/;Apache 2.0;https://www.kaggle.com/ratthachat/imet-resnet50-keras-starter;1.0;['sklearn', 'pytorch', 'tensorflow', 'keras', 'skimage'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ann'];['filter', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'resnet'];https://www.kaggle.com/c/imet-2019-fgvc6;0.716;0.413;2020-12-13 11:40:08;multiple data sources;['gpu, beginner, deep learning'];iMet: ResNet50 Keras Starter;Python notebook;4378.0;34;;
2019-04-10 18:53:56;Chainer Starter Kernel for iMet Collection 2019 - FGVC6What is this kernel?This is a baseline example using Chainer and ChainerCV. I share this kernel mainly for practice of writing kernel, and for sharing some (maybe useful) information e.g. training settings. Summary of model, training, and inferencebase model: SEResNet152 pre-trained weights on ImageNet obtain output of Global Average Pooling Layer (pool5) and feed it to Dense Layer input shape: (ch, height, witdh) = (3, 128, 128) preprocessing for images subtract per-channel mean of all train images, and devide by 255 (after data augmentation)    training fine-tuning all over the model, not freezing any layer data augmentation horizontal flip random_distort random_rotate(angle ∈ [-10, 10]) random_expand => resize_with_random_interpolation random crop   max epoch: 20 batch size: 128 optimizer: NesterovSGD momentum = 0.9, weight decay = 1e-04   learning schedule: cosine anealing max_lr = 0.01, min_lr = 0.0001 I ran only one cycle. Note: decaying learning rate by epoch, not iteration (for simple implementation)   loss: Focal Loss alpha = 0.5, gamma = 2 Note: Loss for each sample is calculated by summation of focal loss for each class. Loss for mini-batch  is calculated by averaging loss for samples in it. At first I calculated each sample's loss by averaging, but it didn't work well.         validation make one validation set, not perform k-fold cross validation randomly split, not considering target(attribute) frequency train : valid = 4 : 1   check each epoch's f-beta score by threshold = 0.2 since f-beta weights recall higher than precision default threshold of fastai's implementation is 0.2      inference not using TTA using best threshold for validation set Thresholds for all classes are same.;Apache 2.0;https://www.kaggle.com/ttahara/imet2019-chainer-starter-seresnet152-focalloss;1.0;['sklearn'];['ner', 'ai', 'cnn', 'cv', 'ml', 'nn', 'ann'];['image classification', 'test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'resnet', 'classification', 'labeled'];https://www.kaggle.com/c/imet-2019-fgvc6;0.673;0.367;2020-12-13 11:40:08;multiple data sources;['gpu, deep learning, image data'];iMet2019 Chainer Starter (SEResNet152 + FocalLoss);Python notebook;1734.0;20;0.537;0.537
2020-04-24 14:16:53;Yandex Praktikum PyTorch ResNet50 Inference - LB 0.699;Apache 2.0;https://www.kaggle.com/alimbekovkz/yandex-praktikum-pytorch-resnet50-inference;1.0;['pytorch', 'albumentations', 'sklearn'];['ai', 'dl', 'cv', 'nn', 'ann'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'resnet'];https://www.kaggle.com/c/imet-2020-fgvc7;0.653;0.367;2020-12-13 11:41:37;multiple data sources;['gpu'];Yandex Praktikum PyTorch ResNet50 Inference;Python notebook;1166.0;20;0.649;0.699
2020-04-24 12:47:47;Yandex Praktikum PyTorch train baseline - LB 0.699;Apache 2.0;https://www.kaggle.com/alimbekovkz/yandex-praktikum-pytorch-train-baseline-lb-0-699;1.0;['pytorch', 'sklearn'];['ner', 'ai', 'cv', 'rl', 'nn', 'ml'];['filter', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'resnet'];https://www.kaggle.com/c/imet-2020-fgvc7;0.668;0.408;2020-12-13 11:41:37;multiple data sources;['gpu'];Yandex Praktikum PyTorch train baseline  LB 0.699;Python notebook;1557.0;32;;
2020-04-15 19:50:16;Using pretrained model on TPU for inference;Apache 2.0;https://www.kaggle.com/ateplyuk/keras-imet2020-infer;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'ml'];['train', 'model', 'label', 'predict'];https://www.kaggle.com/c/imet-2020-fgvc7;0.579;0.099;2020-12-13 11:41:37;multiple data sources;[];Keras iMet2020 (infer);Python notebook;321.0;1;0.226;0.238
2020-04-15 15:44:15;Training model using TPU and save model;Apache 2.0;https://www.kaggle.com/ateplyuk/keras-imet2020-tpu-train;1.0;['tensorflow', 'sklearn', 'keras', 'pillow'];['ann', 'ai', 'nn', 'ml'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict'];https://www.kaggle.com/c/imet-2020-fgvc7;0.625;0.236;2020-12-13 11:41:37;iMet Collection 2020 - FGVC7;['tpu'];Keras iMet2020 TPU (train);Python notebook;687.0;5;;
2020-05-09 01:45:30;Getting pretrained model to start from with no internetThanks to https://www.kaggle.com/aminyakubu/aptos-2019-blindness-detection-fast-ai for the guidance on how to load pretrained models into this.  I just watched the error for learn = cnn_learner(....) from two cells down to identify the directory to copy the pth file to and what the postfixed id was. This is the original instructions shared:  Later, I use resnet as the base architecture. However, since we can't use the internet for this kernel in this competition I will set these directories which will contain the models. This is because, cnn_learner will check those directories first before attempting to download. When internet for the kernel is turned off and these models don't exist, an error will be raised. To add the models, click on add dataset at the top right corner of this kernel and search for resnet. Make sure to choose resnet for PyTorch Thanks Amin!  https://www.kaggle.com/aminyakubu;Apache 2.0;https://www.kaggle.com/finlaymacrae/fastai-resnet34-transfer-learning;1.0;['pytorch'];['ner', 'ai', 'dl', 'cnn', 'nn'];['train', 'model', 'layer', 'label', 'loss', 'relu', 'resnet'];https://www.kaggle.com/c/imet-2020-fgvc7;0.603;0.214;2020-12-13 11:41:37;multiple data sources;[];Fastai resnet34 transfer learning;Python notebook;475.0;4;0.583;0.641
2020-05-05 21:19:32;Some CNN BoisFirst, thanks for some useful notebook https://www.kaggle.com/dimakyn/multi-label-keras https://github.com/lmoroney/dlaicourse https://github.com/salmanhiro/Galaxy-Zoo-CNN Then I would like to hear some music;Apache 2.0;https://www.kaggle.com/salmanhiro/imet-2020-cnn-model;1.0;['tensorflow', 'keras'];['ner', 'ai', 'dl', 'cnn', 'rl', 'nn'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/imet-2020-fgvc7;0.569;0.292;2020-12-13 11:41:37;iMet Collection 2020 - FGVC7;['gpu'];iMet 2020 CNN Model;Python notebook;273.0;9;;
2020-04-29 13:20:16;Yandex Praktikum PyTorch train baseline - LB 0.699;Apache 2.0;https://www.kaggle.com/shaman89/yandex-praktikum-pytorch-train-baseline-lb-0-699;1.0;['pytorch', 'sklearn'];['ner', 'ai', 'cv', 'rl', 'nn', 'ml'];['filter', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'resnet'];https://www.kaggle.com/c/imet-2020-fgvc7;0.487;0.099;2020-12-13 11:41:37;multiple data sources;[];Yandex Praktikum PyTorch train baseline  LB 0.699;Python notebook;85.0;1;;
2020-04-13 12:48:40;Assumption  Only 1000 rows are taken in this notebook,  When you generalize the model for all 1 lakh 40 thousand rows the accuracy is quite high However the notebook which i tried uploading from my system to kaggle didnt work out due to technical issues In this notebook i shall only be dealing with 1000 rows , the accuracy would be really bad  But this would be a pretty good intuition to start with the analytics  To support my work please upvote and comment your suggestions;Apache 2.0;https://www.kaggle.com/tathagatbanerjee/tag-classifier-visualization-transfer-learning;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cv', 'nn', 'ann'];['filter', 'training data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'understanding'];https://www.kaggle.com/c/imet-2020-fgvc7;0.574;0.188;2020-12-13 11:41:37;iMet Collection 2020 - FGVC7;[];Tag Classifier Visualization & Transfer Learning;Python notebook;296.0;3;;
2019-06-01 16:48:14;Example of transfer learning from pretrained model using Keras  and Efficientnet (https://pypi.org/project/efficientnet/).;Apache 2.0;https://www.kaggle.com/ateplyuk/inat2019-starter-keras-efficientnet;1.0;['tensorflow', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ann'];['test data', 'train', 'model', 'epoch', 'validation data', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/inaturalist-2019-fgvc6;0.758;0.483;2020-12-13 11:42:48;multiple data sources;['deep learning, earth and nature, classification, +1 moreanimals'];Inat2019 Starter Keras (EfficientNet);Python notebook;12892.0;80;;
2019-04-09 05:31:41;iNaturalist Competition 2018 Training CodeI did not write the following code myself. I copied this from last years baseline and only did some refactorization to make the code run in this kernel. Actually, I was just exploring the dataset and trying to see how past solutions do. All the credit goes to user macaoda. So far, I managed to make the pre trained model run and also trained it on a few epochs over the training data. As you can see, the scores do not match this years baseline yet. According to user zz, scores of at least 0.22 are possible with slight changes. Sadly, I will not be able to spend more time with this competition. Hope, this kernel helps you in some way.;Apache 2.0;https://www.kaggle.com/feichin/inception3-last-years-baseline;1.0;['pytorch', 'tensorflow'];['ai', 'dl', 'rl', 'nn', 'ann'];['predict', 'training data', 'train', 'model', 'epoch', 'label', 'loss', 'computer vision', 'relu'];https://www.kaggle.com/c/inaturalist-2019-fgvc6;0.675;0.367;2020-12-13 11:42:48;iNaturalist 2019 at FGVC6;['gpu'];Inception3 - last years baseline;Python notebook;1780.0;20;0.52210;0.51697
2019-04-03 06:24:52;attempt 1 to get the inception benchmark working code is from : https://github.com/macaodha/inat_comp_2018 very premature modifications to work with torch v1 and the current dataset, wip, or I should say, not yet working...in progress;Apache 2.0;https://www.kaggle.com/interneuron/previous-benchmark-in-a-kernel-v0-0-0;1.0;['pytorch', 'tensorflow'];['ai', 'nn', 'ann', 'rl'];['predict', 'train', 'model', 'epoch', 'label', 'loss', 'computer vision', 'relu'];https://www.kaggle.com/c/inaturalist-2019-fgvc6;0.628;0.152;2020-12-13 11:42:48;iNaturalist 2019 at FGVC6;['gpu'];previous benchmark in a kernel, v0.0.0;Python notebook;734.0;2;;
2019-09-06 00:02:45;"iNaturalist 2019 EDA + DLAs part of the FGVC6 workshop at CVPR 2019, Kaggle is conducting the iNat Challenge 2019, the large scale species classification competition, sponsored by Microsoft. It is estimated that the natural world contains several million species of plants and animals. Without expert knowledge, many of these species are extremely difficult to accurately classify due to their visual similarity. The goal of this competition is to push the state of the art in automatic image classification for real world data that features a large number of fine-grained categories. This Kernel will use the idea of ""Transfer Learning"", various pre-trained model will be used be used for the problem of multiclassification. Kudos and main ideas / reference:  hsinwenchang/keras-data-augmentation-visualize ateplyuk/inat2019-starter-keras-efficientnet";Apache 2.0;https://www.kaggle.com/praxitelisk/inaturalist-2019-eda-dl;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ann'];['image classification', 'train', 'model', 'epoch', 'validation data', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'resnet', 'classification'];https://www.kaggle.com/c/inaturalist-2019-fgvc6;0.599;0.0;2020-12-13 11:42:48;iNaturalist 2019 at FGVC6;['gpu'];iNaturalist 2019 EDA + DL;Python notebook;442.0;0;;
2019-04-16 16:09:38;Transfer learning from pretrained model using Keras.;Apache 2.0;https://www.kaggle.com/sujoykg/xception-keras;1.0;['tensorflow', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ann'];['test data', 'train', 'model', 'epoch', 'validation data', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/inaturalist-2019-fgvc6;0.687;0.152;2020-12-13 11:42:48;multiple data sources;['gpu'];Xception Keras;Python notebook;2301.0;2;0.99094;0.99106
2018-09-21 20:05:28;CNN with 20 Classes trained on Open Image Validation Set;Apache 2.0;https://www.kaggle.com/hemantime/cnn-with-20-classest-version4;1.0;['tensorflow', 'keras'];['ai', 'cnn', 'cv', 'rl', 'nn', 'ann'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/inclusive-images-challenge;0.632;0.268;2020-12-13 11:44:51;multiple data sources;['gpu'];Fork of CNN with 20 Classes trained Validation Set;Python notebook;780.0;7;0.00000;0.00000
2018-11-04 22:38:46;Multi-Label Classification Example using KerasThis notebook is an example of a baseline model I trained. In this example, I used the tuning labels as training data, validation data, and test data. However the real baseline model used 1.7M training images from the Open Images Dataset and training labels created from concatenating thr train_human_labels, train_machine_labels, and train_bounding_boxes.;Apache 2.0;https://www.kaggle.com/phmagic/keras-densenet121-multi-label-baseline;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'nn', 'cv'];['training data', 'test data', 'train', 'model', 'epoch', 'validation data', 'layer', 'loss', 'label', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/inclusive-images-challenge;0.713;0.281;2020-12-13 11:44:51;Inclusive Images Challenge;['gpu'];Keras - DenseNet121  - Multi-Label Baseline;Python notebook;4096.0;8;;
2018-09-07 19:18:49;Example functions you can pass to keras to monitoring f2 scores during training.;Apache 2.0;https://www.kaggle.com/ryanzhang/keras-f2-metric;1.0;['tensorflow', 'keras'];['ai'];['train'];https://www.kaggle.com/c/inclusive-images-challenge;0.666;0.268;2020-12-13 11:44:51;Inclusive Images Challenge;[];keras f2 metric;Python notebook;1505.0;7;;
2018-09-11 15:36:16;CNN with 20 Classes trained on Open Image Validation Set;Apache 2.0;https://www.kaggle.com/victorhz/cnn-with-20-classes-trained-validation-set;1.0;['tensorflow', 'keras'];['ai', 'cnn', 'cv', 'rl', 'nn', 'ann'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/inclusive-images-challenge;0.714;0.421;2020-12-13 11:44:51;multiple data sources;['gpu, beginner, data visualization, +2 moredeep learning, cnn'];CNN with 20 Classes trained Validation Set;Python notebook;4160.0;37;0.00000;0.00000
2018-09-11 15:46:45;CNN with 20 Classes trained on Open Image Validation Set;Apache 2.0;https://www.kaggle.com/victorhz/fork-of-cnn-with-20-classes-trained-validation-set;1.0;['tensorflow', 'keras'];['ai', 'cnn', 'cv', 'rl', 'nn', 'ann'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/inclusive-images-challenge;0.603;0.188;2020-12-13 11:44:51;multiple data sources;['gpu'];Fork of CNN with 20 Classes trained Validation Set;Python notebook;474.0;3;0.00000;0.00000
2017-05-21 11:12:23;Hi, Kagglers! Hereafter I will try to create some baselines for your submissions to start from.  This Kernel touches submission part mostly AND ONE WELL-KNOWN FILM :) For more details about Dataset - please check my Data Exploration Kernel Brief description The Dataset is an anonymized sample of over 3,000,000 grocery orders from more than 200,000 Instacart users.  The goal of a competition is to predict which previously purchased products will be in a user’s next order. Stay tuned, this notebook will be updated on a regular basisP.s. Upvotes and comments would let me update it faster and in a more smart way :);Apache 2.0;https://www.kaggle.com/frednavruzov/dumb-and-the-dumber-baselines-plb-0-3276826;1.0;['textblob', 'nltk'];['ner', 'ai', 'nn', 'ann'];['train', 'test data', 'filter', 'predict'];https://www.kaggle.com/c/instacart-market-basket-analysis;0.739;0.493;2020-12-13 11:49:56;Instacart Market Basket Analysis;[];Dumb-and-the-Dumber-Baselines (PLB=0.3276826);Python notebook;7816.0;92;;
2017-06-01 20:53:31;Hi, Kagglers! Hereafter I will try to reveal some basics about Instacart dataset by conducting an exploratory data analysis of given Dataset Brief description The Dataset is an anonymized sample of over 3,000,000 grocery orders from more than 200,000 Instacart users.  The goal of a competition is to predict which previously purchased products will be in a user’s next order. Stay tuned, this notebook will be updated on a regular basisP.s. Upvotes and comments would let me update it faster and in a more smart way :);Apache 2.0;https://www.kaggle.com/frednavruzov/instacart-exploratory-data-analysis;1.0;['textblob', 'nltk'];['ner', 'ai', 'gan', 'rl', 'nn', 'ann'];['filter', 'test data', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/instacart-market-basket-analysis;0.745;0.484;2020-12-13 11:49:56;Instacart Market Basket Analysis;[];Instacart-Exploratory-Data-Analysis;Python notebook;8950.0;81;;
2017-07-29 05:59:56;This script is translate from @Fabienvs's R code, I think it may help kagglers who do not use R. I really appreciate @Fabienvs's great work, to be honest, I have no idea about how to handling this kind of problem(this is the first time I encounter recommendation problem- -) here we go!!  below exist some very useful functions I write by my own, you can download from my github repo sorry for adding some Chinese in it, it would not affect the code The dataset is too big, you should run it on your desktop!;Apache 2.0;https://www.kaggle.com/nickycan/lb-0-3805009-python-edition;1.0;['xgboost', 'sklearn'];['dl', 'ner', 'ai', 'nn'];['predict', 'train', 'model', 'loss', 'recommend'];https://www.kaggle.com/c/instacart-market-basket-analysis;0.76;0.497;2020-12-13 11:49:56;Instacart Market Basket Analysis;['classification, xgboost, recommender systems'];LB 0.3805009, Python Edition;Python notebook;13439.0;97;;
2017-08-09 18:49:05;Word2Vec on Instacart productsThe goal of this kernel is to try a Word2Vec model on the data of product ordersThe orders can act as sentences and product ids can act as words, in this kernel we will see if the model will learn any useful information about the products from the order history of all users, maybe in the future this can be used as input to a classifier that recommends products.This gave me a slight increase in my LB score, so it's a useful featurePlease upvote if you like it and let me know in the discussion if you have any remarks/ideasI also further explain the kernel in a blog post: http://omarito.me/word2vec-product-recommendations/;Apache 2.0;https://www.kaggle.com/omarito/word2vec-for-products-analysis-0-01-lb;1.0;['tensorflow', 'sklearn', 'gensim'];['ai', 'nn', 'ann', 'gan'];['train', 'recommend', 'model', 'label'];https://www.kaggle.com/c/instacart-market-basket-analysis;0.763;0.479;2020-12-13 11:49:56;Instacart Market Basket Analysis;[];Word2Vec for products analysis + 0.01 LB;Python notebook;14871.0;76;;
2019-06-23 14:02:34;"QDA + Pseudo Labeling + Gaussian Mixture = LB 0.975The dataset for Kaggle competition ""Instant Gratification"" appears to be 512 datasets concatenated where each sub dataset is believed to be created by Sklearn's make_classification. EDA suggests the following parameters: X, y = make_classification(n_samples=1024, n_features=255, n_informative=33+x,             n_redundant=0, n_repeated=0, n_classes=2, n_clusters_per_class=3,             weights=None, flip_y=0.05, class_sep=1.0, hypercube=True, shift=0.0,              scale=1.0, shuffle=True, random_state=None) # where 0<=x<=14   The important parameters to note are n_clusters_per_class=3 and n_informative=33+x. This means that the data resides in 33+x dimensional space within 6 hyper-ellipsoids. Each hyper-ellipsoid is a multivariate Gaussian distribution therefore the best classifiers to use are QDA, Pseudo Labeling, and Gaussian Mixture. (See appendix for EDA showing 3 clusters per class).  Better than Perfect Classifier!If Kaggle generated the data with the above function call to make_classification then Many participants will submit a perfect classifier since the data is easy to separate using QDA and GM. Therefore to win this Kaggle competition, we must submit a better than perfect classifier! The code presented in this kernel has randomness added (and marked in the code below) which allows this classifier to score as much as LB 0.00050 better than a perfect classifier. If the data is made with Sklearn's make_classification, perfect classification is classifying everything correctly except the 2.5% randomly flipped labels. No model can consistently predict the flipped labels correct. However, if you add randomness to your model sometimes it will do better than perfect (and get some flipped targets correct) and sometimes it will do worse. Below is a scatter plot of this kernel's performance. The dotted line is a perfect classifier and each dot is one attempt of this kernel to classify a synthetic dataset (that is similar to this comp's data). The 200 dots represent 10 attempts made on each of 20 different randomly created synthetic datasets. The black dotted lines were determined by modifying make_classification to output the AUC of perfect classification. (See Appendix 3 for more info).  Besides indicating perfect classification on average, this scatter plot also shows that there is no correlation between this kernel's public LB and private LB performance. Therefore for our final submission, we will not choose our highest public LB submission. We will run this kernel 30 times and submit two versions chosen at random regardless of their public LB performance. Then we cross our fingers and hope that those two runs score better than perfect private test dataset classification :P";Apache 2.0;https://www.kaggle.com/cdeotte/3-clusters-per-class-0-975;1.0;['pattern', 'sklearn'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['training data', 'test data', 'train', 'model', 'label', 'predict', 'rank', 'classification', 'labeled'];https://www.kaggle.com/c/instant-gratification;0.725;0.547;2020-12-13 11:53:26;Instant Gratification;['gpu'];3 Clusters Per Class - [0.975];Python notebook;5439.0;195;;
2019-05-19 18:55:07;"Logistic Regression scores LB 0.800In this kernel, we present a simple logistic regression model for Kaggle's ""Instant Gratification"" competition. This kernel demonstrates that interactions between the variable wheezy-copper-turtle-magic and the other variables exist. And it demonstrates that a simple model can perform well. Without interactions LR (logistic regression) scores CV 0.530, and with interactions LR scores CV 0.805 and LB 0.808 Load Data";Apache 2.0;https://www.kaggle.com/cdeotte/logistic-regression-0-800;1.0;['sklearn'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ann'];['filter', 'regression', 'train', 'model', 'label', 'logistic regression', 'predict', 'rank'];https://www.kaggle.com/c/instant-gratification;0.768;0.558;2020-12-13 11:53:26;Instant Gratification;[];Logistic Regression - [0.800];Python notebook;17129.0;230;0.80832;0.80878
2019-05-23 14:00:16;"Does Private Dataset have same structure as Train Dataset?Answer: YESIn normal Kaggle competitions, the test.csv that we download contains the private test dataset and the above question is easy to verify. In this competition, ""Instant Gratification"", the test.csv that we download does not contain the private test dataset. Can we still answer the question above? Yes. The unique structure of the data has been explained here. (There are 512 partial datasets within the full dataset. And each partial dataset has a different set of approximately 40 important features as identified by different standard deviations.) We have observed that both the training dataset and public test dataset have this structure. Does the private dataset also have this structure? In this kernel, we probe the private dataset and confirm that it has the same structure. The structure of the data encourages building 512 separate models. In this kernel we also show how to build a single model instead of 512. We will build a high scoring NN (LB 0.930) by using the wonderful starter code provided by Abhishek here (please upvote Abishek's kernel) and improved upon by Vladislav here. This is accomplished by removing the dataset's useless datablocks and converting the magic variable into categorical. We will probe the Private LB and ask ""Does the private test dataset have the same special structure as training and public test?"". If the answer is ""yes"", this kernel will submit an ensemble of NN and SVC and score LB 0.950. If the answer is ""no"", this kernel will submit all zeros and score LB 0.500. To see the answer, view this kernel's LB score above.";Apache 2.0;https://www.kaggle.com/cdeotte/private-lb-probing-0-950;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn'];['filter', 'training data', 'test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'rank', 'relu'];https://www.kaggle.com/c/instant-gratification;0.732;0.551;2020-12-13 11:53:26;Instant Gratification;['gpu'];Private LB Probing - [0.950];Python notebook;6486.0;207;0.95088;0.95005
2019-06-06 01:15:30;"Pseudo Labeling with QDA scores LB 0.969Roman posted a kernel introducing pseudo labeling here. I would like to explain why it works, make a few improvements, and demonstrate the power of this technique! This kernel is the same as my support vector machine kernel here with QDA and pseudo labeling added. It achieves an impresive CV 0.970 and LB 0.969 In Santander's Customer Transaction competition, team Wizardry used pseudo labeling to increase their private LB by 0.0005 allowing them to beat second place by 0.0002 for the $25,000 prize! here In ""Instant Gratification"" competition, we are building 512 models where each model's train data has approximately 512 rows and 40 columns. With 40 variables, a quadratic model would like more rows. With pseudo labeling, we can get an additional 400 rows of training data and increase CV and LB by 0.005!";Apache 2.0;https://www.kaggle.com/cdeotte/pseudo-labeling-qda-0-969;1.0;['sklearn'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn'];['training data', 'test data', 'train', 'model', 'label', 'predict', 'rank', 'labeled'];https://www.kaggle.com/c/instant-gratification;0.784;0.603;2020-12-13 11:53:26;Instant Gratification;[];Pseudo Labeling - QDA - [0.969];Python notebook;27544.0;469;;
2019-05-21 00:23:21;"Support Vector Machine scores LB 0.925In our previous kernel here, we built 512 linear models using logistic regression in conjuction with the magic feature and scored LB 0.808. In this kernel we will build 512 nonlinear models using support vector machine with polynomial degree=4 kernel and score LB 0.926. Previously we performed feature selection with Lasso, aka LR's L1-penalty. Now we will perform feature selection with sklearn's VarianceThreshold selector (which will select more or less the same features). The success of this kernel demonstrates the nature of ""Instant Gratification"" competition data. It appears that the data is actually 512 datasets combined together. Each dataset has rougly 512 observations. Thus the total training data has 262144 = 512 * 512 observations. Each partial dataset is identified by a unique wheezy-copper-turtle-magic value. This kernel shows that each dataset's target is a nonlinear function of approximately 40 important features (and each dataset uses a different 40 important features). The next thing to investigate is whether there are interactions between the partial datasets that can improve prediction. If that is the case then instead of building 512 separate models, we need to build a single model that allows interactions. (Possibly NN with interesting architecture). Also each model (in this kernel) only uses about 40 features. Within each partial dataset, are the other 215 features really useless, or can we use them to improve prediction? Load Data";Apache 2.0;https://www.kaggle.com/cdeotte/support-vector-machine-0-925;1.0;['sklearn'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'nn'];['filter', 'training data', 'regression', 'train', 'model', 'label', 'logistic regression', 'predict', 'rank'];https://www.kaggle.com/c/instant-gratification;0.756;0.571;2020-12-13 11:53:26;Instant Gratification;[];Support Vector Machine - [0.925];Python notebook;12292.0;279;0.93098;0.92895
2019-06-10 23:05:22;Lasso + Gaussian Mixture ModelsWith this kernel I want to demonstrate how to use Gaussian mixture Models (GMM) which have the nice property to train unsupervised, so you can also use the test set. I use Graphical Lasso as an estimator for the initial value of precision matrix (= inverse Covariance) and mean;Apache 2.0;https://www.kaggle.com/christofhenkel/graphicallasso-gaussianmixture;1.0;['sklearn'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn'];['rank', 'model', 'train', 'predict'];https://www.kaggle.com/c/instant-gratification;0.728;0.521;2020-12-13 11:53:26;Instant Gratification;[];GraphicalLasso + GaussianMixture;Python notebook;5837.0;135;;
2019-06-08 20:50:23;Who needs models, just do statsticsFirst of all, 95% of the kernel is stolen from Chris, I just exchanged QDA with heuristic statistics. The main point is, that if we assume our variables to be multivariate normal distributed (which we know from the make_classification function) we can just calcuate the probability that a data point belongs to either of the two ellipses by calculating probablities.;Apache 2.0;https://www.kaggle.com/christofhenkel/lets-implement-qda-by-ourself;1.0;['sklearn'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ml'];['training data', 'test data', 'train', 'model', 'label', 'predict', 'rank', 'classification', 'labeled'];https://www.kaggle.com/c/instant-gratification;0.69;0.483;2020-12-13 11:53:26;Instant Gratification;[];Lets implement QDA by ourself;Python notebook;2459.0;80;;
2019-06-11 12:24:29;Pseudo-Labelled PolyLR and QDAThis kernel shows the potential of adding quadratic polynomial features, a simple logistic regression can learn just like QDA. I also tested pseudo labelling and blending with QDA. Thanks to Chris's great kernels LR, SVC, probing, pseudo labelling and mhviraf's kernel make_classification which shows how the dataset was generated. Please also upvote those kernels.;Apache 2.0;https://www.kaggle.com/gogo827jz/pseudo-labelled-polylr-and-qda;1.0;['sklearn'];['ner', 'ai'];['regression', 'train', 'model', 'label', 'logistic regression', 'predict', 'classification', 'labeled'];https://www.kaggle.com/c/instant-gratification;0.709;0.481;2020-12-13 11:53:26;Instant Gratification;[]; Pseudo-Labelled PolyLR and QDA ;Python notebook;3765.0;78;;
2019-06-03 19:57:26;"DescriptionUPDATE: In this version of the kernel we will try to test the idea of selecting features using LOFO. For more details about LOFO please see Ahmet Erdem's kernel available at this link. The feature selection step is going to slow down the training process, so this new version will run longer than 1 minute. If you want to see the original kernel that runs less than a minute please refer to Version 1 of this kernel. The original kernel scores 0.99610 on the LB. Unfortunately, we won't be able to use this result as a baseline for comparison because we won't be able to submit our work to LB: in order for LOFO to work, an external package, lofo-importance, must be loaded but the usage of external packages is banned by the competion rules. However, it is possible to compute the cross-validation score for the QDA model without LOFO. As a matter of fact, I have already done it in a different kernel: link (see the ""Repeat Using the Standard Parameters"" section). The result was a CV score of 0.96629.  Let's see if selecting features with LOFO can improve this baseline. SPOILER: Basically, the resutl is very inconclusive -- the combined AUC went up from 0.96629 to 0.96727, the fold-average AUC went down from 0.96628 to 0.96213, and the standard deviation increased from 9e-05 to 0.0097. It would be nice to submit it to the LB to see how well it performs.";Apache 2.0;https://www.kaggle.com/graf10a/single-qda-lb-0-96610-time-1-min;1.0;['sklearn'];['ai', 'nn', 'ann', 'cv'];['train', 'model', 'filter', 'predict'];https://www.kaggle.com/c/instant-gratification;0.711;0.481;2020-12-13 11:53:26;Instant Gratification;[];Single_QDA_LB_0.96610_time<_1_min;Python notebook;3923.0;78;;
2019-05-29 00:33:00;As of now, despite that only a few days have passed since this competition started, we know a lot about the structure of dataset. We know about ID's, splits, etc. etc. I tried to put everything we knew so far together and generate a synthetic train.csv dataset from scratch as similar as possible to Kaggle's train.csv. I then ran some EDA on it and also trained some of the public kernels on this synthetic dataset and compared the CV score to theirs. Hope you enjoy this kernel. Don't forget to upvote and share your opinions. First, we generate the dataset from 512 different classification datasets by using sklearn's make_calssification.;Apache 2.0;https://www.kaggle.com/mhviraf/synthetic-data-for-next-instant-gratification;1.0;['pattern', 'sklearn'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn'];['gru', 'filter', 'regression', 'train', 'model', 'logistic regression', 'predict', 'rank', 'classification'];https://www.kaggle.com/c/instant-gratification;0.728;0.559;2020-12-13 11:53:26;Instant Gratification;[];Synthetic data for (next?) Instant Gratification;Python notebook;5905.0;233;;
2019-06-04 14:40:48;Attention! Warning! Use at your own risk!If you are going to use pseudo labeling technique (which is used in this kernel) make sure you understand what you are doing. Otherwise you will horribly overfit to Public LB and will be shaken down on Private LB. Thus you should not use this submission as is, but instead find a way to improve your model with this technique.;Apache 2.0;https://www.kaggle.com/nroman/i-m-overfitting-and-i-know-it;1.0;['sklearn'];['ai', 'cv'];['filter', 'train', 'fitting', 'model', 'label', 'predict'];https://www.kaggle.com/c/instant-gratification;0.729;0.502;2020-12-13 11:53:26;Instant Gratification;[];I'm overfitting and I know it;Python notebook;5971.0;103;0.96914;0.96814
2019-05-19 19:10:08;Thanks @abhishek for his kernel https://www.kaggle.com/abhishek/beating-the-benchmark-neural-networkDue to 'wheezy-copper-turtle-magic' is categorical feature, I decided to add one-hot encoding.;Apache 2.0;https://www.kaggle.com/speedwagon/neural-network-baseline;1.0;['tensorflow', 'sklearn', 'keras'];['dl', 'ai', 'nn', 'rl'];['filter', 'train', 'model', 'neural network', 'epoch', 'layer', 'loss', 'predict', 'relu'];https://www.kaggle.com/c/instant-gratification;0.728;0.506;2020-12-13 11:53:26;Instant Gratification;['gpu'];Neural Network baseline;Python notebook;5819.0;109;;
2019-05-30 08:52:50;Quadratic Discriminant AnalysisNotice that execution time of this kernel is 83 sec.;Apache 2.0;https://www.kaggle.com/speedwagon/quadratic-discriminant-analysis;1.0;['sklearn'];['ner', 'ai'];['filter', 'train', 'model', 'predict', 'classification'];https://www.kaggle.com/c/instant-gratification;0.749;0.554;2020-12-13 11:53:26;Instant Gratification;[];Another model for your blending;Python notebook;9944.0;217;;
2019-05-22 00:19:32;OverviewThe purpose of this kernel is to take a look at the data, come up with some insights, and attempt to create a predictive model or two. This notebook is still very raw. I will work on it as my very limited time permits, and hope to expend it in the upcoming days and weeks. PackagesFirst, let's load a few useful Python packages. This section will keep growing in subsequent versions of this EDA.;Apache 2.0;https://www.kaggle.com/tunguz/instant-eda;1.0;['xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'nn'];['filter', 'test data', 'regression', 'train', 'model', 'label', 'logistic regression', 'predict', 'rank'];https://www.kaggle.com/c/instant-gratification;0.732;0.514;2020-12-13 11:53:26;Instant Gratification;[];Instant EDA;Python notebook;6462.0;121;0.94348;0.94209
2016-07-18 11:27:48;Sequence prefixes lookupThis approach is described in Neil Sloane's book Encyclopedia of Integer Sequences (chapter 2.5: analysis of differences). Suppose we have a sequence [ 1, 8, 27, 64, 125, 216 ] and want to predict next term. This sequence is cubes: f(n)=n3. An array of differences is [ 8 - 1, 27 - 8, 64 - 27, 125 - 64, 216 - 125 ] = [ 7, 19, 37, 61, 91 ]. A simple quick look at this sequence doesn't let us recognize it. We'll define it as f1(n)=f0(n+1)−f0(n) where f0(n)=f(n) is the original sequence. If we calculate differences once again, we get: [ 19 - 7, 37 - 19, 61 - 37, 91 - 61 ] = [ 12, 18, 24, 30 ]. And this pattern is already recognizable. Let's take one more: [ 18 - 12, 24 - 18, 30 - 24 ] = [ 6, 6, 6 ]. A constant value of 6. How to get a next element? We need to add one more constant 6 to the array of third differences. Then the next element of second differences f2(n)=f2(n−1)+f3(n−1). So, f2(5)=f2(4)+f3(4)=30+6=36. Analogously, f1(6)=f1(5)+f2(5)=91+36=127. Finally, f0(7)=f0(6)+f1(6)=216+127=343. Check: f(7)=73=343=f0(7) – correct. Another example: [ 1, 2, 4, 8, 16, 32, 64 ]. Differences: [ 2 - 1, 4 - 2, 8 - 4, 16 - 8, 32 - 16, 64 - 32 ] = [ 1, 2, 4, 8, 16, 32 ]. The result is the original sequence itself. We can take the next element from the first array: 64. Then the next element of original sequence is f0(8)=f0(7)+f1(7)=64+64=128. In many cases a next item of sequence can be predicted by calculating a next item of differences array. And if that array is recognizable then we are able to easily find the next item. It's possible to recognize an array by looking it up in a prefix tree (trie). That trie would contain not sequences themselves but their signatures. We'll use a definition of signature function suggested by Nina Chen in this article with a slight change: signature(seq)=sign(seq)⋆seqGCD(seq). Here, sign is a sign of the first non-zero item of sequence seq (+1 if the item is positive, or -1 otherwise) and GCD is a greatest common divisor of all sequence elements. Example: sequence [ 2, 4, 6, 8 ] would be stored in a trie as [ 1, 2, 3, 4 ] because GCD( [ 2, 4, 6, 8 ] ) = 2 and we divide each element of sequence by GCD. A GCD function definition (taken from Nina Chen's article):;Apache 2.0;https://www.kaggle.com/balzac/prefixes-lookup-0-22;1.0;['pattern'];['ai', 'nn', 'ann'];['train', 'filter', 'predict'];https://www.kaggle.com/c/integer-sequence-learning;0.744;0.357;2020-12-13 11:57:13;Integer Sequence Learning;[];Prefixes lookup (0.22);Python notebook;8918.0;18;;
2017-07-06 21:32:30;This kernels aims at segmenting the cervix using the technique presented in this paper: https://www.researchgate.net/publication/24041301_Automatic_Detection_of_Anatomical_Landmarks_in_Uterine_Cervix_Images;Apache 2.0;https://www.kaggle.com/chattob/cervix-segmentation-gmm;1.0;['skimage', 'sklearn'];['ai', 'nn', 'ann', 'cv'];['train', 'model', 'label', 'k-means', 'predict'];https://www.kaggle.com/c/intel-mobileodt-cervical-cancer-screening;0.764;0.491;2020-12-13 11:58:48;Intel & MobileODT Cervical Cancer Screening;[];Cervix segmentation (GMM);Python notebook;15245.0;89;;
2017-08-27 01:45:01;"Cervix Image SegmentationI'd first like to say thank you to  https://www.kaggle.com/philschmidt/intel-mobileodt-cervical-cancer-screening/cervix-eda/notebook Those competing in the Lung Cancer detection competition for the masking idea All those I have learned from in the Kaggle community and outside   I hope you learn from this script and is improved upon. This is my first Kaggle kernel so please give feedback where you see appropriate :D IF YOU KNOW A BETTER WAY TO DO A CLUSTER CROP, PLEASE LET ME KNOW :) One of the first things I noticed about the images is that there are borders of a ""random"" width/height that contain no ""information"". We really want to reduce the data to just the necessary components, ie. the cervix in this instance. AFAIK, all other parts of the picture provide no information that will help our classifier. From here I looked into medical imaging but saw k-means clustering with cv2 seemed to handle the task pretty well.";Apache 2.0;https://www.kaggle.com/cpruce/cervix-image-segmentation;1.0;['skimage'];['ai', 'dl', 'cv'];['image segmentation', 'training data', 'train', 'k-means', 'clustering'];https://www.kaggle.com/c/intel-mobileodt-cervical-cancer-screening;0.733;0.319;2020-12-13 11:58:48;Intel & MobileODT Cervical Cancer Screening;[];Cervix Image Segmentation;Python notebook;6688.0;12;;
2017-04-12 23:09:19;Plot a Confusion MatrixI find it helpful to see how well a classifier is doing by plotting a confusion matrix. This function produces both 'regular' and normalized confusion matrices.;Apache 2.0;https://www.kaggle.com/grfiv4/plot-a-confusion-matrix;1.0;['sklearn'];['ml'];['model', 'label', 'classification', 'predict'];https://www.kaggle.com/c/intel-mobileodt-cervical-cancer-screening;0.816;0.458;2020-12-13 11:58:48;Intel & MobileODT Cervical Cancer Screening;[];Plot a Confusion Matrix;Python notebook;79734.0;58;;
2017-03-19 05:11:08;0. First of allThis kernel is the tutorial to explore and visualize datasets and train Convolutional Neural Network (CNN) on keras. I'm not good at English. So, please post a comment if there are any unknown points:) Additionally, this kernel is unfinished, still writing. I will do my best! This kernel is getting better little by little. Many thanks to all of the comments.;Apache 2.0;https://www.kaggle.com/kambarakun/how-to-start-with-python-on-colfax-cluster;1.0;['tensorflow', 'keras'];['ner', 'ai', 'cnn', 'cv', 'nn'];['train', 'model', 'neural network', 'predict', 'recommend', 'convolutional neural network'];https://www.kaggle.com/c/intel-mobileodt-cervical-cancer-screening;0.753;0.449;2020-12-13 11:58:48;Intel & MobileODT Cervical Cancer Screening;[];How to start with python on Colfax Cluster;Python notebook;11060.0;52;;
2017-05-05 18:43:15;This notebook goes through a simple process of finding all the images, generating a few basic features, building a classifier and then applying to classifier on the images;Apache 2.0;https://www.kaggle.com/kmader/file-features-based-submission;1.0;['skimage', 'tpot'];['ner', 'ai', 'dl', 'cv'];['train', 'generation', 'training data', 'predict'];https://www.kaggle.com/c/intel-mobileodt-cervical-cancer-screening;0.663;0.253;2020-12-13 11:58:48;Intel & MobileODT Cervical Cancer Screening;[];File Features-based Submission;Python notebook;1408.0;6;;
2017-06-17 01:53:37;"Finding Leaked ImagesThis kernel aims to find images ""leaked"" from the train set into test set (because sometimes md5sum isn't enough!). We will use RGB histogram as feature vectors then compute L2 distance between test vectors and train vectors to see if we get a match. Note: An even better approach is to use an ImageNet trained CNN (VGG16, ResNet50, etc.) with FC layers removed to get bottleneck features rather than histogram. EDIT: Rather than leaked images I should say leaked ""patients"" as the images are not identical but from the same patient.";Apache 2.0;https://www.kaggle.com/kylehounslow/a-method-for-finding-leaked-images-in-test-set;1.0;['sklearn'];['ai', 'dl', 'cnn', 'cv', 'nn'];['train', 'vgg', 'resnet', 'layer'];https://www.kaggle.com/c/intel-mobileodt-cervical-cancer-screening;0.645;0.334;2020-12-13 11:58:48;Intel & MobileODT Cervical Cancer Screening;[];A Method for Finding Leaked Images in Test Set;Python notebook;994.0;14;;
2017-05-21 09:59:24;This kernel is intended as a simple end-to-end tutorial with local validation using mxnet, one of the few deep learning frameworks for R. There are not that many mxnet examples in the web so I hope this template will be a usefull starting point for those beginning to build their first convolutional networks. Mxnet updated version has more functions to explore that I will not be using, exploring them can be your next step. Being this just a template-tutorial and limited by Kaggle kernel environment we will be using a very much reduced image resolution 64x64 and cpu mode (convnets training is much faster on gpus, more on that later). Also convnet architecture will be very simple, just two convolutional layers with pooling. With this in mind, lets make clear what the kernel will and achieve:  A simple image preprocessing pipeline that ends with dimensions ready for mxnet training. A two convolutional layer, two pooling net for clasification. A clasification result almost as good as one achieved by a dart throwing monkey, (with three classes a monkey would get a logloss of (log(3) =  1.098612))  ( EDIT: We get a probably too optimistic error in our local validation of 0.9539. Better than expected. A submission with this exact parameters gets 1.04438 on LB. Worse than sample submission benchmark but still better than a monkey! ) Some parts of this code are taken from this fantastic kernel for State Farm Kaggle Competition here If you find this kernel useful remember to upvote!;Apache 2.0;https://www.kaggle.com/miguelpm/r-mxnet-simple-tutorial;1.0;['mxnet'];['ai', 'dl', 'ml', 'nn', 'ann'];['filter', 'train', 'model', 'epoch', 'deep learning', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/intel-mobileodt-cervical-cancer-screening;0.77;0.362;2020-12-13 11:58:48;Intel & MobileODT Cervical Cancer Screening;[];R Mxnet simple tutorial;R notebook;18237.0;19;;
2017-04-12 23:00:51;Cervix EDAIn this competition we have a multi-class classification problem with three classes. We are asked, given an image, to identify the cervix type. From the data description: In this competition, you will develop algorithms to correctly classify cervix types based on cervical images. These different types of cervix in our data set are all considered normal (not cancerous), but since the transformation zones aren't always visible, some of the patients require further testing while some don't. This decision is very important for the healthcare provider and critical for the patient. Identifying the transformation zones is not an easy task for the healthcare providers, therefore, an algorithm-aided decision will significantly improve the quality and efficiency of cervical cancer screening for these patients. The submission format is asking for a probability for each of the three different cervix types. In this notebook we will be looking at:  basic dataset stats like number of samples per class, image sizes different embeddings of RGB image space pairwise distances and a clustermap of images in RGB space (linear) model selection with basic multi class evaluation metrics.  If you like this kernel, please give an upvote, thanks! :);Apache 2.0;https://www.kaggle.com/philschmidt/cervix-eda-model-selection;1.0;['pattern', 'skimage', 'sklearn'];['ai', 'rl', 'cv', 'nn', 'ann'];['training data', 'regression', 'train', 'fitting', 'model', 'clustering', 'loss', 'label', 'logistic regression', 'predict', 'rank', 'understanding', 'classification'];https://www.kaggle.com/c/intel-mobileodt-cervical-cancer-screening;0.783;0.545;2020-12-13 11:58:48;Intel & MobileODT Cervical Cancer Screening;[];Cervix EDA & Model selection;Python notebook;26820.0;190;;
2017-03-19 23:24:31;Data exploration Visualization of all training data, all testing data Visualize some additional training data Clustering of training and test data Basic skin detection Some stats using jpg exif;Apache 2.0;https://www.kaggle.com/vfdev5/data-exploration-1;1.0;['sklearn'];['ai', 'nn', 'ann', 'cv'];['filter', 'training data', 'test data', 'train', 'model', 'clustering', 'label', 'predict'];https://www.kaggle.com/c/intel-mobileodt-cervical-cancer-screening;0.732;0.421;2020-12-13 11:58:48;Intel & MobileODT Cervical Cancer Screening;[];Data exploration;Python notebook;6552.0;37;;
2017-04-29 11:57:17;Type 1 clusteringI want to understand what kind of images we have acording to the standard procedure, for example described here. Namely, do we have images :  native cervix acetic acid lugol iodine  of the same patient ? Edit: Clustering method updated;Apache 2.0;https://www.kaggle.com/vfdev5/type-1-clustering;1.0;['sklearn'];['ai', 'cv'];['train', 'clustering', 'predict'];https://www.kaggle.com/c/intel-mobileodt-cervical-cancer-screening;0.678;0.383;2020-12-13 11:58:48;Intel & MobileODT Cervical Cancer Screening;[];Type 1 clustering;Python notebook;1911.0;24;;
2017-05-09 13:24:58;Hi everyone, this kernel is about applying different segmentation methods to the images of the cervixMethods used:  a channel saturaion Watershed Edge detection K-means  References can be found at the beginning of each method;Apache 2.0;https://www.kaggle.com/zahaviguy/cervix-image-segmentation;1.0;['sklearn', 'opencv-python'];['ai', 'cv', 'ml', 'nn', 'ann'];['train', 'model', 'clustering', 'label', 'k-means', 'predict'];https://www.kaggle.com/c/intel-mobileodt-cervical-cancer-screening;0.681;0.292;2020-12-13 11:58:48;Intel & MobileODT Cervical Cancer Screening;[];Cervix Image Segmentation;Python notebook;2019.0;9;;
2017-05-12 00:57:57;This is a basic Keras model.;Apache 2.0;https://www.kaggle.com/amlacorp/keras-starter-fork;1.0;['tensorflow', 'skimage', 'keras'];['ai', 'nn', 'ann', 'cv'];['filter', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/invasive-species-monitoring;0.608;0.214;2020-12-13 12:11:50;Invasive Species Monitoring;[];Keras Starter Fork;Python notebook;516.0;4;;
2017-05-15 20:35:23;This is my first kaggle competition. All suggestions are welcome. I achieved ~98% AUC using tensorflow v1.2 and pretrained VGG16 model downloaded from http://download.tensorflow.org/models/vgg_16_2016_08_28.tar.gz;Apache 2.0;https://www.kaggle.com/ardiya/tensorflow-vgg-pretrained;1.0;['tensorflow', 'skimage'];['dl', 'ner', 'ai', 'nn'];['filter', 'train', 'model', 'epoch', 'layer', 'vgg', 'loss', 'label', 'predict'];https://www.kaggle.com/c/invasive-species-monitoring;0.763;0.281;2020-12-13 12:11:50;Invasive Species Monitoring;[];Tensorflow VGG Pretrained;Python notebook;14833.0;8;;
2017-05-26 10:42:03;Kaggle Invasive Species Monitoring: Get 0.97 accuracy with minimal effort.Finetune VGG16 top layers with Keras as described by Francois Chollet here: https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html;Apache 2.0;https://www.kaggle.com/chmaxx/finetune-vgg16-0-97-with-minimal-effort;1.0;['tensorflow', 'keras'];['ner', 'ai', 'cnn', 'rl', 'nn', 'ml'];['train', 'model', 'epoch', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'recommend', 'classification'];https://www.kaggle.com/c/invasive-species-monitoring;0.725;0.311;2020-12-13 12:11:50;Invasive Species Monitoring;[];Finetune VGG16: 0.97% with minimal effort;Python notebook;5481.0;11;;
2017-05-07 00:05:20;"Starter's Pack for Invasive Species DetectionHello everyone! This is Chris, the main researcher behind the dataset featured in this competition!First of all, we want to send a huge amount of thanks to Kaggle for making this nonprofit competition a real thing! I am here to help everyone getting a head start in the competition! We are going to be building a pretty simple yet very powerful classificator based on the blog entry ""Building powerful image classification models using very little data"" by F. Chollet. We are going to make use of Keras (Theano as backend) and the VGG16 pretrained weights. We will build our own fully connected layers to replace the top of VGG16 and later fine-tune the model for a few epochs (so we get some juicy extra AUC points in the leaderboard). The training is light, so it should run in an average Intel I5 laptop's CPU overnight! To keep the code as similar as possible to the blog entry, this notebook is compiling together what in the blog are 2 different scripts. We are doing so sequentially, so it is easier to go to the source blog and get better understanding. First, we are going to predict features for our training and validation sets for the last convolutional layers and save those to disk. Then we are going to use those predicted features to train our little fully connected model that will tell us whether there is or not an invasive species.";Apache 2.0;https://www.kaggle.com/crequena/starter-s-pack-for-invasives-detection;1.0;['tensorflow', 'keras', 'theano'];['ner', 'ai', 'dl', 'rl', 'nn'];['image classification', 'train', 'model', 'epoch', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'understanding', 'classification'];https://www.kaggle.com/c/invasive-species-monitoring;0.68;0.346;2020-12-13 12:11:50;Invasive Species Monitoring;[];Starter's Pack for Invasives Detection;Python notebook;1983.0;16;;
2017-05-10 08:00:05;use Keras pre-trained VGG16this is my first notebook. pre-trained VGG16 is quickly and good performance. I learned from official Keras blog tutorial  Building powerful image classification models using very little data;Apache 2.0;https://www.kaggle.com/fujisan/use-keras-pre-trained-vgg16-acc-98;1.0;['tensorflow', 'keras', 'theano'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'nn', 'ann'];['image classification', 'test data', 'train', 'model', 'epoch', 'validation data', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'resnet', 'classification'];https://www.kaggle.com/c/invasive-species-monitoring;0.803;0.477;2020-12-13 12:11:50;Invasive Species Monitoring;[];use Keras pre-trained VGG16  acc 98%;Python notebook;50971.0;74;;
2017-07-04 05:50:57;This is my first notebook, it references pytorch example: Pytorch transfer learning tutorial It may not exactly give you 0.988 due to random seed, but should be very close. It won't be able to run on kaggle since time limitation. Full code can be downloaded from here: code on github;Apache 2.0;https://www.kaggle.com/idv2005/pytorch-starter-lb-0-988;1.0;['pytorch'];['ner', 'ai', 'dl', 'rl', 'nn', 'ann'];['predict', 'train', 'model', 'epoch', 'label', 'loss'];https://www.kaggle.com/c/invasive-species-monitoring;0.659;0.253;2020-12-13 12:11:50;Invasive Species Monitoring;[];Pytorch starter LB 0.988;Python notebook;1299.0;6;;
2017-08-09 20:48:18;"From the beginning, I decided to use Keras for the task. As for the start I googled ""keras images classification"" and found great blog post by Francois Chollet. (blog https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html github code https://gist.github.com/fchollet/7eb39b44eb9e16e59632d25fb3119975) The code in the blog has simple and understandable structure. Also, there are few posts in the competition Kernels where the similar approach was applied. Thus some addition insight is available. (Specifically, these two kernels helped me a lot: https://www.kaggle.com/ogurtsov/0-99-with-r-and-keras-inception-v3-fine-tune https://www.kaggle.com/fujisan/use-keras-pre-trained-vgg16-acc-98)";Apache 2.0;https://www.kaggle.com/ievgenvp/keras-flow-from-directory-on-python;1.0;['tensorflow', 'sklearn', 'keras', 'theano'];['ner', 'ai', 'dl', 'nn', 'ml'];['test data', 'train', 'model', 'neural network', 'epoch', 'validation data', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/invasive-species-monitoring;0.782;0.334;2020-12-13 12:11:50;Invasive Species Monitoring;[];Keras flow_from_directory on Python;Python notebook;25731.0;14;;
2017-08-16 02:02:21;Load DatasetsSince we will be using a generator we don't need to actually load in any files into memory, all we need is the filepaths :);Apache 2.0;https://www.kaggle.com/jamesrequa/keras-k-fold-inception-v3-1st-place-lb-0-99770;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'nn', 'ann'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict'];https://www.kaggle.com/c/invasive-species-monitoring;0.749;0.427;2020-12-13 12:11:50;Invasive Species Monitoring;['deep learning, cnn'];Keras k-fold Inception V3 (1st place LB 0.99770);Python notebook;10001.0;40;;
2018-05-24 16:18:01;"Keras pre-trained VGG16 [KAGGLE RUNNABLE VERSION]SummarySome time ago I come across this nice kernel use Keras pre-trained VGG16 acc 98% The author ran this code in his computer but, it was not possible at that moment to execute it in Kaggle because some limitations:  There wasn't support for GPU's It wasn't possible to use a pretrained model as it wasn't possible to download the data files  Nowadays these limitations don't exist and I wanted to try so, I have done some little adaptations to the mentioned kernel. The author asked that it took about 20s for him to process each epoc with a GTX1080ti , Kaggle uses at this moment NVIDIA Tesla K80 and it takes about 52 secods per epoch (not too bad) References:  use Keras pre-trained VGG16 acc 98% Building powerful image classification models using very little data Pretrained Keras Models: Symlinked; Not Copied  Dogs vs. Cats Redux Playground Competition, 3rd Place Interview";Apache 2.0;https://www.kaggle.com/lbronchal/keras-pre-trained-vgg16-kaggle-runnable-version;1.0;['tensorflow', 'keras'];['ner', 'ai', 'cnn', 'cv', 'rl', 'ml', 'nn', 'ann'];['image classification', 'test data', 'train', 'model', 'epoch', 'validation data', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/invasive-species-monitoring;0.637;0.253;2020-12-13 12:11:50;multiple data sources;['gpu'];Keras pre-trained VGG16 [KAGGLE RUNNABLE VERSION];Python notebook;852.0;6;0.98687;0.98687
2017-06-04 01:20:55;"Note: The code in this notebook is meant to be run locally, NOT in kaggle's cloud! My approach to this was to use the Inception v3 model, which is trained on a very broad array of images and then just re-train the final layer to focus only on classifying invasive and non-invasive. There is a really good Codelab from Google that goes over the whole procedure of retraining Inception v3. If you follow the Codelab, you will eventually get to the optional step ""Training on your own categories"". This was the trigger for me to search for a dataset and I found this one, which even has a real-life purpose. Cool! In this notebook I show you the only things I implemented in order to adapt this dataset to the retrain workflow covered in the codelab:";Apache 2.0;https://www.kaggle.com/mbeierling/retraining-inception-v3;1.0;['tensorflow'];['ai'];['filter', 'train', 'model', 'layer', 'label', 'predict', 'recommend'];https://www.kaggle.com/c/invasive-species-monitoring;0.714;0.214;2020-12-13 12:11:50;Invasive Species Monitoring;[];Retraining Inception v3;Python notebook;4162.0;4;;
2017-07-11 04:35:58;This notebook is the first try of the invasive classificationThe first section is the visualization of image and the second part is the model part using Keras.  Make some edit due to run time in Kaggle Kernels;Apache 2.0;https://www.kaggle.com/netzone/visualization-using-cv2-and-keras-starter;1.0;['tensorflow', 'skimage', 'keras'];['ner', 'ai', 'cv'];['filter', 'training data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/invasive-species-monitoring;0.662;0.188;2020-12-13 12:11:50;Invasive Species Monitoring;[];Visualization using CV2 and Keras Starter;Python notebook;1372.0;3;;
2017-05-21 06:47:00;Use Resnet model for bottleneck feature extraction.Resnet pre-trained model is available here. I have used Inception_resnet_v2 model. If you come across this transfer learning concept first time, go through the chapter of stanford CS231. This blog will clear all your doubts about transfer learning.;Apache 2.0;https://www.kaggle.com/patilpramod2157/transfer-learning-using-inception-resnet-v2;1.0;['tensorflow', 'xgboost', 'sklearn'];['ner', 'ai', 'nn', 'cv'];['regression', 'train', 'model', 'layer', 'label', 'logistic regression', 'predict', 'relu', 'resnet', 'classification'];https://www.kaggle.com/c/invasive-species-monitoring;0.734;0.253;2020-12-13 12:11:50;Invasive Species Monitoring;[];Transfer learning using inception_resnet_v2;Python notebook;6799.0;6;;
2017-05-30 23:41:02;Invasive Species Monitoring: LBP texture descriptorThis method give 88% acc on the leaderboard... Code with all the pipe line :  https://github.com/VieVie31/kaggle_invasive_species;Apache 2.0;https://www.kaggle.com/vievie31/invasive-species-monitoring-lbp-descriptor;1.0;['pattern', 'skimage', 'sklearn'];['ai'];['filter', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/invasive-species-monitoring;0.611;0.188;2020-12-13 12:11:50;Invasive Species Monitoring;[];Invasive Species Monitoring: LBP descriptor;Python notebook;536.0;3;;
2019-05-19 16:11:11;Implementing a residual neural network from scratch.references:https://www.kaggle.com/xhlulu/reducing-image-sizes-to-32x32 https://www.coursera.org/learn/convolutional-neural-networks/home/welcome https://www.kaggle.com/xhlulu/cnn-baseline-iwildcam-2019;Apache 2.0;https://www.kaggle.com/akumaldo/resnet-from-scratch-keras;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'dl', 'cnn', 'nn', 'ann'];['filter', 'train', 'model', 'output layer', 'neural network', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'resnet'];https://www.kaggle.com/c/iwildcam-2019-fgvc6;0.716;0.268;2020-12-13 12:12:46;multiple data sources;['deep learning, multiclass classification'];RESNET from scratch - KERAS ;Python notebook;4462.0;7;0.090;0.118
2019-03-26 05:35:15;General informationCamera Traps (or Wild Cams) enable the automatic collection of large quantities of image data. Biologists all over the world use camera traps to monitor biodiversity and population density of animal species As biologists try to expand the scope of these models from specific regions where they have collected training data to nearby areas they are faced with an interesting probem: how do you classify a species in a new region that you may not have seen in previous training data? In this challenge the training data and test data are from different regions, namely The American Southwest and the American Northwest. We have 23 classes for which we need to make a classification. Using external data is allowed.;Apache 2.0;https://www.kaggle.com/artgor/iwildcam-basic-eda;1.0;['albumentations', 'sklearn'];['ner', 'ai', 'cv', 'rl', 'ml', 'nn', 'ann'];['training data', 'test data', 'train', 'model', 'label', 'classification'];https://www.kaggle.com/c/iwildcam-2019-fgvc6;0.651;0.379;2020-12-13 12:12:46;iWildCam 2019 - FGVC6;['gpu, exploratory data analysis'];iWildCam basic EDA;Python notebook;1115.0;23;;
2019-04-12 07:38:44;Simple example of transfer learning from pretrained model using PyTorch.  Metrics: f1_score;Apache 2.0;https://www.kaggle.com/ateplyuk/iwildcam2019-pytorch-starter;1.0;['pytorch', 'sklearn'];['ai', 'nn', 'cv'];['predict', 'train', 'model', 'epoch', 'label', 'loss'];https://www.kaggle.com/c/iwildcam-2019-fgvc6;0.686;0.423;2020-12-13 12:12:46;iWildCam 2019 - FGVC6;['gpu'];iWildCam2019 PyTorch Starter;Python notebook;2255.0;38;;
2019-05-21 21:31:44;iWildCam 2019 EDA Content Introduction  Prepare the data analysis  Data exploration  Model  References;Apache 2.0;https://www.kaggle.com/gpreda/iwildcam-2019-eda-and-prediction;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cnn', 'gan', 'rl', 'nn', 'ann'];['filter', 'training data', 'test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'classification', 'labeled'];https://www.kaggle.com/c/iwildcam-2019-fgvc6;0.733;0.465;2020-12-13 12:12:46;multiple data sources;['gpu, image data, multiclass classification'];iWildCam 2019 EDA and Prediction;Python notebook;6603.0;64;;
2019-04-01 02:37:19;Resize iWildCam 2019 and iNat Idaho dataTrain models on complete image data (iWildCam 2019 + supplemental iNat Idaho)  iWildCam2019: https://www.kaggle.com/c/iwildcam-2019-fgvc6/data Supplemental iNat Idaho data: https://github.com/visipedia/iwildcam_comp Original idea of resizing imgs from https://www.kaggle.com/xhlulu/reducing-image-sizes-to-32x32;Apache 2.0;https://www.kaggle.com/rbarman/iwildcam-2019-inat-idaho-resized;1.0;['sklearn'];['ner', 'ai', 'cv', 'nn', 'ann'];['train', 'model', 'predict'];https://www.kaggle.com/c/iwildcam-2019-fgvc6;0.618;0.236;2020-12-13 12:12:46;iWildCam 2019 - FGVC6;['beginner'];iWildCam 2019 + iNat Idaho - Resized;Python notebook;608.0;5;;
2019-10-15 10:52:59;Continuation of my learning through Convolutional Neural Networks in TensorFlow Coursera course https://www.coursera.org/learn/convolutional-neural-networks-tensorflow/ https://www.kaggle.com/rblcoder/learning-cnn-in-tensorflow-coursera-course;Apache 2.0;https://www.kaggle.com/rblcoder/cnn-in-tf-coursera-course-iwildcam-2019-mobilenet;1.0;['tensorflow', 'keras'];['ner', 'ai', 'dl', 'cnn', 'rl', 'ml', 'nn', 'ann'];['train', 'model', 'neural network', 'epoch', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'convolutional neural network'];https://www.kaggle.com/c/iwildcam-2019-fgvc6;0.644;0.334;2020-12-13 12:12:46;multiple data sources;['gpu, beginner, image data, +2 moreneural networks, multiclass classification'];CNN in Tf Coursera course: iWildCam 2019 MobileNet;Python notebook;985.0;14;;
2019-05-26 03:45:45;Fastai starterThis is some basic starter code for using fastai for this dataset. The code/model is based on this kernel and uses a pretrained DenseNet121, along with Mixup as implemented by the fastai library.;Apache 2.0;https://www.kaggle.com/tanlikesmath/fastai-starter-iwildcam-2019;1.0;['pytorch'];['ner', 'ai', 'dl', 'cnn', 'rl', 'nn'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'classification'];https://www.kaggle.com/c/iwildcam-2019-fgvc6;0.676;0.357;2020-12-13 12:12:46;iWildCam 2019 - FGVC6;['gpu'];fastai starter - iWildCam 2019;Python notebook;1814.0;18;0.075;0.089
2019-04-04 02:20:38;Here we import all the neccesary libraries;Apache 2.0;https://www.kaggle.com/twhitehurst3/keras-transfer-learning-iwildcam-2019;1.0;['tensorflow', 'sklearn', 'keras'];['dl', 'ner', 'ai', 'nn'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'classification'];https://www.kaggle.com/c/iwildcam-2019-fgvc6;0.643;0.253;2020-12-13 12:12:46;multiple data sources;['gpu'];Keras Transfer Learning - iWildCam 2019;Python notebook;957.0;6;0.102;0.128
2019-03-27 19:01:55;CNN Baseline - iWildCam 2019Breakdown of this notebook:  Loading the 32x32 dataset: Load the data generated in Reducing Image Sizes to 32x32. Create Callback for F1 Score: F1-macro score is the official metric of the competition. We create a callback to keep track of that value as we train the model. Creating and Training the Model: Create a simple model (taken from the official Keras tutorial) and train it. Evaluation: Display the plots from the training history. Submission: Run predictions with model.predict, and create submission csv file.  References cifar10_cnn_keras.py: Heavily inspired from this tutorial created by the Keras team. The architecture and training process is directly taken from them. Keras CNN Starter - PetFinder: History plot and submission are inspired by this kernel Reducing Image Sizes to 32x32: Image data (X_train, X_test) come from the output of this kernel. How to compute f1 score for each epoch in Keras: Needed to compute the F1 Score after each epoch.;Apache 2.0;https://www.kaggle.com/xhlulu/cnn-baseline-iwildcam-2019;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cnn', 'nn'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/iwildcam-2019-fgvc6;0.691;0.357;2020-12-13 12:12:46;multiple data sources;['gpu, deep learning, classification, +1 morecnn'];CNN Baseline - iWildCam 2019;Python notebook;2497.0;18;0.093;0.125
2019-03-29 01:02:12;DenseNet Transfer Learning - iWildCam 2019Breakdown of this notebook:  Loading the 32x32 dataset: Load the data generated in Reducing Image Sizes to 32x32. Create Callback for F1 Score: F1-macro score is the official metric of the competition. We create a callback to keep track of that value as we train the model. Creating and Training the Model: Create a DenseNet model, and load weights pretrained on ImageNet. Train it on the entire dataset. Evaluation: Display the plots from the training history. Submission: Run predictions with model.predict, and create submission csv file.  References cifar10_cnn_keras.py: Heavily inspired from this tutorial created by the Keras team. The architecture and training process is directly taken from them. Keras CNN Starter - PetFinder: History plot and submission are inspired by this kernel Reducing Image Sizes to 32x32: Image data (X_train, X_test) come from the output of this kernel. How to compute f1 score for each epoch in Keras: Needed to compute the F1 Score after each epoch. CNN Baseline - iWildCam 2019: This is a fork of this notebook.;Apache 2.0;https://www.kaggle.com/xhlulu/densenet-transfer-learning-iwildcam-2019;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cnn', 'nn'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'classification'];https://www.kaggle.com/c/iwildcam-2019-fgvc6;0.752;0.439;2020-12-13 12:12:46;multiple data sources;['gpu, deep learning, classification, +2 moreimage data, cnn'];DenseNet Transfer Learning - iWildCam 2019;Python notebook;10841.0;46;;
2019-03-27 02:59:14;Reducing Image Sizes to 32x32I think that some of you will be interested in trying smaller models to get started (e.g. a CNN with only a few connected layers). However, those datasets seem to be really big (150k test images and 195k training images) as well as high resolution. Just trying to create a GPU kernel and preprocessing the images seem to take a while. Therefore, I created this kernel in order to reduce the image to the smallest usable size (i.e. 32x32, similar to CIFAR10/100). Please feel free to use this as an output to your exploration models, or to modify this for other image sizes. Let me know your thoughts! References https://www.kaggle.com/xhlulu/exploration-and-preprocessing-for-keras-224x224;Apache 2.0;https://www.kaggle.com/xhlulu/reducing-image-sizes-to-32x32;1.0;['keras'];['ai', 'nn', 'cnn', 'cv'];['train', 'model', 'label', 'layer'];https://www.kaggle.com/c/iwildcam-2019-fgvc6;0.71;0.39;2020-12-13 12:12:46;iWildCam 2019 - FGVC6;['beginner, data cleaning'];Reducing Image Sizes to 32x32;Python notebook;3825.0;26;;
2020-03-16 07:15:01;Simple example of transfer learning from pretrained model using PyTorch.  Metrics: f1_score;Apache 2.0;https://www.kaggle.com/ateplyuk/iwildcam2020-pytorch-start;1.0;['pytorch', 'skimage', 'sklearn'];['ai', 'nn', 'ann', 'cv'];['train', 'model', 'epoch', 'label', 'loss'];https://www.kaggle.com/c/iwildcam-2020-fgvc7;0.686;0.411;2020-12-13 12:13:39;multiple data sources;['gpu'];iWildCam2020_Pytorch_Start;Python notebook;2242.0;33;0.598;0.425
2020-09-22 16:18:19;Trains a Resent50 model on the GPU and saves as a pth.;Apache 2.0;https://www.kaggle.com/blueturtle/wildlife-cam-resent50;1.0;['tensorflow'];['ai', 'nn', 'ann', 'cv'];['train', 'model', 'epoch', 'label', 'loss', 'relu', 'resnet'];https://www.kaggle.com/c/iwildcam-2020-fgvc7;0.545;0.099;2020-12-13 12:13:39;iWildCam 2020 - FGVC7;[];Wildlife Cam;Python notebook;190.0;1;;
2020-03-29 08:36:26;This is my first attempt to participiate in Kaggle. I am sure I have made mistakes. It would be nice if you read and let me know my stupidities:D;Apache 2.0;https://www.kaggle.com/mohammadmortaji/my-first-experience-iwild2020;1.0;['tensorflow', 'keras'];['ner', 'ai', 'cnn', 'cv', 'nn', 'ann'];['training data', 'train', 'model', 'epoch', 'layer', 'vgg', 'alexnet', 'label', 'loss', 'resnet'];https://www.kaggle.com/c/iwildcam-2020-fgvc7;0.563;0.188;2020-12-13 12:13:39;iWildCam 2020 - FGVC7;['gpu'];my_first_experience_iWild2020;Python notebook;248.0;3;;
2020-04-26 14:05:12;I refered following kernels, thank you! https://www.kaggle.com/ateplyuk/inat2019-starter-keras-efficientnet/data https://www.kaggle.com/mobassir/keras-efficientnetb2-for-classifying-cloud;Apache 2.0;https://www.kaggle.com/nayuts/iwildcam-2020-efficientnetb2;1.0;['tensorflow', 'sklearn', 'keras', 'pillow'];['ner', 'ai', 'cv', 'rl', 'ml', 'nn', 'ann'];['predict', 'test data', 'train', 'model', 'epoch', 'layer', 'loss'];https://www.kaggle.com/c/iwildcam-2020-fgvc7;0.622;0.236;2020-12-13 12:13:39;iWildCam 2020 - FGVC7;[];iWildCam 2020 EfficientnetB2;Python notebook;653.0;5;;
2020-04-29 05:22:52;iWildCam 2020 - FGVC7Let's detect wild animals in new places!;Apache 2.0;https://www.kaggle.com/nayuts/iwildcam-2020-overviewing-for-start;1.0;['sklearn', 'pillow', 'tensorflow', 'pattern', 'keras'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['gru', 'filter', 'machine learning', 'training data', 'test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict'];https://www.kaggle.com/c/iwildcam-2020-fgvc7;0.722;0.463;2020-12-13 12:13:39;iWildCam 2020 - FGVC7;['beginner, data visualization, exploratory data analysis'];iWildCam 2020 Overviewing for start;Python notebook;5091.0;62;0.446;0.370
2020-03-22 14:55:31;About this kernelCredited to @Nayu's kernel. I changed it with tf2.x codes and support TPU. For fast training, I resized the images into 64*64.  Let your TPU burn...;Apache 2.0;https://www.kaggle.com/qinhui1999/iwildcam-2020-efficientnetb7-tpu-starter-v1;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ann'];['unlabeled', 'training data', 'test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'labeled'];https://www.kaggle.com/c/iwildcam-2020-fgvc7;0.657;0.281;2020-12-13 12:13:39;multiple data sources;['tpu'];iWildCam 2020 EfficientnetB7  TPU starter v1;Python notebook;1247.0;8;0.484;0.435
2020-03-15 00:09:47;The code/model is based on this kernel and uses a pretrained DenseNet121, along with Mixup as implemented by the fastai library.;Apache 2.0;https://www.kaggle.com/seriousran/simple-starter-iwildcam-2020;1.0;['pytorch'];['ner', 'ai', 'cnn', 'ml', 'nn', 'ann'];['train', 'model', 'epoch', 'loss', 'label', 'predict', 'resnet', 'classification'];https://www.kaggle.com/c/iwildcam-2020-fgvc7;0.643;0.311;2020-12-13 12:13:39;iWildCam 2020 - FGVC7;['gpu'];Simple Starter - iWildCam 2020;Python notebook;957.0;11;0.420;0.205
2020-10-28 16:00:42;Tutorial: # NLP (Natural Language Processing) with Python Agenda Representing text as numerical data Reading a text-based dataset into pandas Vectorizing our dataset Building and evaluating a model Comparing models Examining a model for further insight Practicing this workflow on another dataset Tuning the vectorizer (discussion)  In this notebook we will discuss a higher level overview of the basics of Natural Language Processing, which basically consists of combining machine learning techniques with text, and using math and statistics to get that text in a format that the machine learning algorithms can understand!;Apache 2.0;https://www.kaggle.com/faressayah/natural-language-processing-nlp-for-beginners;1.0;['pattern', 'vocabulary', 'sklearn', 'nltk'];['ner', 'ai', 'dl', 'rl', 'nlp', 'nn', 'ann'];['machine learning', 'training data', 'regression', 'train', 'model', 'natural language processing', 'label', 'logistic regression', 'text classification', 'predict', 'naive bayes', 'understanding', 'classification', 'natural language'];https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification;0.765;0.557;2020-12-13 12:15:35;multiple data sources;['beginner, text data, text mining'];Natural Language Processing (NLP) 🧾 for Beginners;Python notebook;15634.0;225;;
2020-06-23 09:00:45;THIS KERNAL IS BLEND OF So awesome kernels present Right nowVote if you love blend.Kernels used comming from these awesome people:For the TF-IDF submissions they are comming from this kernel:NB-SVM strong linear baseline [TPU-Inference] Super Fast XLMRoberta Jigsaw TPU: BERT with Huggingface and Keras inference of bert tpu model ml w/ validation Train from MLM finetuned XLM-R large;Apache 2.0;https://www.kaggle.com/hamditarek/ensemble;1.0;['keras'];['ai', 'ml'];['train', 'model', 'classification'];https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification;0.809;0.545;2020-12-13 12:15:35;multiple data sources;['classification, nlp, binary classification, +1 moreensembling'];🤗🤗 Ensemble 🤗🤗;Python notebook;62339.0;190;0.9473;0.9488
2020-03-28 16:15:58;About this notebookJigsaw Multilingual Toxic Comment Classification is the 3rd annual competition organized by the Jigsaw team. It follows Toxic Comment Classification Challenge, the original 2018 competition, and Jigsaw Unintended Bias in Toxicity Classification, which required the competitors to consider biased ML predictions in their new models. This year, the goal is to use english only training data to run toxicity predictions on many different languages, which can be done using multilingual models, and speed up using TPUs. Many awesome notebooks has already been made so far. Many of them used really cool technologies like Pytorch XLA. This notebook instead aims at constructing a fast, concise, reusable, and beginner-friendly model scaffold. It will focus on the following points:  Using Tensorflow and Keras: Tensorflow is a powerful framework, and Keras makes the training process extremely easy to understand. This is especially good for beginners to learn how to use TPUs, and for experts to focus on the modelling aspect. Using Huggingface's transformers library: This library is extremely popular, so using this let you easily integrate the end result into your ML pipelines, and can be easily reused for your other projects. Native TPU usage: The TPU usage is abstracted using the native strategy that was created using Tensorflow's tf.distribute.experimental.TPUStrategy. This avoids getting too much into the lower-level aspect of TPU management. Use a subset of the data: Instead of using the entire dataset, we will only use the 2018 subset of the data available, which makes this much faster, all while achieving a respectable accuracy.;Apache 2.0;https://www.kaggle.com/miklgr500/jigsaw-tpu-bert-with-huggingface-and-keras;1.0;['nltk', 'sklearn', 'pytorch', 'tensorflow', 'vocabulary', 'keras'];['ner', 'ai', 'dl', 'gan', 'ml', 'nn', 'ann'];['filter', 'training data', 'test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'classification'];https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification;0.745;0.51;2020-12-13 12:15:35;multiple data sources;['tpu'];Jigsaw TPU: BERT with Huggingface and Keras;Python notebook;9121.0;115;0.9185;0.9158
2020-06-22 17:14:23;A mind map for of NLP;Apache 2.0;https://www.kaggle.com/rftexas/ml-cheatsheet-a-mind-map-for-nlp;1.0;['pattern', 'vocabulary'];['ner', 'ai', 'dl', 'rl', 'ml', 'nlp', 'nn', 'rnn', 'ann'];['unlabeled', 'recurrent neural network', 'machine translation', 'predict', 'gru', 'neuron', 'train', 'epoch', 'lstm', 'recommend', 'classification', 'labeled', 'propagation', 'model', 'neural network', 'layer', 'loss', 'hidden layer', 'generation', 'deep learning', 'label', 'computer vision'];https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification;0.699;0.52;2020-12-13 12:15:35;Jigsaw Multilingual Toxic Comment Classification;[];[ML CHEATSHEET] A mind map for NLP ;Python notebook;2998.0;132;;
2020-06-06 23:51:13;About this notebookThis notebook trains from the XLM-Roberta large model which was finetuned with masked language modelling on the jigsaw test dataset Link. This notebook also implements a few improvements compared to a previous starter notebook that I shared  1, It trains on translated data 2, It uses different learning rate for the head layer and the transformer 3, It restores the model weights after training to the checkpoint which had the highest validation score  Suggestions/improvements are appreciated!  References: The shared XLM-Roberta large model, finetuned on the Jigsaw multilingual test data with masked language modelling Notebook link / Dataset link My previous starter notebook link This notebook uses the translated versions of the training dataset too, big thanks to Michael Kazachok! link This notebook uses different learning rate for the transformer and the head, I got the ideas from the writeup of the winning team of the Google QUEST Q&A Labeling competition  link, I have seen it described to be useful elsewhere too. This notebook heavily relies on the great notebook by, Xhulu: @xhulu  The tensorflow distrubuted training tutorial: Link;Apache 2.0;https://www.kaggle.com/riblidezso/train-from-mlm-finetuned-xlm-roberta-large;1.0;['caffe', 'tensorflow', 'sklearn', 'keras'];['ai', 'nn', 'ml', 'gan'];['training data', 'test data', 'train', 'model', 'validation data', 'layer', 'loss', 'label', 'predict', 'classification'];https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification;0.726;0.516;2020-12-13 12:15:35;multiple data sources;['tpu, nlp'];Train from MLM finetuned XLM-R large;Python notebook;5659.0;126;0.9412;0.9422
2020-05-02 18:36:00;NLP AlbumentationsHi everyone! Recently I have published my inference kernel Now I would like to share with you, my friends, experience in computer vision competition! CV? Yes, DL/CV/NLP are very similar. I have got good boost when I used this great library albumentations;Apache 2.0;https://www.kaggle.com/shonenkov/nlp-albumentations;1.0;['pytorch', 'albumentations', 'nltk'];['ai', 'dl', 'rl', 'cv', 'nlp'];['train', 'computer vision', 'classification'];https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification;0.718;0.537;2020-12-13 12:15:35;Jigsaw Multilingual Toxic Comment Classification;['nlp'];NLP Albumentations;Python notebook;4588.0;169;;
2020-04-26 21:49:26;"Super Fast Inference [~ 2 min] using multi TPU on PyTorch/XLAHi everyone! My name is Alex Shonenkov, I am researcher, in Love with NLP and DL. First of all, I would like to say ""BIG THANKS"" organizers of this competition:  https://www.kaggle.com/c/deepfake-detection-challenge 6.5% kernels were crushed on Private Stage, despite on success in Public Stage. And many teams have got score 0.5 for every sample in prediction and get score 0.69314. For example, 3th public place ""WestLake"" have got this score. https://www.kaggle.com/c/deepfake-detection-challenge/discussion/145623 I have silver zone solution in computer vision competition, but I didn't take medal. https://www.kaggle.com/c/deepfake-detection-challenge/discussion/145982 After this precedent I don't see any point in continuing to do any competitions. I would like to share knowledges with you, my friends. P.S. I am sorry for high score kernels, but I hope you can improve your solutions using my kernels.";Apache 2.0;https://www.kaggle.com/shonenkov/tpu-inference-super-fast-xlmroberta;1.0;['pytorch', 'albumentations', 'spacy', 'nltk'];['ner', 'ai', 'dl', 'gan', 'rl', 'nlp', 'nn'];['filter', 'generation', 'train', 'model', 'computer vision', 'predict', 'rank', 'classification'];https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification;0.762;0.565;2020-12-13 12:15:35;multiple data sources;['tpu, deep learning, nlp'];[TPU-Inference] Super Fast XLMRoberta;Python notebook;14308.0;255;0.9443;0.9459
2020-05-04 21:54:30;Training Pipeline by @shonenkov using multi TPU on PyTorch/XLAHi everyone! My name is Alex Shonenkov, I am researcher, in Love with NLP and DL. Recently I have published my ideas about this competition:  [TPU-Inference] Super Fast XLMRoberta NLP Albumentations Hack with Parallel Corpus Class Balance with PyTorch/XLA open-subtitles-toxic-pseudo-labeling  if you didn't see this kernels and datasets, I recommend to read all of them because it may help you for better understand this kernel and achieve success in competition :);Apache 2.0;https://www.kaggle.com/shonenkov/tpu-training-super-fast-xlmroberta;1.0;['nltk', 'sklearn', 'pytorch', 'albumentations', 'spacy'];['ner', 'ai', 'dl', 'rl', 'nlp', 'nn'];['filter', 'train', 'model', 'epoch', 'layer', 'computer vision', 'loss', 'label', 'predict', 'rank', 'recommend', 'classification', 'labeled'];https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification;0.748;0.552;2020-12-13 12:15:35;multiple data sources;['deep learning, nlp'];[TPU-Training] Super Fast XLMRoberta;Python notebook;9734.0;209;0.9400;0.9416
2020-04-13 19:19:47;About this NotebookNLP is a very hot topic right now and as belived by many experts '2020 is going to be NLP's Year' ,with its ever changing dynamics it is experiencing a boom , same as computer vision once did. Owing to its popularity Kaggle launched two NLP competitions recently and me being a lover of this Hot topic prepared myself to join in my first Kaggle Competition. As I joined the competitions and since I was a complete beginner with Deep Learning Techniques for NLP, all my enthusiasm took a beating when I saw everyone Using all  kinds of BERT , everything just went over my head,I thought to quit but there is a special thing about Kaggle ,it just hooks you. I thought I have to learn someday , why not now , so I braced myself and sat on the learning curve. I wrote a kernel on the Tweet Sentiment Extraction competition that has now got a gold medal , it can be viewed here : https://www.kaggle.com/tanulsingh077/twitter-sentiment-extaction-analysis-eda-and-model  After 10 days of extensive learning(finishing all the latest NLP approaches) , I am back here to share my leaning , by writing a kernel that starts from the very Basic RNN's to built over , all the way to BERT . I invite you all to come and learn alongside with me and take a step closer towards becoming an NLP expert;Apache 2.0;https://www.kaggle.com/tanulsingh077/deep-learning-for-nlp-zero-to-transformers-bert;1.0;['sklearn', 'pytorch', 'tensorflow', 'vocabulary', 'keras'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nlp', 'nn', 'rnn', 'ann'];['recurrent neural network', 'machine translation', 'predict', 'gru', 'machine learning', 'neuron', 'train', 'epoch', 'lstm', 'recommend', 'classification', 'model', 'neural network', 'layer', 'loss', 'hidden layer', 'understanding', 'test data', 'fitting', 'output layer', 'deep learning', 'label', 'computer vision', 'u-net'];https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification;0.782;0.628;2020-12-13 12:15:35;multiple data sources;['beginner, deep learning, nlp, +1 moretransfer learning'];Deep Learning For NLP: Zero To Transformers & BERT;Python notebook;25954.0;729;0.8736;0.8704
2020-06-01 17:09:16;About this Notebook In 2018 ,Google open sourced the device which was the backbone of their state of the art results ,the TPU's (more on them in a bit) . They made TPU's available through their cloud services for anyone to use at $2/hour and after some time TPU's were made available for free on Google colab .  As we all know TPU's are very fast and give state of the art results for neural networks , however initially it could only be used with TensorFlow and Keras , leaving the pytorch fans really frustated as they didn't want to shift to TF . This led to a chain of events for the development of way allowing TPU's to be used with Pytorch  Hence Pytorch-XLA module was developed which lets pytorch to run its graph on xla_devices like TPU's .   In the Jigsaw competition TPU's have been used in various different ways , on single cores, multi cores, using different chechpoints etc,etc . However when I tried to understand the Publically shared kernels to explore how to use TPU cores with pytorch, I found it was really difficult to comphrehend. Also for Jigsaw the best performing model is XLM-Roberta which is a fairly large model and throws an error if someone is not careful with memory management. The complexity of TPU's and usage of XLM-Roberta with TPU's left me frustated and angry . I decided to take this TPU thing slowly and started with small models building on that with a lot of experimentations upto XLM-Roberta . In this Notebook I share my experimentations with Pytorch-XLA and TPU's . I will start from basic TPU usage and build on that to show how to use TPUs on multiple cores and also with multithreading. I will also share some tips and tricks which would be useful when using TPU's with Pytorch XLA. If you want to learn to use TPU's the easy way, this might be a good place to start After learning this You will be able to Decode and easily understand ALEX's and Abhishek's kernels;Apache 2.0;https://www.kaggle.com/tanulsingh077/pytorch-xla-understanding-tpu-s-and-xla;1.0;['sklearn', 'pillow', 'pytorch', 'tensorflow', 'spacy', 'keras'];['ner', 'ai', 'dl', 'rl', 'ml', 'nlp', 'nn', 'ann'];['filter', 'training data', 'train', 'model', 'neural network', 'epoch', 'deep learning', 'layer', 'loss', 'rank', 'classification'];https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification;0.708;0.507;2020-12-13 12:15:35;Jigsaw Multilingual Toxic Comment Classification;['tpu, transfer learning'];Pytorch-XLA: Understanding TPU's and XLA;Python notebook;3674.0;110;;
2020-03-29 06:11:27;As I get closer to the grandmaster tier, I want to take this opportunity to thank this amazing community which has taught me so much about data science and life in general. I also want to thank everyone who made this journey so beautiful and memorable!;Apache 2.0;https://www.kaggle.com/tarunpaparaju/jigsaw-multilingual-toxicity-eda-models;1.0;['nltk', 'gensim', 'sklearn', 'tensorflow', 'textblob', 'keras'];['ner', 'ai', 'nlu', 'dl', 'cnn', 'gan', 'rl', 'ml', 'nlp', 'nn', 'rnn', 'ann'];['filter', 'recognition', 'natural language processing', 'predict', 'relu', 'gru', 'machine learning', 'training data', 'train', 'epoch', 'lstm', 'text classification', 'classification', 'propagation', 'model', 'neural network', 'layer', 'loss', 'rank', 'understanding', 'output layer', 'deep learning', 'label', 'natural language', 'convolutional neural network'];https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification;0.775;0.58;2020-12-13 12:15:35;multiple data sources;['data visualization, exploratory data analysis, nlp, +1 moretext data'];Jigsaw Multilingual Toxicity : EDA + Models 🤬;Python notebook;20940.0;322;;
2020-04-01 00:22:50;About this notebookJigsaw Multilingual Toxic Comment Classification is the 3rd annual competition organized by the Jigsaw team. It follows Toxic Comment Classification Challenge, the original 2018 competition, and Jigsaw Unintended Bias in Toxicity Classification, which required the competitors to consider biased ML predictions in their new models. This year, the goal is to use english only training data to run toxicity predictions on many different languages, which can be done using multilingual models, and speed up using TPUs. Many awesome notebooks has already been made so far. Many of them used really cool technologies like Pytorch XLA. This notebook instead aims at constructing a fast, concise, reusable, and beginner-friendly model scaffold. It will focus on the following points:  Using Tensorflow and Keras: Tensorflow is a powerful framework, and Keras makes the training process extremely easy to understand. This is especially good for beginners to learn how to use TPUs, and for experts to focus on the modelling aspect. Huggingface's transformers library: This library is extremely popular, so using this let you easily integrate the end result into your ML pipelines, and can be easily reused for your other projects. Multilingual DistilBERT: DistilBERT is 2 times faster and 25% lighter than multilingual BERT base, all while retaining 92% of its performance. This model let you quickly experiments with different ideas, and when you are ready for the real thing, just change two lines of code to use bert-base-multilingual-cased. Blazing fast tokenization: Huggingface's tokenizers is order of magnitude faster than the default BERT tokenizer, since it is written in Rust, and uses a Python interface. Native TPU usage: The TPU usage is abstracted using the native strategy that was created using Tensorflow's tf.distribute.experimental.TPUStrategy. This avoids getting too much into the lower-level aspect of TPU management. Subset of the data: Instead of using the entire dataset, we will only use the 2018 subset of the data available, which makes this much faster, all while achieving a respectable accuracy.  References Original Author: @xhlulu Original notebook: Link;Apache 2.0;https://www.kaggle.com/xhlulu/jigsaw-tpu-distilbert-with-huggingface-and-keras;1.0;['pytorch', 'vocabulary', 'tensorflow', 'keras'];['ner', 'ai', 'dl', 'gan', 'ml', 'nn', 'ann'];['training data', 'train', 'model', 'epoch', 'layer', 'loss', 'predict', 'classification'];https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification;0.745;0.493;2020-12-13 12:15:35;Jigsaw Multilingual Toxic Comment Classification;['tpu'];Jigsaw TPU: DistilBERT with Huggingface and Keras;Python notebook;8945.0;91;0.8653;0.8632
2020-04-01 02:46:43;About this notebookJigsaw Multilingual Toxic Comment Classification is the 3rd annual competition organized by the Jigsaw team. It follows Toxic Comment Classification Challenge, the original 2018 competition, and Jigsaw Unintended Bias in Toxicity Classification, which required the competitors to consider biased ML predictions in their new models. This year, the goal is to use english only training data to run toxicity predictions on many different languages, which can be done using multilingual models, and speed up using TPUs. Many awesome notebooks has already been made so far. Many of them used really cool technologies like Pytorch XLA. This notebook instead aims at constructing a fast, concise, reusable, and beginner-friendly model scaffold. THIS DOES NOT USE ANY TRANSLATED DATA, BUT IT DOES TRAIN ON THE VALIDATION SET. References Original Author: @xhlulu Original notebook: Link;Apache 2.0;https://www.kaggle.com/xhlulu/jigsaw-tpu-xlm-roberta;1.0;['pytorch', 'tensorflow', 'keras'];['ner', 'ai', 'dl', 'gan', 'ml', 'nn', 'ann'];['training data', 'train', 'model', 'epoch', 'layer', 'loss', 'predict', 'classification'];https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification;0.785;0.59;2020-12-13 12:15:35;Jigsaw Multilingual Toxic Comment Classification;['tpu, nlp, neural networks, +1 moretensorflow'];Jigsaw TPU: XLM-Roberta;Python notebook;27833.0;380;0.9362;0.9383
2018-03-17 09:02:19;The public kernals are filled with Blends of Blends of Blends and maybe someone can blend to 1.00000 too. Ok, Nothing wrong in that. I just thought good solid kernals should not be lost within the chaos. So, I've compiled and categorized a list of resources that have taught something to me. Please add on to this list in the comments below, if I've missed any good kernals. Simple Naive-Bayes: https://www.kaggle.com/jhoward/nb-svm-strong-linear-baseline https://www.kaggle.com/jhoward/nb-svm-strong-linear-baseline#261316          # Custom SK learn class for Naive Bayes    Tf-IDF and simple Logistic Regression: https://www.kaggle.com/tunguz/logistic-regression-with-words-and-char-n-grams            # ngram range=(2,6)   -->    can capture a lot of information! https://www.kaggle.com/yekenot/toxic-regression  Wordbatch: https://www.kaggle.com/anttip/wordbatch-1-3-3-fm-ftrl-lb-0-9812                          # FM_FTRL  H20, Word2Vec in R: https://www.kaggle.com/brandenkmurray/h2o-word2vec-starter-toxic-comments  Deep learning: GRU(Gated Recurrent Units): https://www.kaggle.com/yekenot/pooled-gru-fasttext/code  Capsule Net(with GRU): https://www.kaggle.com/chongjiujjin/capsule-net-with-gru https://github.com/Godricly/comment_toxic https://github.com/bojone/Capsule/blob/master/Capsule_Keras.py                   # Base implementations of CapsNet in Keras https://github.com/XifengGuo/CapsNet-Keras    LSTM: https://www.kaggle.com/sbongo/for-beginners-tackling-toxic-using-keras                             # Explains basic of LSTM well https://www.kaggle.com/CVxTz/keras-bidirectional-lstm-baseline-lb-0-069                         # Simple baseline https://www.kaggle.com/jhoward/improved-lstm-baseline-glove-dropout                              # Glove pretrained features + LSTM  Attention: https://www.kaggle.com/sermakarevich/hierarchical-attention-network https://www.kaggle.com/qqgeogor/keras-lstm-attention-glove840b-lb-0-043                      # LSTM + Attention layer  Convolution(CNNs): https://www.kaggle.com/yekenot/textcnn-2d-convolution https://www.kaggle.com/sbongo/for-beginners-go-even-deeper-with-char-gram-cnn  Bi Directional GRU CNNs: https://www.kaggle.com/konohayui/bi-gru-cnn-poolings https://www.kaggle.com/eashish/bidirectional-gru-with-convolution  Blending Helpers:What is blending?  https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/51058 What all do I need to check before blending?  https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/50827            ## Model correlations https://www.kaggle.com/ogrellier/things-you-need-to-be-aware-of-before-stacking https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/49964          ## Class leakage in level 0 models    OOF stackering: https://www.kaggle.com/hhstrand/oof-stacking-regime  Stacker scrpits: https://www.kaggle.com/reppic/lazy-ensembling-algorithm  Covariance shift / Adversarial Validation: ( By how much test is different than train?) https://www.kaggle.com/ogrellier/check-unicode-script-distribution https://www.kaggle.com/ogrellier/adversarial-validation-and-lb-shakeup https://www.kaggle.com/konradb/adversarial-validation  Others:Creating more data:Using translations  https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/48038  Study materials: https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/46073#latest-277688 https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/46038  Spell checker: https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/51426  Tuning:Tuning DL models :  https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/50602  And a company good at Marketing.  https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/47172  Good pipeline though. https://github.com/neptune-ml/kaggle-toxic-starter And finally here's my blender:;Apache 2.0;https://www.kaggle.com/jagangupta/lessons-from-toxic-blending-is-the-new-sexy;1.0;['keras', 'h2o'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'nn', 'ml'];['gru', 'regression', 'train', 'model', 'deep learning', 'layer', 'lstm', 'logistic regression', 'classification', 'naive bayes'];https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge;0.746;0.517;2020-12-13 12:20:07;Toxic Comment Classification Challenge;[];Lessons from Toxic : Blending is the new sexy;Python notebook;9305.0;127;;
2018-03-11 11:00:51;Update:The kernal has been updated for the new test and train datasets.;Apache 2.0;https://www.kaggle.com/jagangupta/stop-the-s-toxic-comments-eda;1.0;['vocabulary', 'nltk', 'sklearn', 'spacy', 'pattern'];['ner', 'ai', 'dl', 'gbm', 'gan', 'cv', 'rl', 'ml', 'nlp', 'nn', 'ann'];['filter', 'training data', 'regression', 'test data', 'train', 'fitting', 'model', 'understanding', 'validation data', 'loss', 'label', 'lstm', 'predict', 'recommend', 'classification'];https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge;0.808;0.618;2020-12-13 12:20:06;multiple data sources;['beginner, data visualization, exploratory data analysis, +1 morenlp'];Stop the S@#$ - Toxic Comments EDA;Python notebook;60589.0;615;;
2018-01-28 01:45:40;Improved LSTM baselineThis kernel is a somewhat improved version of Keras - Bidirectional LSTM baseline along with some additional documentation of the steps. (NB: this notebook has been re-run on the new test set.);Apache 2.0;https://www.kaggle.com/jhoward/improved-lstm-baseline-glove-dropout;1.0;['tensorflow', 'keras'];['ner', 'ai', 'nn'];['train', 'model', 'epoch', 'layer', 'loss', 'lstm', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge;0.8;0.583;2020-12-13 12:20:07;multiple data sources;[];Improved LSTM baseline: GloVe + dropout;Python notebook;46436.0;340;0.97665;0.97718
2018-02-03 20:44:11;IntroductionThis kernel shows how to use NBSVM (Naive Bayes - Support Vector Machine) to create a strong baseline for the Toxic Comment Classification Challenge competition. NBSVM was introduced by Sida Wang and Chris Manning in the paper Baselines and Bigrams: Simple, Good Sentiment and Topic Classiﬁcation. In this kernel, we use sklearn's logistic regression, rather than SVM, although in practice the two are nearly identical (sklearn uses the liblinear library behind the scenes). If you're not familiar with naive bayes and bag of words matrices, I've made a preview available of one of fast.ai's upcoming Practical Machine Learning course videos, which introduces this topic. Here is a link to the section of the video which discusses this: Naive Bayes video.;Apache 2.0;https://www.kaggle.com/jhoward/nb-svm-strong-linear-baseline;1.0;['sklearn'];['ai', 'dl', 'rl', 'nn', 'ann'];['machine learning', 'training data', 'regression', 'train', 'model', 'label', 'logistic regression', 'predict', 'classification', 'naive bayes'];https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge;0.831;0.644;2020-12-13 12:20:06;Toxic Comment Classification Challenge;['beginner, nlp, linguistics'];NB-SVM strong linear baseline;Python notebook;138428.0;984;;
2018-04-09 02:28:31;Classifying multi-label comments with Logistic RegressionRhodium BengStarted on 20 December 2017 This kernel is inspired by:  kernel by Jeremy Howard : NB-SVM strong linear baseline + EDA (0.052 lb) kernel by Issac : logistic regression (0.055 lb) Solving Multi-Label Classification problems, https://www.analyticsvidhya.com/blog/2017/08/introduction-to-multi-label-classification/;Apache 2.0;https://www.kaggle.com/rhodiumbeng/classifying-multi-label-comments-0-9741-lb;1.0;['pattern', 'vocabulary', 'sklearn'];['ner', 'ai', 'rl', 'nn', 'ann'];['training data', 'test data', 'regression', 'train', 'model', 'label', 'logistic regression', 'predict', 'classification'];https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge;0.791;0.532;2020-12-13 12:20:07;Toxic Comment Classification Challenge;['classification, nlp, logistic regression, +1 morenaive bayes'];Classifying multi-label comments (0.9741 lb);Python notebook;33698.0;156;;
2018-02-01 08:43:47;"In this kernel, we shall see if pretrained embeddings like Word2Vec, GLOVE and Fasttext, which are pretrained using billions of words could improve our accuracy score as compared to training our own embedding. We will compare the performance of models using these pretrained embeddings against the baseline model that doesn't use any pretrained embeddings in my previous kernel here.  Perhaps it's a good idea to briefly step in the world of word embeddings and see what's the difference between Word2Vec, GLOVE and Fasttext. Embeddings generally represent geometrical encodings of words based on how frequently appear together in a text corpus. Various implementations of word embeddings described below differs in the way as how they are constructed. Word2Vec The main idea behind it is that you train a model on the context on each word, so similar words will have similar numerical representations. Just like a normal feed-forward densely connected neural network(NN) where you have a set of independent variables and a target dependent variable that you are trying to predict, you first break your sentence into words(tokenize) and create a number of pairs of words, depending on the window size. So one of the combination could be a pair of words such as ('cat','purr'), where cat is the independent variable(X) and 'purr' is the target dependent variable(Y) we are aiming to predict. We feed the 'cat' into the NN through an embedding layer initialized with random weights, and pass it through the softmax layer with ultimate aim of predicting 'purr'. The optimization method such as SGD minimize the loss function ""(target word | context words)"" which seeks to minimize the loss of predicting the target words given the context words. If we do this with enough epochs, the weights in the embedding layer would eventually represent the vocabulary of word vectors, which is the ""coordinates"" of the words in this geometric vector space.  The above example assumes the skip-gram model. For the Continuous bag of words(CBOW), we would basically be predicting a word given the context. GLOVE GLOVE works similarly as Word2Vec. While you can see above that Word2Vec is a ""predictive"" model that predicts context given word, GLOVE learns by constructing a co-occurrence matrix (words X context) that basically count how frequently a word appears in a context. Since it's going to be a gigantic matrix, we factorize this matrix to achieve a lower-dimension representation. There's a lot of details that goes in GLOVE but that's the rough idea. FastText FastText is quite different from the above 2 embeddings. While Word2Vec and GLOVE treats each word as the smallest unit to train on, FastText uses n-gram characters as the smallest unit. For example, the word vector ,""apple"", could be broken down into separate word vectors units as ""ap"",""app"",""ple"". The biggest benefit of using FastText is that it generate better word embeddings for rare words, or even words not seen during training because the n-gram character vectors are shared with other words. This is something that Word2Vec and GLOVE cannot achieve.";Apache 2.0;https://www.kaggle.com/sbongo/do-pretrained-embeddings-give-you-the-extra-edge;1.0;['vocabulary', 'tensorflow', 'keras', 'gensim'];['ner', 'ai', 'gan', 'rl', 'ml', 'nn', 'ann'];['training data', 'train', 'fitting', 'model', 'input layer', 'neural network', 'epoch', 'layer', 'loss', 'label', 'lstm', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge;0.8;0.585;2020-12-13 12:20:06;multiple data sources;['beginner, nlp, neural networks'];Do Pretrained Embeddings Give You The Extra Edge?;Python notebook;45180.0;350;;
2018-01-24 09:43:29;This notebook attempts to tackle this classification problem by using Keras LSTM. While there are many notebook out there that are already tackling using this approach, I feel that there isn't enough explanation to what is going on each step. As someone who has been using vanilla Tensorflow, and recently embraced the wonderful world of Keras, I hope to share with fellow beginners the intuition that I gained from my research and study.  Join me as we walk through it.;Apache 2.0;https://www.kaggle.com/sbongo/for-beginners-tackling-toxic-using-keras;1.0;['tensorflow', 'keras'];['ner', 'ai', 'dl', 'cnn', 'rl', 'nn', 'rnn'];['gru', 'train', 'model', 'input layer', 'neural network', 'epoch', 'deep learning', 'layer', 'reward', 'lstm', 'label', 'loss', 'relu', 'classification'];https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge;0.801;0.61;2020-12-13 12:20:06;Toxic Comment Classification Challenge;['beginner, classification, nlp'];[For Beginners] Tackling Toxic Using Keras;Python notebook;47378.0;534;;
2019-05-17 19:20:09;This is the inference kernel for BERT pytorch. Check out the amazing Kernel for finetuning BERT by Yuval: https://www.kaggle.com/yuval6967/toxic-bert-plain-vanila;Apache 2.0;https://www.kaggle.com/abhishek/pytorch-bert-inference;1.0;['pytorch'];['ai', 'nn'];['filter', 'train', 'model', 'layer', 'label', 'predict', 'classification'];https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification;0.772;0.552;2020-12-13 12:22:44;multiple data sources;['gpu, classification'];Pytorch BERT Inference;Python notebook;19082.0;210;;
2019-05-14 14:35:17;Try Using these Amazing kernels https://www.kaggle.com/christofhenkel/how-to-preprocessing-for-glove-part1-eda https://www.kaggle.com/christofhenkel/how-to-preprocessing-for-glove-part2-usage https://www.kaggle.com/nz0722/reasoning-some-text-cleaning-not-work    And avoid this kernel as it Might Have unseen bugs (due to my little NLP Knowledge)  **Sorry.**;Apache 2.0;https://www.kaggle.com/adityaecdrid/public-version-text-cleaning-vocab-65;1.0;['gensim'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nlp', 'nn', 'ann'];['gru', 'generation', 'train', 'recognition', 'model', 'understanding', 'reward', 'layer', 'rectifier', 'loss', 'rank', 'recommend', 'classification'];https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification;0.744;0.53;2020-12-13 12:22:44;multiple data sources;['data cleaning, nlp'];[Public Version] Text Cleaning - Vocab ~65%+;Python notebook;8795.0;152;;
2019-05-12 18:56:31;General informationThis is a basic kernel with CNN. In this kernel I train a CNN model on folds and calculate the competition metric (not simple auc).;Apache 2.0;https://www.kaggle.com/artgor/cnn-in-keras-on-folds;1.0;['lightgbm', 'nltk', 'sklearn', 'tensorflow', 'keras'];['ner', 'ai', 'dl', 'cnn', 'gbm', 'cv', 'rl', 'nn'];['gru', 'filter', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'lstm', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification;0.748;0.512;2020-12-13 12:22:44;multiple data sources;['gpu, beginner, deep learning, +1 moreclassification'];CNN in keras on folds;Python notebook;9908.0;119;0.92373;0.92373
2019-04-24 17:18:12;Update: Following the suggestion by @adityaecdrid and @jackwei (thanks!) I have added a comparison between different implementations of sequence bucketing including the one used in @authmans great kernel and changed the sequence bucketing method used as a result of this.;Apache 2.0;https://www.kaggle.com/bminixhofer/speed-up-your-rnn-with-sequence-bucketing;1.0;['pytorch', 'tensorflow', 'keras', 'pattern'];['ner', 'ai', 'dl', 'gan', 'nn', 'rnn', 'ml'];['machine learning', 'train', 'model', 'neural network', 'epoch', 'validation data', 'loss', 'label', 'lstm', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification;0.761;0.554;2020-12-13 12:22:44;multiple data sources;['gpu, beginner'];Speed up your RNN with Sequence Bucketing;Python notebook;13770.0;218;;
2019-03-29 00:15:26;Load and pre-process the data set;Apache 2.0;https://www.kaggle.com/dborkan/benchmark-kernel;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'ml', 'nn', 'ann'];['test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification;0.765;0.552;2020-12-13 12:22:44;multiple data sources;['gpu'];Benchmark Kernel;Python notebook;15508.0;209;;
2019-06-17 22:51:11;"On 2018, Kaggle launched a competition in association with Jigsaw/Conversation AI to classify toxic comments. The original competition can be viewed here. A toxic comment is a comment that is rude, disrespectful or otherwise likely to make someone leave a discussion. The goal of that competition was to build a multi-headed model that’s capable of detecting different types of of toxicity like threats, obscenity, insults, and identity-based hate. However, the models developed in that competition unfortunately associated the targetted group with toxicity, i.e. ""gay"". For example, a comment like ""I am a gay woman"" would be classified as toxic. This happened as the examples of identities associated with toxicity outnumbered neutral comments regarding the same identity. Therefore, the same team launched a new competition to recognize unintended bias towards identities. We are asked to use a dataset labeled with the associated identity. Let's look into the dataset and understand it first, so we can create a model that can better deal with bias. At the time I started this notebook, I looked at the kernel https://www.kaggle.com/nz0722/simple-eda-text-preprocessing-jigsaw to have a quick start. So I want to take a moment to thank the Author for the kernel. The purpose of this Kernel is to walk Kaggle newbies through the process of data exploration and visualization. In this notebook, we will use Pandas to do a little bit of data wrangling and Plotly and Seaborn to visualize the result of our wrangling.";Apache 2.0;https://www.kaggle.com/ekhtiar/unintended-eda-with-tutorial-notes;1.0;['pattern', 'sklearn', 'nltk', 'gensim'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['train', 'model', 'label', 'understanding', 'classification', 'labeled'];https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification;0.736;0.504;2020-12-13 12:22:44;Jigsaw Unintended Bias in Toxicity Classification;['beginner, data visualization, exploratory data analysis'];Unintended EDA [with Tutorial Notes];Python notebook;7110.0;106;;
2019-05-29 20:26:13;The Quora Insincere Questions Classification spawned several great kernels for more background on word embeddings:  How to: Preprocessing when using embeddings A look at different embeddings.!  In this kernel I'm going to explore the influence of different word embeddings on unintended bias. First, I'm going to benchmark popular word embeddings with the Simple LSTM courtesy of thousandvoices. If you want to skip ahead to the results, click the link for word embeddings comparison. After that I'll introduce operations we can perform on word embeddings and I'll construct a bunch of combinations to benchmark. I'll cover concatenating embeddings and constructing meta embeddings from several different vector spaces. Skip to complete embeddings comparison for the final results. If this helps your model or if you have any ideas for other combinations leave a comment and upvote! I have since added a proper section on BERT embeddings since my initial test scored much lower than expected.    Contents  Without Pretrained Embeddings Fasttext Embeddings GloVe Embeddings Concept Numberbatch Embeddings BERT Embeddings Word Embeddings Comparison Concatenating Fasttext+GloVe Embeddings Weighted Predictions by Bias Score Constructing Meta-Embeddings GloVe+Fasttext Meta-Embeddings Weighted Meta-Embeddings Complete Embeddings Comparison;Apache 2.0;https://www.kaggle.com/nholloway/the-effect-of-word-embeddings-on-bias;1.0;['sklearn', 'mxnet', 'tensorflow', 'spacy', 'vocabulary', 'keras'];['ai', 'cv', 'rl', 'nlp', 'nn', 'ann'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'lstm', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification;0.735;0.509;2020-12-13 12:22:44;multiple data sources;['exploratory data analysis, feature engineering, nlp'];The Effect of Word Embeddings on Bias;Python notebook;7040.0;113;;
2019-05-10 13:47:08;Many thanks to the following kagglers and their great kernels: @Andrew Lukyanenko, https://www.kaggle.com/artgor/toxicity-eda-model-interpretation-and-more @Eike Dehling: https://www.kaggle.com/eikedehling/feature-engineering @Jagan: https://www.kaggle.com/jagangupta/stop-the-s-toxic-comments-eda @Theo Viel: https://www.kaggle.com/theoviel/improve-your-score-with-some-text-preprocessing @Aditya Soni: https://www.kaggle.com/adityaecdrid/public-version-text-cleaning-vocab-65 @Guillaume Martin: https://www.kaggle.com/gemartin/load-data-reduce-memory-usage @Shujian Liu: https://www.kaggle.com/shujian/test-the-difficulty-of-this-classification-tasks Thanks @kotakota1110 for his suggestion in Time Series part.;Apache 2.0;https://www.kaggle.com/nz0722/simple-eda-text-preprocessing-jigsaw;1.0;['nltk', 'gensim'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nn', 'ann'];['train', 'model', 'label', 'classification'];https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification;0.766;0.553;2020-12-13 12:22:44;multiple data sources;['beginner, data visualization, exploratory data analysis, +1 moredata cleaning'];Simple EDA Text Preprocessing - Jigsaw ;Python notebook;16005.0;212;;
2019-03-30 23:14:20;ReferencesI've made use of some great kernels already - check them out and give them an upvote if any of this is useful! Preprocessing https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings  https://www.kaggle.com/theoviel/improve-your-score-with-text-preprocessing-v2   Model Architecture-- https://www.kaggle.com/tunguz/bi-gru-cnn-poolings-gpu-kernel-version Other https://www.kaggle.com/dborkan/benchmark-kernel  https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/discussion/87245;Apache 2.0;https://www.kaggle.com/taindow/simple-cudnngru-python-keras;1.0;['tensorflow', 'sklearn', 'keras', 'gensim'];['ner', 'ai', 'dl', 'cnn', 'gan', 'rl', 'nlp', 'nn', 'ann'];['gru', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'classification'];https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification;0.731;0.505;2020-12-13 12:22:44;multiple data sources;['gpu'];Simple CuDNNGRU [Python + Keras];Python notebook;6316.0;107;0.92529;0.92529
2019-06-26 23:48:42;Thanks for @christofhenkel @abhishek @iezepov for their great work: https://www.kaggle.com/christofhenkel/how-to-preprocessing-for-glove-part2-usage https://www.kaggle.com/abhishek/pytorch-bert-inference https://www.kaggle.com/iezepov/starter-gensim-word-embeddings;Apache 2.0;https://www.kaggle.com/timon88/bert-lstm-simple-blender-0-93844-lb;1.0;['nltk', 'gensim', 'pytorch', 'tensorflow', 'keras'];['ner', 'ai', 'dl', 'rl', 'nn'];['filter', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'lstm', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification;0.744;0.501;2020-12-13 12:22:44;multiple data sources;['gpu'];BERT + LSTM (simple blender) - 0.93844 LB;Python notebook;8698.0;102;0.93849;0.00000
2019-11-28 14:53:43;Kaggle ML & DS SurveyEvery year we have a Machine Learning and Data Science Survey from Kaggle. Well, this is the third time :) In this kernel I wanted to do some analysis which would be interesting to me and so I have decided to have a look at the russian kagglers (as I'm russian myself). I'll show how our characteristics changed (or not changed) over time and what is interesting about us. Let's assume that the survery is representative and allows to make conclusions. For some features it is possible to compare data in different years, but for others either there is no such data or the data is in very different formats. Let's start.;Apache 2.0;https://www.kaggle.com/artgor/a-look-at-russian-kagglers-over-time;1.0;['xgboost', 'lightgbm', 'catboost', 'sklearn', 'pytorch', 'albumentations', 'tensorflow', 'keras', 'tpot'];['ner', 'ai', 'dl', 'automl', 'gbm', 'gan', 'rl', 'nlp', 'nn', 'ml'];['rank', 'filter', 'model', 'machine learning'];https://www.kaggle.com/c/kaggle-survey-2019;0.713;0.505;2020-12-13 12:25:09;multiple data sources;['beginner, data visualization, exploratory data analysis'];A look at russian kagglers over time;Python notebook;4093.0;108;;
2019-12-02 20:31:22;Deep Dive into Science: Exploring PhD Community with Network AnalysisThis notebook was prepared by Ekaterina Melianova and Artem Volgin;Apache 2.0;https://www.kaggle.com/artvolgin/exploring-phd-community-with-network-analysis;1.0;['pattern', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'automl', 'cv', 'rl', 'ml', 'nlp', 'nn', 'ann'];['filter', 'recurrent neural network', 'natural language processing', 'machine learning', 'train', 'clustering', 'generative adversarial network', 'model', 'neural network', 'layer', 'loss', 'rank', 'understanding', 'bayesian', 'automated machine learnin', 'generation', 'deep learning', 'label', 'computer vision', 'natural language', 'convolutional neural network'];https://www.kaggle.com/c/kaggle-survey-2019;0.722;0.468;2020-12-13 12:25:10;multiple data sources;['beginner'];Exploring PhD Community with Network Analysis;Python notebook;5038.0;66;;
2020-12-07 20:38:52;Kaggle: A Community About Learning and Sharing KnowledgeIn this notebook I want to explore what the current trends in Data Science are and what we can learn from experienced Machine Learning practitioners. For this, I will also incorporate the Meta-Kaggle dataset and the Chai Time Data Science dataset. This year has been eventful to say the least. Let's explore the Kaggle survey data and find out what the current trends in Data Science are:  Did PyTorch exceed TensorFlow/Keras in popularity? Do students have to invest in expensive GPUs for their projects or are there any affordable alternatives available?  TPUs are now available in Kaggle kernels but how popular are they? GPT-3 received a lot of media attention this year. How familiar are Kagglers with NLP? Did you notice the Julia option for Kaggle kernels? What is Julia and is it going to replace Python and R?;Apache 2.0;https://www.kaggle.com/iamleonie/trends-in-2020-with-advice-from-top-kagglers;1.0;['xgboost', 'lightgbm', 'sklearn', 'pytorch', 'tensorflow', 'spacy', 'keras'];['ner', 'ai', 'dl', 'cnn', 'gbm', 'gan', 'rl', 'ml', 'nlp', 'nn', 'rnn', 'ann'];['linear regression', 'machine learning', 'filter', 'regression', 'train', 'model', 'neural network', 'deep learning', 'natural language processing', 'computer vision', 'label', 'predict', 'rank', 'decision tree', 'resnet', 'recommend', 'natural language', 'bayesian'];https://www.kaggle.com/c/kaggle-survey-2019;0.663;0.453;2020-12-13 12:25:10;multiple data sources;['data visualization, exploratory data analysis, deep learning, +1 moresurvey analysis'];Trends in 2020 with Advice from Top Kagglers;Python notebook;1411.0;55;;
2019-12-02 14:41:36;This year I transitioned from being an aspiring  Data Scientist(a student) to an actual one. When I was preparing to enter this field ,I had a lot of questions about Data Scientists. Like, What do they look like? Where do they come from? 😂😂 Just kidding.;Apache 2.0;https://www.kaggle.com/ibtesama/a-guide-for-aspiring-data-scientists;1.0;['pattern', 'xgboost', 'lightgbm'];['ner', 'ai', 'cnn', 'gbm', 'gan', 'cv', 'rl', 'nlp', 'nn', 'rnn', 'ml'];['filter', 'recurrent neural network', 'machine translation', 'vgg', 'logistic regression', 'predict', 'sentiment analysis', 'machine learning', 'object detection', 'train', 'reinforcement learning', 'text classification', 'clustering', 'recommend', 'generative adversarial network', 'classification', 'image classification', 'model', 'neural network', 'decision tree', 'understanding', 'resnet', 'bayesian', 'image segmentation', 'chatbot', 'regression', 'automated machine learnin', 'generation', 'deep learning', 'label', 'gradient boosting', 'computer vision', 'random forest', 'natural language', 'convolutional neural network'];https://www.kaggle.com/c/kaggle-survey-2019;0.724;0.516;2020-12-13 12:25:09;2019 Kaggle Machine Learning & Data Science Survey;['beginner, data visualization, exploratory data analysis, +1 moresurvey analysis'];A guide for aspiring Data Scientists;Python notebook;5327.0;125;;
2019-12-25 19:23:55;Finally, we have the Kaggle Survey 2019 dataset! This is the third edition of the survey conducted among the users of our favorite portal on various topics related to machine learning and data science.;Apache 2.0;https://www.kaggle.com/michau96/kagglers-continent-battle-2019;1.0;['xgboost'];['ner', 'ai', 'dl', 'cnn', 'gan', 'rl', 'ml', 'nn', 'rnn', 'ann'];['recommend', 'filter', 'machine learning', 'regression', 'recurrent neural network', 'generative adversarial network', 'model', 'neural network', 'deep learning', 'artificial neural network', 'label', 'random forest', 'rank', 'decision tree', 'classification', 'convolutional neural network', 'bayesian'];https://www.kaggle.com/c/kaggle-survey-2019;0.71;0.508;2020-12-13 12:25:09;2019 Kaggle Machine Learning & Data Science Survey;['beginner, data visualization, exploratory data analysis, +1 moresurvey analysis'];Kagglers Continent Battle 2019 🌍;R notebook;3857.0;112;;
2019-12-02 07:35:50;"An analysis of the 2019 Kaggle ML and DS Survey for Women's Representation in Machine Learning and Data Science Pic Credits:rawpixel.com / Freepik Women in tech didn't matter to people until tech started mattering to people: Rachel Sklar  In the last few years, a lot of effort has being made in society to increase women's representation in the tech world. The idea behind these efforts is that attracting and retaining more women in science, technology, engineering, and mathematics (STEM) will ultimately enhance innovation and creativity. When women are not involved in these fields, experiences, needs, and desires that are unique to women may be overlooked. It is not that there aren't any female role models out there to inspire us. Do you remember the iconic photograph of Katie Bouman in 2019, watching the black hole's first photograph as it was being reconstructed? Not only was it a breakthrough moment for the scientific community, but an equally proud one for all the women scientists all over the world. A historic moment not just for science, but for women in science, too.  Similarly, women have also been making significant contributions to the fields of Machine Learning and Data Science. Be it Margaret Hamilton or Grace Hopper in the past or Corinna Cortes and Fei Fei Li today; women have made their presence felt with their work. More and more girls are being motivated to take up science and research in school and colleges. A lot of companies today are coming forward to change the world of work. This year, even the United Nations celebrated International Women's Day under the official theme #BalanceforBetter, advocating a more gender-balanced world. However, as it may seem, not everything is still so ""gung-ho"" when it comes to women's representation is the Data Science field. The ratios are still skewed, and women still occupy far fewer leadership roles than men. But let's not just assume things but rather use data to verify our assumptions, and the 2019 Kaggle ML & DS survey is an excellent place to start. Let the numbers speak for themselves. ObjectiveThe objective of this notebook to analyze the survey data to answer an important question: is the women participation in STEM really improving, or is it just a hype? Let's use our analysis skills to investigate whether things seem to be actually improving or is still much left to be done. The Annual Kaggle surveyKaggle's annual Machine Learning and Data Science Survey is in its third year now. This year, as in 2017 and 2018, Kaggle has conducted an industry-wide survey that presents a comprehensive view of the state of data science and machine learning. The Survey Challenges from 2017 and 2018 were very informative, and so is expected out of the 2019 survey too. MethodologyThis notebook will only focus on the women in ML and DS, thereby analyzing the answers of the female respondents solely. The analysis will be two-fold:  Analysis of the 2019 Kaggle DS & ML survey for Female respondents. Comparisons of the results in the 2019 study with the previous two surveys. This will present a better picture and show whether are things are improving for real or not.  In this notebook, we shall analyze the female participation in the survey under six different categories, namely:  Analyzing data under these different categories should give us a fair idea of the nature of women's representation is the ML and DS realm.";Apache 2.0;https://www.kaggle.com/parulpandey/geek-girls-rising-myth-or-reality;1.0;['pattern'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'generation', 'model', 'natural language processing', 'label', 'recommend', 'natural language'];https://www.kaggle.com/c/kaggle-survey-2019;0.774;0.591;2020-12-13 12:25:09;multiple data sources;['data visualization, exploratory data analysis, survey analysis'];Geek Girls Rising : Myth or Reality!;Python notebook;20103.0;384;;
2020-07-05 21:57:52;A deep learning of Deep Learning Pic Credits: Getty Deep Learning (DL) is progressing by leaps and bounds at a phenomenally fast pace with so much new research, papers, ideas, models being developed throughout the world. The last few years have seen a lot of solutions being built using deep learning methods and frameworks and this is expected to only increase in the future. This notebook analyses the deep learning practitioners from the 2019 Kaggle ML & DS Survey to understand patterns, get insights, learn challenges and maybe even answer some questions regarding the current and future landscape of deep learning:  Who are these deep learning practitioners? Are they concentrated in a certain geography or age or background? Are deep learning practitioners very different from other machine learning practitioners? Do they have a different career path or have different salaries? Does deep learning require a lot of money and resources? Are the tools, products and languages used very different requiring special skills? What does the future of deep learning hold for us? Will it significantly change industries or even modeling and solutioning methods?     ...and many more. P.S.: The insights shared in this notebook are based on the 2019 Kaggle Survey data only and not all of them necessarily would be similar in the real world.;Apache 2.0;https://www.kaggle.com/rohanrao/a-deep-learning-of-deep-learning;1.0;['pattern', 'xgboost', 'lightgbm'];['ner', 'ai', 'dl', 'automl', 'cnn', 'gbm', 'gan', 'cv', 'rl', 'ml', 'nlp', 'nn', 'rnn', 'ann'];['recurrent neural network', 'logistic regression', 'machine learning', 'object detection', 'train', 'generative adversarial network', 'classification', 'image classification', 'model', 'neural network', 'understanding', 'decision tree', 'bayesian', 'image segmentation', 'regression', 'generation', 'deep learning', 'label', 'gradient boosting', 'computer vision', 'random forest', 'convolutional neural network'];https://www.kaggle.com/c/kaggle-survey-2019;0.72;0.47;2020-12-13 12:25:10;multiple data sources;['data visualization, exploratory data analysis, survey analysis'];A deep learning of Deep Learning;Python notebook;4794.0;68;;
2019-12-02 16:05:44;"Is Spending $$$ for MS in Data Science worth it ? A detailed comparative analysis of people with and without university degrees for data science  2019 was an important year for me, Not only I got engaged this year but also I completed my higher education degree. After working for several years in the industry I decided to take a short break, go back to academics and pursue higher education. No doubt, it was one of the best learning experiences I had but there was also a huge investment of time and money. Many people often contact me regularly asking about my experience and viewpoint about such degrees. They ask questions like - whether is it worth spending huge chunks of money for such degrees? Well, there is no fixed answer for such questions because every individual have a different viewpoint and their opinion might be biased. The best way to answer this question is to make use of data, analyse the cohorts of people (example - data scientists) who are well settled in the industry, measure and compare if there are any significant differences in their roles, position, responsibilities, and annual compensation. This type of analysis can provide many interesting insights and help in looking at the broader view of the scenario. In this notebook, I decided to take a stab at this scenario and have shared my experience along with the key insights and a detailed analysis of Kaggle's annual data science survey data.   Source: UpslashThere are one set of people who wants to pursue higher education degrees due to their passion and interest. For these people, it makes sense to get enrol in the relevant university courses and pursue their passion. On the other hand, there is another set of people, who wants to obtain these degrees only to get a specific job title, a specific job role, or a position that get them more money. For this set, university degrees are not the only option, there are many alternatives which can also result in the same outcomes. The most obvious example is in the field of Data Science and Analytics. In recent years, university degrees such as ""Masters in Data Science"" or ""Masters in Analytics"" are sought as one of the must-haves to enter into this field. It is not astonishing that Data Scientist is one of the fastest-growing job titles across the globe and the demand for skilled data scientists is increasing. This has given the universities an option to attract students and make immense money. Several universities have started dedicated degree courses specialized in data science and analytics. Those want to become a data scientist or to switch from another profession to data science profession are now strongly considering these university degrees as the only pathway. But these university courses are not easy to get in and affordable for everyone. These degrees don’t come for free, tuition fees can be exorbitant and can range anything from USD 30,000 to USD 100,000. And that doesn’t include the actual cost of living. Many consider applying for student loans but they add a huge lump sum to the existing mountain of debts. A common myth is that the earning potential for those with postgraduate qualifications is higher but of course, there is no guarantee that one will get a stable job at the end of it. Additionally, Pursuing a university’s higher degree takes anything from one to three years, depending on different factors. This can seem like a long time, especially when the fellow peers are getting started on their careers, while one is still studying. The question of interest here is -  does one need to get that expensive higher education degree, do they create a difference from those who do not have university degrees?. Some resources online also suggest that one can get the depth of knowledge, variety of skills and learn something new. But again, is it possible to get the same skills, same profile, or even better compensation without such degrees?.  Kaggle conducted their Annual Data Science survey and it was full of interesting questions. Participants of this survey were asked different questions about their demographics, profiles, companies, what they use etc. I analysed this data intending to dig deeper into the profiles of people who completed the university degrees to learn data science and those who did not. The focus of the story in this notebook is to identify if the working data scientists with official higher education degrees differ significantly from the other group. The analysis and storyline are segmented according to different factors. Note - For the analysis, I removed the respondents who were ""students"" and ""not employed"". The two groups were selected based on the respondent's choice if they completed the university degrees to learn data science or not. Contents 1. Sources of Learning Data Science     - Why People Choose Higher Education Degrees     - The Academic Landscape : Masters in Data Science Degrees 2. Proportion of Individuals with University Degrees 3. Are there a Significant Differences - With and Without University Degrees ?     3.1 Compensation         - Key Characteristics : Data Scientists earning > USD 150K     3.2 Job Roles     3.3 Job Profiles         - Other Tools : Usage and Comparison 4. Identifying Key Traits 5. Conclusions 6. References  1. Sources of Learning Data Science Data science skills are straightforward to obtain, they need experience and learning. Nowadays there are many online and offline which teaches them in detail. While some prefer online courses such as Coursera or Udacity, some prefer to go to universities for a year or two-year long dedicated courses. Let's look at what are the most popular sources of learning data science among the respondents of the kaggle survey. In this question, one participant could have chosen multiple choices, hence the x-axis represents ""percentage"" of respondents who selected a particular choice.";Apache 2.0;https://www.kaggle.com/shivamb/spending-for-ms-in-data-science-worth-it;1.0;['xgboost', 'lightgbm', 'sklearn', 'pytorch', 'tensorflow', 'pattern', 'keras'];['ner', 'ai', 'dl', 'gbm', 'gan', 'rl', 'ml', 'nn', 'ann'];['filter', 'recurrent neural network', 'reward', 'logistic regression', 'predict', 'machine learning', 'train', 'recommend', 'generative adversarial network', 'propagation', 'model', 'neural network', 'layer', 'rank', 'decision tree', 'bayesian', 'regression', 'deep learning', 'label', 'gradient boosting', 'random forest', 'convolutional neural network'];https://www.kaggle.com/c/kaggle-survey-2019;0.776;0.575;2020-12-13 12:25:09;2019 Kaggle Machine Learning & Data Science Survey;['data visualization, survey analysis'];Spending $$$ for MS in Data Science -  Worth it ? ;Python notebook;21625.0;301;;
2019-12-02 04:33:58;Introduction : ⚜️ The Hitchhiker's Guide to the Kaggle GalaxyRoad to Kaggle Grandmaster!!  Hi, I'm a semi-newbie who loves kaggle :) First, I would like to thank the Kaggle team and the Kagglers for conducting this survey. I am happy to be able to analyze these data. I've been preparing for an algorithm competition (such as ICPC) for about three years, and it's been about a year since I entered the DS/ML field. I love the sharing culture of AI, so I have some community managers in Korea, and I have a Facebook page.  My Facebook Page Background, made by me :)  I'm going to analyze / visualize what I'd be curious about as a newbie Kaggler. I am analyzing what I was wondering about, what frameworks are some people doing, and what frameworks are they using? I'm not as good at English as a native speaker. Therefore, I will replace some of the articles with highly readable visualizations. Invites you to a world of interactive and unusual visualizations. Please enjoy my kernel!!  img from https://giphy.com/gifs/friends-nick-at-nite-xT0BKiK5sOCVdBUhiM   Table of Contents Simple Distribution (Age, Gender, Country) Age & Gender Gender & Country Thinking About Gender imbalance     Which Algorithm Is Most Popular? How About Machine Learning Frameworks & Tools? Correlation between Algorithm & Tools Relationship between structured data and unstructured data   How About Popularity of Kaggler's Programming Language? What is the relationship between ML Career and Language recommendations? What is the relationship between Programming Career and Language recommendations? Personal thoughts about the visualization library my experience & introduce visualization library   What kind of DB do people use?  How about Kaggler's development environment like? IDE Notebook   What kind of Jobs do Kagglers have? What is their educational background? Jobs & Education Jobs & Language Jobs & ML Framework   Is salary high depending on career? How about educational background? Career & Salary Education & Salary   How about Gender, Age, Country & Salary? Age & Salary Gender & Salary Gender wage inequality   Country & Salary   Where is the Best Source to study machine learning? Favorite Source Best Source   Who paid a lot? Gender & Spending Age & Spending;Apache 2.0;https://www.kaggle.com/subinium/the-hitchhiker-s-guide-to-the-kaggle;1.0;['autosklearn', 'xgboost', 'lightgbm', 'catboost', 'sklearn', 'pytorch', 'albumentations', 'tensorflow', 'pattern', 'keras', 'tpot'];['ner', 'ai', 'automl', 'cnn', 'gbm', 'gan', 'cv', 'rl', 'ml', 'nlp', 'nn', 'ann'];['recurrent neural network', 'reward', 'natural language processing', 'logistic regression', 'machine learning', 'recommend', 'generative adversarial network', 'model', 'neural network', 'rank', 'decision tree', 'bayesian', 'regression', 'automated machine learnin', 'deep learning', 'label', 'gradient boosting', 'computer vision', 'random forest', 'natural language', 'convolutional neural network'];https://www.kaggle.com/c/kaggle-survey-2019;0.74;0.534;2020-12-13 12:25:09;2019 Kaggle Machine Learning & Data Science Survey;['data visualization, exploratory data analysis, survey analysis'];⚜️ The Hitchhiker's Guide to the Kaggle;Python notebook;8042.0;162;;
2019-12-23 23:27:40;Data Science New Migration Profession in 2019  Everyone wants a better job, in a better company and in a better place      Data Science is the most wished and wanted profession in 2019. For the past few years most of the specialists like Data Analysts, BI developers, Statisticians, Mathematicians, Technical Engineers are pursuing new profession and learning hard Data Science and Machine Learning. One of the best battlefield for learning and practicing DS and ML is KAGGLE, an easy to use platform with web-based environment.     Data Scientist is the new migration profession. Professionals from all over the world are looking for better paid jobs in better companies and located in best countries, which will offer a better life for them and their families. People are inspired by Kaggle grand masters and their career paths, learning new ML and DS techniques.    In this story we will analyze the Kaggle Survey from 3 points:   Money: salary, spending, etc.   Knowledge: programming languages, libraries, algorithms, etc.   Destination: countries, platforms, courses etc.   Let’s try to analyze each chapter of our story, interact with data and make your own conclusions.    Chapter 1 | Follow the Money     Salary is the biggest motivator in learning and pursuing a new profession. One of the sexiest professions nowadays is the Data Scientist or any related to Machine Learning. Kaggle offer us the possibility to have a combination of skills and being famous in the world and wanted by head-hunters. One of my friends told me somehow that his dream is to become a competition Grandmaster and his next step will be deleting his entire resume and just write just 3 words in the middle “Kaggle Competition Grandmaster”.   But enough lyrics, let’s start our journey by discovering new insights in the data.   All charts are highly interactive and you can filter by clicking on charts and drill down to expected level.;Apache 2.0;https://www.kaggle.com/zinovadr/data-scientist-the-new-migration-profession-2019;1.0;['h2o'];['ner', 'ai', 'dl', 'rl', 'nn', 'ml'];['rank', 'filter', 'machine learning', 'predict'];https://www.kaggle.com/c/kaggle-survey-2019;0.691;0.465;2020-12-13 12:25:10;multiple data sources;[];Data Scientist the new Migration Profession - 2019;Python notebook;2503.0;64;;
2019-11-04 13:23:59;Introduction  In this kernel we will be exploring different model architectures, their performance (against one another) and create an ensembled submission of all of our models and submit it to the Leaderboard. I've picked 4 of my best performing models so far for this kernel, everything coded up using the fast.ai library and PyTorch. And... Please don't forget to smash that UPVOTE button.  So lets jump right into it...  What are we doing in this kernel? 1. Getting Started  2. Loading Data + EDA  3. Data Processing  4. Defining our Models  5. Training and Inference  6. Comparing Model Performances  7. Creating Average Ensembled Submission;Apache 2.0;https://www.kaggle.com/abhinand05/k-mnist-ensemble-of-4-models-lb-0-985-starterkit;1.0;['pytorch', 'caffe'];['ner', 'ai', 'dl', 'cnn', 'nn', 'ann'];['train', 'model', 'output layer', 'understanding', 'neural network', 'epoch', 'layer', 'vgg', 'loss', 'label', 'alexnet', 'predict', 'computer vision', 'recommend', 'resnet', 'relu', 'convolutional neural network'];https://www.kaggle.com/c/Kannada-MNIST;0.634;0.435;2020-12-13 12:26:21;multiple data sources;['data visualization, exploratory data analysis, deep learning, +1 moreneural networks'];K-MNIST: Ensemble of 4 Models LB 0.985+ StarterKit;Python notebook;814.0;44;0.98340;0.98160
2020-01-08 13:26:46;A Simple CNN Tutorial with App.Benan AKCA    INTRODUCTION  CONVOLUTIONAL NEURAL NETWORKS  Convolution Layer Steps of Convolution Operation Stride An Example of Convolution Operation Why Do We Use Filters?    Padding Why do we use Padding? Equation of Calculating Output Dimension Types of Padding in Keras   Pooling Layer Hyper Parameters of Pooling Operation Why do we use Pooling? Types of Pooling in Keras   Batch Normalization Layer Drop Out Layer   APPLICATION WITH CNN  Import Modules Understanding the Data Data Preprocessing Normalizing the Data Train and Test Splitting Reshape Data to Appropriate Sizes    Building and Training a CNN Model  Model - Build Model - Compile Categorical Cross Entropy Optimizer On-the-Fly Data Augmentation   Model - Fit   Evaluation of the Model  Accuracy and Loss Curves *  Test Set Accuracy Score Confusion Matrix F1 Score Calculation Evaluate with Another Dataset Submit for Competition     CONCLUSION;Apache 2.0;https://www.kaggle.com/benanakca/kannada-mnist-cnn-tutorial-with-app-top-2;1.0;['pattern', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cnn', 'rl', 'ml', 'nn', 'ann'];['filter', 'recognition', 'natural language processing', 'artificial neural network', 'predict', 'relu', 'ground truth', 'neuron', 'train', 'epoch', 'activation function', 'recommend', 'classification', 'propagation', 'image classification', 'model', 'neural network', 'layer', 'loss', 'hidden layer', 'understanding', 'fitting', 'deep learning', 'gradient descent', 'label', 'computer vision', 'natural language', 'convolutional neural network'];https://www.kaggle.com/c/Kannada-MNIST;0.74;0.496;2020-12-13 12:26:21;Kannada MNIST;['beginner, deep learning, cnn'];Kannada MNIST:CNN Tutorial with App.(Top %2);Python notebook;7922.0;95;;
2020-01-03 01:04:12;Kannada MNIST CNNKannada is a language spoken predominantly by people of Karnataka in southwestern India. The language has roughly 45 million native speakers and is written using the Kannada script. The goal of this competition is to use Machine Learning to correctly label hand-written digits written in the Kannada script. The Kannada dataset format is based on the dataset used in the original MNIST dataset where the objective was the same but the hand-written digits were in Arabic numerals. If you find this code helpful please upvote;Apache 2.0;https://www.kaggle.com/datahobbit/cnn-for-digit-recognition-in-the-kannada-script;1.0;['tensorflow', 'sklearn', 'keras', 'theano'];['ner', 'ai', 'dl', 'cnn', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'test data', 'train', 'fitting', 'model', 'recognition', 'output layer', 'neural network', 'epoch', 'validation data', 'layer', 'loss', 'label', 'predict', 'relu', 'convolutional neural network'];https://www.kaggle.com/c/Kannada-MNIST;0.693;0.431;2020-12-13 12:26:21;Kannada MNIST;['data visualization, deep learning, classification, +1 morecnn'];CNN for Digit Recognition in the Kannada script ;Python notebook;2619.0;42;;
2020-11-30 09:17:23;# TensorFlow 2 Tutorial: Get Started in Deep Learning With tf.keras   I hope you find this kernel useful and your UPVOTES would be highly appreciated Credit: Jason Brownlee: Original Tutorial;Apache 2.0;https://www.kaggle.com/faressayah/tensorflow-2-tutorial-get-started-in-deep-learning;1.0;['theano', 'sklearn', 'tensorflow', 'pattern', 'keras'];['ner', 'ai', 'cnn', 'rl', 'ml', 'nn', 'rnn', 'ann'];['recurrent neural network', 'recognition', 'input layer', 'natural language processing', 'predict', 'relu', 'machine learning', 'training data', 'train', 'epoch', 'lstm', 'activation function', 'recommend', 'classification', 'propagation', 'image classification', 'model', 'neural network', 'layer', 'loss', 'hidden layer', 'understanding', 'supervised learning', 'speech recognition', 'test data', 'regression', 'fitting', 'output layer', 'validation data', 'deep learning', 'gradient descent', 'label', 'natural language', 'convolutional neural network'];https://www.kaggle.com/c/Kannada-MNIST;0.694;0.411;2020-12-13 12:26:21;multiple data sources;['beginner, deep learning'];TensorFlow 2 Tutorial Get Started in Deep Learning;Python notebook;2695.0;33;;
2019-09-22 21:15:29;Manifold mixupHere I implement the idea from the paper Manifold Mixup: Better Representations by Interpolating Hidden States. It is a new regularization method which allows for training very deep and wide neural networks with much less overfitting. This notebook is a simple PyTorch implementation of CNN with manifold mixup. This is not precise implementation of the paper. Input mixupIt's easier to first understand what is input mixup: mixup: BEYOND EMPIRICAL RISK MINIMIZATION. Input mixup is a regularization done during training procedure. Here is the piece of PyTorch code from the paper: # y1, y2 should be one-hot vectors for(x1, y1), (x2, y2)in zip(loader1, loader2):     lam = numpy.random.beta(alpha, alpha)     x = Variable(lam*x1 + (1. - lam)*x2)     y = Variable(lam*y1 + (1. - lam)*y2)     optimizer.zero_grad()     loss(net(x), y).backward()     optimizer.step() In short: model is given a linear combination of inputs and is asked to return linear combination of outputs. It forces the network to interpolate between samples. Manifold mixupManifold mixup is a similar idea, but the interpolation is done at a random layer inside neural network. Sometimes it is the 0'th layer, which means input mixup. It forces the network to interpolate between hidden representations of samples.;Apache 2.0;https://www.kaggle.com/hocop1/manifold-mixup-using-pytorch;1.0;['pytorch', 'sklearn'];['ner', 'ai', 'cnn', 'nn', 'ann'];['training data', 'test data', 'train', 'fitting', 'model', 'neural network', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/Kannada-MNIST;0.693;0.413;2020-12-13 12:26:21;Kannada MNIST;['gpu, classification, cnn, +1 moreresearch'];Manifold mixup using PyTorch;Python notebook;2649.0;34;0.98880;0.98740
2019-09-29 14:39:55;Define required constantsImage size is 28*28 as per the MNIST standards and images are grayscale, so number of channels is 1.;Apache 2.0;https://www.kaggle.com/kaushal2896/kannada-mnist-using-cnn;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cnn', 'ml', 'nn', 'ann'];['filter', 'training data', 'train', 'fitting', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/Kannada-MNIST;0.638;0.375;2020-12-13 12:26:21;Kannada MNIST;['beginner, deep learning, classification'];Kannada MNIST using CNN;Python notebook;875.0;22;;
2019-11-07 19:41:04;Understanding CNNs with Kannada-MNISTImportsThese are the imports we need to get started with machine leraning  Pandas - Used for handling csv data MatPlotLib - Used for plotting graphs Keras - A popular deep learning library we will use to create our CNN SKLearn - Popular machine learning library we will use to split our data;Apache 2.0;https://www.kaggle.com/kenanajk/understanding-cnns-with-kannada-mnist;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cnn', 'rl', 'nn', 'ann'];['filter', 'input layer', 'predict', 'relu', 'machine learning', 'neuron', 'train', 'epoch', 'model', 'neural network', 'layer', 'loss', 'hidden layer', 'understanding', 'fitting', 'output layer', 'deep learning', 'label', 'convolutional neural network'];https://www.kaggle.com/c/Kannada-MNIST;0.709;0.444;2020-12-13 12:26:21;Kannada MNIST;['beginner, deep learning, classification'];Understanding CNNs with Kannada-MNIST;Python notebook;3718.0;49;0.98940;0.98880
2019-10-09 01:55:11;Machine Learning on Kannada MNIST   Kannada is a language spoken predominantly by people of Karnataka in southwestern India. The language has roughly 45 million native speakers and is written using the Kannada script. </div>  I hope this kernel helpful and some UPVOTES would be very much appreciated;Apache 2.0;https://www.kaggle.com/marcovasquez/basic-ml-logistic-dt-pca-xgboost;1.0;['pytorch', 'xgboost', 'sklearn', 'keras'];['ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['machine learning', 'training data', 'regression', 'test data', 'train', 'fitting', 'model', 'supervised learning', 'clustering', 'label', 'logistic regression', 'predict', 'unsupervised learning', 'decision tree', 'classification'];https://www.kaggle.com/c/Kannada-MNIST;0.693;0.467;2020-12-13 12:26:21;Kannada MNIST;[];Basic ML 🔢 Logistic, DT, PCA, XGBOOST;Python notebook;2615.0;65;;
2020-02-27 12:17:33;"Getting started with Dimensionality Reduction Techniques in PythonA 3 part serieson Dimensionality reduction techniques using the Kannada MNIST dataset  Key Objectives: In this series of notebooks, we shall study about three Dimensionality reduction techniques using the Kannada MNIST dataset. The techniques are PCA, t-SNE and UMAP. Part 1: Visualizing Kannada MNIST with PCA Part 2: Visualizing Kannada MNIST with t-SNE Part 3: Visualizing Kannada MNIST with UMAP  What is Dimensionality Reduction  A lot of Machine Learning problems consists of hundreds to thousands of features. having such a large number of features poses certain problems mainly :  Slows down the training process It becomes hard to find a good solution   This problem is also sometimes termed as The Curse of Dimensionality and Dimensionality Reduction or Dimension reduction is the process of reducing the number of random variables under consideration by obtaining a set of principal variables[1]. In other words, the goal is to take something that is very high dimensional and get it down to something that is easier to work with, without losing much of the information. Importance of Dimensionality Reduction : Getting down to two or three features can help us visualize our data which is an important part of data analysis Often a lot of dimensionality in the data is redundant and we can get rid of that that can be sueful for the machine learning process. Reducing the dimensionality can also help us in visualising the data easily.  For instance, the famous MNIST dataset is 784 dimensional when we unfold those digits into long vectors and we shouldn't really need 784 dimensions to describe a datapoint in this dataset. There should be some compact representation of this dataset and we should still be able to get some meaninful result.  Main Approaches for Dimensionality Reduction  There are two main approaches to reducing dimensionality: Projection and Manifold Learning.  Projection : This technique deals with projecting every data point which is in high dimension,  onto a subspace suitable lower-dimensional space in a way which approximately preserves the distances between the points[2]. For instance the figure below, the points in 3D are projected onto a 2D plane. This is a lower-dimensional (2D) subspace of the high-dimensional (3D) space and the axes correspond to new features z1 and z2 (the coordinates of the projections on the plane).   Source : [Beginners Guide To Learn Dimension Reduction Techniques(https://www.analyticsvidhya.com/blog/2015/07/dimension-reduction-methods/) Keep in mind that projection may not always be the best method to achieve dimensional reduction.  Manifold Learning : Manifold learning is an approach to non-linear dimensionality reduction. Algorithms for this task are based on the idea that the dimensionality of many data sets is only artificially high.   Jake VanderPlas explains Manifold Learning in a very intuitive way in his book :Python Data Science handbook and here is an excerpt from the book itself; ""manifold learning—a class of unsupervised estimators that seeks to describe datasets as low-dimensional manifolds embedded in high-dimensional spaces. When you think of a manifold, I'd suggest imagining a sheet of paper: this is a two-dimensional object that lives in our familiar three-dimensional world, and can be bent or rolled in that two dimensions. In the parlance of manifold learning, we can think of this sheet as a two-dimensional manifold embedded in three-dimensional space. Rotating, re-orienting, or stretching the piece of paper in three-dimensional space doesn't change the flat geometry of the paper: such operations are akin to linear embeddings. If you bend, curl, or crumple the paper, it is still a two-dimensional manifold, but the embedding into the three-dimensional space is no longer linear. Manifold learning algorithms would seek to learn about the fundamental two-dimensional nature of the paper, even as it is contorted to fill the three-dimensional space.""  Part1: Principal Component Analysis(PCA) in Python  PCA is a very common technique for dimensionality reduction. The idea behind it is very simple:  Identify a Hyperplane that lies closest to the data Project the data onto the hyperplane.   Projecting 2D-data to a line (PCA However, it is important to choose the right hyperplane so that when the data is projected onto it, it the maximum amount of variation or information about how the original data is distributed. In other words, the axis that minimizes the mean squared distance between the original dataset and its projection onto that axis. Principal ComponentsThe axis that explains the maximum amount of variance int he training set is called the principal components. The axis othogonal to this axis is called the second principal component. Thus in 2D, there will be 2 principal components. However, for a higher dimensions, PCA would find a third component orthogonal to the other two components and so on.  Source : A Layman’s Introduction to Principal Components Implementing PCA using Scikit LearnScikit-Learn’s PCA class implements PCA using SVD decomposition. Let's apply PCA on Kannada MNIST data set for visualization. 1. PCA for VisualisationAn effective way to visualize high-dimensional data is to represent each data object by a two-dimensional point in such a way that similar objects are represented by nearby points, and that dissimilar objects are represented by distant points. The resulting two-dimensional points can be visualized in a scatter plot. This leads to a map of the data that reveals the underlying structure of the objects, such as the presence of clusters.Let's see how we can use PCA to do that.";Apache 2.0;https://www.kaggle.com/parulpandey/part1-visualizing-kannada-mnist-with-pca;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'rl', 'nn', 'ann'];['filter', 'machine learning', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/Kannada-MNIST;0.695;0.4;2020-12-13 12:26:21;Kannada MNIST;['beginner, data visualization'];Visualizing Kannada MNIST with PCA;Python notebook;2751.0;29;;
2020-05-18 13:29:24;Visualizing Kannada MNIST with t-SNEA 3 part series on Dimensionality reduction techniques using the Kannada MNIST dataset  Drawbacks of PCAIn my last kernel titled Visualizing Kannada MNIST with PCA, I demonstrated how we could visualize the Kannada MNIST dataset by reducing the 784 dimensions into 2 thereby, making it easy to be viewed by human eye. We used PCA for reducing the dimensionality of the dataset. PCA essentially tries project the original data onto the directions where variance is maximum. In our case it projcected the data onto 2 Dimensions which could then be easily visualised. However, the visualisations produced by PCA was not able to do such a good job in differentiating all the digits.This is because PCA is a linear projection, which means it can’t capture non-linear dependencies. In this notebook we shall explore another Dimensionality reduction technique called t-SNE and see if it gives us better results as compared to PCA  Part2: t-SNE(T-distributed stochastic neighbour embedding) in Python  Table of Contents What is t-SNE Embeddings] t-SNE under the hood t-SNE with Scikit learn Interactively visualising t-SNE with Bokeh Further Readings  t-SNEt-SNE or T-distributed stochastic neighbour embedding takes a high dimensional data set and reduces it to a low dimensional graph that retains a lot of the original information. It does so by giving each data point a location in a two or three-dimensional map. This technique finds clusters in data thereby making sure that an embedding preserves the meaning in the data.  t-SNE reduces dimensionality while trying to keep similar instances close and dissimilar instances apart. EmbeddingsAn embedding is essentially a low-dimensional space into which a high dimensional vector can be translated. During translation, an embedding preserves the semantic relationship of the inputs by placing similar inputs close together in the embedding space. Let’s try and wrap our head around this concept with examples. Here is a grab from the creators of the Embedding projector, a tool which enables us to visualise high dimensional data easily.  Embeddings from Parul Pandey on Vimeo.t-SNE under the hoodt-SNE, was proposed by Geoffry Hinton’s and Laurens van der Maaten  back in 2008. Their paper titled Visualizing Data using t-SNE is an essential read for soembody trying to understand t-SNE. Here is how t-SNE basically works:  First, a probability distribution is created in a high dimensional space. This means if we pick a point in the dataset, we define the probability of picking another point as a neighbour. Next, a low dimensional space is then created that has the same(or as near as possible) probability distribution as the high Dimensional space.  t-SNE with Scikit learnScikit-learn has an implementation of t-SNE available, and you can check its documentation here.;Apache 2.0;https://www.kaggle.com/parulpandey/visualizing-kannada-mnist-with-t-sne;1.0;['sklearn'];['ner', 'ai', 'ml', 'nn', 'ann'];['filter', 'test data', 'train', 'model', 'understanding', 'label', 'recommend'];https://www.kaggle.com/c/Kannada-MNIST;0.705;0.482;2020-12-13 12:26:21;Kannada MNIST;['beginner, data visualization'];Visualizing Kannada MNIST with t-SNE;Python notebook;3418.0;79;;
2019-10-23 07:31:11;IntroductionIn this Kernel We will learn about Convolution Neural Networks.After reading this notebook you will learn:  Basic Understanding of data Preparing our data How a CNN works How tp build a CNN How to Make prediction  How to Evaluate your model How to make submission   If you like my work,please consider giving an upvote !;Apache 2.0;https://www.kaggle.com/shahules/indian-way-to-learn-cnn;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cnn', 'rl', 'ml', 'nn', 'ann'];['activation function', 'filter', 'training data', 'train', 'fitting', 'model', 'neural network', 'epoch', 'deep learning', 'layer', 'validation data', 'loss', 'label', 'rectifier', 'predict', 'relu', 'understanding', 'classification'];https://www.kaggle.com/c/Kannada-MNIST;0.774;0.56;2020-12-13 12:26:21;Kannada MNIST;['beginner, cnn, india'];Indian way to learn CNN;Python notebook;20006.0;237;;
2020-01-30 05:55:29;T-SNE code from this kernel https://www.kaggle.com/carlolepelaars/97-on-mnist-with-a-single-decision-tree-t-sne  If you want to get better score on leaderboard, I would recommend you to study https://www.kaggle.com/c/digit-recognizer this competition first!  Same model can get better score on kannada-mnist dataset than digit-recognizer dataset;Apache 2.0;https://www.kaggle.com/subinium/t-sne-viz-on-kannada-mnist;1.0;['sklearn'];['ai', 'nn', 'ann', 'rl'];['train', 'model', 'label', 'predict', 'recommend'];https://www.kaggle.com/c/Kannada-MNIST;0.599;0.383;2020-12-13 12:26:21;Kannada MNIST;['data visualization, exploratory data analysis'];T-SNE & Viz on Kannada MNIST ;Python notebook;444.0;24;;
2019-12-14 05:06:12;If this kernel helps you fortunately, please upvote it. Thanks you. :);Apache 2.0;https://www.kaggle.com/yonminma/keras-easy-with-0-9892-score;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'rl', 'nn', 'ann'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/Kannada-MNIST;0.652;0.371;2020-12-13 12:26:21;Kannada MNIST;['gpu'];Keras, easy with 0.9892 score;Python notebook;1143.0;21;0.98920;0.98680
2017-10-29 21:02:55;Relevent Member Data from Churn Competition;Apache 2.0;https://www.kaggle.com/joshwilkins2013/churn-baby-churn-user-logs;1.0;['sklearn'];['ner', 'ai', 'dl', 'rl', 'nn', 'ann'];['machine learning', 'train', 'label', 'predict', 'recommend'];https://www.kaggle.com/c/kkbox-churn-prediction-challenge;0.722;0.387;2020-12-13 12:29:18;multiple data sources;[];Churn Baby Churn - User Logs;Python notebook;5085.0;25;;
2017-12-13 11:11:43;IntroductionIn this kernel are presented data exploration and preparation for WSDM - KKBox's Churn Prediction Challenge the goal of which is to build a predictive model to classify users between 2 classes: churn (1) and non-churn (0) based their activity and payment history along all their lifetime on service.;Apache 2.0;https://www.kaggle.com/moonday/first-steps-in-churn-prediction-problem;1.0;['pattern'];['ner', 'ai', 'nn'];['train', 'model', 'generation', 'predict'];https://www.kaggle.com/c/kkbox-churn-prediction-challenge;0.718;0.268;2020-12-13 12:29:18;WSDM - KKBox's Churn Prediction Challenge;['beginner, classification'];First steps in Churn Prediction Problem;Python notebook;4617.0;7;;
2019-05-28 17:09:28;Simple Deep Learning: Feedforward Neural Network;Apache 2.0;https://www.kaggle.com/ripcurl/feedforward-neural-network-0-12174;1.0;['tensorflow', 'sklearn', 'keras'];['dl', 'ai', 'nn', 'rl'];['train', 'model', 'neural network', 'epoch', 'deep learning', 'layer', 'loss', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/kkbox-churn-prediction-challenge;0.661;0.302;2020-12-13 12:29:18;WSDM - KKBox's Churn Prediction Challenge;['beginner, deep learning, neural networks'];Feedforward Neural Network - 0.12174;Python notebook;1347.0;10;;
2017-12-15 22:44:43;Note that the autoencoder code are borrowed from the following notebook: https://github.com/curiousily/Credit-Card-Fraud-Detection-using-Autoencoders-in-Keras/blob/master/fraud_detection.ipynb The code used for summary statistics / dtype fixing belongs to ZihaoXu.;Apache 2.0;https://www.kaggle.com/zxql2015/1-autoencoder-with-keras;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['autoencoder', 'random forest', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/kkbox-churn-prediction-challenge;0.758;0.362;2020-12-13 12:29:18;WSDM - KKBox's Churn Prediction Challenge;[];1. Autoencoder with Keras;Python notebook;12957.0;19;;
2017-10-19 00:07:35;I'm here to make friends to work on this interesting challenge together. Skype me: sarazxy Welcome your comments.;Apache 2.0;https://www.kaggle.com/bitit1994/parameter-grid-search-lgbm-with-scikit-learn;1.0;['lightgbm', 'sklearn'];['ai', 'dl', 'gbm', 'cv', 'rl'];['train', 'fitting', 'model', 'loss', 'label', 'gradient boosting', 'predict', 'decision tree', 'classification'];https://www.kaggle.com/c/kkbox-music-recommendation-challenge;0.719;0.311;2020-12-13 12:31:41;WSDM - KKBox's Music Recommendation Challenge;[];Parameter grid search LGBM with scikit-learn;Python notebook;4731.0;11;;
2017-10-09 20:16:27;Days instead of DatesOn this notebook I will show you how I improve the score by replacing date data, and converting it into number of days. In this case specifically I will use ALL the fields on the datasets, but only replace the expiration_date and registration_init_time fields by calculating the difference in days between the two dates. expiration_date−registration_init_time=membership_daysAcknowledgements:This notebook is primarily based on the grate TalySacc's Script. The modifications are mainly for make understanding easier. I also tried to comment the code as much as I could.;Apache 2.0;https://www.kaggle.com/juanumusic/days-instead-of-dates-lgbm-0-66870;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'ml', 'gbm'];['predict', 'test data', 'train', 'model', 'label', 'loss', 'understanding'];https://www.kaggle.com/c/kkbox-music-recommendation-challenge;0.687;0.311;2020-12-13 12:31:41;WSDM - KKBox's Music Recommendation Challenge;[];Days instead of Dates (LGBM 0.66870);Python notebook;2296.0;11;;
2017-11-07 08:40:33;Music Recommendation -- Random Forest, XGboost;Apache 2.0;https://www.kaggle.com/myonin/music-recommendation-random-forest-xgboost;1.0;['xgboost', 'sklearn'];['ai', 'dl', 'cv'];['filter', 'random forest', 'train', 'model', 'label', 'predict', 'recommend', 'classification'];https://www.kaggle.com/c/kkbox-music-recommendation-challenge;0.762;0.411;2020-12-13 12:31:41;WSDM - KKBox's Music Recommendation Challenge;[];Music Recommendation -- Random Forest, XGboost;Python notebook;14180.0;33;;
2018-07-11 11:23:33;AS we  have imported necessary modules now we can start withEDA (Exploratory Data Analysis) with wrangling of data and visualizingThe necessary thing for out statiscal analysis as well insights of our dataLast steps would be data imputations , merging , cross validations ,Hyperparmaters tuning and visualization of every algowhat we used what areIt's result with Time consumption of algos producing the results;Apache 2.0;https://www.kaggle.com/rohandx1996/recommendation-system-with-83-accuracy-lgbm;1.0;['xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'ml', 'nn', 'ann'];['machine learning', 'training data', 'test data', 'train', 'model', 'loss', 'label', 'predict', 'decision tree', 'classification'];https://www.kaggle.com/c/kkbox-music-recommendation-challenge;0.722;0.429;2020-12-13 12:31:41;WSDM - KKBox's Music Recommendation Challenge;['data visualization, classification, feature engineering, +2 moredata cleaning, gradient boosting'];Recommendation System with 83% accuracy lgbm ;Python notebook;5140.0;41;;
2017-11-22 02:56:52;In this kernel, I would like to introduce you to boosting and LightGBM. Many of the kernels written for this competition have used light GBM and have produced really good results. These kernels have produced really useful insights into how to use light GBM. In this kernel, I would like deep dive into LightGBM and provide you my insights into how it works. I am writing this kernel to provide more insights into how lgbm works and how we can improve our model. I will be using Asmita's kernel (https://www.kaggle.com/asmitavikas/feature-engineered-0-68310) as a base. (This kernel does not provide any insights into feature engineering. One can refer to Asmita's kernel for that). I will be starting with a few basic questions about boosting and then move into specific one's about LightGBM (especially its hyper parameters) References/useful resources: https://www.analyticsvidhya.com/blog/2017/06/which-algorithm-takes-the-crown-light-gbm-vs-xgboost/ https://www.analyticsvidhya.com/blog/2015/09/complete-guide-boosting-methods/ https://www.analyticsvidhya.com/blog/2015/11/quick-introduction-boosting-algorithms-machine-learning/ https://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc What is boosting? Boosting combines a set of weak learners to form a strong rule. It is an iterative process. How boosting works? The weak rules are generated by a base learning algorithm. These rules are generated iteratively and combined at the end to form a single strong rule. Boosting gives more importance to observations which are wrongly classified. How is boosting different from bagging? Unlike bagging algorithms which just reduce variance, boosting reduces both bias and variance.;Apache 2.0;https://www.kaggle.com/vinnsvinay/introduction-to-boosting-using-lgbm-lb-0-68357;1.0;['xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'gbm', 'rl', 'nn'];['predict', 'train', 'fitting', 'model', 'understanding', 'gradient descent', 'gradient boosting', 'loss', 'decision tree', 'classification'];https://www.kaggle.com/c/kkbox-music-recommendation-challenge;0.756;0.449;2020-12-13 12:31:41;WSDM - KKBox's Music Recommendation Challenge;[];Introduction to Boosting using LGBM(LB: 0.68357);Python notebook;12245.0;52;;
2017-05-01 12:26:31;Hello everyone,As the competition has already ended way before, I coded this as a part of my practise. Feel free to suggest anything.;Apache 2.0;https://www.kaggle.com/aakashkerawat/exploring-and-predicting-lb-score-0-60160;1.0;['pattern', 'xgboost', 'sklearn'];['ner', 'ai', 'gbm', 'cv', 'rl', 'nn'];['filter', 'regression', 'generation', 'train', 'model', 'loss', 'label', 'logistic regression', 'gradient boosting', 'predict', 'rank', 'understanding', 'random forest', 'naive bayes'];https://www.kaggle.com/c/kobe-bryant-shot-selection;0.685;0.362;2020-12-13 12:34:34;Kobe Bryant Shot Selection;[];Exploring and predicting LB score 0.60160;Python notebook;2209.0;19;;
2016-04-23 20:10:04;Notice the red dot at where the basket should be? He misses a lot of shots from under the basket. Must be those common ball scenarios.;Apache 2.0;https://www.kaggle.com/arjoonn/preliminary-exploration;1.0;['sklearn'];['ner', 'ai', 'cv'];['train', 'model', 'label', 'predict'];https://www.kaggle.com/c/kobe-bryant-shot-selection;0.759;0.449;2020-12-13 12:34:34;Kobe Bryant Shot Selection;[];Preliminary exploration;Python notebook;13042.0;52;0.60854;0.60854
2016-05-01 13:57:42;Let's perform analysis!Hello, I'm Dixhom. Here I talk about how to preform feature engineering, delete unwanted variables, build a model and make submission data! So this is a tutorial for data science beginners. So let's get the ball rolling. (This is for a kaggle competition 'Kobe Bryant Shot Selection' (https://www.kaggle.com/c/kobe-bryant-shot-selection));Apache 2.0;https://www.kaggle.com/dixhom/data-analysis-for-beginners;1.0;['sklearn'];['ner', 'ai', 'cv', 'nn', 'ml'];['training data', 'train', 'model', 'layer', 'loss', 'label', 'predict'];https://www.kaggle.com/c/kobe-bryant-shot-selection;0.771;0.437;2020-12-13 12:34:34;Kobe Bryant Shot Selection;[];Data analysis for beginners;Python notebook;18401.0;45;0.90742;0.90742
2017-02-28 05:51:03;Kobe Shots - Show Me Your Best ModelThe following notebook presents a thought process of creating and debugging ML algorithm for predicting whether a shot is successfull or missed (binary classification problem). 1. PreparationLoad librariesLoad all required libraries;Apache 2.0;https://www.kaggle.com/kevins/kobe-shots-show-me-your-best-model;1.0;['sklearn'];['ner', 'ai', 'dl', 'gbm', 'cv', 'ml', 'nn', 'ann'];['filter', 'training data', 'regression', 'random forest', 'train', 'model', 'loss', 'label', 'logistic regression', 'gradient boosting', 'predict', 'rank', 'decision tree', 'classification'];https://www.kaggle.com/c/kobe-bryant-shot-selection;0.66;0.268;2020-12-13 12:34:34;Kobe Bryant Shot Selection;[];Kobe Shots - Show Me Your Best Model;Python notebook;1316.0;7;0.95463;0.95463
2016-05-11 14:48:57;Kobe Shots - Show Me Your Best ModelThe following notebook presents a thought process of creating and debugging ML algorithm for predicting whether a shot is successfull or missed (binary classification problem). 1. PreparationLoad librariesLoad all required libraries;Apache 2.0;https://www.kaggle.com/khozzy/kobe-shots-show-me-your-best-model;1.0;['sklearn'];['ner', 'ai', 'dl', 'gbm', 'cv', 'ml', 'nn', 'ann'];['filter', 'training data', 'regression', 'random forest', 'train', 'model', 'loss', 'label', 'logistic regression', 'gradient boosting', 'predict', 'rank', 'decision tree', 'classification'];https://www.kaggle.com/c/kobe-bryant-shot-selection;0.769;0.442;2020-12-13 12:34:34;Kobe Bryant Shot Selection;[];Kobe Shots - Show Me Your Best Model;Python notebook;17372.0;48;0.95485;0.95485
2017-09-13 18:17:41;"Psychology of a Professional AthleteIn this script we explore all shot attempts of Kobe Bryant throughout his career and try to see if Kobe displays the ""hot hand"" effect";Apache 2.0;https://www.kaggle.com/selfishgene/psychology-of-a-professional-athlete;1.0;['sklearn'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ml'];['training data', 'regression', 'train', 'model', 'loss', 'label', 'predict'];https://www.kaggle.com/c/kobe-bryant-shot-selection;0.785;0.54;2020-12-13 12:34:34;Kobe Bryant Shot Selection;['data visualization, sports, basketball, +1 moreintermediate'];Psychology of a Professional Athlete;Python notebook;27923.0;177;;
2019-08-13 09:21:52;Kuzushiji Recognition with the concept of Hand-Written digit recognition;Apache 2.0;https://www.kaggle.com/basu369victor/kuzushiji-recognition-just-like-digit-recognition;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ai', 'cnn', 'gan', 'cv', 'rl', 'nn', 'ann'];['machine learning', 'training data', 'object detection', 'train', 'fitting', 'model', 'recognition', 'neural network', 'epoch', 'deep learning', 'layer', 'loss', 'label', 'predict', 'relu', 'understanding', 'classification', 'ground truth'];https://www.kaggle.com/c/kuzushiji-recognition;0.683;0.435;2020-12-13 12:36:30;Kuzushiji Recognition;['beginner, deep learning, dailychallenge'];Kuzushiji Recognition just like Digit Recognition;Python notebook;2103.0;44;;
2019-10-13 21:04:41;You open doors when you open books... doors that swing wide to unlimited horizons of knowledge, wisdom, and inspiration that will enlarge the dimensions of your life. ~ Wilferd Peterson;Apache 2.0;https://www.kaggle.com/christianwallenwein/visualization-useful-functions-small-eda;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cv'];['filter', 'machine learning', 'training data', 'test data', 'train', 'recognition', 'model', 'label', 'predict', 'computer vision'];https://www.kaggle.com/c/kuzushiji-recognition;0.737;0.489;2020-12-13 12:36:30;multiple data sources;['beginner, data visualization'];Visualization + useful functions + small EDA;Python notebook;7350.0;87;;
2019-08-20 11:51:22;Kuzushiji recognition with MaskRCNN using Keras/TensorflowThis kernel is here to establish the pipeline to use a MaskRCNN on the Kuzushiji competition dataset, even though there is little chance it can obtain great results in the processing time allowed on kernels. It is using the Matterplot implementation of MaskRCNN and is inspired from this kernel from the iMaterialist competition. One of the key steps that is introduced in this kernel is the data preparation which consists of generating masks using an Otsu threshold.If you find this kernel useful, please give an upvote! :);Apache 2.0;https://www.kaggle.com/frlemarchand/keras-maskrcnn-kuzushiji-recognition;1.0;['tensorflow', 'keras'];['ner', 'ai', 'cnn', 'gan', 'cv', 'rl', 'nn', 'ann'];['filter', 'test data', 'train', 'recognition', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'resnet'];https://www.kaggle.com/c/kuzushiji-recognition;0.721;0.437;2020-12-13 12:36:30;multiple data sources;['gpu'];Keras MaskRCNN - Kuzushiji Recognition;Python notebook;4986.0;45;0.000;0.000
2019-10-06 13:39:51;UNet character detectorThis competition has 2 tasks:  detection classification    Here I do only detection. Classification is made further in the same way as MNIST. For this purpose I need to predict not only centers of characters, but also bounding boxes. UNet is utilized here to predict two binary masks: 1) Bounding boxes 2) Centers;Apache 2.0;https://www.kaggle.com/hocop1/unet-character-detector;1.0;['pytorch', 'skimage', 'sklearn'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'train', 'recognition', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'resnet', 'classification', 'u-net', 'ground truth'];https://www.kaggle.com/c/kuzushiji-recognition;0.699;0.44;2020-12-13 12:36:30;Kuzushiji Recognition;['gpu, deep learning, cnn'];UNet character detector;Python notebook;2976.0;47;;
2019-10-22 15:18:08;Kuzushiji Recognition Complete GuideBuild a model to transcribe ancient Kuzushiji into contemporary Japanese characters   Imagine the history contained in a thousand years of books. What stories are in those books? What knowledge can we learn from the world before our time? What was the weather like 500 years ago? What happened when Mt. Fuji erupted? How can one fold 100 cranes using only one piece of paper? The answers to these questions are in those books. Japan has millions of books and over a billion historical documents such as personal letters or diaries preserved nationwide. Most of them cannot be read by the majority of Japanese people living today because they were written in “Kuzushiji”. Even though Kuzushiji, a cursive writing style, had been used in Japan for over a thousand years, there are very few fluent readers of Kuzushiji today (only 0.01% of modern Japanese natives). Due to the lack of available human resources, there has been a great deal of interest in using Machine Learning to automatically recognize these historical texts and transcribe them into modern Japanese characters. kernel completed!  Content EDA New df_train missing data char stats top-10 chars top-100 chars (plot)     Simple Visualization KMINST Save the 683464 chars/digits images in kminst.zip and info.csv Examples of obtained chars from a random image.     KMINST Classification Simple KNN Deep Learning     Simple Predictions Visualization  Other kernelsI will create other kernels to perform different tasks: digitalize images, train models, do inferences etc . Here you can check them: More information Must-read material Worldwide Competition to Develop AI for Historical Japanese Character (Kuzushiji) Recognition KMNIST Dataset Osaka University;Apache 2.0;https://www.kaggle.com/jesucristo/kuzushiji-recognition-complete-guide;1.0;['sklearn'];['ner', 'ai', 'cv', 'rl', 'ml', 'nn', 'ann'];['machine learning', 'train', 'recognition', 'model', 'deep learning', 'label', 'predict', 'classification'];https://www.kaggle.com/c/kuzushiji-recognition;0.72;0.47;2020-12-13 12:36:30;multiple data sources;['beginner, data visualization, deep learning, +1 moreclassification'];Kuzushiji Recognition Complete Guide;Python notebook;4825.0;68;;
2019-08-06 23:52:28;Let's take a look at the first image;Apache 2.0;https://www.kaggle.com/latimerb/kuzushiji-visualization-masking;1.0;['pytorch', 'skimage'];['ai', 'cnn', 'ml', 'nn', 'ann'];['train', 'recognition', 'model', 'layer', 'label', 'predict', 'resnet'];https://www.kaggle.com/c/kuzushiji-recognition;0.618;0.302;2020-12-13 12:36:30;multiple data sources;['gpu'];Kuzushiji - Visualization + Masking;Python notebook;612.0;10;;
2019-10-14 18:31:33;"The following is just a rough draft/incomplete solution to the problem. I don't know if I'll be able to complete on time or not becuase of University stuff. But here it is as of now. I put heavy emphasis on the preprocessing. A lot of the preprocessing is stuff I learnt from my college course ""Digital Image Processing"". The YOLOv3 script is based on https://github.com/qqwweee/keras-yolo3";Apache 2.0;https://www.kaggle.com/pr1c3f1eld/data-cleaning-and-pre-processing;1.0;['tensorflow', 'keras'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'nn', 'ann'];['filter', 'train', 'recognition', 'model', 'output layer', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/kuzushiji-recognition;0.676;0.346;2020-12-13 12:36:30;Kuzushiji Recognition;['data visualization, image data, computer vision, +1 moredata analytics'];Yolov3 model with pretrained weights;Python notebook;1832.0;16;;
2019-07-20 18:06:34;You should be Careful 2 problems!1. different value nums of label for submission train > U+306F 1231 3465 133 53 U+304C 275 1652 84 69 ... <br/>  submission > U+003F 1 1 U+FF2F 2 2<br/>  Label of train df is consist of 5 values, however, label of submission df needs only 3 values!   2. there is na in labels You should fill na!;Apache 2.0;https://www.kaggle.com/seriousran/try-to-break-0;1.0;['tensorflow', 'keras'];['ai'];['gru', 'train', 'model', 'layer', 'label'];https://www.kaggle.com/c/kuzushiji-recognition;0.677;0.418;2020-12-13 12:36:30;Kuzushiji Recognition;[];Try to break 0;Python notebook;1866.0;36;0.003;0.003
2019-07-23 04:27:42;Sorry I can't speak and write well. First write in Japanese, then translate into English and append.;Apache 2.0;https://www.kaggle.com/wakamezake/kuzushiji-eda;1.0;['pytorch'];['ai'];['train', 'recognition', 'label'];https://www.kaggle.com/c/kuzushiji-recognition;0.652;0.371;2020-12-13 12:36:30;Kuzushiji Recognition;['data visualization, exploratory data analysis'];Kuzushiji_EDA;Python notebook;1143.0;21;;
2019-04-15 18:38:20;This Notebook just work on a Local Machine. So you have to download this notebook. Here's a script version: https://www.kaggle.com/arteam/download-and-extract-tar-files-train-data-script This a notebook to download and extract the Train Data from the 500 .tar files. It is based on PC Jimmmy's Download 500 tar Training dataset! . Credits and Thanks to PC Jimmmy!!!;Apache 2.0;https://www.kaggle.com/arteam/download-and-extract-500-tar-training-data;1.0;['tensorflow'];['ner', 'ai', 'dl', 'rl', 'nn', 'ann'];['train', 'training data'];https://www.kaggle.com/c/landmark-recognition-2019;0.675;0.292;2020-12-13 12:41:50;Google Landmark Recognition 2019;[];Download and extract 500 tar Training Data ;Python notebook;1790.0;9;;
2019-04-14 11:14:25;Everyone is busy downloading and there was no kernel that kind of does the initial exploration to see how the images look like and how would a simple work on this dataset. Hence I went forward and created one. This kernel does not save any file locally and just uses them on the fly during training using a keras generator. Time ranges around ~240secs for an epoch with total 1280 images on a ResNet50 (with very minimal number of classes). There may be a few mistakes, you never know. Happy Kaggling!;Apache 2.0;https://www.kaggle.com/mayukh18/dataset-exploration-and-simple-on-the-fly-training;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn'];['filter', 'train', 'model', 'epoch', 'layer', 'loss', 'resnet'];https://www.kaggle.com/c/landmark-recognition-2019;0.698;0.408;2020-12-13 12:41:49;Google Landmark Recognition 2019;['gpu'];Dataset Exploration and Simple On-the-Fly Training;Python notebook;2928.0;32;;
2019-04-10 03:59:10;Lots of folks confused on the Train dataset - several, including me trying to download the images using one of the offered scripts.  That's not how we get the train images. There are 500 seperate tar compressed files.  This script downloads and saves the tar files to a local drive.  Will work tomorrow on script to uncompress.   I am 6 month newbie in Python - so use with care:) DOWN LOAD THIS NOTEBOOK AND RUN ON YOUR LOCAL PC.   Since the script is written for local machine only it's filled with error messages here on Kaggle as I can seem to save a clean version without commit - which of course runs the script and generates errors. I had lots of starts and stops but guessing 6 hours total time with my 1GB internet connection.;Apache 2.0;https://www.kaggle.com/pcjimmmy/download-500-tar-training-dataset;1.0;['tensorflow'];['ner', 'ai', 'dl', 'rl', 'nn', 'ann'];['train', 'recommend'];https://www.kaggle.com/c/landmark-recognition-2019;0.722;0.379;2020-12-13 12:41:49;Google Landmark Recognition 2019;[];Download 500 tar Training dataset;Python notebook;5054.0;23;;
2019-05-03 21:57:48;In this competition it is not only important to predict the landmark for an image but also to make sure that if an image is not a landmark that we don't make a prediction. Correctly identifying non-landmark images in the test set will increase the score of a submission.  Removing as much of the non-landmark images from the training set will decrease the total amount of images that we need to train on and it will improve the 'correctness' of the model if it is trained on the landmark images and not on all the selfies, hotel-rooms and beds etcetera that were made near the landmark. A good way to start the identification is to use the Places365 dataset and models as described on this webpage. I've created a small dataset of 50 images selected from the 4+ million in the trainset to show how it could be done. In the Places365 dataset there 365 classes and each class is also marked as either 'indoor' or 'outdoor'. We could interpret this also as 'non-landmark' or 'landmark'. It could be further optimized offcourse...an image of the inside of a castle will be marked as 'indoor' but will very likely be a legitimate 'landmark'. Just by using the default 'indoor/outdoor' marker and determining it for both train and test data I was able to improve my best model so far with about 0.015 - 0.02 score on the leaderboard.;Apache 2.0;https://www.kaggle.com/rsmits/keras-landmark-or-non-landmark-identification;1.0;['tensorflow', 'keras'];['ai', 'dl', 'rl', 'cv', 'nn'];['test data', 'train', 'recognition', 'model', 'vgg', 'label', 'predict'];https://www.kaggle.com/c/landmark-recognition-2019;0.735;0.442;2020-12-13 12:41:49;multiple data sources;['gpu, data visualization'];Keras Landmark or Non-Landmark identification;Python notebook;6935.0;48;;
2020-08-16 12:19:04;"IntroductionThis notebook is forked from https://www.kaggle.com/rhtsingh/pytorch-training-inference-efficientnet-baseline by @rhtsingh - if you are kind enough to upvote my notebook, please also upvote @rhtsingh's. What have I changed?  Because no internet is allowed for submission with this competition, I've created a dataset with EfficientNet resources to enable submission. There is so much data to train on, so little time. So to get started, rather than train on the public training set, this notebook trains on the private training set. From the data documentation: ""the private training set contains only a 100k subset of the total public training set. This 100k subset contains all of the training set images associated with the landmarks in the private test set."" Given that we're going to use the private training set here, there is no point burning CPU/GPU time training on the public training set. So I've added an option to skip, based on detecting a given id in the test set (which is in the public test set, but evidently not in the private test set). Even with a little tuning, I was still stuck at a LB score of 0.0000 with EfficientNet B0, so I moved up to B4.  Update Added seeds for random engines to try and remove non-determinism. The LB score seems to be right on the 0.0000/1 boundary.  ConclusionA fairly standard EfficientNet baseline (thanks @rhtsingh) doesn't appear to able to get a good result here. Next steps: Study past years' winning solutions and start from there!";Apache 2.0;https://www.kaggle.com/andypenrose/pytorch-training-inference-efficientnet-b4;1.0;['pytorch', 'albumentations', 'sklearn'];['ner', 'ai', 'cv', 'rl', 'nn', 'ann'];['filter', 'test data', 'train', 'recognition', 'model', 'epoch', 'loss', 'label', 'predict'];https://www.kaggle.com/c/landmark-recognition-2020;0.689;0.413;2020-12-13 12:43:16;multiple data sources;[];[PyTorch Training+Inference] EfficientNet B4;Python notebook;2415.0;34;0.0000;0.0000
2020-08-10 19:36:39;Landmark RecognitionIn this notebook, I will try to perform exploratory data analysis (EDA) on this dataset. As I am a beginner myself, I will try to explain the findings as much as possible. Please give your valuable opinions and suggestions in the comments. The following notebooks helped me a lot to write this notebook:  https://www.kaggle.com/chirag9073/landmark-recognition-exploratory-data-analysis/notebook https://www.kaggle.com/azaemon/mura-classification  Check out my other notebooks if interested: https://www.kaggle.com/azaemon/notebooks;Apache 2.0;https://www.kaggle.com/azaemon/eda-data-augmentation-for-beginners;1.0;['albumentations'];['ner', 'ai', 'cv', 'rl', 'nn', 'ann'];['train', 'recognition', 'model', 'label', 'recommend', 'classification'];https://www.kaggle.com/c/landmark-recognition-2020;0.657;0.403;2020-12-13 12:43:16;Google Landmark Recognition 2020;['beginner, data visualization, exploratory data analysis'];EDA + Data Augmentation for Beginners;Python notebook;1257.0;30;;
2020-09-18 21:07:44;"Update6Using same pipeline with an efficientnetb3, efficientnetb5 using arc face margin 0.15 and NUM_TO_RERANK = 1. Also, retrain the model with image size 512. Update5Using same pipeline with an efficientnetb3 using arc face margin 0.15. Update4Blend efficientnetB1 and B2 and change the NUM_TO_RANK to 3. Blending did not improve the score that much, i believe it is because both efficientnets are correlated. To blend 2 models, just average the embeddings. Update3Change validation to 2%, efficientnetB1 and train with more epochs. The number of unique training classes is 81313 of 81313 total classes The number of unique validation classes is 24574 of 81313 total classes Training with 1548860 images Validating with 31610 images Update2Using retrieval with private train dataset increase public score a lot. Non landmark images and images with a few observations are hard to predict. For this case I use a arcface layer with an efficientnetB0, and the val loss accuracy was 0.730. The nice thing is that leaderboard is much better than last experiment. Well there is a los of ground for improvement. I updated the script so you can experiment with this pipeline. The number of unique training classes is 80937 of 81313 total classes The number of unique validation classes is 64024 of 81313 total classes Update1Used EfficientNetB5 with 100% of the data using 20% validation. The number of unique training classes is 80937 of 81313 total classes The number of unique validation classes is 64024 of 81313 total classes This model got a validation accuracy of 0.86. CommentsSup kaggle, in this pipeline and script i want to share my results trianing my own models so that you can use this as a baseline. Here i trained a basic efficientnetB3 with the total amount of classes ""81313"". I only used 80% of the total training data and my experiments show me that if you train with more data, the validation score improves and also the public leaderboard. Becuase we are only trianing with 80% of the data, we are not actually trianing all the classes because there are some classes that have 2 samples. Here are some basic stats for the trained model. The number of unique training classes is 74450 of 81313 total classes The number of unique validation classes is 66213 of 81313 total classes The validation accuracy score is 0.82 and the gap is 0.80 Important: Im still not sure why my validation is not align with the public leaderboard score, i believe it is because is has another target distribution + non landmark images, but this is just an hypothesis. Some insights that you may find usefull are the following:  Here is a discussion where I comment the dataset im using https://www.kaggle.com/c/landmark-recognition-2020/discussion/180056 Bigger image size gives better score but they need more resources to train, in other words it will take more time Bigger efficientnets give better scores Retrieval methods adjust to this problem much more that normal classification, so you want to try that approach, this is just an example to get you started building and fitting your own models Model was trained in colab tpu, with a regular free account you have 12 hours to train your model, if you need more time just save the model each epoch and then reload it in another session and continue training";Apache 2.0;https://www.kaggle.com/ragnar123/efficientnetb3-data-pipeline-and-model;1.0;['tensorflow', 'sklearn', 'keras', 'pillow'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['training data', 'train', 'fitting', 'model', 'recognition', 'epoch', 'validation data', 'layer', 'loss', 'label', 'predict', 'rank', 'classification', 'ground truth'];https://www.kaggle.com/c/landmark-recognition-2020;0.73;0.477;2020-12-13 12:43:16;multiple data sources;[];EfficientNetB3 data Pipeline and Model;Python notebook;6242.0;74;0.4467;0.4705
2020-08-02 11:09:13;References: https://github.com/CSAILVision/places365Robin Smiths - Keras Landmark or Non-Landmark identification from Google Landmark Recognition 2019;Apache 2.0;https://www.kaggle.com/rhtsingh/pytorch-landmark-or-non-landmark-identification;1.0;['keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn'];['filter', 'test data', 'train', 'recognition', 'model', 'layer', 'label', 'predict', 'resnet', 'classification'];https://www.kaggle.com/c/landmark-recognition-2020;0.656;0.418;2020-12-13 12:43:16;Google Landmark Recognition 2020;['gpu, beginner, classification, +2 moredata cleaning, image data'];PyTorch Landmark or Non-Landmark identification;Python notebook;1235.0;36;;
2020-07-30 18:30:08;[PyTorch Training + Inference] EfficientNet BaselineNote: I have exhausted my GPU for this week and so was unable to complete training. When training started I had only 1/30hr left.;Apache 2.0;https://www.kaggle.com/rhtsingh/pytorch-training-inference-efficientnet-baseline;1.0;['pytorch', 'albumentations', 'sklearn'];['ner', 'ai', 'cv', 'nn', 'ann'];['filter', 'test data', 'train', 'recognition', 'model', 'epoch', 'loss', 'label', 'predict'];https://www.kaggle.com/c/landmark-recognition-2020;0.719;0.47;2020-12-13 12:43:16;Google Landmark Recognition 2020;['beginner, pytorch'];[PyTorch Training+Inference] EfficientNet Baseline;Python notebook;4708.0;68;;
2020-08-23 23:59:32;In the current competition there seem to be only a few kernels (ok .. besides the kernel provided by the competition organisers and related forks) that use a DL classification model. With this kernel I hope to add a little to the choices that are available and still provide a nice score given the GPU time available. Some keypoints of this kernel:  Simple EfficientNet B2 model Custom head Custom sampling An attempt to detect when an object is no landmark by using a Places365 model. I'am using the same model as in my notebook during last years Landmark Recognition Landmark Notebook  If you liked this kernel then please give it an upvote :-) I'am looking forward to any questions or remarks you might have that I can use to improve this kernel.;Apache 2.0;https://www.kaggle.com/rsmits/tf-keras-effnet-b2-non-landmark-removal;1.0;['sklearn', 'pillow', 'albumentations', 'tensorflow', 'keras'];['ner', 'ai', 'dl', 'gan', 'cv', 'nn', 'ann'];['generation', 'train', 'recognition', 'model', 'input layer', 'epoch', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/landmark-recognition-2020;0.686;0.418;2020-12-13 12:43:16;multiple data sources;['gpu, deep learning, classification, +1 morecomputer vision'];TF Keras EffNet B2 - Non Landmark Removal;Python notebook;2264.0;36;0.0932;0.1044
2020-08-25 07:41:44;Google Landmark Recognition 2020 Label famous (and not-so-famous) landmarks in images This is he third Landmark Recognition competition of the series. Did you ever go through your vacation photos and ask yourself: What is the name of this temple I visited in China? Who created this monument I saw in France? Landmark recognition can help! This technology can predict landmark labels directly from image pixels, to help people better understand and organize their photo collections. This competition challenges Kagglers to build models that recognize the correct landmark (if any) in a dataset of challenging test images.;Apache 2.0;https://www.kaggle.com/sandy1112/landmarkreco-2020-class-imbalance-deep-dive-eda;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cnn', 'gan', 'cv', 'rl', 'nn', 'ann'];['training data', 'train', 'recognition', 'model', 'epoch', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'resnet'];https://www.kaggle.com/c/landmark-recognition-2020;0.674;0.44;2020-12-13 12:43:16;multiple data sources;['gpu, beginner, exploratory data analysis, +2 moreimage data, computer vision'];LandmarkReco-2020-Class Imbalance Deep Dive -EDA;Python notebook;1755.0;47;;
2020-08-02 22:19:35;Fast Image Reading via Multiprocessing & Getting Image SizesThe train dataset contains ~1.5 million images. The popular image libraries, such as imageio or cv2, read ~20 images in a second on average (the average is based on first 38k images in the train dataset). Reading 1.5 million images with this average rate would give a total reading time of 20.8 hr, which is impossibly long to keep the kaggle notebebook alive. This reading time can be reduced by multiprocessing as can be shown in this notebook. Exploiting this faster reading time, I present here a full list of image size (xsize, ysize) and depth (channel) information for all train images. P.S. Please don't forget to upvote, if you find the notebook useful.;Apache 2.0;https://www.kaggle.com/tolgadincer/landmark-recognition-multiprocessing-image-size;1.0;['tensorflow'];['ai', 'nn', 'ann', 'cv'];['train', 'recognition'];https://www.kaggle.com/c/landmark-recognition-2020;0.641;0.397;2020-12-13 12:43:16;Google Landmark Recognition 2020;[];Landmark-Recognition-Multiprocessing | Image-Size;Python notebook;925.0;28;;
2018-05-15 15:11:48;IntroductionThe project is used to label famous (and not-so-famous) landmarks in images.This Kernel explore the train and test datasets from Google Landmark Recognition Challenge. Please feel free to fork and further develop this Kernel.  Load Libraries;Apache 2.0;https://www.kaggle.com/amardeepbansal/gimagerecognigtion;1.0;['skimage'];['ner', 'ai', 'rl', 'nn', 'ml'];['filter', 'training data', 'test data', 'train', 'recognition', 'model', 'label'];https://www.kaggle.com/c/landmark-recognition-challenge;0.651;0.236;2020-12-13 12:46:43;Google Landmark Recognition Challenge;['beginner, data visualization, deep learning'];GImageRecognigtion;Python notebook;1119.0;5;0.00000;0.00000
2018-05-14 08:02:38;How to set up directory for keras flow_from_directory function;Apache 2.0;https://www.kaggle.com/ericbenhamou/sub-directories-for-keras-flow-from-directory;1.0;['keras'];['ner', 'ai', 'cnn', 'gan', 'rl', 'nn'];['train', 'label'];https://www.kaggle.com/c/landmark-recognition-challenge;0.725;0.327;2020-12-13 12:46:43;Google Landmark Recognition Challenge;[];Sub directories  for keras.flow_from_directory;Python notebook;5449.0;13;;
2018-03-05 19:57:52;Quick Start: Google Landmark Recognition Challenge This Kernel aims to be a quick and easy way for anyone to start the Google Landmark Recognition Challenge. In just 2 steps, you will be able to load the datasets, and get an explanatory visualization of it.  If you like this Kernel of find it useful, please upvote it or/and leave a comment.  Any feedback, advise, comment would be highly appreciated in order to improve this Kernel.;Apache 2.0;https://www.kaggle.com/gdangel0/quick-start-google-landmark-recognition-challenge;1.0;['sklearn'];['ner', 'ai', 'rl', 'ml', 'nn', 'ann'];['training data', 'filter', 'train', 'recognition', 'label'];https://www.kaggle.com/c/landmark-recognition-challenge;0.69;0.214;2020-12-13 12:46:43;Google Landmark Recognition Challenge;['beginner, data visualization, exploratory data analysis'];Quick Start: Google Landmark Recognition Challenge;Python notebook;2442.0;4;;
2018-02-05 23:03:21;Baseline ModelHere we try and build a simple baseline model to have a frame of reference for others;Apache 2.0;https://www.kaggle.com/kmader/baseline-landmark-model;1.0;['skimage'];['ai', 'rl'];['train', 'model', 'label'];https://www.kaggle.com/c/landmark-recognition-challenge;0.714;0.302;2020-12-13 12:46:43;Google Landmark Recognition Challenge;[];Baseline Landmark Model;Python notebook;4236.0;10;0.00000;0.00000
2018-08-03 11:04:55;OverviewThe kaggle kernel-based version of the tf-hub notebook here. The example uses the pretrained DELF feature detector for the recognition;Apache 2.0;https://www.kaggle.com/kmader/tensorflow-hub-for-scene-recognition;1.0;['tensorflow', 'skimage'];['ai', 'nn', 'ann', 'rl'];['train', 'recognition', 'model', 'test data'];https://www.kaggle.com/c/landmark-recognition-challenge;0.684;0.319;2020-12-13 12:46:43;Google Landmark Recognition Challenge;[];Tensorflow-Hub for Scene Recognition;Python notebook;2185.0;12;;
2019-03-29 06:04:05;This is fast image downloader using this trick: https://www.kaggle.com/c/landmark-recognition-challenge/discussion/49703 And you can change target size that you prefer. Reference: https://www.kaggle.com/c/landmark-recognition-challenge/discussion/48895 For 256,256 this should be 22 GB For 224,224 this should be 16.8 GB For 139,139 this should be 6.5 GB For 128,128 this should be 5.5 GB For 96,96 this should be 3.1 GB For 64,64 this should be 1.4 GB;Apache 2.0;https://www.kaggle.com/lyakaap/fast-resized-image-download-python-3;1.0;['pattern'];['ai', 'rl'];['train', 'recognition', 'recommend', 'test data'];https://www.kaggle.com/c/landmark-recognition-challenge;0.732;0.418;2020-12-13 12:46:43;Google Landmark Recognition Challenge;[];Fast Resized Image Download (Python 3);Python notebook;6445.0;36;;
2019-12-02 13:29:33;This notebook will show you how you can use Pytorch and a pretrained Resnet model to develop an algorithm that can help you compare 2 images. Underlying concept is to convert a high dimensional image to a manageable representative set of features using a pretrained DNN. In this case I have chosen resnet18 (not resnet34/50/101/152 - because of hardware limitations imposed by my laptop) At work I had the opportunity to evalutate multiple different models - VGG16, VGG19 and InceptionV3, with respect to a retail use case where given a set of apparel data from one retailer, I had to find exact matches in another. Resnet50 gave me the best accuracy - consistently for multiple retailers. And I found it to be resilient to changes in image background, illumination etc which was great. The idea here tries to exploit a vector space and plots each image in the high-dimensional vector space and use cosine distance to evaluate the distance between any 2 vectors.;Apache 2.0;https://www.kaggle.com/pankajgiri/resnet-feature-extraction-pytorch;1.0;['pytorch', 'sklearn'];['ai', 'nn', 'ml', 'rl'];['train', 'model', 'vgg', 'layer', 'resnet'];https://www.kaggle.com/c/landmark-retrieval-2019;0.625;0.152;2020-12-13 12:48:00;multiple data sources;[];resnet_feature_extraction_pytorch;Python notebook;692.0;2;;
2020-08-10 17:25:00;Work in progress/incompleteFeel free to give feedback!;Apache 2.0;https://www.kaggle.com/akensert/glret-cosface-with-distributed-tf;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'nn', 'ann'];['filter', 'train', 'model', 'epoch', 'layer', 'label', 'loss', 'resnet'];https://www.kaggle.com/c/landmark-retrieval-2020;0.671;0.405;2020-12-13 12:53:48;multiple data sources;[];[GLRet] CosFace with distributed TF;Python notebook;1645.0;31;;
2020-08-10 12:19:51;Work in progress/incompleteFeel free to give feedback!;Apache 2.0;https://www.kaggle.com/akensert/glret-triplet-semi-hard-loss-with-distributed-tf;1.0;['tensorflow', 'sklearn', 'keras'];['dl', 'ai', 'nn', 'ann'];['filter', 'train', 'model', 'epoch', 'layer', 'label', 'loss', 'resnet'];https://www.kaggle.com/c/landmark-retrieval-2020;0.665;0.387;2020-12-13 12:53:48;multiple data sources;['gpu'];[GLRet] Triplet Semi Hard Loss with distributed TF;Python notebook;1479.0;25;0.02743;0.03843
2020-08-08 11:02:47;In this notebook we will see how we can convert a pytorch model into a format that is valid for submission. This notebook is just to show how we can convert a pretrained resnet_18 model to submission format for this competition. The model is not trained and this notebook will generate 0.0 score on LB but doesnt give you error while submission.;Apache 2.0;https://www.kaggle.com/chandanverma/convert-pytorch-model-to-tf-2-2-submission-format;1.0;['pytorch', 'tensorflow', 'keras'];['ner', 'ai', 'nn', 'cv'];['train', 'model', 'vgg', 'layer', 'resnet'];https://www.kaggle.com/c/landmark-retrieval-2020;0.616;0.39;2020-12-13 12:53:48;multiple data sources;[];Convert Pytorch model to TF 2.2 submission format;Python notebook;585.0;26;;
2020-07-03 15:49:45;First draft... Need to be improved Upvotes appreciated :);Apache 2.0;https://www.kaggle.com/kvsnoufal/triplet-loss-cnn-model-knn-first-attempt;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'nn', 'cv'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/landmark-retrieval-2020;0.663;0.387;2020-12-13 12:53:48;Google Landmark Retrieval 2020;['gpu'];Triplet Loss: CNN Model + KNN first attempt;Python notebook;1399.0;25;0.00000;0.00000
2020-08-13 15:24:35;Since I completed the Convolutional Neural Networks course on Coursera I've been looking for a challenge where I can practice a model with triplet loss. While the size and complexity of this dataset may not be ideal I thought this would be a good opportunity to do so.;Apache 2.0;https://www.kaggle.com/mattbast/google-landmark-retrieval-triplet-loss;1.0;['tensorflow', 'keras'];['ner', 'ai', 'dl', 'rl', 'nn', 'ann'];['training data', 'train', 'model', 'neural network', 'epoch', 'layer', 'loss', 'predict', 'convolutional neural network'];https://www.kaggle.com/c/landmark-retrieval-2020;0.689;0.431;2020-12-13 12:53:48;multiple data sources;['tpu'];Google Landmark Retrieval - Triplet Loss;Python notebook;2401.0;42;;
2020-07-11 11:24:34;There has been a lot of confusion on how exactly we are supposed to submit our model. As the Data section of the competition states: Your model must be named submission.zip and be compatible with TensorFlow 2.2. The submission.zip should contain all files and directories created by the tf.saved_model_save function using Tensorflow's SavedModel format.  Now question is what exactly in the SavedModel format do we need to submit. Also, majority of us don't want to use tensorflow to train our models. And we don't know how to preprocess. So we'll tackle two things mainly.  Use our own keras model in submission. How to preprocess.  Let's get started.;Apache 2.0;https://www.kaggle.com/mayukh18/creating-submission-from-your-own-model;1.0;['tensorflow', 'keras'];['cv', 'ai', 'gan'];['train', 'model', 'layer', 'vgg', 'predict', 'rank'];https://www.kaggle.com/c/landmark-retrieval-2020;0.727;0.5;2020-12-13 12:53:48;multiple data sources;['deep learning, image data'];Creating Submission From Your Own Model;Python notebook;5749.0;101;;
2020-08-04 05:02:16;The purpose of this notebook is to illustrate how to create Resnet50 from scratch on Tensorflow 2.x . This kernel just uses top 100 classes. For actual competition we would need to model all classes with neccessary methods to handle class imbalance;Apache 2.0;https://www.kaggle.com/sandy1112/create-and-train-resnet50-from-scratch;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'nn', 'ann'];['filter', 'train', 'model', 'epoch', 'deep learning', 'layer', 'label', 'loss', 'relu', 'resnet'];https://www.kaggle.com/c/landmark-retrieval-2020;0.718;0.479;2020-12-13 12:53:48;Google Landmark Retrieval 2020;['gpu, beginner, deep learning, +1 moremulticlass classification'];Create and Train ResNet50 from scratch;Python notebook;4623.0;76;;
2020-07-31 13:56:57;In this notebook, I will show you Tensorflow implementation of ArcFace layer, GeM pooling layer and how to train everything on TPU.TPU must read and store data from/to Google cloud storage. Although you could access input data in this gs dir: KaggleDatasets().get_gcs_path(), I would recommand you to shard and serialise the data beforehand using this script from DELF repo. Afterwards you should upload shards to your google cloud storage and uses tf.data.TFRecordDataset to load them. It can increase your training time by 4x. Here I will continue as data has been sharded and serialised.;Apache 2.0;https://www.kaggle.com/suruili/arcface-gem-train-on-tpu;1.0;['pytorch', 'tensorflow', 'keras', 'pattern'];['ai', 'dl', 'cnn', 'nn', 'ann'];['train', 'model', 'output layer', 'epoch', 'layer', 'loss', 'label', 'predict', 'resnet'];https://www.kaggle.com/c/landmark-retrieval-2020;0.695;0.442;2020-12-13 12:53:48;Google Landmark Retrieval 2020;[];ArcFace + GeM + Train on TPU;Python notebook;2747.0;48;;
2020-10-03 21:54:53;This notebook provides the possibility to sample and view batches of images by re-running the same cell multiple times;Apache 2.0;https://www.kaggle.com/vstepanenko/batch-image-viewer;1.0;['tensorflow', 'keras'];['ner', 'ai', 'nn'];['train', 'label'];https://www.kaggle.com/c/landmark-retrieval-2020;0.642;0.452;2020-12-13 12:53:48;Google Landmark Retrieval 2020;['image data'];Batch image viewer;Python notebook;933.0;54;;
2020-07-05 13:47:39;Deep Local and Global Image FeaturesIn this kernel I will use DELF for building a first baseline kerenl. DELF project presents code for deep local and global image feature methods, which are particularly useful for the computer vision tasks of instance-level recognition and retrieval. These were introduced in the DELF, Detect-to-Retrieve, DELG.   Acknowledgment: In the following link, you can find the project source code, installation guidlines and pretrained models by @andre faraujo:  https://github.com/tensorflow/models/tree/master/research/delf Please upvote if you find this kernel useful;Apache 2.0;https://www.kaggle.com/waelkh/landmark2020-delf-model-submission-code;1.0;['pattern', 'tensorflow', 'skimage', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ann'];['object detection', 'train', 'recognition', 'model', 'label', 'computer vision', 'resnet'];https://www.kaggle.com/c/landmark-retrieval-2020;0.71;0.456;2020-12-13 12:53:48;multiple data sources;['computer vision'];Landmark2020-DELF model & submission code;Python notebook;3796.0;57;;
2019-02-04 09:11:02;What is this competition all about? Given seismic signals we are asked to predict the time until the onset of laboratory earthquakes. The training data is a single sequence of signal and seems to come from one experiment alone. In contrast the test data consists of several different sequences, called segments, that may correspond to different experiments. The regular pattern we might find in the train set does not match those of the test segments.  For each test data segment with its corresponding seg_id we are asked to predict it's single time until the lab earthquake takes place.;Apache 2.0;https://www.kaggle.com/allunia/shaking-earth;1.0;['pattern', 'sklearn'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'training data', 'test data', 'generation', 'train', 'model', 'validation data', 'label', 'predict'];https://www.kaggle.com/c/LANL-Earthquake-Prediction;0.803;0.634;2020-12-13 13:01:16;LANL Earthquake Prediction;['exploratory data analysis'];Shaking Earth;Python notebook;50789.0;813;;
2019-04-23 10:17:25;General informationCorrectly predicting earthquakes is very important for preventing deaths and damage to infrastructure. In this competition we try to predict time left to the next laboratory earthquake based on seismic signal data. Training data represents one huge signal, but in test data we have many separate chunks, for each of which we need to predict time to failure. This is my second kernel for this competition, here is the link to the first one. In this kernel I'll try to create more useful features and generate more data for training.;Apache 2.0;https://www.kaggle.com/artgor/earthquakes-fe-more-features-and-samples;1.0;['catboost', 'xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'gbm', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'training data', 'regression', 'generation', 'train', 'test data', 'model', 'loss', 'label', 'predict'];https://www.kaggle.com/c/LANL-Earthquake-Prediction;0.807;0.622;2020-12-13 13:01:16;LANL Earthquake Prediction;['data visualization, exploratory data analysis, feature engineering, +1 moreregression'];Earthquakes FE. More features and samples;Python notebook;58697.0;655;2.62189;1.49868
2019-05-05 15:16:42;DescriptionThis kernel is a continuation of my previous kernels and is aimed at creating a huge number of features, which were invented in different public kernels (including mine). Please notice, that high number of available features doesn't mean that using all of them at once is a good idea :) Feature selection should be used to limit the number of features. Another important point: some of the code for feature creation is commented, because otherwise kernel hits time limit. I generated these features locally and created a dataset with them: https://www.kaggle.com/artgor/lanl-features Also I wrote another kernel to show various model interpretation and feature selection technics: https://www.kaggle.com/artgor/feature-selection-model-interpretation-and-more;Apache 2.0;https://www.kaggle.com/artgor/even-more-features;1.0;['catboost', 'xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'gbm', 'cv', 'rl', 'nn', 'ann'];['filter', 'regression', 'generation', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/LANL-Earthquake-Prediction;0.749;0.529;2020-12-13 13:01:16;LANL Earthquake Prediction;['data visualization, feature engineering, regression'];Even more features;Python notebook;10044.0;151;2.56438;1.47918
2019-05-12 18:54:06;General informationIn this kernel I'll try various technics for models interpretability and feature selection. Also I'll compare various models. I use the features from my dataset: https://www.kaggle.com/artgor/lanl-features This dataset was created using this kernel: https://www.kaggle.com/artgor/even-more-features/ UPD: Thanks to the new kaggle update we can write code in kernels and import it. This is much more convenient and useful. I'm moving all the functions I can into this script: https://www.kaggle.com/artgor/artgor-utils So if you see somewhere code like artgot_utils.function_name(parameters) - it is from this script;Apache 2.0;https://www.kaggle.com/artgor/feature-selection-model-interpretation-and-more;1.0;['catboost', 'xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'gbm', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'regression', 'train', 'model', 'label', 'predict', 'random forest'];https://www.kaggle.com/c/LANL-Earthquake-Prediction;0.776;0.549;2020-12-13 13:01:16;multiple data sources;['regression, model explainability'];Feature selection, model interpretation and more;Python notebook;21440.0;201;;
2019-04-10 21:27:19;Important noticeDue to some weird bug I can't answer the comments on this kernel - my answers aren't posted. And I can't upvote comments on this kernel. So, I'm sorry, but I can't answer :( But it seems I can answer in other kernels, so I can reply, if you post a comment to my second kernel. General informationCorrectly predicting earthquakes is very important for preventing deaths and damage to infrastructure. In this competition we try to predict time left to the next laboratory earthquake based on seismic signal data. Training data represents one huge signal, but in test data we have many separate chunks, for each of which we need to predict time to failure. This kernel is dedicated to exploration of LANL Earthquake Prediction Challenge. In my second kernel I pay more attention to feature engineering and data generation.;Apache 2.0;https://www.kaggle.com/artgor/seismic-data-eda-and-baseline;1.0;['catboost', 'xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'gbm', 'cv', 'rl'];['filter', 'training data', 'test data', 'generation', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/LANL-Earthquake-Prediction;0.784;0.586;2020-12-13 13:01:16;LANL Earthquake Prediction;['data visualization, exploratory data analysis, feature engineering, +1 moreregression'];Seismic data EDA and baseline;Python notebook;27532.0;358;2.80795;1.64116
2019-02-06 21:47:17;"Predicting Earthquakes?Predicting earthquakes has long been thought to be near-impossible. But same has been said about many other things, I still remember how 15 years ago my IT teacher in high school was saying that speech recognition can never be done reliably by a computer, and today it's more reliable than a human. So who knows, maybe this competition will be a major step in solving another ""impossible"" problem. Importance of predicting earthquakes is hard to underestimate - selected years of our century claimed hundreds of thousands of causalities. Being able to predict earthquakes could allow us to better protect human life and property.";Apache 2.0;https://www.kaggle.com/avloss/audio-analysis-with-animation;1.0;['pattern'];['ner', 'ai', 'gan', 'rl', 'ml', 'nn', 'ann'];['speech recognition', 'training data', 'train', 'recognition', 'layer', 'predict'];https://www.kaggle.com/c/LANL-Earthquake-Prediction;0.72;0.497;2020-12-13 13:01:16;multiple data sources;['data visualization, exploratory data analysis, advanced'];Exploratory AUDIO Analysis;Python notebook;4826.0;97;;
2019-05-01 03:47:16;"Hyperopt Made Simple!Automated Parameter Tuning in One Function: quick_hyperopt()  Parameter tuning can be a chore. Which parameters should be changed? And by how much? There are an almost infinite combination, so how can we find the best ones? Simple methods like GridSearch can manually run through some preset combinations but will not necessarily pick the best possible parameters, just the best in the set you provided. And this grid will have to be changed when you add new features or otherwise modify your data. A more nuanced approach is to use Bayesian optimisation, probabilistically selecting the optimum values for each parameter after every round of evaluation. This kernel provides a single function for automated Bayesian hyperparameter optimisation with LightGBM, XGBoost and CatBoost via the Hyperopt package. Simply enter your data, target, and the type of model, and it will output a parameter dictionary you can then supply to your model-training kernels. While Hyperopt is a powerful tool, it can be difficult to implement and utilise. This function does the hard(-ish) work for you! I owe a great debt to Will Koehrsen for his exhaustive kernel on automated parameter tuning. While I have streamlined, modified and generalised much of his work for easy use with different model frameworks, I strongly recommend reading his kernel from top to bottom. It contains a thorough examination of how Bayesian parameter tuning works better than random selection, along with a step-by-step guide on outputting the Hyperopt progress logs. If your aim is to truly understand the how and why of parameter tuning, his kernels are some of the best resources you'll find. The basic form of the function in this kernel is as follows: optimum_parameter_dictionary = quick_hyperopt(data, labels, 'model_type', NUM_EVALS) where 'model_type' is either 'lgbm' for LightGBM, 'xgb' for XGBoost or 'cb' for CatBoost, and NUM_EVALS is the number of parameter optimisation rounds. optimum_paramater_dictionary is the parameter dictionary you can supply to the relevant model. Usage Notes  Parameter tuning can be a lengthy and intensive process. If the kernel is crashing or failing to finish, you may be using too much of your data; consider sampling it and running multiple kernels with each sample. You can then take the average/majority vote of each parameter that hyperopt selects. You can also reduce the number of evaluation rounds with the global parameter NUM_EVALS.  This function is written for regression tasks, but includes instructions on what must be modified if you are performing a classification task instead. I have tried to make this as simple as possible. By default it will use ROC-AUC as its objective metric for LightGBM/XGBoost and Log Loss for CatBoost.  For speed, when optimising a CatBoost model this function is designed to work with GPU. Some CatBoost parameters aren't yet written to work with GPU so I've left them out. LightGBM and XGBoost work quickly with Hyperopt on CPU alone but I've left options for activating them in the code - simply uncomment the relevant lines. For LightGBM you'll have to compile the GPU version in your kernel by following the steps here.  You may want to include other parameters in the search space or remove others; hopefully the code is transparent enough for you to work out how to modify it yourself according to your needs. For example, you may want to use different evaluation metrics, learning rate ranges or model objectives.  The default objective metric for this function is Mean Absolute Error (MAE). For many regression tasks, Root Mean Squared Error (RMSE) is the preferred metric. Be sure to change this in the code below if required.   Data Preparation Your data does not need any special preperation before using quick_hyperopt() beyond the requirements of the desired model (CatBoost for example may complain about NaNs and infinite values). Simply separate the features from the labels/targets. The training features can be either a Pandas DataFrame or 2-D NumPy array. The labels can be either a Pandas Series, a single-column Pandas DataFrame or a flattened 1-D NumPy array.";Apache 2.0;https://www.kaggle.com/bigironsphere/parameter-tuning-in-one-function-with-hyperopt;1.0;['catboost', 'xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'gbm', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'training data', 'regression', 'train', 'fitting', 'model', 'loss', 'label', 'predict', 'recommend', 'classification', 'bayesian'];https://www.kaggle.com/c/LANL-Earthquake-Prediction;0.744;0.515;2020-12-13 13:01:16;multiple data sources;['optimization'];Parameter Tuning in One Function with Hyperopt;Python notebook;8772.0;123;2.58504;1.49914
2019-04-07 15:25:23;LANL Earthquake EDA and PredictionDataset used: LANL Earthquake Prediction  Content Introduction  Prepare the data analysis  Data exploration  Feature engineering Model Submission  References;Apache 2.0;https://www.kaggle.com/gpreda/lanl-earthquake-eda-and-prediction;1.0;['catboost', 'xgboost', 'sklearn', 'lightgbm'];['ai', 'gbm', 'rl', 'nn', 'ann'];['filter', 'training data', 'regression', 'test data', 'train', 'model', 'neural network', 'layer', 'label', 'predict'];https://www.kaggle.com/c/LANL-Earthquake-Prediction;0.802;0.612;2020-12-13 13:01:16;LANL Earthquake Prediction;[];LANL Earthquake EDA and Prediction;Python notebook;49671.0;546;;
2019-05-19 22:21:00;LANL Earthquake New Approach EDA Content Introduction  Prepare the data analysis  Calculate aggregated features New features exploration  Conclusions  References;Apache 2.0;https://www.kaggle.com/gpreda/lanl-earthquake-new-approach-eda;1.0;['xgboost', 'sklearn', 'lightgbm'];['ai', 'ml', 'gbm'];['filter', 'machine learning', 'test data', 'train', 'model', 'layer', 'label', 'predict'];https://www.kaggle.com/c/LANL-Earthquake-Prediction;0.73;0.501;2020-12-13 13:01:16;LANL Earthquake Prediction;['data visualization, exploratory data analysis, feature engineering'];LANL Earthquake New Approach EDA;Python notebook;6162.0;102;;
2019-02-17 18:30:03;General informationJust Andrew's Data Munging plus a quick Genetic Programming Model;Apache 2.0;https://www.kaggle.com/scirpus/andrews-script-plus-a-genetic-program-model;1.0;['catboost', 'xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'gbm', 'nn', 'ann'];['filter', 'regression', 'train', 'model', 'label'];https://www.kaggle.com/c/LANL-Earthquake-Prediction;0.765;0.55;2020-12-13 13:01:16;LANL Earthquake Prediction;[];Andrews Script plus a Genetic Program  Model;Python notebook;15511.0;205;2.68973;1.44872
2020-04-09 10:17:13;IntroductionIn this kernel, I will walk you through some methods used to denoise seismic signals (and other signals in general) and explain exactly how they work. We will look at Wavelet Denoising with High-Pass Filters and Average Smoothing. The first method is used to remove the artificial impulse and the latter one is used to remove general noise.The main problem in the specific case of seismic signals is the fact that the signal we measure with a seismograph is not an accurate representation of the actual underground seismic signal we are trying to uncover. In seismology, we (the people trying to measure the seismic signals) artificially generate signals called impulse signals. These impulse signals interact with the Earth's actual seismic signal (which is what we need) to produce the final signal which our seismograph picks up (this same process takes place in the laboratory simulation of an earthquake). So, the real challenge is to uncover the actual signal from mixed seismogram (which is a combination of the Earth's impulse signal and the artificial impulse signal). This actual underlying signal would be a better predictor of earthquake timing than the original raw signal, because it represents the actual seismic activity.;Apache 2.0;https://www.kaggle.com/tarunpaparaju/lanl-earthquake-prediction-signal-denoising;1.0;['statsmodels', 'lightgbm', 'pattern'];['ner', 'ai', 'dl', 'gbm', 'rl', 'nn'];['train', 'model', 'filter', 'predict'];https://www.kaggle.com/c/LANL-Earthquake-Prediction;0.733;0.528;2020-12-13 13:01:16;LANL Earthquake Prediction;['data visualization, exploratory data analysis, data cleaning, +1 moresignal processing'];LANL Earthquake Prediction : Signal Denoising;Python notebook;6674.0;148;;
2019-05-03 04:27:51;"Kaggle LANL Earthquake Prediction ModelingKevin MaherRegis University MSDS696 Data Science Practicum IIAssociate Professor Dr. Robert MasonMay 2, 2019Spring, 2019; In partial fullfillment of the Master of Science in Data Science degree, Regis University, Denver, CO";Apache 2.0;https://www.kaggle.com/vettejeep/masters-final-project-model-lb-1-392;1.0;['xgboost', 'lightgbm', 'catboost', 'sklearn', 'tensorflow', 'keras'];['ner', 'ai', 'dl', 'gbm', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'predict', 'ground truth', 'machine learning', 'training data', 'train', 'recommend', 'linear regression', 'model', 'support vector machines', 'rank', 'understanding', 'decision tree', 'supervised learning', 'test data', 'regression', 'generation', 'fitting', 'validation data', 'deep learning', 'label', 'gradient boosting', 'random forest'];https://www.kaggle.com/c/LANL-Earthquake-Prediction;0.757;0.563;2020-12-13 13:01:16;LANL Earthquake Prediction;[];"Masters Final Project – Model; LB~1.392";Python notebook;12418.0;250;;
2016-12-28 19:09:59;"NOTE: I managed to get an LB of 0.0052 with this code, but due to some randomness still in the script, the score varies between 0.016 and 0.005. Using some form of kfold-validation reduces this variance. EDIT: I would run this somewhere other than Kaggle locally for 150 epochs instead of 89 like I have it set to below; 89 is the best I could do without the script timing out. The IdeaI started this competition by simply feeding the pre-extracted features into a multi-layer perceptron with one hidden layer and got surprisingly good results, but I still had all this image data that I wasn't using. My immediate thought then was to simply combine a convolutional neural network on the images with the pre-extracted features MLP and train the entire model end to end. Keras's functional API gives us a really easy way to do this. Below, I'll outline the process of getting this model working along, point out some nice resources to learning about convolutional nets, and do some visualization of what the neural network is actually doing. But before we do that, let's just get all the data loading out of the way.";Apache 2.0;https://www.kaggle.com/abhmul/keras-convnet-lb-0-0052-w-visualization;1.0;['tensorflow', 'sklearn', 'keras', 'theano'];['ner', 'ai', 'cnn', 'rl', 'ml', 'nn', 'ann'];['filter', 'training data', 'test data', 'train', 'model', 'neural network', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'classification', 'convolutional neural network', 'hidden layer'];https://www.kaggle.com/c/leaf-classification;0.776;0.505;2020-12-13 13:03:36;Leaf Classification;[];Keras ConvNet LB 0.0052 w/ Visualization;Python notebook;21633.0;108;0.00899;0.00899
2016-12-01 09:39:02;I've noticed that all types of features contain 64 samples. So it would be good to split them into different dimensions and after it we will have input shape (64, 3) for one sample. The simple network described below gives 96% - 98% (depends on random initialization) accuracy on validation set with size 0.1 and  0.05467 of score in Kaggle competition on test set.;Apache 2.0;https://www.kaggle.com/alexanderlazarev/simple-keras-1d-cnn-features-split;1.0;['tensorflow', 'sklearn', 'keras'];['ai'];['filter', 'train', 'model', 'epoch', 'validation data', 'layer', 'label', 'loss', 'relu'];https://www.kaggle.com/c/leaf-classification;0.797;0.4;2020-12-13 13:03:36;Leaf Classification;[];Simple Keras 1D CNN + features split;Python notebook;40946.0;29;;
2017-04-13 18:57:32;"IntroHello! This is a short guide on how to set up basic classifiers for the ""Leaf Classification"" dataset. I'm still a novice in the field, I've been poking around Kaggle for a while now, so this is more of a notebook for myself, to keep track of what I am learning, than an actual guide. Suggestions and comments are more than welcome! I will use three of the simplest classification methods (Naïve Bayes, Random Forest and Logistic Regression) and, given the high number of features in this dataset, I will briefly comment on how to reduce their correlation with Principal Component Analysis.";Apache 2.0;https://www.kaggle.com/asparago/3-basic-classifiers-and-features-correlation;1.0;['pattern', 'sklearn'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['training data', 'random forest', 'regression', 'train', 'fitting', 'model', 'loss', 'label', 'logistic regression', 'predict', 'decision tree', 'classification', 'naive bayes', 'bayesian'];https://www.kaggle.com/c/leaf-classification;0.754;0.379;2020-12-13 13:03:36;Leaf Classification;['classification, random forest, logistic regression, +1 morenaive bayes'];3 Basic Classifiers and Features Correlation;Python notebook;11434.0;23;;
2016-11-27 11:29:52;Shapelets for time series classificationHello everyone, in this notebook, I would like to show an implementation of shapelet feature extraction. The nice thing about this extraction technique is that it is somewhat interpretable and delivers some insight. Moreover, this technique can be applied on all 1-D series (time-series or converted contours of objects);Apache 2.0;https://www.kaggle.com/group16/shapelets;1.0;['skimage'];['ner', 'ai', 'nn', 'ann'];['label', 'classification'];https://www.kaggle.com/c/leaf-classification;0.727;0.327;2020-12-13 13:03:36;Leaf Classification;[];Shapelets;Python notebook;5734.0;13;;
2016-09-04 20:20:50;Which Classifier is Should I Choose?This is one of the most import questions to ask when approaching a machine learning problem. I find it easier to just test them all at once. Here's 10 of your favorite Scikit-Learn algorithms applied to the leaf data.;Apache 2.0;https://www.kaggle.com/jeffd23/10-classifier-showdown-in-scikit-learn;1.0;['sklearn'];['ner', 'ai', 'gan', 'nn', 'ann'];['machine learning', 'predict', 'train', 'label', 'loss'];https://www.kaggle.com/c/leaf-classification;0.813;0.579;2020-12-13 13:03:36;Leaf Classification;[];10 Classifier Showdown in Scikit-Learn;Python notebook;71678.0;318;;
2017-03-15 18:08:58;IntroStep-by-step guide for extracting features from shapes by turning them into time-series. The functions are optimized for the Swedish Leaf Dataset as it is published on Kaggle. Data Scientists spend vast majority of their time by data preparation, not model optimization. So let's dive into that a bit. Here is the second part, it is more advanced and follows PEP8;Apache 2.0;https://www.kaggle.com/lorinc/feature-extraction-from-images;1.0;['skimage'];['ner', 'ai', 'nn'];['model', 'classification'];https://www.kaggle.com/c/leaf-classification;0.809;0.539;2020-12-13 13:03:36;Leaf Classification;[];feature extraction from images;Python notebook;62186.0;174;;
2016-11-18 16:40:18;Input:  image (jpg) 8bit grayscale high contrast noisy  Output  a 2 Standard Deviation sized, 1st eigenvector-rotated ellipse a Gaussian smoothed leaf shape the leaf contour  Tested thoroughly, pretty robust. During the feature extraction  images are rotated, clipped, resampled noise is removed converted to 1bit   contours are  transformed into time series downsampled to the same number of points    This enables comparison and machine learning. Next steps:  finding and quantifying symmetry, eccentricity, concaveness describing the three shapes independently from size and rotation describing multiple levels of variability (fourier transform?);Apache 2.0;https://www.kaggle.com/lorinc/feature-extraction-v4;1.0;['skimage', 'sklearn'];['ner', 'ai'];['filter', 'machine learning'];https://www.kaggle.com/c/leaf-classification;0.719;0.319;2020-12-13 13:03:36;Leaf Classification;[];feature extraction v4;Python notebook;4688.0;12;;
2016-09-11 18:18:46;Leaf ClassificationUsing Neural Networks through Keras;Apache 2.0;https://www.kaggle.com/najeebkhan/neural-network-through-keras;1.0;['keras', 'sklearn', 'theano'];['ai', 'rl', 'nn', 'cv'];['training data', 'neuron', 'train', 'fitting', 'model', 'neural network', 'epoch', 'layer', 'loss', 'label', 'predict', 'classification'];https://www.kaggle.com/c/leaf-classification;0.737;0.357;2020-12-13 13:03:36;Leaf Classification;[];Neural Network through Keras;Python notebook;7384.0;18;;
2017-10-26 01:50:11;Visualizing K-Means with Leaf DatasetThis script is about perhaps the simplest and most popular unsupervised learning algorithm out there: the K-Means clustering algorithm. In this script we will apply K-Means on a small dataset of 1600 binary leaf images with different shapes and try to get a feel for the distribution of leaf images using different visualizations that clarify different aspects about how one can interpret K-Means results. We will then continue to see if the K-Means features (distances from cluster centers) are informative in terms of classifying leafs and determine what is the optimal K (number of clusters) for the sake of leaf type classification. Note: This script is a follow-up script to the PCA script which is very similar but about PCA.;Apache 2.0;https://www.kaggle.com/selfishgene/visualizing-k-means-with-leaf-dataset;1.0;['pattern', 'skimage', 'sklearn'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ann'];['test data', 'random forest', 'regression', 'train', 'model', 'supervised learning', 'clustering', 'label', 'k-means', 'logistic regression', 'predict', 'unsupervised learning', 'classification'];https://www.kaggle.com/c/leaf-classification;0.756;0.452;2020-12-13 13:03:36;Leaf Classification;['beginner, data visualization, model comparison, +1 morek-means'];Visualizing K-Means with Leaf Dataset;Python notebook;12024.0;54;;
2017-09-22 11:37:18;Visualizing PCA with Leaf DatasetIn this script we will apply PCA on leaf images and try to get a feel for the distribution of leaf images using visualizations that (hopefully) clarify different aspects about how to interpret PCA results. We will then continue to see if the PCA features are informative in terms of classifying leafs and determine how many of those we need. I've just updated another script, similar in nature to this one, just focused about k-means. if you enjoyed this one, be sure to also check out the k-means script as well;Apache 2.0;https://www.kaggle.com/selfishgene/visualizing-pca-with-leaf-dataset;1.0;['skimage', 'sklearn'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ann'];['random forest', 'regression', 'train', 'model', 'label', 'k-means', 'logistic regression', 'predict', 'classification'];https://www.kaggle.com/c/leaf-classification;0.766;0.487;2020-12-13 13:03:36;Leaf Classification;['data visualization, model comparison, pca, +1 moreintermediate'];Visualizing PCA with Leaf Dataset;Python notebook;16268.0;85;;
2017-02-12 12:36:29;This is based on the 10 Classifier Showdown in Scikit-Learn Notebook by Jeff Delaney;Apache 2.0;https://www.kaggle.com/udaysa/svm-with-scikit-learn-svm-with-parameter-tuning;1.0;['sklearn'];['cv', 'ai', 'gan'];['train', 'model', 'loss', 'label', 'predict', 'classification'];https://www.kaggle.com/c/leaf-classification;0.778;0.311;2020-12-13 13:03:36;Leaf Classification;[];SVM with Scikit-Learn (SVM with parameter tuning);Python notebook;22740.0;11;;
2020-11-21 19:40:24;Mechanisms of Action (MoA) Prediction: EDA Image credit: https://www.labiotech.eu/cancer/forx-therapeutics-cancer-treatment/ In this competition, we are suposed to develop algorithms and train models to determine the mechanism of action of a new drug based on the gene expression and cell viability information. In this EDA, we will try to find patterns in the data, interactions between the targets in both scored and nonscored datasets and the relationship between targets and their target genes.  PROJECT CONTENT 1- FEATURES OVERVIEW2- CELL VIABILITY FEATURES3. GENE EXPRESSION FEATURES4. TARGETS (MoA)4.1 Scored targets4.2 Non-Scored targets4.3 Drug_ID  5. TEST FEATURES;Apache 2.0;https://www.kaggle.com/amiiiney/drugs-moa-classification-eda;1.0;['pattern'];['ner', 'ai', 'gan', 'cv', 'rl', 'nn'];['filter', 'test data', 'train', 'model', 'label', 'predict', 'understanding', 'classification'];https://www.kaggle.com/c/lish-moa;0.754;0.559;2020-12-13 13:16:12;Mechanisms of Action (MoA) Prediction;['exploratory data analysis, biology, genetics'];Drugs MoA classification: EDA;Python notebook;11580.0;235;;
2020-11-18 23:48:56;RAPIDS - Genetic Algorithm KNN - [CV 0.01840]The RAPIDS library is now available in all Kaggle notebooks. Hooray! Simply type import cuml or import cudf to load the two most popular packages. RAPIDS is described here. RAPIDS cuDF accelerates dataframe operations using GPU and has a similar api as Pandas. RAPIDS cuML accelerates machine learning algorithms using GPU and has a similar api as Scikit-Learn. Since RAPIDS ML algorithms are so fast, we can do things that were never possible like applying genetic algorithms to ML hyperparameter searchs! The ML algorithm kNN is very sensitive to the scaling of the feature columns. In this notebook, we find the weights for feature columns (0 <= w <= 1) using a genetic algorithm. This is similar to a feature selection algorithm like ridge regression which shrinks the importance of features. Alternatively we could mimic lasso regression if we choose only weights w = 0 and w = 1.;Apache 2.0;https://www.kaggle.com/cdeotte/rapids-genetic-algorithm-knn-cv-0-01840;1.0;['sklearn'];['ner', 'ai', 'cv', 'rl', 'nn', 'ml'];['filter', 'machine learning', 'regression', 'generation', 'train', 'test data', 'model', 'loss', 'label', 'predict'];https://www.kaggle.com/c/lish-moa;0.716;0.538;2020-12-13 13:16:12;multiple data sources;['gpu'];RAPIDS - Genetic Algorithm KNN - [CV 0.01840];Python notebook;4396.0;172;;
2020-09-10 11:05:23;Framing as a binary classification problemIn this notebook I create a baseline model using XGBoost and framing the problem as a n-binary classification problems (where n=206 and is the total number of classes). I make use of the MultiOutputClassifier wrapper in sklearn. This has the advantages that :  You can use models capable only of binary classification It is easy to implement  But has the disadvantages that:  You lose any correlation between labels which could be useful to the model You need to train n models and is therefore slow  Updates (started version 9)  v9:  dropped ctl_vehicle instances in-fold, kept in validation;Apache 2.0;https://www.kaggle.com/fchmiel/xgboost-baseline-multilabel-classification;1.0;['xgboost', 'sklearn'];['ai'];['filter', 'train', 'model', 'loss', 'label', 'predict', 'classification'];https://www.kaggle.com/c/lish-moa;0.762;0.558;2020-12-13 13:16:12;Mechanisms of Action (MoA) Prediction;['gpu, xgboost, multilabel classification'];XGBoost baseline - multilabel classification;Python notebook;14169.0;230;;
2020-10-24 17:22:57;"DISCLAIMER The following notebook it's highly based on the works TabNetRegressor 2.0 [TRAIN + INFER], MOA competition and  MoA | Pytorch | 0.01859 | RankGauss | PCA | NN, please check it out. I have to add that i don't make this notebook for ""upvotes"" but feedback.";Apache 2.0;https://www.kaggle.com/hiramcho/moa-tabnet-with-pca-rank-gauss;1.0;['pytorch', 'sklearn'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ml'];['filter', 'machine learning', 'regression', 'train', 'model', 'epoch', 'deep learning', 'loss', 'label', 'predict', 'rank'];https://www.kaggle.com/c/lish-moa;0.766;0.538;2020-12-13 13:16:12;multiple data sources;['beginner, tabular data, pytorch, +1 moregenetics'];MoA Predictions 🧬: Overfitting with TabNet;Python notebook;16256.0;170;0.01629;0.01848
2020-10-26 04:00:19;This is an Updated version of my previous public kernel https://www.kaggle.com/kushal1506/moa-pytorch-0-01859-rankgauss-pca-nn;Apache 2.0;https://www.kaggle.com/kushal1506/moa-pytorch-feature-engineering-0-01846;1.0;['pytorch', 'sklearn'];['ai', 'dl', 'cv', 'rl', 'nn', 'ml'];['filter', 'train', 'model', 'epoch', 'loss', 'label', 'predict', 'rank', 'relu'];https://www.kaggle.com/c/lish-moa;0.743;0.546;2020-12-13 13:16:12;multiple data sources;['gpu'];MoA | Pytorch | Feature Engineering | 0.01846;Python notebook;8510.0;193;0.01631;0.01844
2020-10-13 22:13:08;Source Pytorch 1.6 : https://pytorch.org/docs/stable/ iterative-stratification : https://github.com/trent-b/iterative-stratification for stratified K fold multilabel TabNet : https://arxiv.org/pdf/1908.07442.pdf https://github.com/dreamquark-ai/tabnet;Apache 2.0;https://www.kaggle.com/ludovick/introduction-to-tabnet-kfold-10-inference;1.0;['pytorch', 'sklearn'];['ai', 'rl', 'cv', 'nn', 'ml'];['activation function', 'training data', 'regression', 'train', 'model', 'neural network', 'epoch', 'validation data', 'layer', 'loss', 'label', 'predict', 'relu', 'decision tree', 'supervised learning'];https://www.kaggle.com/c/lish-moa;0.737;0.527;2020-12-13 13:16:12;multiple data sources;[];Introduction to TabNet - Kfold 10 [INFERENCE];Python notebook;7270.0;146;;
2020-09-18 06:02:56;If you are looking for a team member, do consider me too !;Apache 2.0;https://www.kaggle.com/namanj27/new-baseline-pytorch-moa;1.0;['pytorch', 'sklearn'];['ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'train', 'model', 'epoch', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/lish-moa;0.768;0.594;2020-12-13 13:16:12;multiple data sources;['beginner, tabular data, medicine, +1 moremultilabel classification'];[New Baseline] Pytorch | MoA;Python notebook;17083.0;409;;
2020-10-27 07:17:02;I'll check distributions of g- and c- of train and test set. They are spiky distribution rather than normal distribution. Regardless of the train and test, they look be in the same shape.;Apache 2.0;https://www.kaggle.com/riadalmadani/pytorch-cv-0-0145-lb-0-01839;1.0;['sklearn'];['ai', 'dl', 'cv', 'rl', 'nn', 'ml'];['filter', 'train', 'model', 'epoch', 'loss', 'label', 'predict', 'rank', 'relu'];https://www.kaggle.com/c/lish-moa;0.753;0.525;2020-12-13 13:16:12;multiple data sources;['pca'];Pytorch CV|0.0145| LB| 0.01839 | ;Python notebook;11289.0;142;;
2020-09-06 20:31:54;0) Set tf random seed, fix typos in preprocess. 1) Based on Version 6 of https://www.kaggle.com/stanleyjzheng/baseline-nn-with-k-folds kernel. 2) Add 7-MultilabelStratifiedKFold, 7 seeds averaging. 3) Add WeightNormalization, Lookahead, ReduceLROnPlateau. 4) Put zeros for ctl_vehicle predictions. 5) Remove control group from training and validation. 6) Model checkpoints (from https://www.kaggle.com/ravy101/drug-moa-tf-keras-starter kernel) 7) Small architecture tune (lb - near noise effect). 8) Feature selection (on full validation): top features by permutation importance (lb - same as 7). What doesn't work* for me: pretrain on nonscored targets training on both scored and nonscored targets RAdam, AdamW weighted loss, focal loss (probably my mistake) selu, leaky-relu pseudolabeling (this version)  *based on local cross validation. In future versions: ...;Apache 2.0;https://www.kaggle.com/simakov/keras-multilabel-neural-network-v1-2;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'nn', 'ml'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/lish-moa;0.757;0.55;2020-12-13 13:16:12;multiple data sources;['gpu'];keras Multilabel Neural Network v1.2;Python notebook;12473.0;204;0.01654;0.01895
2020-10-29 05:22:40;"About this NotebookHello everyone , Its been long since I have written a detailed notebook in the way I love to and I was itching to do so. Kaggle competitions can be very intimidating at times given they not only need good machine learning skills but also heavy domain knowledge. People always ask me how and where to start with kaggle , how do I manage to do good in competitions which require heavy domain knowledge , What level of knowledge do we need before starting a Kaggle competition ,etc . This notebook is meant to answer all those questions and is specially for anyone who wants to start with live competitions but is overwhelmed by the shear amount of things that a live competitions bring to the table. I was thinking of writing this from a long time now , but I was waiting for the right competition and here we have it , ""good old tabular competition"" which is a rare sight at kaggle. So without any further delay if you want to get started with live kaggle competitions or want to do good in kaggle competitions or need a detailed pathway on approaching kaggle competitions,etc , be sure to stick with me till the end of this notebook as   This is a step by step guide on How to Tackle Any Kaggle Competition : The Noob's Way  Note :- This notebook is a part of my Series : Mr KnowNothing's Weekends , in which I have planned a lot of more things ,if you liked this notebook and are interested in more such content you can know more about the series and follow along here  Important Note : All the steps/advices which I give in this notebook are from my personal experience and contain methods which I personally use.  I still consider myself a Kaggle Noob who is trying to learn,hence everything which I write might not be the optimal way , its just a guide to help people, I request all Kagglers to correct me in the comments if they feel there might be a better approach for what I am following now . I would really appreciate views of other Kagglers      , Thanks";Apache 2.0;https://www.kaggle.com/tanulsingh077/tackling-any-kaggle-competition-the-noob-s-way;1.0;['pattern', 'xgboost', 'sklearn'];['ner', 'ai', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'regression', 'train', 'model', 'reward', 'clustering', 'loss', 'label', 'lstm', 'predict', 'rank', 'understanding', 'classification'];https://www.kaggle.com/c/lish-moa;0.728;0.53;2020-12-13 13:16:12;Mechanisms of Action (MoA) Prediction;['gpu, beginner, exploratory data analysis, +1 morexgboost'];Tackling any Kaggle Competition : The Noob's Way;Python notebook;5862.0;152;;
2020-11-27 03:47:49;Main Idea write your inference as python scripts so that each time it should clear the cache and reset the state submit sample submission to pass through initial commit run all inference codes for whole test set;Apache 2.0;https://www.kaggle.com/underwearfitting/make-final-submission-the-efficient-way;1.0;['pytorch'];['ai', 'cv'];['lstm', 'resnet'];https://www.kaggle.com/c/lish-moa;0.763;0.537;2020-12-13 13:16:12;multiple data sources;[];Make Final Submission: the efficient way;Python notebook;14565.0;169;0.01616;0.01820
2020-10-13 15:10:49;If you like, pls upvote and check my other kernelhttps://www.kaggle.com/utkukubilay/notebooks -> orginal kernel https://www.kaggle.com/namanj27/new-baseline-pytorch-moa?scriptVersionId=42580548-> LGBM Model https://www.kaggle.com/utkukubilay/drug-prediction-lgbm-model;Apache 2.0;https://www.kaggle.com/utkukubilay/pytorch-moa-0-01867;1.0;['pytorch', 'sklearn'];['ai', 'dl', 'gbm', 'cv', 'rl', 'nn', 'ml'];['filter', 'train', 'model', 'epoch', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/lish-moa;0.739;0.529;2020-12-13 13:16:12;multiple data sources;['gpu, deep learning, classification, +2 morepython, tensorflow'];Pytorch | MoA | 0.01867;Python notebook;7750.0;151;;
2020-11-19 13:51:42;If you Like It Please Upvote It;Apache 2.0;https://www.kaggle.com/vikazrajpurohit/3-model-training-and-inference;1.0;['pytorch', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'ml', 'nlp', 'nn', 'ann'];['filter', 'training data', 'regression', 'train', 'model', 'neural network', 'epoch', 'validation data', 'layer', 'loss', 'label', 'predict', 'relu', 'recommend', 'resnet'];https://www.kaggle.com/c/lish-moa;0.799;0.533;2020-12-13 13:16:12;multiple data sources;['gpu'];3 MODEL Training and Inference;Python notebook;44155.0;159;0.01614;0.01824
2020-09-08 15:58:33;About this notebook PyTorch NN starter code MultilabelStratifiedKFold 5 folds   If this notebook is helpful, feel free to upvote :);Apache 2.0;https://www.kaggle.com/yasufuminakama/moa-pytorch-nn-starter;1.0;['pytorch', 'sklearn'];['ai', 'dl', 'cv', 'nn', 'rnn', 'ml'];['filter', 'train', 'model', 'epoch', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/lish-moa;0.758;0.585;2020-12-13 13:16:12;multiple data sources;['gpu'];MoA / PyTorch NN starter;Python notebook;12869.0;351;0.01676;0.01909
2020-03-04 19:02:51;One Feature Model Scores LB 0.930!In this notebook, we will explore the Kaggle Ion Comp data and explore a one feature model. The LB result of 0.930 is enlightening. Here we manually remove signal drift. Note that it is better to use machine learning to remove drift, but doing it by hand once allows us to understand its nature and build better models later.;Apache 2.0;https://www.kaggle.com/cdeotte/one-feature-model-0-930;1.0;['sklearn'];['ner', 'ai', 'ml', 'nn', 'ann'];['machine learning', 'training data', 'test data', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/liverpool-ion-switching;0.775;0.605;2020-12-13 13:17:30;University of Liverpool - Ion Switching;[];One Feature Model - [0.930];Python notebook;20849.0;484;0.91544;0.92788
2020-03-18 18:50:25;Simple kNN scores LB 0.938 in 30 seconds!In this notebook, we build a simple model using Nvidia RAPIDS cuML's blazingly fast kNN algorithm. The high CV and LB of this model confirms the simple nature of Kaggle's Ion Switching competition data. We will be using this competition's cleaned dataset posted here. So this notebook also shows that the clean dataset is infact very clean. Feel free to use the clean dataset in your future notebooks and don't forget to upvote the clean dataset :-) The clean dataset uses Markus' great cleaning method here.;Apache 2.0;https://www.kaggle.com/cdeotte/rapids-knn-30-seconds-0-938;1.0;['xgboost', 'sklearn'];['ner', 'ai', 'dl', 'cv', 'ml', 'nn', 'ann'];['filter', 'training data', 'test data', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/liverpool-ion-switching;0.749;0.555;2020-12-13 13:17:30;multiple data sources;['gpu'];RAPIDS kNN - 30 seconds - [0.938];Python notebook;10159.0;220;0.93194;0.93819
2020-03-20 15:08:14;"Introduction The problem we are trying to solve in this competition is known as a Hidden Markov Model. There exists an algorithm which finds the most probable solution for such problems without any ""real machine learning"": the Viterbi algorithm. In this notebook, I explain this algorithm and apply it to the problem at hand. Since the organizers have mentioned the Viterbi algorithm several times, I think it's instructive to demonstrate it here, even though it also results in a LB score of only ~0.935, providing further confirmation for the fact that there simpy isn't any additional information available in the data.";Apache 2.0;https://www.kaggle.com/friedchips/the-viterbi-algorithm-a-complete-solution;1.0;['sklearn'];['ai', 'gan', 'rl', 'nn', 'ann'];['machine learning', 'training data', 'test data', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/liverpool-ion-switching;0.704;0.505;2020-12-13 13:17:30;multiple data sources;['data visualization'];The Viterbi Algorithm - A Complete Solution;Python notebook;3312.0;108;0.92589;0.93222
2020-02-27 08:30:31;IntroductionIn this kernel, I'd like to share the approach using 1D Convolutional Neural Networks(1D CNN). 1D CNN is sometimes effective to analyze time series data. This kernel introduces U-Net architecture with 1D CNN.;Apache 2.0;https://www.kaggle.com/kmat2019/u-net-1d-cnn-with-keras;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cnn', 'rl', 'nn', 'ann'];['regression', 'train', 'model', 'neural network', 'epoch', 'layer', 'loss', 'predict', 'relu', 'resnet', 'classification', 'u-net', 'convolutional neural network'];https://www.kaggle.com/c/liverpool-ion-switching;0.745;0.521;2020-12-13 13:17:30;University of Liverpool - Ion Switching;['gpu, beginner, cnn'];U-Net(1D CNN) with Keras;Python notebook;8960.0;135;0.86543;0.91669
2020-02-27 21:56:53;EDA - Ion SwitchingMany diseases, including cancer, are believed to have a contributing factor in common. Ion channels are pore-forming proteins present in animals and plants. They encode learning and memory, help fight infections, enable pain signals, and stimulate muscle contraction. If scientists could better study ion channels, which may be possible with the aid of machine learning, it could have a far-reaching impact. When ion channels open, they pass electric currents. Existing methods of detecting these state changes are slow and laborious. Humans must supervise the analysis, which imparts considerable bias, in addition to being tedious. These difficulties limit the volume of ion channel current analysis that can be used in research. Scientists hope that technology could enable rapid automatic detection of ion channel current events in raw data.   I'll update this EDA notebook in the following days/weeks. Stay tuned!;Apache 2.0;https://www.kaggle.com/pestipeti/eda-ion-switching;1.0;['lightgbm', 'sklearn'];['ai', 'gbm', 'rl', 'nn', 'ann'];['machine learning', 'regression', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/liverpool-ion-switching;0.729;0.515;2020-12-13 13:17:30;University of Liverpool - Ion Switching;['exploratory data analysis, time series analysis'];EDA - Ion Switching;Python notebook;6023.0;123;0.81821;0.91021
2020-04-03 21:21:13;Thanks to https://www.kaggle.com/siavrez/wavenet-keras, learned a lot.;Apache 2.0;https://www.kaggle.com/ragnar123/wavenet-with-1-more-feature;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'cv', 'rl', 'nn', 'rnn', 'ann'];['filter', 'training data', 'train', 'model', 'epoch', 'validation data', 'layer', 'loss', 'predict', 'classification'];https://www.kaggle.com/c/liverpool-ion-switching;0.735;0.498;2020-12-13 13:17:30;multiple data sources;['gpu'];Wavenet with 1 more feature;Python notebook;7029.0;98;0.93970;0.94102
2020-03-02 03:50:11;A Simple EDA with minimal Description. The model is just some minor changes to physically-possible One of the charts (plot_rolling_window) is from eda-ion-switching and the denoising functions are from dwt-signal-denoising;Apache 2.0;https://www.kaggle.com/siavrez/simple-eda-model;1.0;['statsmodels', 'xgboost', 'lightgbm', 'catboost', 'sklearn'];['ai', 'gbm', 'rl', 'nn', 'ann'];['filter', 'train', 'model', 'loss', 'label', 'predict'];https://www.kaggle.com/c/liverpool-ion-switching;0.732;0.507;2020-12-13 13:17:30;University of Liverpool - Ion Switching;['gpu'];Simple EDA-Model;Python notebook;6480.0;110;0.82736;0.93807
2020-04-04 17:46:55;The validation scheme is based on seq2seq-rnn-with-gru, and cleaned data is from data-without-drift and Kalman filter is from https://www.kaggle.com/teejmahal20/single-model-lgbm-kalman-filter and the added feature is from wavenet-with-1-more-feature. I also used ragnar's data in this version clean-kalman. The Wavenet is based on https://github.com/philipperemy/keras-tcn, https://github.com/peustr/wavenet and https://github.com/basveeling/wavenet and also https://www.kaggle.com/wimwim/wavenet-lstm. If any refrence is not mentioned it was not intentional, please add them in comments. Previous versions were mainly based on https://www.kaggle.com/wimwim/wavenet-lstm;Apache 2.0;https://www.kaggle.com/siavrez/wavenet-keras;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'nn', 'rnn', 'ann'];['gru', 'filter', 'train', 'model', 'epoch', 'layer', 'loss', 'lstm', 'predict', 'classification', 'propagation'];https://www.kaggle.com/c/liverpool-ion-switching;0.773;0.549;2020-12-13 13:17:30;multiple data sources;['gpu'];WaveNet-Keras;Python notebook;19532.0;201;0.94002;0.94127
2020-08-11 00:05:04;University of Liverpool - Ion Switching;Apache 2.0;https://www.kaggle.com/vbmokin/ion-switching-advfe-lgb-wavenet-confmatrix;1.0;['xgboost', 'lightgbm', 'sklearn', 'tensorflow', 'keras'];['ai', 'gbm', 'cv', 'rl', 'ml', 'nlp', 'nn', 'rnn', 'ann'];['filter', 'training data', 'regression', 'train', 'model', 'epoch', 'validation data', 'layer', 'loss', 'label', 'logistic regression', 'predict', 'relu', 'recommend', 'classification'];https://www.kaggle.com/c/liverpool-ion-switching;0.764;0.522;2020-12-13 13:17:30;multiple data sources;['classification, feature engineering'];Ion Switching - AdvFE, LGB, Wavenet, ConfMatrix;Python notebook;15364.0;137;0.93737;0.93934
2020-01-02 11:52:24;There are 19 variables of categorical types and 653 is of float type and 99 is of integeral value.;Apache 2.0;https://www.kaggle.com/shadab123456/loan-default-prediction-new;1.0;['sklearn'];['ner', 'ai', 'cv', 'rl', 'nn', 'ann'];['machine learning', 'test data', 'regression', 'random forest', 'train', 'fitting', 'model', 'loss', 'label', 'logistic regression', 'predict', 'classification'];https://www.kaggle.com/c/loan-default-prediction;0.622;0.0;2020-12-13 13:17:50;Loan Default Prediction - Imperial College London;[];Loan_Default_Prediction_New;Python notebook;651.0;0;;
2020-09-08 00:43:50;Lyft: Comprehensive guide to start competition The image from L5Kit official document: http://www.l5kit.org/README.html In this kernel, I will explain how to setup develop environment & the data for this competition. The dataset structure is a bit complicated since the Lyft Level 5 dataset contains various kinds of information. Lyft provided a useful library to deal with this data, we need to learn how to fully-utilize these provided tools at first!;Apache 2.0;https://www.kaggle.com/corochann/lyft-comprehensive-guide-to-start-competition;1.0;['xgboost', 'lightgbm', 'catboost', 'sklearn', 'pytorch'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'train', 'model', 'neural network', 'layer', 'label', 'predict', 'resnet'];https://www.kaggle.com/c/lyft-motion-prediction-autonomous-vehicles;0.753;0.559;2020-12-13 13:21:25;multiple data sources;['beginner, data visualization, computer vision, +1 moreautomobiles and vehicles'];Lyft: Comprehensive guide to start competition;Python notebook;11287.0;232;;
2020-09-08 00:39:15;Lyft: Deep into the l5kit library The image from L5Kit official document: http://www.l5kit.org/README.html Continued from the previous kernel Lyft: Comprehensive guide to start competition. In this kernel, I will look into the raw data structures and l5kit library in more detail with code reading. After understanding these, I hope you can arrange the data by yourself to build a better pipleline for motion prediction. Table of Contents 1. Understanding Rasterizer class   2. Understanding EgoDataset/AgentDataset class   3. Understanding raw data structures  The first part is same with previous kernel, please jump to 1. Understanding Rasterizer class for the main topic of this kernel.;Apache 2.0;https://www.kaggle.com/corochann/lyft-deep-into-the-l5kit-library;1.0;['xgboost', 'lightgbm', 'catboost', 'sklearn', 'pytorch'];['ai', 'dl', 'cnn', 'gbm', 'rl', 'ml', 'nn', 'ann'];['filter', 'train', 'model', 'understanding', 'label', 'predict', 'recommend', 'resnet'];https://www.kaggle.com/c/lyft-motion-prediction-autonomous-vehicles;0.737;0.55;2020-12-13 13:21:25;multiple data sources;['beginner, data visualization, exploratory data analysis, +2 moreimage data, automobiles and vehicles'];Lyft: Deep into the l5kit library;Python notebook;7336.0;204;;
2020-09-26 10:26:33;Lyft: Prediction with multi-mode confidence The image from L5Kit official document: http://www.l5kit.org/README.html Continued from the previous kernel:  Lyft: Comprehensive guide to start competition Lyft: Deep into the l5kit library Lyft: Training with multi-mode confidence  In this kernel, I will run prediction code for competition submission where the model is trained in previous kernel. I uploaded trained models as dataset lyft-resnet18-baseline Please upvote the dataset as well if this kernel helps you :);Apache 2.0;https://www.kaggle.com/corochann/lyft-prediction-with-multi-mode-confidence;1.0;['xgboost', 'lightgbm', 'catboost', 'sklearn', 'pytorch'];['ai', 'gbm', 'ml', 'nn', 'ann'];['filter', 'train', 'model', 'epoch', 'layer', 'label', 'predict', 'relu', 'resnet'];https://www.kaggle.com/c/lyft-motion-prediction-autonomous-vehicles;0.735;0.509;2020-12-13 13:21:26;multiple data sources;['gpu, beginner, image data, +2 morecnn, automobiles and vehicles'];Lyft: Prediction with multi-mode confidence;Python notebook;7022.0;114;29.909;25.742
2020-09-25 06:34:42;Lyft: Training with multi-mode confidence The image from L5Kit official document: http://www.l5kit.org/README.html Continued from the previous kernel:  Lyft: Comprehensive guide to start competition Lyft: Deep into the l5kit library  In this kernel, I will run pytorch CNN model training. Especially, followings are new items to try:  Predict multi-mode with confidence: As written in evaluation metric page, we can predict 3 modes of motion trajectory. Training loss with competition evaluation metric Use Training abstraction library pytorch-ignite and pytorch-pfn-extras.  [Update 2020/9/6] Published prediction kernel: Lyft: Prediction with multi-mode confidence Try yourself how good score you can get using only single model without ensemble! :);Apache 2.0;https://www.kaggle.com/corochann/lyft-training-with-multi-mode-confidence;1.0;['xgboost', 'lightgbm', 'catboost', 'sklearn', 'pytorch'];['ner', 'ai', 'dl', 'cnn', 'gbm', 'rl', 'ml', 'nn', 'ann'];['filter', 'training data', 'train', 'model', 'neural network', 'epoch', 'validation data', 'layer', 'loss', 'label', 'predict', 'relu', 'understanding', 'resnet'];https://www.kaggle.com/c/lyft-motion-prediction-autonomous-vehicles;0.734;0.512;2020-12-13 13:21:26;multiple data sources;['gpu, beginner, image data, +2 morecnn, pytorch'];Lyft: Training with multi-mode confidence;Python notebook;6802.0;118;;
2020-11-16 14:08:03;1. IntroductionThis is an Exploratory Data Analysis (EDA) Kernel for Lyft Motion Prediction for Autonomous Vehicles competition dataset.  We start with the analysis preparation, which requires, for this competition, to install and load several packages for load and manage l5kit dataset. We follow with data exploration, reviewing the agents, the scenes, the frames and following with inspection of the animated scenes.;Apache 2.0;https://www.kaggle.com/gpreda/lyft-first-data-exploration;1.0;['pillow'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml'];['filter', 'model', 'understanding', 'label', 'predict', 'recommend', 'resnet'];https://www.kaggle.com/c/lyft-motion-prediction-autonomous-vehicles;0.692;0.462;2020-12-13 13:21:26;multiple data sources;[];Lyft First Data Exploration;Python notebook;2548.0;61;;
2020-10-11 14:27:02;Lyft: Complete train and prediction pipeline (update for l5kit 1.1.0) The image from L5Kit official document: http://www.l5kit.org/README.html This notebook is updated to be compatible with the new lyft environment, see the discussion We did it all wrong and l5kit 1.1.0 release.For a high level overview, check out this article how to build a motion prediction model for autonomous vehicles. In this notebook I present an end-to-end train and prediction pipeline to predict vehicle motions with a pretrained model included. Unfortunately because of Kaggle memory constraint we can only either run the train part or the prediction part by toggling the parameters in the config part. Some of the code here are taken from the tutorial notebook and the following kernels:  Lyft: Training with multi-mode confidence Lyft: Prediction with multi-mode confidence  which is part of a wonderful series of introductory notebooks by corochann  Lyft: Comprehensive guide to start competition Lyft: Deep into the l5kit library Save your time, submit without kernel inference Lyft: pytorch implementation of evaluation metric Lyft: Training with multi-mode confidence Lyft: Prediction with multi-mode confidence  Note: This notebook aims to create the best single possible, i.e. without any ensemeble, which should only be done near the end of the competition. Since it is still early in the competition, this notebook is still a baseline, any suggestion to improve is appreciated.;Apache 2.0;https://www.kaggle.com/huanvo/lyft-complete-train-and-prediction-pipeline;1.0;['pytorch'];['ai', 'rl', 'ml', 'nn', 'ann'];['filter', 'test data', 'train', 'model', 'epoch', 'layer', 'loss', 'predict', 'relu', 'resnet'];https://www.kaggle.com/c/lyft-motion-prediction-autonomous-vehicles;0.75;0.536;2020-12-13 13:21:26;multiple data sources;['gpu'];Lyft: Complete train and prediction pipeline;Python notebook;10216.0;167;23.515;23.622
2020-08-31 14:51:34;This is an inference kernel. Please find the training kernel here.;Apache 2.0;https://www.kaggle.com/kneroma/lgbm-on-lyft-tabular-data-inference;1.0;['lightgbm'];['dl', 'ai', 'nn', 'gbm'];['training data', 'train', 'model', 'label', 'predict', 'rank'];https://www.kaggle.com/c/lyft-motion-prediction-autonomous-vehicles;0.671;0.45;2020-12-13 13:21:28;multiple data sources;['tabular data, gradient boosting, lightgbm'];LGBM on Lyft Tabular Data [Inference];Python notebook;1662.0;53;;
2020-09-28 07:38:19;Lyft Motion Prediction for Autonomous Vehicles 🚗Build motion prediction models for self-driving vehicles🚗;Apache 2.0;https://www.kaggle.com/kool777/lyft-level5-eda-training-inference;1.0;['pytorch'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nn', 'ann'];['filter', 'training data', 'test data', 'train', 'model', 'neural network', 'deep learning', 'layer', 'loss', 'label', 'predict', 'relu', 'understanding', 'resnet', 'ground truth'];https://www.kaggle.com/c/lyft-motion-prediction-autonomous-vehicles;0.736;0.512;2020-12-13 13:21:26;multiple data sources;['gpu, beginner, exploratory data analysis, +1 morecomputer vision'];Lyft Level5: EDA + Training + Inference;Python notebook;7091.0;119;121.216;116.546
2020-11-05 09:43:35;Lyft: Understanding the data  and EDA;Apache 2.0;https://www.kaggle.com/nxrprime/understanding-the-data-catalyst-kekas-baseline;1.0;['xgboost', 'lightgbm', 'pytorch', 'albumentations', 'tensorflow'];['ner', 'ai', 'dl', 'gbm', 'rl', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'training data', 'train', 'model', 'understanding', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'recommend', 'resnet'];https://www.kaggle.com/c/lyft-motion-prediction-autonomous-vehicles;0.801;0.607;2020-12-13 13:21:24;multiple data sources;['gpu'];Understanding the data + Catalyst/Kekas baseline;Python notebook;47581.0;503;;
2020-08-26 15:30:29;Pytorch Baseline - InferenceNotes  Do not forget to enable the GPU (TPU) for training You have to add kaggle_l5kit as utility script Parts of the code below is from the official example Train notebook  Version #1 Single mode baseline (resnet-18) Trained for 25000 iterations (batch 32) Input size 300px, history 1s (10 frames) Adam (1e-3) MSE Loss  Version #2 Retrained with traffic lights;Apache 2.0;https://www.kaggle.com/pestipeti/pytorch-baseline-inference;1.0;['pytorch'];['ai', 'nn', 'ann'];['filter', 'test data', 'train', 'model', 'layer', 'loss', 'predict', 'relu', 'resnet'];https://www.kaggle.com/c/lyft-motion-prediction-autonomous-vehicles;0.748;0.535;2020-12-13 13:21:26;multiple data sources;['gpu, computer vision'];Pytorch Baseline - Inference;Python notebook;9889.0;164;140.603;134.091
2020-08-25 18:19:31;Pytorch Baseline - TrainNotes  Do not forget to enable the GPU (TPU) for training You have to add kaggle_l5kit as utility script Parts of the code below is from the official example Baseline inference notebook;Apache 2.0;https://www.kaggle.com/pestipeti/pytorch-baseline-train;1.0;['pytorch'];['ai', 'nn', 'ann'];['filter', 'train', 'model', 'layer', 'loss', 'predict', 'relu', 'resnet'];https://www.kaggle.com/c/lyft-motion-prediction-autonomous-vehicles;0.742;0.529;2020-12-13 13:21:26;multiple data sources;['gpu, beginner, deep learning, +1 morecomputer vision'];Pytorch Baseline - Train;Python notebook;8308.0;150;;
2020-09-19 07:16:55;All you need to know when tackling Time Series Data!!    Table of Contents Fetch the data1 Downcasting2 Melting the data3 Exploratory Data Analysis4 Feature Engineering5 Modelling and Prediction6;Apache 2.0;https://www.kaggle.com/anshuls235/time-series-forecasting-eda-fe-modelling;1.0;['lightgbm'];['ner', 'ai', 'gan', 'gbm', 'rl', 'nn'];['filter', 'machine learning', 'train', 'model', 'validation data', 'label', 'predict', 'supervised learning'];https://www.kaggle.com/c/m5-forecasting-accuracy;0.78;0.593;2020-12-13 13:22:57;M5 Forecasting - Accuracy;['beginner, data visualization, exploratory data analysis, +1 morefeature engineering'];Time Series Forecasting-EDA, FE & Modelling📈;Python notebook;24226.0;397;;
2020-03-29 10:57:31;I have updated this notebook to modify the wrmsse function  at 29th Mar. New wrmsse function for LGBM metric calculate wrmsse only for last 28 days to consider non-zero demand period. Please refer comment section. I have commented the detail of my fixing. (note:I have also remove some variable to reduce the run-time and changed 'objective' in lgbm to 'poisson'.) This kernel is:  Based on Very fst Model. Thanks @ragnar123.   Based on m5-baseline. Thank @harupy. to explain the detail of these great notebook by Japanese especially for beginner.    Additionaly, I have added an relatively efficient evaluation of WRSSE for LGBM metric to these kernel.;Apache 2.0;https://www.kaggle.com/girmdshinsei/for-japanese-beginner-with-wrmsse-in-lgbm;1.0;['tensorflow', 'xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'gbm', 'rl', 'nn'];['filter', 'test data', 'regression', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/m5-forecasting-accuracy;0.767;0.563;2020-12-13 13:22:57;M5 Forecasting - Accuracy;['beginner'];for_Japanese_beginner(with WRMSSE in LGBM));Python notebook;16342.0;248;5.39065;0.61256
2020-03-24 01:17:12;This kernel is:- Based on Very fst Model. Thanks @ragnar123.- Automatically uploaded by push-kaggle-kernel.- Formatted by Black.;Apache 2.0;https://www.kaggle.com/harupy/m5-baseline;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'nn', 'ml'];['filter', 'test data', 'regression', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/m5-forecasting-accuracy;0.787;0.562;2020-12-13 13:22:57;M5 Forecasting - Accuracy;[];m5-baseline;Python notebook;29823.0;243;5.39065;0.73102
2020-04-09 04:34:06;This notebook aims to push the public LB under 0.50. Certainly, the competition is not yet at its peak and there clearly remains room for improvement.;Apache 2.0;https://www.kaggle.com/kneroma/m5-first-public-notebook-under-0-50;1.0;['lightgbm'];['ai', 'rl', 'nn', 'gbm'];['train', 'model', 'label', 'predict', 'rank'];https://www.kaggle.com/c/m5-forecasting-accuracy;0.802;0.627;2020-12-13 13:22:57;M5 Forecasting - Accuracy;[];M5 First Public Notebook Under 0.50;Python notebook;48233.0;716;0.75946;0.48874
2020-04-06 21:00:35;This notebook is a python implementation of this great R Kernel . Using data.table with R make things faster and efficient while, in python, a special care needs to be paid in order to get the data filled into memory, and even after a lot of tries, this still seems unachievable !;Apache 2.0;https://www.kaggle.com/kneroma/m5-forecast-v2-python;1.0;['lightgbm'];['ai', 'gbm'];['train', 'model', 'label', 'predict', 'rank'];https://www.kaggle.com/c/m5-forecasting-accuracy;0.771;0.568;2020-12-13 13:22:57;M5 Forecasting - Accuracy;[];M5 Forecast v2 Python;Python notebook;18494.0;269;0.77116;0.51029
2020-04-24 01:10:16;from eli5 documentation (seems it's perfect explanation) The idea is the following: feature importance can be measured by looking at how much the score (accuracy, mse, rmse, mae, etc. - any score we’re interested in) decreases when a feature is not available. To do that one can remove feature from the dataset, re-train the estimator and check the score. But it requires re-training an estimator for each feature, which can be computationally intensive. Also, it shows what may be important within a dataset, not what is important within a concrete trained model. To avoid re-training the estimator we can remove a feature only from the test part of the dataset, and compute score without using this feature. It doesn’t work as-is, because estimators expect feature to be present. So instead of removing a feature we can replace it with random noise - feature column is still there, but it no longer contains useful information. This method works if noise is drawn from the same distribution as original feature values (as otherwise estimator may fail). The simplest way to get such noise is to shuffle values for a feature, i.e. use other examples’ feature values - this is how permutation importance is computed.  It's not good when feature remove (replaced by noise) but we have better score. Simple and easy.;Apache 2.0;https://www.kaggle.com/kyakovlev/m5-custom-features;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'rl', 'gbm'];['filter', 'regression', 'train', 'model', 'validation data', 'loss', 'label', 'predict'];https://www.kaggle.com/c/m5-forecasting-accuracy;0.759;0.556;2020-12-13 13:22:57;multiple data sources;[];M5 - Custom features;Python notebook;13263.0;223;;
2020-03-29 14:42:45;M5 Forecast: Keras with Categorical Embeddings V2This notebook tries to model expected sales of product groups. Since many of the features are categorical, we use this example to show how embedding layers make life easy when dealing with categoric inputs for neural nets by skipping the step of making dummy variables by hand. Data preprocessing and feature engineering is very similar (but not identical) to this R kernel and uses ideas from the two excellent kernels Very fst Model and M5 ForecasteR. To gain an extra 3 GB of RAM, we do not use GPU acceleration for the training.;Apache 2.0;https://www.kaggle.com/mayer79/m5-forecast-keras-with-categorical-embeddings-v2;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'nn'];['filter', 'training data', 'test data', 'train', 'model', 'epoch', 'validation data', 'layer', 'loss', 'label', 'predict'];https://www.kaggle.com/c/m5-forecasting-accuracy;0.768;0.54;2020-12-13 13:22:57;M5 Forecasting - Accuracy;['deep learning, neural networks'];M5 Forecast: Keras with Categorical Embeddings V2;Python notebook;16919.0;175;;
2020-06-02 21:30:52;Predicting Time Series with LSTM Deep Learning NetworkBackgroundSince this is my first Time Series competition in Kaggle, I am mainly using it for learning. There are great kernel here, mostly using the boosting models (the most popular is LightGBM  And I have learned how to prepare the data and use it with this popular model. Moving forwards, I have decided to learn a bit more about the use of deep learning for Time Series prediction. I do have a background from other competition with deep learning but for image vision, working mostly with Pytorch. To go deeper and learn the topic, I have decided to build a learning kernel, that at least at the beginning will explain the topic and the concepts, the definition and the basics, From my experience when you try to explain to others, you learn the most. So the first kernel is only trying to explain the basic idea using an arbitrary series from the M5 data. I hope that the next versions will go deeper and I can provide a full submission with deep learning. If you like my kernel - Please VoteIf You like this kernel  Here a similar one with Seq2Seq model : https://www.kaggle.com/omershect/learning-pytorch-seq2seq-with-m5-data-set;Apache 2.0;https://www.kaggle.com/omershect/learning-pytorch-lstm-deep-learning-with-m5-data;1.0;['lightgbm', 'gensim', 'sklearn', 'pytorch', 'tensorflow', 'keras'];['ner', 'ai', 'dl', 'gbm', 'rl', 'ml', 'nn', 'rnn', 'ann'];['filter', 'recurrent neural network', 'input layer', 'predict', 'relu', 'machine learning', 'train', 'epoch', 'lstm', 'model', 'neural network', 'layer', 'loss', 'hidden layer', 'understanding', 'regression', 'output layer', 'deep learning', 'label'];https://www.kaggle.com/c/m5-forecasting-accuracy;0.753;0.554;2020-12-13 13:22:57;M5 Forecasting - Accuracy;['gpu, deep learning, lstm'];Learning Pytorch LSTM Deep Learning with M5 Data ;Python notebook;11202.0;218;;
2020-03-07 00:15:51;Objective Make a baseline model that predict the validation (28 days).  This competition has 2 stages, so the main objective is to make a model that can predict the demand for the next 28 days;Apache 2.0;https://www.kaggle.com/ragnar123/very-fst-model;1.0;['tensorflow', 'xgboost', 'sklearn', 'lightgbm'];['ai', 'rl', 'gbm'];['filter', 'test data', 'regression', 'train', 'model', 'validation data', 'label', 'predict'];https://www.kaggle.com/c/m5-forecasting-accuracy;0.785;0.588;2020-12-13 13:22:57;M5 Forecasting - Accuracy;[];Very fst Model;Python notebook;27802.0;371;5.39065;0.64127
2020-03-14 13:15:40;Objective Make a baseline model that predict the validation (28 days).  This competition has 2 stages, so the main objective is to make a model that can predict the demand for the next 28 days;Apache 2.0;https://www.kaggle.com/ratan123/m5-forecasting-lightgbm-with-timeseries-splits;1.0;['tensorflow', 'xgboost', 'sklearn', 'lightgbm'];['cv', 'ai', 'rl', 'gbm'];['filter', 'test data', 'regression', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/m5-forecasting-accuracy;0.829;0.536;2020-12-13 13:22:57;M5 Forecasting - Accuracy;['beginner, feature engineering'];M5 Forecasting : Lightgbm with Timeseries Splits;Python notebook;129142.0;165;5.39065;0.78635
2020-03-27 18:02:43;"M5 Forecasting Challenge The goal of this notebook is to give competitors a quick overview of the 2020 M5 competition. After reading it you should have a good idea of the objective you are trying to solve, the data provided and the metrics you will be scored on. Some tl;dr items to note:  There are two parallel competitions: Accuracy and Uncertainty The accuracy competition will use the metric: Weighted Root Mean Squared Scaled Error (RMSSE) The uncertainty competition will use the metric: Weighted Scaled Pinball Loss (WSPL)   We are tasked with forecasting hierarchical sales data from Wal-Mart. The data, covers stores in three US States (California, Texas, and Wisconsin) and includes item level, department, product categories, and store details. In addition, it has explanatory variables such as price, promotions, day of the week, and special events.";Apache 2.0;https://www.kaggle.com/robikscube/m5-forecasting-starter-data-exploration;1.0;['pattern', 'sklearn'];['ai', 'dl', 'cnn', 'gbm', 'gan', 'rl', 'nn', 'ann'];['predict', 'training data', 'train', 'model', 'validation data', 'label', 'loss'];https://www.kaggle.com/c/m5-forecasting-accuracy;0.798;0.629;2020-12-13 13:22:57;M5 Forecasting - Accuracy;[];M5 Forecasting  - Starter Data Exploration 📉;Python notebook;42761.0;747;;
2020-05-26 15:52:06;Data Visualization Notebook1st public version: Created on May 6th, 2020. 2nd public version: Created on May 7th, 2020. 3rd public version: Created on May 10th, 2020. 4th public version: Created on May 15th, 2020.  (Add Department Analysis) 5th public version: Created on May 16th, 2020.  (Add Next week event and value analysis) 6th public version: Created on May 16th, 2020.  (Add Dynamic Factor Analysis) 7th public version: Created on May 23th, 2020.  (Fix some codes in Standard deviation analysis in each store, Thank you for your comment, Kevin.) 8th public version: Created on May 26th, 2020. (Fix Bugs and Add Calendar Plot) 9th public version: Created on May 26th, 2020. (Add more precise PCA Plot, See PCA Section) Hello, everyone. I'm one of the challenger of this competition M5 -accuracy- . I'd like to find some useful insights for predictiong the test dataset. Here I created a notebook for data visualization especially for beginners like me. I appreciate all of your views and comments. https://www.kaggle.com/robikscube/m5-forecasting-starter-data-exploration His notebook is super great. If you have time, I strongly recommend you to take a look. And I'll introduce other good kernels in Reference Section Here is table of contents in this notebook:  Import Libraries and Data Input Data Cleaning Data Visualization  Total Item Sold Transition Item Sold in each day type Item sold in each State and Store Standard deviation analysis in each store   Item Sold relation Analysis Dynamic Factor Analysis Trial Store Analysis Snap Purchase Analysis Event Pattern Analysis One Item Features Analysis Sell Price Analysis Sell price and value relationship Department Analysis Next Week Events and This Week Sales Relationship Analysis Relationship of Lag Variables Calendar Visualization PCA Trial   Summary  Future Work References;Apache 2.0;https://www.kaggle.com/ryuheeeei/let-s-start-from-here-beginners-data-analysis;1.0;['statsmodels', 'xgboost', 'lightgbm', 'sklearn', 'pattern'];['ner', 'ai', 'dl', 'gbm', 'rl', 'ml', 'nn', 'ann'];['filter', 'training data', 'regression', 'test data', 'train', 'fitting', 'model', 'clustering', 'label', 'predict', 'recommend'];https://www.kaggle.com/c/m5-forecasting-accuracy;0.753;0.529;2020-12-13 13:22:57;M5 Forecasting - Accuracy;['beginner, data visualization, exploratory data analysis'];Let's Start from Here! Beginners' Data Analysis;Python notebook;11058.0;150;;
2020-06-08 20:23:21;"M5 - Sales Uncertainty Prediction Sources and guidelines Preparing to start Loading packages Loading data   ""What is meant by probabilistic forecasting?""... What is a grouped time series? How does the hierarchy look like? How can we generate forecasts for grouped timeseries?   The submission format Intro Prediction intervals and quartiles Aggregation levels Submission EDA   The Weighted Scaled Pinball loss The formula Playing with the loss implementation   The Naive method Prediction intervals for the Naive method Computing the loss for one timeseries of level 12   Facebook's Prophet LSTM and bootstrapped residuals Basic idea Setting up LSTM Fitting the model to the top-level series Check residuals for autocorrelation  Computing PIs using bootstrapped residuals   Where to go next?";Apache 2.0;https://www.kaggle.com/allunia/m5-sales-uncertainty-prediction;1.0;['statsmodels', 'sklearn', 'pattern'];['ner', 'ai', 'dl', 'rl', 'nn', 'ml'];['filter', 'training data', 'train', 'fitting', 'model', 'epoch', 'validation data', 'layer', 'loss', 'label', 'lstm', 'predict', 'understanding', 'bayesian'];https://www.kaggle.com/c/m5-forecasting-uncertainty;0.748;0.525;2020-12-13 13:24:02;M5 Forecasting - Uncertainty;['gpu, beginner, exploratory data analysis'];M5 - Sales Uncertainty Prediction;Python notebook;9743.0;142;;
2020-03-04 17:28:47;Other kernel abount this competition M5 Forecasting - Accuracy Simple Baseline with Prophet, LB:0.87287 M5 Forecasting - Accuracy EDA  Please upvote me, I am really need a bronze, thanks guys, have a nice day.;Apache 2.0;https://www.kaggle.com/holoong9291/eda-for-m5-2-en;1.0;['statsmodels', 'sklearn'];['ai', 'dl'];['filter', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/m5-forecasting-uncertainty;0.676;0.379;2020-12-13 13:24:02;M5 Forecasting - Uncertainty;[];EDA for M5-2 - EN/中文;Python notebook;1834.0;23;;
2020-06-25 02:29:00;The M5 competition loss is a little ugly, epecially when it comes to the Uncertainty's one with it's WSPL! So far, there is no, if not little, public implementation of that beast (I still talking about the WSPL and not the american  crime drama series). As I was saying it on M5  Accuracy my implementation is based on a deep inspection of the loss combined with an intelligent choice of pandas' components. Too much talk, let's dive in it !;Apache 2.0;https://www.kaggle.com/kneroma/fast-wsp-loss-implementation-5s;1.0;['pytorch', 'tensorflow', 'keras'];['ner', 'ai', 'rl'];['train', 'loss', 'regression', 'predict'];https://www.kaggle.com/c/m5-forecasting-uncertainty;0.553;0.319;2020-12-13 13:24:02;multiple data sources;[];Fast WSP Loss Implementation (5s);Python notebook;215.0;12;;
2020-06-12 19:49:32;Quantile Regression - Tensorflow CPU - CV3This kernel is mainly a fork of Quantile-Regression-with-Keras interesting kernel from Ulrich GOUE. It adds TimeSeries split cross validation on the last 3 folds for better regularization.   Fork#1 from: https://www.kaggle.com/ulrich07/quantile-regression-with-keras Fork#2 from: https://www.kaggle.com/chrisrichardmiles/m5u-wsplevaluator-weighted-scaled-pinball-loss Some code optimization to make it simple. LabelEncoder added. Embedding dimensions rules updated. Data starting from 2014-03-28. Float16 removed. SCALED option added. CV3 added for regularization.  v1.0: 2xDense64+1xDense32, dt_week_end category added, CV3: Last 3 folds (28 days each), EPOCH=20, LB=0.1720;Apache 2.0;https://www.kaggle.com/mpware/quantile-regression-cv3-tf;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'rl', 'cv', 'nn'];['regression', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'ground truth'];https://www.kaggle.com/c/m5-forecasting-uncertainty;0.653;0.371;2020-12-13 13:24:02;multiple data sources;[];Quantile-Regression-CV3-TF;Python notebook;1160.0;21;0.21180;0.17210
2020-03-18 20:36:55;M5 Forecasting Competition GluonTS TemplateThis notebook can be used as a starting point for participating in the M5 uncertainty forecasting competition using GluonTS-based tooling.;Apache 2.0;https://www.kaggle.com/steverab/m5-forecast-compet-uncert-gluonts-template;1.0;['mxnet'];['ner', 'ai', 'rl', 'nn', 'rnn', 'ml'];['predict', 'train', 'model', 'epoch', 'validation data', 'loss', 'ground truth'];https://www.kaggle.com/c/m5-forecasting-uncertainty;0.673;0.397;2020-12-13 13:24:02;M5 Forecasting - Uncertainty;[];M5 Forecast. Compet. (Uncert.) GluonTS Template;Python notebook;1718.0;28;;
2020-03-29 23:34:03;Time Series Clustering For Forecasting PreparationThe M5 dataset is a set of time series of daily sales by item Categories, Departments, Stores, and Items. These levels of granularity have a heirarchical structure, in that:  A Category has multiple Departments A Department spans across multiple Stores A Department contains multiple Items A combination of Item and Store is a the most granular level of series (SKU).   Unlike more vanilla time series forecasting tasks - where one uses a single series to predict the future of the series, this structure allows for transfer learning between series. For example: It may be that a group of items have similar sales patterns, due to seasonality in demand or supply, etc. Thus, it would make sense for a model to learn learn shared patterns to provide more robust forecasts. On the other hand, demand for groups of items might differ substancially due to external forces. Training a model to try and find similarities between these groups might only introduce noise - as the demand/supply for these items are structurally different. Clustering seriesThe purpose of this notebook is to demonstrate how we might group items that have similar underlying structure before diving into modeling using several clustering approaches. This way, we could pre-process series within groups in a similar way, and train a model for each cluster which specializes in learning this underlying structure. In this notebook I'll use a naive heirarchical method to cluster the series, point out the shortcoming of this approach, and speak about a method to approach these shortcomings called Dynamic Time Warping.;Apache 2.0;https://www.kaggle.com/timib1203/time-series-clustering-for-forecasting-preparation;1.0;['pattern', 'sklearn'];['ner', 'ai', 'rl', 'nn', 'ml'];['regression', 'train', 'model', 'clustering', 'label', 'predict'];https://www.kaggle.com/c/m5-forecasting-uncertainty;0.73;0.367;2020-12-13 13:24:02;M5 Forecasting - Uncertainty;['data cleaning, clustering'];Time Series Clustering For Forecasting Preparation;Python notebook;6189.0;20;;
2020-06-24 10:58:15;This notebook is a continuation of https://www.kaggle.com/ulrich07/quantile-regression-with-keras. Our point is to say it is maybe wrong to write off RNN or CNN nets. Maybe this can lead to a good solution. I'm sure that you guys can iterate on it and better this work !!!;Apache 2.0;https://www.kaggle.com/ulrich07/do-not-write-off-rnn-cnn;1.0;['tensorflow', 'lightgbm', 'sklearn', 'keras'];['ner', 'ai', 'cnn', 'gbm', 'rl', 'nn', 'rnn', 'ann'];['gru', 'regression', 'generation', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict'];https://www.kaggle.com/c/m5-forecasting-uncertainty;0.697;0.413;2020-12-13 13:24:02;multiple data sources;['gpu'];Do not write off RNN & CNN !!!;Python notebook;2877.0;34;0.19502;0.12193
2020-06-09 19:46:36;It is a baseline model. Feel free to add your own FE magic !!!;Apache 2.0;https://www.kaggle.com/ulrich07/quantile-regression-with-keras;1.0;['tensorflow', 'lightgbm', 'sklearn', 'keras'];['ner', 'ai', 'rl', 'gbm'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/m5-forecasting-uncertainty;0.74;0.483;2020-12-13 13:24:02;multiple data sources;['neural networks'];Quantile-Regression-with-Keras;Python notebook;7845.0;80;;
2017-02-02 07:10:47;Collaborative filtering starter with Keras. Learned from Jeremy Howard's MOOC. Up vote if you find this helpful.;Apache 2.0;https://www.kaggle.com/aikinogard/cf-starter-with-keras-0-560136;1.0;['tensorflow', 'keras'];['ai', 'nn'];['filter', 'train', 'model', 'epoch', 'layer', 'loss', 'predict'];https://www.kaggle.com/c/march-machine-learning-mania-2017;0.741;0.413;2020-12-13 13:48:32;March Machine Learning Mania 2017;[];CF starter with Keras ~0.560136;Python notebook;8167.0;34;;
2017-02-04 12:37:33;Set some constants we need to compute Elo ratings;Apache 2.0;https://www.kaggle.com/kplauritzen/elo-ratings-in-python;1.0;['sklearn'];['ner', 'ai', 'nn'];['epoch', 'label', 'regression', 'loss'];https://www.kaggle.com/c/march-machine-learning-mania-2017;0.787;0.352;2020-12-13 13:48:32;March Machine Learning Mania 2017;[];Elo Ratings in Python;Python notebook;30273.0;17;;
2018-03-14 19:26:08;Predict NCAA Basketball 2017 Here we will use Logistic Regression to predict the outcomes of every possible matchup in the 2017 March Madness basketball tournament.  Our classifier will make its decision based off of the values for 17 features.  One important feature is a ranking metric called ELO (Link #1, Link #2) while the remaining 16 features are traditional basketball metrics (described below).  Note that many functions are adapted from this solution from 2016.;Apache 2.0;https://www.kaggle.com/paultimothymooney/predict-ncaa-basketball-2017-491782;1.0;['sklearn'];['ner', 'ai', 'gan', 'cv', 'rl', 'nn', 'ml'];['regression', 'train', 'model', 'label', 'logistic regression', 'predict', 'rank'];https://www.kaggle.com/c/march-machine-learning-mania-2017;0.699;0.268;2020-12-13 13:48:33;multiple data sources;['sports, basketball'];Predict NCAA Basketball 2017 (.491782);Python notebook;2969.0;7;;
2018-04-07 01:52:13;Predict NCAA Basketball 2018 Here we will use Logistic Regression to predict the outcomes of every possible matchup in the 2018 March Madness basketball tournament.  Our classifier will make its decision based off of the values for 17 features.  One important feature is a ranking metric called ELO (Link #1, Link #2) while the remaining 16 features are traditional basketball metrics (described below).  Note that many functions are adapted from this solution from 2016.;Apache 2.0;https://www.kaggle.com/paultimothymooney/predict-ncaa-basketball-2018;1.0;['sklearn'];['ner', 'ai', 'gan', 'cv', 'rl', 'nn', 'ml'];['regression', 'train', 'model', 'label', 'logistic regression', 'predict', 'rank'];https://www.kaggle.com/c/march-machine-learning-mania-2017;0.683;0.214;2020-12-13 13:48:33;multiple data sources;['sports, basketball'];Predict NCAA Basketball 2018;Python notebook;2129.0;4;;
2020-05-01 01:37:01;At-Large and Seeding Automation via Machine Learning:The NCAA Men's basketball season can be viewed in three distinct sections. The first is the regular season. This is when all non-conference and conference games are played. The second and shortest is the conference tournament where teams can earn a chance to play in the NCAA Tournament. Lastly, the third section - reserved for only 68 teams - is the tournament used to crown the champion.  It could be fairly stated the reason NCAA men's basketball teams play the regular season is for the opportunity to play in the NCAA tournament. Some teams are guaranteed this opportunity by winning their end of season conference tournament. Teams that don't win their conference tournament may still receive an invitation via an at-large selection as a result of the high quality of their regular season and conference tournament play. After the selection committee chooses the at-large teams, it must assign all teams, both conference tournament winners and at-large selections, a seed. The purpose of this notebook is two-fold: first, to model the at-large teams and second, to assign each team a seed. Both processes will use machine learning approaches to derive the results. Along the way, we'll compare the expected versus actual results. Who made it into the at-large field under the wire and who was left standing in the cold? Who received higher or lower seeding than expected? With a high degree of accuracy, can we automate the at-large and seeding process for the NCAA Men's Basketball Tournament? How do we handle the 2020 season?;Apache 2.0;https://www.kaggle.com/btesch/ncaa-at-large-selection-and-seeding-automation;1.0;['lightgbm'];['ner', 'ai', 'dl', 'gbm', 'gan', 'cv', 'rl', 'nn', 'ml'];['filter', 'machine learning', 'regression', 'training data', 'train', 'model', 'validation data', 'reward', 'loss', 'label', 'predict', 'rank', 'classification'];https://www.kaggle.com/c/march-madness-analytics-2020;0.579;0.281;2020-12-13 13:49:58;multiple data sources;[];NCAA At-Large Selection and Seeding Automation;Python notebook;317.0;8;;
2020-05-01 01:35:02;Madness at Home and on the Court - Part 1Authors: Emilien Etchevers, Kieran Janin, Michael Karpe, Remi Le Thai, Haley Wohlever ContentsIn this notebook  Introduction  NCAA March Madness Data Analysis Seeding and Entertainment Madness through Unpredictability Entertainment due to Closeness of Games    In the second notebook:  Tweets on NCAA Data Analysis Temporal Evolution of Engagement Team Mentions Count in Tweets Sentiment Analysis for Tweets on NCAA   Conclusion  1. IntroductionMarch Madness is a period of excitement for everyone: from the die-hard fan to the serial gambler, this NCAA tournament has something for all. One of the major draws of the competition is its intangible and intoxicating element of unpredictability: with the closely packed games and high end teams, there’s always a chance for an upset, for an unexpected streak, or for a “Cinderella story.” We set out here to try to uncover whether or not these seemingly unpredictable moments could be anticipated? What truly contributes to the “madness” of a game and to this season of collegiate basketball? Our first challenge in this endeavor was attempting to define “madness.” Are we referring to the intensity of the game? the moves of each player on the court? Or are we referring to the crowd’s reaction to the outcome of a match? to the fan’s entertainment back home? Rather than limit our exploration, we decided to consider both possibilities. To do this effectively, we separated our work into two distinct categories: 1) that of empirical and “objective” madness that arises from the teams’ past game statistics and match events, and 2) that of emotional and “subjective” madness that comes from the enthusiasm of the fans while watching a game. This second type of madness is evaluated in a separate notebook which follows this one. Depending on who you ask, madness can have many meanings, but here we focus on it as the entertainment and pleasure that unites everyone around a great game of basketball. 2. NCAA March Madness Data AnalysisFor exploring the objective madness in this competition, the main data source at our disposal is the NCAA data provided through Kaggle. This data source is full of detailed and relevant information for the 2015 to 2019 seasons, from team and player names down to precisely recorded details on events that occur during each match! 2.1. Seeding and EntertainmentThe main question we explored is: can entertainment be linked to a team’s seed? In the extreme case of this is whether, by default, watching a seed 1 team compete will inherently be more enjoyable than watching a seed 16 team compete? We did this by first looking at specific events that occur during matches and working to see whether certain events were correlated with certain seeds. To perform this analysis, we start by loading useful packages as well as the relevant data. We opted to use some pre-processing performed by JasonVizkovic in his Notebook: Moreyball in the College Game...A Full NCAA EDA. It was particularly useful for helping us to isolate definite scoring attempts, understand whether they were assisted or not, and more.;Apache 2.0;https://www.kaggle.com/emimis/madness-at-home-and-on-the-court-part-1;1.0;['pattern', 'xgboost'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ann'];['filter', 'train', 'model', 'layer', 'loss', 'label', 'predict', 'rank', 'understanding', 'sentiment analysis'];https://www.kaggle.com/c/march-madness-analytics-2020;0.572;0.281;2020-12-13 13:49:58;multiple data sources;[];Madness at Home and on the Court - Part 1;R notebook;285.0;8;;
2020-04-30 11:07:35;"Uncovering March Madness® Cinderella StoriesGoogle Cloud & NCAA® March Madness Analytics 2020Kaggle Analytics Prediction Competition April 30, 2020 CONTENTS OF THIS FILE I. Definition 1.1. Project Overview 1.2. Problem Statement 1.3. Methodology   II. Implementation 2.1. The Basics, 1985-2020 2.2. Geography, 2010-2020 2.3. Team Box Scores, 2003-2019 2.4. Play-by-play, 2015-2020 2.5. Individual Statistics, 2015-2020 2.6. Public Rankings, 2003-2020 2.7. Prediction Experiment   III. Results 3.1. General Findings 3.2. Uncovering Cinderellaness 3.3. Predicting Cinderellas   References   A Note to the ReaderEditorial ""we"" is used in place of ""I"" and in the meaning of ""the author and the reader"". I recommend reading the I. Definition and III. Results sections before the II. Implementation.  ABSTRACTOur analysis aimed to define common features and specific trends among ""Cinderella"" teams in NCAA® men's basketball. In this context, Cinderella was defined as any basketball team seeded 10th or worse that has advanced to the Round 3 in NCAA® tournament. We have divided all the remaining teams into two more categories - Top and Ordinary. We explored, filtered and analyzed NCAA® data across different dimensions and used descriptive statistics and exploratory visualizations to summarize main characteristics about the data in general, and in particular about ""Cinderellaness"" as our target of interest. Our analysis demonstrated that a typical Cinderella team is ranked between 20 and 65 in a pre-tournament rankings of a popular ranking systems. Cinderellas are good at shooting 2-pointers in the regular season, but not so much in the tournaments. The opposite is true for the three-point goals - Cinderellas have the highest three-point field goal ratio in NCAA® tournaments of all team categories. Cinderellas are successful in defensive rebounding and will likely have a positive Rebound Margin in the regular season games. They typically win with a high scoring margin in Round 2 of NCAA® tournament, but it is harder for them to keep it as high in the later rounds. For this research, we have trained eXtreme Gradient Boosting (XGBoost) machine learning algorithm to predict which team had the best potential to become a Cinderella before the March Madness was canceled. Our model predicted that ETSU (East Tennessee State University) was the most likely candidate for a Cinderella team of the 2020 season.  I. Definition1.1. Project OverviewProject Origin Each season there are thousands of men's and women's NCAA® basketball games played between Division I teams, culminating in March Madness®, the national championship tournaments that start in the middle of March [1]. The men's and women's NCAA basketball tournaments are beloved American sports traditions. These are single-elimination tournaments, which means that the championship team has to win at least six games in a row to claim the title. This high-stakes environment — plus the chance to witness a crazy ""Cinderella-story"" upset, gives the tournament its March Madness® nickname [4]. The challenge of the ""Google Cloud & NCAA® March Madness Analytics"" competition, sponsored by Google Cloud and hosted by Kaggle, is to present an exploratory analysis of the March Madness® using a Kaggle Notebook. Prerequisite Knowledge In this study, we assume that the reader is familiar with the basic NCAA® men's basketball rules and terminology. For those new to basketball, we recommend [4] and [26] for a quick introduction. Input Data The input NCAA® data is provided for this competition and is available from the competition website. The data is about college basketball games and teams and is divided into 6 sections - The Basics, Team Box Scores, Geography, Public Rankings, Play-by-play and Supplements. Please refer to the Data [1] section at the bottom of this notebook for a full description of each file. On March 12, 2020, NCAA® canceled the Division I men's and women's 2020 basketball tournaments, as well as all remaining winter and spring NCAA® championships based on the evolving COVID-19 public health threat [2], so the 2020 data is incomplete and does not have an information about 2020 NCAA® tournament bracket. 1.2. Problem StatementThe goal of our project is to use data analysis to explain ""cinderellaness"" - define common features and specific trends among ""Cinderella"" teams in NCAA® men's basketball. The intended solution is to:  Define and filter out our target of interest - ""Cinderella"" teams Preprocess, filter and analyze input data Build visualizations to provide insights into the data & metrics Use machine learning to predict which team had the potential to become a Cinderella in a 2020 season Communicate the results of the analysis  1.3. MethodologyData Exploration and Preprocessing Scientific computing and analysis packages such as NumPy and Pandas will be used to explore and preprocess the data. Data cleaning will be performed where necessary. We will filter data across different categories, such as regular season vs. NCAA® tournament, all games vs. games won, team segment vs. metric vs. season. Data SegmentationThe essential part of our analysis is to divide men's NCAA® basketball teams into 3 groups - Cinderella, Top and Ordinary. A March Madness Cinderella is a team that greatly exceeds its NCAA® tournament expectations. They are generally afterthoughts on the Selection Sunday bracket, but wind up becoming one of the biggest stories of the tournament [3]. In NCAA®, the field of teams is divided into four geographical regions. Each region has between 16 and 18 teams, which are assigned a seed number of one through 18, with the best team in the region awarded the No. 1 seed. Traditionally, the highest seeds (Nos. 1 through 8) have enjoyed more success than the lower seeds (Nos. 9 through 16). The lower seeds represent potential Cinderellas of the tournament. A Cinderella team is one that unexpectedly achieves success in the tournament. Traditionally, Cinderella's chariot turns back into a pumpkin before getting to the Final Four [4] (also see Figure 1). Considering the above definition, we decided to use the following segmentation as the foundation for our discussion and analysis:  CINDERELLA - any basketball team seeded 10th or worse that has advanced to the Round 3 in NCAA® tournament. This group is our target of interest. TOP - top-seeded (Nos. 1 through 4) teams who have advanced to the Round 3 in NCAA® tournament. This group will represent the most competitive teams - teams that match expectations. ORDINARY - all the other NCAA® tournament teams not falling under two previous categories, for example seeded No 2. but lost in the first-round game. Note that all seed Nos. 5 through 9 will always fall under this category.";Apache 2.0;https://www.kaggle.com/evanca/uncovering-cinderellaness;1.0;['pattern', 'tensorflow', 'xgboost', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'reward', 'predict', 'ground truth', 'machine learning', 'training data', 'train', 'recommend', 'classification', 'labeled', 'model', 'layer', 'support vector machines', 'loss', 'rank', 'understanding', 'decision tree', 'supervised learning', 'test data', 'regression', 'fitting', 'label', 'gradient boosting', 'random forest'];https://www.kaggle.com/c/march-madness-analytics-2020;0.614;0.327;2020-12-13 13:49:58;multiple data sources;[];Uncovering Cinderellaness;Python notebook;565.0;13;;
2020-04-29 00:04:23;What keeps your eyes glued to the screen while you are watching a basketball game?Arguably, the answer is in the lines of  your love for the game your support for one of the contending teams how hard-fought the game is  In this notebook, we will try to quantify the last point or, by abusing the terminology of the competition, define how competitive a college basketball game can be. Trying to describe in numbers the emotion rushing through the crowd while the ball is flying towards the basket and ends in a buzzer-beater might be too ambitious. However, the core assumption of this notebook is that a score for competitiveness can be extracted by observing how the game unfolded. To do so, we will make extensive use of play-by-play data that tells us what happened during the game and when. For the past 6 Seasons, we have this information for both the Men's and the Women's tournaments and, while some differences between the two tournaments can be found, we found that the way the game can unfold, either by turning out to be competitive or not, is the same for both. We will thus model them together as we are interested in finding out how to create such a score for a generic basketball game. This notebook is organized as follows  Data preparation: everything can be found in this utility script and the key concept will be summarized in this section. A hard definition for a competitive game: what conditions a game should satisfy to be considered competitive. A score for competitiveness: where a Machine Learning model will guide us towards the definition of our score. Finding the Madness: here we will analyse how the score relates to the key characteristics of a game. Limits and next steps: where we will conclude our journey.  Data preparationThe functions that create the data we are going to use can be found in this utility script, where the non-trivial statistics were generated by following these definitions. In summary,  By using the scoring events, we get the game result during the game. We focus on 3 moments: the full game, the second half, the last 3 minutes. We get how many times the lead of the game changed in each of these (overlapping) periods. We aggregate and count the events in each period, for example the number of TO in the last 3 minutes.  Here a sample of the final result;Apache 2.0;https://www.kaggle.com/lucabasa/quantify-the-madness-a-study-of-competitiveness;1.0;['pattern', 'xgboost', 'sklearn'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'nn', 'ml'];['machine learning', 'train', 'model', 'layer', 'loss', 'label', 'predict', 'rank', 'classification', 'labeled'];https://www.kaggle.com/c/march-madness-analytics-2020;0.684;0.431;2020-12-13 13:49:58;multiple data sources;['data visualization, sports, basketball, +1 moremodel explainability'];Quantify the Madness, a study of competitiveness;Python notebook;2184.0;42;;
2020-05-01 01:47:35;"Redefining the RosterUsing unsupervised machine learning to cluster NCAA players by their stats. Most people who watch March Madness are familiar with the standard positions of basketball: guards, forwards, and centers. But as basketball continues to evolve, the lines that define players have become more blurred. In a 2013 article, Myron Medcalf questioned if the traditional positions were even still relevant. Metcalf said, ""The descriptors that made sense years ago feel inadequate today. Point guards, shooting guards, small forwards, power forwards and centers -- in some cases -- have been replaced by young men who simply call themselves players. [1]"" My question, then is: What does the data show us about player positions? Would it be possible to categorize players' positions based solely on the data? After defining these ""positions"" what types of rosters fare well in the March Madness tournament? Using an unsupervised machine learning technique called clustering, I've identified 5 distinct types of college basketball players. They are: Ball Distributors, Elite Bigs, Shot Takers, 3 Point Specialists, and Paint Dominators. In this notebook, I'll go through the process used to identify these groups, and go into more detail about what makes each unique. So let's let the data tell the story of the players who rule March Madness!";Apache 2.0;https://www.kaggle.com/robikscube/redefining-ncaa-basketball-positions-using-data;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'gan', 'rl', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'model', 'layer', 'clustering', 'loss', 'label', 'predict', 'rank'];https://www.kaggle.com/c/march-madness-analytics-2020;0.643;0.357;2020-12-13 13:49:58;multiple data sources;[];Redefining NCAA Basketball Positions using Data!;Python notebook;954.0;18;;
2016-10-02 17:50:13;Taking a look at the energy distributions for particular sensor channels throws up some interesting results.  For all patients, some of the sensor channels exhibit a bi-modal behaviour with high and low energy states, perhaps corresponding to whether the patient was awake or asleep.  For patient 2, we find that some of the channels exhibit glitchy behaviour whereby the channel energy drops to near zero for extended periods of time (which is distinct from the all zero dropouts common to all patients). Furthermore, some of this glitchy behaviour is confined to only the training set suggesting that the train and test data sets may cover two disjoint time intervals.;Apache 2.0;https://www.kaggle.com/andy101/exploring-the-channel-energies;1.0;['statsmodels', 'pattern'];['ner', 'ai', 'dl', 'rl', 'nn', 'ann'];['test data', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/melbourne-university-seizure-prediction;0.657;0.214;2020-12-13 13:55:26;Melbourne University AES/MathWorks/NIH Seizure Prediction;[];Exploring the channel energies;Python notebook;1249.0;4;;
2016-09-08 23:01:00;Version of ZFTurbo's excellent Seizure Boost script that: a) Can actually run on the full data more than 10% of the time (by virtue of being a notebook) b) Has some experimental additional features added me;Apache 2.0;https://www.kaggle.com/anokas/seizure-boosting;1.0;['xgboost', 'sklearn'];['ai', 'gbm', 'cv', 'rl', 'nn', 'ann'];['train', 'model', 'predict'];https://www.kaggle.com/c/melbourne-university-seizure-prediction;0.716;0.34;2020-12-13 13:55:25;Melbourne University AES/MathWorks/NIH Seizure Prediction;[];Seizure Boosting ++;Python notebook;4443.0;15;0.00000;0.00000
2016-11-30 04:22:32;Feature Extractor for the EEG Data FilesCloudy with a Chance of InsightThis is a refactored fork of Deep's feature extractor which was part of a winning entry in a past Kaggle EEG competition. The code below only loads the MATLAB data files and pre-processes them by extracting possibly useful features that you can use to train machine learning models on.;Apache 2.0;https://www.kaggle.com/treina/feature-extractor-matlab2python-translated;1.0;['pattern', 'sklearn'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'training data', 'neuron', 'train', 'fitting', 'model', 'epoch', 'label', 'predict', 'recommend', 'classification', 'labeled'];https://www.kaggle.com/c/melbourne-university-seizure-prediction;0.729;0.387;2020-12-13 13:55:25;Melbourne University AES/MathWorks/NIH Seizure Prediction;[];Feature Extractor Matlab2python translated;Python notebook;6024.0;25;;
2018-03-13 06:13:06;Collaborative FilteringThis is a starter notebook forked from last year's competition. This is an implementation of Collaborative filtering starter with Keras. Uses only the win(1) and loss(0) label of each match and categorical encoding of team Ids as training data. Essentially the formula used is shown below: Model prediction = Dot product of the 2 teams in each match (embedding vectors)+ (Team1 bias) + (Team2 bias);Apache 2.0;https://www.kaggle.com/dicksonchin93/collaborative-filtering;1.0;['tensorflow', 'keras'];['ai', 'nn'];['filter', 'training data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict'];https://www.kaggle.com/c/mens-machine-learning-competition-2018;0.689;0.319;2020-12-13 13:57:27;Google Cloud & NCAA® ML Competition 2018-Men's;[];Collaborative Filtering;Python notebook;2399.0;12;0.67697;0.67697
2018-02-25 15:09:20;First we import some datasets of interest;Apache 2.0;https://www.kaggle.com/eaturner/logistics-and-basic-stats-lb-public-0-046;1.0;['sklearn'];['ner', 'ai', 'gan', 'cv', 'rl', 'nn'];['training data', 'regression', 'train', 'model', 'layer', 'loss', 'label', 'logistic regression', 'predict'];https://www.kaggle.com/c/mens-machine-learning-competition-2018;0.715;0.362;2020-12-13 13:57:27;Google Cloud & NCAA® ML Competition 2018-Men's;['logistic regression'];Logistics and Basic Stats(LB Public - ~0.046);Python notebook;4296.0;19;0.00000;0.00000
2018-02-22 22:48:23;4. COMPETITION PERIOD....YOU ARE RESPONSIBLE FOR DETERMINING THE CORRESPONDING TIME ZONE IN YOUR LOCATION.;Apache 2.0;https://www.kaggle.com/gaborfodor/i-don-t-always-read-the-rules;1.0;['keras', 'sklearn'];['ner', 'ai', 'nn', 'ann'];['model', 'test data', 'predict'];https://www.kaggle.com/c/mens-machine-learning-competition-2018;0.694;0.393;2020-12-13 13:57:27;Google Cloud & NCAA® ML Competition 2018-Men's;[];I don't always read the rules...;Python notebook;2667.0;27;;
2018-02-13 01:33:34;OverviewThis is a starter notebook inspired by last year's Logistic Regression on Tournament Seeds by Kasper P. Lauritzen starter kernel. It creates a basic logistic regression model based on the seed differences between teams. Note that the predictions for Stage 1's sample submissions file are already based on known outcomes, and the Tourney data this model is trained on includes that data. For Stage 2, you will be predicting future outcomes based on the teams selected for the tournament on March 11.;Apache 2.0;https://www.kaggle.com/juliaelliott/basic-starter-kernel-ncaa-men-s-dataset;1.0;['sklearn'];['ai', 'nn', 'cv'];['training data', 'regression', 'train', 'model', 'layer', 'loss', 'label', 'logistic regression', 'predict'];https://www.kaggle.com/c/mens-machine-learning-competition-2018;0.764;0.501;2020-12-13 13:57:27;Google Cloud & NCAA® ML Competition 2018-Men's;[];Basic Starter Kernel - NCAA Men's Dataset;Python notebook;14955.0;102;;
2018-03-11 16:34:30;Elo ratings based on regular-season games;Apache 2.0;https://www.kaggle.com/lpkirwin/fivethirtyeight-elo-ratings;1.0;['sklearn'];['ner', 'ai', 'nn', 'ann'];['loss', 'predict'];https://www.kaggle.com/c/mens-machine-learning-competition-2018;0.749;0.46;2020-12-13 13:57:27;Google Cloud & NCAA® ML Competition 2018-Men's;[];FiveThirtyEight_Elo_ratings;Python notebook;9928.0;60;;
2018-03-12 17:56:19;THIS NOTEBOOK IS BASED ON THE STATISTICS ON REGULAR SEASON TO PREDICT NCAA TOURNEY MATCHES.f_ denotes first team with low ID. s_denotes second team with high ID. It may look like containing several for loops but the data wasn't so tiddy.;Apache 2.0;https://www.kaggle.com/mbkinaci/tidying-data-xgboost-feature-importance;1.0;['xgboost'];['dl', 'ai', 'nn', 'ann'];['filter', 'test data', 'train', 'model', 'predict', 'rank'];https://www.kaggle.com/c/mens-machine-learning-competition-2018;0.686;0.352;2020-12-13 13:57:27;Google Cloud & NCAA® ML Competition 2018-Men's;[];TIDYING DATA  : XGBOOST FEATURE IMPORTANCE;Python notebook;2257.0;17;;
2018-03-13 16:43:26;Mens Tourney Prediction Analysis I the believe the following are important in determing a teams success in the tourney 1) Seeding 2) Strength of Conference 3) Individual team statistics 4) Experience;Apache 2.0;https://www.kaggle.com/virtonos/advanced-basketball-analytics;1.0;['xgboost', 'sklearn'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['training data', 'test data', 'regression', 'random forest', 'train', 'fitting', 'model', 'layer', 'loss', 'label', 'logistic regression', 'predict', 'rank', 'classification'];https://www.kaggle.com/c/mens-machine-learning-competition-2018;0.687;0.319;2020-12-13 13:57:27;multiple data sources;[];Advanced basketball analytics;Python notebook;2326.0;12;0.62324;0.62324
2019-02-18 04:20:27;Utilizing Embedding to Predict NCAA GamesInspired by http://www.sloansportsconference.com/wp-content/uploads/2018/02/1008.pdf, an outcome based embedding model, I was tempted to try and predict the outcome of NCAA games. Treating each team as an entity, I look at one season (2017) and see if there is anything to gain from the resulting embeddings afterwards. I then augment the model by jointly estimating the points scored by each team as well, and review the embeddings again.;Apache 2.0;https://www.kaggle.com/abhijitbrahme/embedding-ncaa-model;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nn', 'ann'];['training data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/mens-machine-learning-competition-2019;0.62;0.268;2020-12-13 13:59:30;Google Cloud & NCAA® ML Competition 2019-Men's;[];Embedding NCAA Model;Python notebook;627.0;7;;
2019-02-15 19:28:55;OverviewThis is a starter notebook inspired by the 2017 Logistic Regression on Tournament Seeds by Kasper P. Lauritzen starter kernel. It creates a basic logistic regression model based on the seed differences between teams. Note that the predictions for Stage 1's sample submissions file are already based on known outcomes, and the Tourney data this model is trained on includes that data. For Stage 2, you will be predicting future outcomes based on the teams selected for the tournament on March 17.;Apache 2.0;https://www.kaggle.com/addisonhoward/basic-starter-kernel-ncaa-men-s-dataset-2019;1.0;['sklearn'];['ai', 'nn', 'cv'];['training data', 'regression', 'train', 'model', 'loss', 'label', 'logistic regression', 'predict'];https://www.kaggle.com/c/mens-machine-learning-competition-2019;0.73;0.447;2020-12-13 13:59:30;Google Cloud & NCAA® ML Competition 2019-Men's;[];Basic Starter Kernel - NCAA Men's Dataset 2019;Python notebook;6221.0;51;0.00000;0.00000
2019-02-19 07:25:55;General informationIn this kernel I'm working with data from Google Cloud & NCAA® ML Competition 2019-Men's Challenge. We'll try to predict winners of NCAA based on previous tournaments! We have a lot of data, so let's start with EDA.  Work in progress.;Apache 2.0;https://www.kaggle.com/artgor/ncaa-men-s-eda-and-models;1.0;['statsmodels', 'xgboost', 'lightgbm', 'catboost', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'nn', 'ml'];['filter', 'training data', 'regression', 'test data', 'train', 'model', 'loss', 'label', 'predict', 'rank'];https://www.kaggle.com/c/mens-machine-learning-competition-2019;0.692;0.393;2020-12-13 13:59:30;Google Cloud & NCAA® ML Competition 2019-Men's;[];NCAA Men's EDA and models;Python notebook;2583.0;27;0.00000;0.00000
2019-03-21 15:06:36;Microsoft has created an algorithm called TrueSkill for the purpose of ranking players using its video game platform.  It is basically a probabalistic algorithm based on the Elo algorithm used to rank chess players.  It can be used to rank players in any activity where there is some concept of win/lose/draw.  The algorithm itself is somewhat hard to understand but fortunately someone has created a Python package which makes it easy to use without understanding the theory behind it.;Apache 2.0;https://www.kaggle.com/gkoundry/rating-teams-using-microsoft-s-trueskill-algorithm;1.0;['sklearn'];['ner', 'ai', 'gan', 'ml', 'nn', 'ann'];['training data', 'regression', 'train', 'model', 'epoch', 'layer', 'logistic regression', 'predict', 'rank', 'understanding'];https://www.kaggle.com/c/mens-machine-learning-competition-2019;0.642;0.292;2020-12-13 13:59:30;Google Cloud & NCAA® ML Competition 2019-Men's;[];Rating teams using Microsoft's TrueSkill algorithm;Python notebook;943.0;9;;
2019-02-20 08:04:27;IntroGood Luck to everyone especially the ones who want to bet against Zion and his Blue devils.  In this kernel I would like to explore the NCAA data with a quick look at some classical and advanced stats in order to understand which statistics may be more useful for predicting the Ws & Ls in the tournament. ICYMI: https://stats.nba.com/help/glossary/ Having a detailed information set about every single games of the different seasons, the first step is to create a dataset which contains aggregated stats for each single team.;Apache 2.0;https://www.kaggle.com/pozz13/ncaa-2k19-eda-zion-s-kingdom;1.0;['sklearn'];['ner', 'ai', 'nlu', 'nn'];['loss', 'model', 'label', 'predict'];https://www.kaggle.com/c/mens-machine-learning-competition-2019;0.697;0.423;2020-12-13 13:59:30;Google Cloud & NCAA® ML Competition 2019-Men's;[];NCAA 2K19 - EDA Zion's Kingdom;Python notebook;2855.0;38;;
2019-02-16 10:59:55;Data-driven power rankingsRanking the teams by their strength is a very important piece of information your model should use. Some of the rankings are using expert opinion (i.e. majority vote of fan opinion). However, this may be not the best approach, as human opinions tend to be biased towards their favorites. Moreover, it may be easy to determine a top few strong teams, but it is a much harder to rank teams in the mid-lower range ranks. In NCAA tournament teams are assigned with tournament starting seeds, which also has expert bias - it is not uncommon, that a team with higher win ratio % would get lower seed compared to a team with lower win ratio %, based on the regular season schedule (which is not the same for every team!). Therefore, the judgment of team strength of assigned seed sometimes get controversial opinion among fans and media! The idea of this kernel is to try to calculate the team strength rankings only based on the  data we have in our disposal. This way we will eliminate all possible human biases and get a robust estimate of team's strength.;Apache 2.0;https://www.kaggle.com/raddar/team-power-rankings;1.0;['statsmodels', 'sklearn'];['ner', 'ai', 'rl', 'nn', 'ann'];['regression', 'model', 'layer', 'logistic regression', 'predict', 'rank'];https://www.kaggle.com/c/mens-machine-learning-competition-2019;0.728;0.503;2020-12-13 13:59:30;Google Cloud & NCAA® ML Competition 2019-Men's;[];Team power rankings;Python notebook;5881.0;105;;
2018-05-27 03:11:39;"IntroductionThis Python notebook seeks to explore Mercari's data set, in order to extract ""what to do"" and ""what not to do"". The main idea is to contribute to the community with quick, but deep, first view of the data. It contains some visualizations and data manipulation, that can be further used to build your own Machine Learning Models. Feel free to contribute to this Kernel with your thoughts. Happy Kaggling!";Apache 2.0;https://www.kaggle.com/huguera/mercari-data-analysis;1.0;['pattern', 'sklearn'];['ner', 'ai', 'dl', 'nn', 'ml'];['machine learning', 'training data', 'train', 'model', 'label'];https://www.kaggle.com/c/mercari-price-suggestion-challenge;0.743;0.477;2020-12-13 14:05:42;Mercari Price Suggestion Challenge;['beginner, data visualization, exploratory data analysis'];Mercari Data Analysis;Python notebook;8622.0;74;;
2017-12-17 16:32:07;BEGINNER'S GUIDE TO MERCARI IN R I'm writing what I believe is a fairly straight forward guide to my thought process through the Mercari challenge. Table of Contents: 1. Import library/datasets 2. Create obvious variables 3. Explore data to Find less obvious variables 4. Prepare the data for xgboost 5. Run an xgboost validation model 6. Analyze results For those who are feeling overwhelmed by the sheer size of this dataset, I recommend slicing 10% off and working on that section of the code. I'll post a quick way to do this. I'll be updating this kernel as I think of ways to improve the efficiency or score of my model.;Apache 2.0;https://www.kaggle.com/jeremiespagnolo/beginner-s-guide-to-mercari-in-r-0-50586;1.0;['pattern', 'xgboost', 'pillow'];['ner', 'ai', 'dl', 'gbm', 'gan', 'cv', 'rl', 'ml', 'nlp', 'nn', 'ann'];['filter', 'train', 'fitting', 'model', 'layer', 'loss', 'label', 'predict', 'recommend'];https://www.kaggle.com/c/mercari-price-suggestion-challenge;0.749;0.462;2020-12-13 14:05:42;Mercari Price Suggestion Challenge;[];BEGINNER'S GUIDE TO MERCARI IN R - [0.50586];R notebook;10079.0;61;;
2017-11-24 10:42:23;This was just an example how nn can solve this problems. Potencial improvements of the kernel: - Increase the embeddings factos - Decrease the batch size - Add Batch Normalization - Try LSTM, Bidirectional RNN, stack RNN - Try with more dense layers or more rnn outputs -  etc. Or even try a new architecture!   Any comment will be welcome. Thanks!;Apache 2.0;https://www.kaggle.com/knowledgegrappler/a-simple-nn-solution-with-keras-0-48611-pl;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'dl', 'cv', 'rl', 'nn', 'rnn', 'ml'];['gru', 'train', 'fitting', 'model', 'epoch', 'layer', 'loss', 'label', 'lstm', 'predict'];https://www.kaggle.com/c/mercari-price-suggestion-challenge;0.789;0.571;2020-12-13 14:05:42;Mercari Price Suggestion Challenge;['deep learning, nlp, rnn'];A simple nn solution with Keras (~0.48611 PL);Python notebook;32009.0;280;;
2017-12-17 20:51:48;ELI5: which features are important for price predictionOr, explain like I'm 5, how does a linear ridge predict prices? ElL5 is a library that can help us with that, let's see it in action. It has support for many models, including XGBoost and LightGBM, but we'll be using it to analyze the Ridge model from scikit-learn.  Overall modelling strategy is inspired by this beatiful kernel Ridge Script by Alexandru Papiu.;Apache 2.0;https://www.kaggle.com/lopuhin/eli5-for-mercari;1.0;['pattern', 'xgboost', 'sklearn', 'lightgbm'];['ai', 'dl', 'gbm', 'cv', 'nn', 'ml'];['train', 'model', 'filter', 'predict'];https://www.kaggle.com/c/mercari-price-suggestion-challenge;0.795;0.566;2020-12-13 14:05:42;Mercari Price Suggestion Challenge;[];ELI5 for Mercari;Python notebook;38357.0;262;;
2017-11-24 13:18:37;Mercari Price Suggestion ChallengeThis is first of its kind and kernel only competition, and stage2 files will not be downloaded and will be available only in kernels. In this notebook, I am doing basic data exploration and reporting my findings. I will be making a simple model at the end to just as to make it complete. Val loss will be reported at the end of this notebook. NOTE - If you find this kernel useful, please upvote, and if you have any suggestion or if anything is not clear please comment, I will try to explain my work In this notebook we will extract many features and make a simple model which runs faster than Bojan :P I will be extracting following features -  Yes/No features  - if description present, if brand name present  Category and brand encoding - category has three levels and we will be seperating each level and then provide encoding for all three levels.  SVD comp on if-idf calculated over item description - self explanatory SVD comp on if-itf calculated over product name - self explanatory item_condition_id - use it without processing shipping - use it without processing  Only very few features in first round of feature extraction  We will train a XGB model to check how the extracted features are performing PS_1:  These features are working very well, please change n_comp in SVD and change the number of iterations in XGB from 80 to 1000, you will get very high accuracies. PS_2: I am learning markov models for predicting probability of author given sentence ( with history of last 3 words), I have taken a part of code from internet and I have written a probability function, but that function is faulty and I am having difficulty fixing it. If you know markov models, please contact or have a look at notebook;Apache 2.0;https://www.kaggle.com/maheshdadhich/i-will-sell-everything-for-free-0-55;1.0;['xgboost', 'sklearn', 'nltk'];['ai', 'rl'];['predict', 'train', 'model', 'clustering', 'label', 'k-means', 'loss'];https://www.kaggle.com/c/mercari-price-suggestion-challenge;0.749;0.517;2020-12-13 14:05:42;Mercari Price Suggestion Challenge;[];I will sell everything for free (~0.55);Python notebook;10037.0;127;;
2018-04-22 10:23:34;IntroductionThis is an initial Explanatory Data Analysis for the Mercari Price Suggestion Challenge with matplotlib. bokeh and Plot.ly - a visualization tool that creates beautiful interactive plots and dashboards.  The competition is hosted by Mercari, the biggest Japanese community-powered shopping app with the main objective to predict an accurate price that Mercari should suggest to its sellers, given the item's information. Update: The abundant amount of food from my family's Thanksgiving dinner has really energized me to continue working on this model. I decided to dive deeper into the NLP analysis and found an amazing tutorial by Ahmed BESBES. The framework below is  based on his source code.  It provides guidance on pre-processing documents and  machine learning techniques (K-means and LDA) to clustering topics.  So that this kernel will be divided into 2 parts:  Explanatory Data Analysis  Text Processing  2.1. Tokenizing and  tf-idf algorithm  2.2. K-means Clustering  2.3. Latent Dirichlet Allocation (LDA)  / Topic Modelling;Apache 2.0;https://www.kaggle.com/thykhuely/mercari-interactive-eda-topic-modelling;1.0;['vocabulary', 'sklearn', 'nltk'];['ner', 'ai', 'dl', 'cv', 'rl', 'nlp', 'nn', 'ml'];['filter', 'machine learning', 'training data', 'train', 'model', 'clustering', 'label', 'k-means', 'predict'];https://www.kaggle.com/c/mercari-price-suggestion-challenge;0.814;0.638;2020-12-13 14:05:42;Mercari Price Suggestion Challenge;['data visualization, exploratory data analysis'];Mercari Interactive EDA + Topic Modelling;Python notebook;73852.0;866;;
2017-12-17 17:48:43;This notebook is meant to be a proof of concept for ideas discussed in this thread. Hopefully it shows that cross-validation can be done even within existing time limits, and that it can be done even better than here with multi-processing and other tricks. In my hands cross-validation has produced scores that agree very well with LB scores - the difference is usually on the order of 0.001. That should give us comfort compared to single runs of individual methods on fold splits and random seeds that are crafted to give the best LB score. Further down the line there is a brief example of how to use out-of-fold predictions to calculate linear blending weights by minimization. Several plots closer to the end will show how individual methods differ in types of prediction errors. Lastly, all out-of-fold files and submission files will be saved if you wish to play with them locally. Fairness warning: This script will not give you a 0.43xx score at the push of a button. You will have to work on your own and modify concepts presented here in order to get that kind of score. A big thank you to @apapiu for his original Ridge script, as the initial data processing here is based on his work. It is a shame that his script has less than 40 votes, while other scripts using his strategy have more votes just because they advertise better LB scores. You know what to do if you agree with me.;Apache 2.0;https://www.kaggle.com/tilii7/cross-validation-weighted-linear-blending-errors;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'gbm', 'cv', 'rl'];['regression', 'train', 'model', 'loss', 'label', 'predict'];https://www.kaggle.com/c/mercari-price-suggestion-challenge;0.733;0.486;2020-12-13 14:05:42;Mercari Price Suggestion Challenge;[];Cross-validation, weighted linear blending, errors;Python notebook;6637.0;83;99.00000;0.44650
2018-01-22 02:42:38;DescriptionThis is an associated model using RNN ,Ridge, and a RidgeCV to solve Mercari Price Suggestion Challenge competition. It currently gets a RMSLE of ~0.419 in the development set and around ~0.427 in the competition, which is better than the currently public Kernals for the competition. I figure I don't have time to keep working on this for the next few weeks so I will simply share this model, along with some notes and thoughts, so that it can help others with their own models or function as a good jumping off point. After this kernal, I will probably bow out for the rest of the comp. If you find this kernal useful, please give me some of them sweet sweet kernel likes. I left some old code attempts in comments as well as a few repeated lines. This is just more matterial to play with if they change the code around. (Referenced Kernal links at the bottom.);Apache 2.0;https://www.kaggle.com/valkling/mercari-rnn-2ridge-models-with-notes-0-42755;1.0;['nltk', 'sklearn', 'tensorflow', 'pattern', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'rnn', 'ann'];['gru', 'training data', 'test data', 'train', 'fitting', 'model', 'output layer', 'epoch', 'validation data', 'layer', 'loss', 'label', 'lstm', 'predict', 'relu', 'labeled'];https://www.kaggle.com/c/mercari-price-suggestion-challenge;0.75;0.51;2020-12-13 14:05:42;Mercari Price Suggestion Challenge;['neural networks, rnn'];Mercari RNN + 2Ridge models with notes (~0.42755);Python notebook;10314.0;115;99.00000;0.43112
2017-05-30 19:41:15;Mercedes-Benz Greener ManufacturingWelcome to a new competition! This time from Mercedes-Benz - our job is to predict how long a car on a production line will take to pass the testing phase. This is a classical regression problem, and we're evaluated with the R2 metric. Let's take a look at the data we're given:;Apache 2.0;https://www.kaggle.com/anokas/mercedes-eda-xgboost-starter-0-55;1.0;['xgboost', 'sklearn'];['ner', 'ai', 'ml', 'rl'];['anomaly detection', 'training data', 'regression', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/mercedes-benz-greener-manufacturing;0.748;0.504;2020-12-13 14:11:17;Mercedes-Benz Greener Manufacturing;[];Mercedes EDA &  XGBoost Starter (~0.55);Python notebook;9781.0;106;;
2017-06-03 12:27:21;Hi, Kagglers! Hereafter I will try to publish some basic approaches to climb up the Leaderboard Competition goal In this competition, Daimler is challenging Kagglers to tackle the curse of dimensionality and reduce the time that cars spend on the test bench. Competitors will work with a dataset representing different permutations of Mercedes-Benz car features to predict the time it takes to pass testing. Winning algorithms will contribute to speedier testing, resulting in lower carbon dioxide emissions without reducing Daimler’s standards. The Notebook adopts skeleton from (maybe?) this script: https://www.kaggle.com/ermolushka/starter-xgboost Stay tuned, this notebook will be updated on a regular basisP.s. Upvotes and comments would let me update it faster and in a more smart way :);Apache 2.0;https://www.kaggle.com/frednavruzov/baselines-to-start-with-lb-0-56;1.0;['xgboost', 'sklearn'];['ai', 'rl', 'cv', 'nn', 'ml'];['train', 'model', 'label', 'predict'];https://www.kaggle.com/c/mercedes-benz-greener-manufacturing;0.759;0.519;2020-12-13 14:11:17;Mercedes-Benz Greener Manufacturing;['xgboost, pca'];Baselines-To-Start-With(LB=0.56+);Python notebook;13210.0;130;;
2017-07-10 04:39:13;This notebook goes through a simple process of extracting usable columns, append decomposition components to the data set, generating a few basic features, building a model and then make predictions. I am using the TPOT package to create a pipeline. TPOT is a Python Automated Machine Learning tool that optimizes machine learning pipelines using genetic programming.  I thought it is useful to add this to the list of kernels available in this competition.;Apache 2.0;https://www.kaggle.com/sheriytm/feature-based-starter-tpot-lb0-559;1.0;['xgboost', 'sklearn', 'tpot'];['ner', 'ai', 'dl', 'cv'];['machine learning', 'training data', 'automated machine learnin', 'train', 'generation', 'model', 'label', 'predict', 'labeled', 'ground truth'];https://www.kaggle.com/c/mercedes-benz-greener-manufacturing;0.713;0.439;2020-12-13 14:11:17;Mercedes-Benz Greener Manufacturing;['beginner, model comparison'];Feature-Based-Starter-TPOT-LB0.559+;Python notebook;4099.0;46;;
2017-06-03 15:29:41;In this notebook, let us explore the dataset that is given for this competition. Objective: This dataset contains an anonymized set of variables that describe different Mercedes cars. The ground truth is labeled 'y' and represents the time (in seconds) that the car took to pass testing. Let us first import the necessary modules.;Apache 2.0;https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-mercedes;1.0;['xgboost', 'sklearn'];['ai'];['train', 'model', 'label', 'predict', 'random forest', 'labeled', 'ground truth'];https://www.kaggle.com/c/mercedes-benz-greener-manufacturing;0.793;0.604;2020-12-13 14:11:17;Mercedes-Benz Greener Manufacturing;['data visualization, exploratory data analysis'];Simple Exploration Notebook - Mercedes;Python notebook;35936.0;481;;
2017-07-15 12:14:28;This is just a simple implementation of likelihood encoding (also known as impact coding or target coding) for the categorical features in python. Just trying to understand how it works. I'm pretty certain code can be improved, specially regarding the creation of the mapping and its application, but I preserved the same implementation I used in which application to the training data, and creation of the encoding map are two different steps.;Apache 2.0;https://www.kaggle.com/tnarik/likelihood-encoding-of-categorical-features;1.0;['sklearn'];['ner', 'ai', 'nn', 'cv'];['train', 'test data', 'model', 'training data'];https://www.kaggle.com/c/mercedes-benz-greener-manufacturing;0.768;0.458;2020-12-13 14:11:17;Mercedes-Benz Greener Manufacturing;[];Likelihood encoding of categorical features;Python notebook;17083.0;58;;
2019-02-25 17:37:23;Microsoft Malware PredictionThe goal of this competition is to predict a Windows machine’s probability of getting infected by various families of malware, based on different properties of that machine. It is really important to find out whether the computer is infected and cure it. We have a huge dataset of data, where most features are categorical. I think that correct mean encoding should be important. Also the number of columns is quite high so it could be tempting to make some automatical processing for all columns. I personally think that it is important to analyze each variable and it could help to do a better processing. In this kernel I'll do a detailed EDA, feature engineering and modelling.;Apache 2.0;https://www.kaggle.com/artgor/is-this-malware-eda-fe-and-lgb-updated;1.0;['xgboost', 'lightgbm', 'catboost', 'sklearn', 'pattern'];['ai', 'dl', 'gbm', 'gan', 'cv', 'rl', 'nn', 'ann'];['filter', 'test data', 'regression', 'train', 'model', 'loss', 'label', 'predict', 'rank'];https://www.kaggle.com/c/microsoft-malware-prediction;0.785;0.575;2020-12-13 14:13:18;Microsoft Malware Prediction;['data visualization, exploratory data analysis, classification, +2 morefeature engineering, gradient boosting'];Is this Malware? [EDA, FE and lgb][updated];Python notebook;28645.0;301;0.60496;0.67502
2019-02-05 23:58:49;Neural Network - Statistical Encoding - Microsoft MalwareThere aren't any examples of using a neural network to model Microsoft Malware, so I thought I'd post one. Also in this kernel, I show statistical one-hot-encoding where only boolean variables that are independently statistically significant are created. Load Train.csv;Apache 2.0;https://www.kaggle.com/cdeotte/neural-network-malware-0-67;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cv', 'rl', 'nn', 'ann'];['filter', 'training data', 'neuron', 'train', 'model', 'neural network', 'epoch', 'layer', 'loss', 'predict', 'relu', 'hidden layer'];https://www.kaggle.com/c/microsoft-malware-prediction;0.74;0.485;2020-12-13 14:13:18;Microsoft Malware Prediction;['feature engineering, neural networks'];Neural Network - Malware - [0.67];Python notebook;7922.0;82;;
2019-01-26 01:06:42;Time Series EDA for Microsoft MalwareFollowing Aditya Soni's great advice, I downloaded timestamps from Microsoft for all 18 million data observations in train.csv and test.csv. Timestamps highlight the unique challenge of this competition. The training data are mostly from August and September 2018 while the test data are mostly from October and November 2018. We are challenged to build a time independent model. Furthermore, there are 80 mostly categorical variables with an average of 1000 categories each. If we naively one hot encode each variable, we would add 80,000 new variables! Therefore we are also challenged to encode data efficiently. In this kernel, we perform EDA, discuss encodings, and build a simple linear logistic model.;Apache 2.0;https://www.kaggle.com/cdeotte/time-series-eda-malware-0-64;1.0;['statsmodels', 'sklearn'];['ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['machine learning', 'training data', 'regression', 'test data', 'train', 'model', 'label', 'logistic regression', 'predict', 'rank'];https://www.kaggle.com/c/microsoft-malware-prediction;0.751;0.535;2020-12-13 14:13:18;multiple data sources;['data visualization, exploratory data analysis, feature engineering'];Time Series EDA - Malware - [0.64];Python notebook;10713.0;163;;
2019-02-21 01:31:18;Time Split Validation - Adversarial EDA - Microsoft MalwareIs anyone else frustrated with the discrepency between CV and LB?! In this kernel, I show an example of two models that both have CV 0.730 but one has LB 0.670 while the other has LB 0.680. Why?! We will explore this and suggest ideas to more accurately estimate LB. The CulpritThe Microsoft Malware data has 82 explanatory variables which can all be intrepreted as categorical variables. The reason for CV and LB gap is the difference between TRAIN and TEST variable value distributions. In this kernel, we compare the variable distributions between TRAIN and TEST. If TRAIN and TEST were random samples from the same population then their distributions would be nearly identical (since sample size is a massive 8 million). But this is not what we see! Why? Because TRAIN is sampled from the population of August September 2018 while TEST is sampled from the different population October November 2018 (shown here). Furthermore we believe that PUBLIC TEST is October 2018 and PRIVATE TEST is November 2018 (shown here).;Apache 2.0;https://www.kaggle.com/cdeotte/time-split-validation-malware-0-68;1.0;['lightgbm', 'sklearn'];['ai', 'dl', 'gbm', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['predict', 'training data', 'test data', 'train', 'model', 'label', 'loss', 'labeled'];https://www.kaggle.com/c/microsoft-malware-prediction;0.752;0.537;2020-12-13 14:13:18;multiple data sources;[];Time Split Validation - Malware - [0.68];Python notebook;10990.0;169;;
2018-12-21 11:58:09;Microsoft Malware detectionIn this kernel, I build a LGBM model using only a subset of the training data, in order to fit in memory. Notebook  Content Utility functions Loading the data   2.1 Get the files and select the variables   2.2 Define the type of each variable Feature engineering   3.1 Frequency encoding   3.2 Label encoding Training the model Feature importance Submission;Apache 2.0;https://www.kaggle.com/fabiendaniel/detecting-malwares-with-lgbm;1.0;['lightgbm', 'sklearn'];['ai', 'dl', 'gbm', 'gan', 'cv', 'rl', 'nn', 'ann'];['filter', 'training data', 'train', 'model', 'label', 'predict', 'rank'];https://www.kaggle.com/c/microsoft-malware-prediction;0.783;0.564;2020-12-13 14:13:18;Microsoft Malware Prediction;[];Detecting Malwares with LGBM;Python notebook;26428.0;251;0.61934;0.67746
2019-03-08 18:31:24;You can remove 17 columns at the Beginning!!As the data is highly dimensional in this competition, it is really difficult to do even a little thing. So, before you begin any work, read this kernel and save your time! I have tried to reduce the column dimension by eliminating less useful columns and selected 17 columns which you can remove just after loading the data sets.  Selected mostly-missing feaures which have more than 99% of missing values. Selected too-skewed features whose majority categories cover more than 99% of occurences. Selected hightly-correlated features. Tested correlations between columns, picked up pairs whose corr is greater than 0.99, compared the distribution of the features in the pairs and corr with HasDetections,  and selected the minor column for elimination.  You can eliminate 17 columns without worry:  (M) PuaMode (M) Census_ProcessorClass (S) Census_IsWIMBootEnabled (S) IsBeta (S) Census_IsFlightsDisabled (S) Census_IsFlightingInternal (S) AutoSampleOptIn (S) Census_ThresholdOptIn (S) SMode (S) Census_IsPortableOperatingSystem (S) Census_DeviceFamily (S) UacLuaenable (S) Census_IsVirtualDevice (C) Platform (C) Census_OSSkuName (C) Census_OSInstallLanguageIdentifier (C) Processor  Here, (M) denotes mostly-missing feaures, (S) means  too-skewed features, and (C) indicates hightly-correlated features. Use this code: remove_cols = ['PuaMode', 'Census_ProcessorClass', 'Census_IsWIMBootEnabled', 'IsBeta', 'Census_IsFlightsDisabled', 'Census_IsFlightingInternal', 'AutoSampleOptIn', 'Census_ThresholdOptIn', 'SMode', 'Census_IsPortableOperatingSystem',  'Census_DeviceFamily', 'UacLuaenable', 'Census_IsVirtualDevice', 'Platform', 'Census_OSSkuName', 'Census_OSInstallLanguageIdentifier', 'Processor'] train.drop(remove_cols, axis=1, inplace=True) test.drop(remove_cols, axis=1, inplace=True)  If you want to see how I got this:In this kernel, I used only train dataset but the result was the same when I used train+test dataset.;Apache 2.0;https://www.kaggle.com/jiegeng94/everyone-do-this-at-the-beginning;1.0;['sklearn'];['ai', 'dl', 'gan', 'rl', 'nn', 'ann'];['test data', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/microsoft-malware-prediction;0.747;0.529;2020-12-13 14:13:18;Microsoft Malware Prediction;['gpu, exploratory data analysis, feature engineering'];Everyone Do this at the Beginning!!;Python notebook;9436.0;150;;
2019-03-03 14:39:02;One of the main issues in this competition is the size of the dataset. Pandas crashes when attempting to load the entire train and test datasets at once. One of the kernels has been able to read the entire train dataset using dask. In this kernels we'll use Python datatable package to load the entire train and test datasets, and do some simple EDA on them. Python datatable is still in early alpha stage and is under very active curent development. It is designed from ground up for big datasets and with efficiency and speed in mind. It is closely related to R's data.table and attempts to mimic its core algorithams and API.;Apache 2.0;https://www.kaggle.com/tunguz/eda-with-python-datatable;1.0;['sklearn', 'h2o'];['ai', 'dl', 'gan', 'rl', 'nn', 'ann'];['predict', 'test data', 'train', 'fitting', 'model', 'epoch', 'loss'];https://www.kaggle.com/c/microsoft-malware-prediction;0.728;0.478;2020-12-13 14:13:18;Microsoft Malware Prediction;[];EDA with Python datatable;Python notebook;5834.0;75;0.64009;0.67999
2018-09-19 21:42:29;Fast and Basic Solution to Movie Review Sentiment Analysis using LSTM I have used some of my previous code from Quora Duplicate Question Competition. https://github.com/aerdem4/kaggle-quora-dup;Apache 2.0;https://www.kaggle.com/aerdem4/fast-basic-lstm-with-proper-k-fold-sentimentembed;1.0;['sklearn', 'tensorflow', 'textblob', 'vocabulary', 'keras'];['ai', 'rl', 'ml', 'cv'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'lstm', 'predict', 'relu', 'sentiment analysis'];https://www.kaggle.com/c/movie-review-sentiment-analysis-kernels-only;0.719;0.45;2020-12-13 14:14:35;multiple data sources;['gpu, nlp, neural networks, +1 morelstm'];Fast Basic LSTM with proper k-fold +SentimentEmbed;Python notebook;4753.0;53;0.68911;0.68911
2018-07-04 16:37:27;In this kernel we will use a simple Convolutional Neural Network to tackle the problem at hand. CNNs are fast and produce adequate enough results, so this will serve as a pretty good baseline for more sophisticated architectures revolving around CNNs. Before we begin, we will set the seed for the components involved. That is, plain ol' Python, Numpy and Tensorflow.;Apache 2.0;https://www.kaggle.com/antmarakis/cnn-baseline-model;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cnn', 'nn'];['training data', 'neuron', 'train', 'fitting', 'model', 'output layer', 'neural network', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'classification', 'convolutional neural network'];https://www.kaggle.com/c/movie-review-sentiment-analysis-kernels-only;0.731;0.418;2020-12-13 14:14:35;Movie Review Sentiment Analysis (Kernels Only);['beginner, deep learning, cnn, +1 moretext data'];CNN Baseline Model;Python notebook;6298.0;36;0.63310;0.63310
2018-12-14 13:54:49;General informationIn this kernel I'll work with data from Movie Review Sentiment Analysis Playground Competition. This dataset is interesting for NLP researching. Sentences from original dataset were split in separate phrases and each of them has a sentiment label. Also a lot of phrases are really short which makes classifying them quite challenging. Let's try!;Apache 2.0;https://www.kaggle.com/artgor/movie-review-sentiment-analysis-eda-and-models;1.0;['lightgbm', 'nltk', 'sklearn', 'tensorflow', 'keras'];['ner', 'ai', 'dl', 'gan', 'gbm', 'cv', 'rl', 'nlp', 'nn'];['gru', 'filter', 'regression', 'train', 'model', 'epoch', 'deep learning', 'layer', 'loss', 'label', 'lstm', 'text classification', 'predict', 'relu', 'sentiment analysis', 'classification'];https://www.kaggle.com/c/movie-review-sentiment-analysis-kernels-only;0.794;0.553;2020-12-13 14:14:35;multiple data sources;['gpu, exploratory data analysis, deep learning, +1 morenlp'];Movie Review Sentiment Analysis EDA and models;Python notebook;37860.0;213;;
2018-08-23 13:24:33;Sentiment Analysis on Movie ReviewsThe sentiment labels are:  0 - negative 1 - somewhat negative 2 - neutral 3 - somewhat positive 4 - positive;Apache 2.0;https://www.kaggle.com/ashishpatel26/movie-review-analysis;1.0;['tensorflow', 'sklearn', 'keras', 'nltk'];['ner', 'ai', 'rl', 'gan'];['gru', 'filter', 'train', 'model', 'layer', 'loss', 'label', 'lstm', 'predict', 'sentiment analysis'];https://www.kaggle.com/c/movie-review-sentiment-analysis-kernels-only;0.682;0.346;2020-12-13 14:14:35;multiple data sources;['gpu, text mining'];Movie Review Analysis ;Python notebook;2068.0;16;;
2018-06-23 15:09:00;To Do :  Some plots LB Accuracy improvement;Apache 2.0;https://www.kaggle.com/codename007/sentiment-analysis-baseline-model;1.0;['sklearn'];['ai', 'nn'];['train', 'test data', 'predict'];https://www.kaggle.com/c/movie-review-sentiment-analysis-kernels-only;0.68;0.346;2020-12-13 14:14:35;Movie Review Sentiment Analysis (Kernels Only);[];Sentiment Analysis : Baseline Model;Python notebook;1995.0;16;0.60990;0.60990
2018-08-02 15:41:24;Intro to Movie Review Sentiment Analysis For the movie review sentiment analysis, we will be working on The Rotten Tomatoes movie review dataset from Kaggle.  Here, we'll have to label phrases on a scale of five values: negative, somewhat negative, neutral, somewhat positive, positive based on the sentiment of the movie reviews. The dataset is comprised of tab-separated files with phrases from the Rotten Tomatoes dataset. Each phrase has a PhraseId. Each sentence has a SentenceId. Phrases that are repeated (such as short/common words) are only included once in the data. The sentiment labels are:  0 - negative 1 - somewhat negative 2 - neutral 3 - somewhat positive 4 - positive  Any suggestions for improvement or comments are highly appreciated! Please upvote(like button) and share this kernel if you like it so that more people can learn from it.;Apache 2.0;https://www.kaggle.com/divsinha/sentiment-analysis-countvectorizer-tf-idf;1.0;['pattern', 'vocabulary', 'sklearn'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'regression', 'training data', 'train', 'test data', 'model', 'loss', 'label', 'logistic regression', 'predict', 'rank', 'understanding', 'sentiment analysis', 'classification', 'natural language'];https://www.kaggle.com/c/movie-review-sentiment-analysis-kernels-only;0.779;0.39;2020-12-13 14:14:35;Movie Review Sentiment Analysis (Kernels Only);['data visualization, exploratory data analysis, classification, +2 moredata cleaning, dailychallenge'];Sentiment Analysis : CountVectorizer & TF-IDF;Python notebook;23820.0;26;;
2018-11-24 17:05:07;Convolutional Neural Networks for Sentence Classification by Yoon Kim in KerasKim's paper was published in 2014 and showed that not only are CNNs great for images but also text. With an extreamly simple architecture Kim outperformed all other models in 4 out of 7 benchmarks at the time. In my first attempt to reproduce a paper on Kaggle, I'm going to try and recreate what he did with Keras.  Architecture - architecture diagram taken from Kim's paper The architecture Kim used goes like this: Firstly, sentences are represented as vectors of words and those words are converted into (300D) vectors giving us a 2D representation for each sentence. Kim uses a few different approaches for creating these word vectors:  CNN-rand: where embeddings are randomly assigned to each word CNN-static: word2vec is used to provide word embeddings. Unknown words are randomly initialised. These embeddings are kept fixed. CNN-non-static: as above, but the vectors are fine-tuned (ie they can be changed) during training  Kim also tried another approach which I won't attempt to do here.. because quite frankly I don't know how. I might attempt this in the future.  CNN-multichannel: Here Kim uses two sets of word vectors. My understanding is he applies both to the sentence (resulting in two, sentence_length x 300D matricies) and performs convolutions on both (see below). During training he fine tunes one embedding but keeps the other one fixed. He states the hope of this was that it would act as a form of regularization but the results were mixed. I'm not sure if this approach was investigated and improved upon in other papers or not. Hopefully it was, it sounds like the kind of thing that might work.  He then performs convolutions on these 2D representations, but he does it in a way you don't see very often. Convolutions of different window sizes (3, 4 and 5) are performed on the representations directly and then max pooled. This is a little like an inception module in the Goog LeNet, but not something I've really seen anywhere else. Finally after a layout of dropout, an output layer is directly used to do the predictions. And that's it! With one conv layer and some max pooling we can get fantastic results! Why this paper is interestingWe all know LSTMs are the king of sentence classification... but are they really? Recently I tried to classify a million sentences where I work with a (admittedly complicated) LSTM. It was estimated it would take 130 hours to run on the machine available. With something inspired by this model it takes around an hour and we achieved compariable accuracy (these are short sentences which is believe why that works). It's also interesting to see totally different approaches to solving this problem. Update while working on another problem I found myself doing something Kim does in this paper which you don't often see: When randomly initializing words not in word2vec, we obtained slight improvements by sampling each dimension from U[−a, a] where a was chosen such that the randomly initialized vectors have the same variance as the pre-trained ones. It would be interesting to see if employing more sophisticated methods to mirror the distribution of pre-trained vectors in the initialization process gives further improvements.  This is really interesting and something I would like to explore in another kernel. Places this differs from Kim's paperSadly I couldn't find the same data Kim used, but I've managed to find something very similar sounding to the SST1 data (from which I can infer the SST2 data) where it looks like we can achieve simiar results. Kim uses a 300D w2v model trained using cbow. I couldn't find this model, but used a 200D model trained using GloVe. The major impact of this is we use an embedding dimension of 200 here. I also swapped out the optimizer Kim used (AdaDelta) for Adam - AdaDelta took forever to run but it looks like you get the same results as Adam. If you're happy to sit there for around 100 epochs you can try it out. Data prepSo let's get started. Before we do anything else we need to get some data and prep it;Apache 2.0;https://www.kaggle.com/hamishdickson/cnn-for-sentence-classification-by-yoon-kim;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cnn', 'gan', 'rl', 'ml', 'nn', 'ann'];['filter', 'train', 'model', 'output layer', 'neural network', 'epoch', 'layer', 'relu', 'loss', 'label', 'lstm', 'predict', 'rank', 'understanding', 'classification', 'convolutional neural network'];https://www.kaggle.com/c/movie-review-sentiment-analysis-kernels-only;0.733;0.352;2020-12-13 14:14:35;multiple data sources;['gpu, classification, nlp, +2 morecnn, text data'];CNN for Sentence Classification by Yoon Kim;Python notebook;6628.0;17;;
2018-08-22 05:56:24;TF-Hub is a platform to share machine learning expertise packaged in reusable resources, notably pre-trained modules. In this tutorial, we will use a TF-Hub text embedding module to train a simple sentiment classifier with a reasonable baseline accuracy. We will then submit the predictions to Kaggle. For more detailed tutorial on text classification with TF-Hub and further steps for improving the accuracy, take a look at Text classification with TF-Hub.;Apache 2.0;https://www.kaggle.com/jeremiahharmsen/tensorflow-hub-for-text-classification;1.0;['tensorflow', 'sklearn'];['ner', 'ai', 'nn', 'ann'];['machine learning', 'training data', 'regression', 'train', 'model', 'epoch', 'label', 'text classification', 'predict', 'sentiment analysis', 'classification'];https://www.kaggle.com/c/movie-review-sentiment-analysis-kernels-only;0.734;0.375;2020-12-13 14:14:35;Movie Review Sentiment Analysis (Kernels Only);['transfer learning'];TensorFlow Hub for Text Classification;Python notebook;6882.0;22;0.65072;0.65072
2018-08-23 10:31:32;"Rotten Tomatoes is an American review-aggregation website for film and television. The company was launched in August 1998 by three undergraduate students at the University of California, Berkeley: Senh Duong, Patrick Y. Lee and Stephen Wang. The name ""Rotten Tomatoes"" derives from the practice of audiences throwing rotten tomatoes when disapproving of a poor stage performance EvalutionSubmissions are evaluated on classification accuracy (the percent of labels that are predicted correctly) for every parsed phrase. The sentiment labels are: 0 - negative 1 - somewhat negative 2 - neutral 3 - somewhat positive 4 - positive";Apache 2.0;https://www.kaggle.com/nikitpatel/eda-cleaning-keras-lstm-clustering;1.0;['nltk', 'sklearn', 'tensorflow', 'textblob', 'keras'];['ner', 'ai', 'dl', 'rl', 'nn'];['gru', 'filter', 'test data', 'train', 'model', 'epoch', 'layer', 'clustering', 'loss', 'label', 'lstm', 'predict', 'understanding', 'classification'];https://www.kaggle.com/c/movie-review-sentiment-analysis-kernels-only;0.72;0.379;2020-12-13 14:14:35;multiple data sources;['exploratory data analysis, data cleaning, clustering, +1 morelstm'];EDA_Cleaning_Keras=(LSTM+Clustering);Python notebook;4867.0;23;0.61714;0.61714
2018-07-20 02:51:13;Movie Review Sentiment Analysis  Classify the sentiment of sentences from the Rotten Tomatoes dataset;Apache 2.0;https://www.kaggle.com/parth05rohilla/sentiment-analysis-using-7-different-techniques;1.0;['tensorflow', 'sklearn', 'keras', 'nltk'];['ner', 'ai', 'cnn', 'rl', 'nn'];['gru', 'machine learning', 'regression', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'lstm', 'predict', 'relu', 'sentiment analysis', 'classification'];https://www.kaggle.com/c/movie-review-sentiment-analysis-kernels-only;0.752;0.39;2020-12-13 14:14:35;Movie Review Sentiment Analysis (Kernels Only);['gpu, data visualization, exploratory data analysis, +1 moredeep learning'];Sentiment Analysis using 7 different techniques;Python notebook;10966.0;26;0.65125;0.65125
2019-03-03 06:53:53;Here are some of my experiences with the movie review sentiment analysis dataset  ( I have also documented my other experiences with Text and NLP ).  The dataset of this competition turned out to be different (read weird here), in a sense regular Data Preparation/Cleansing and Feature harvesting didn't work. But this gave me a great learning.  I tried many possible combinations of data preparation/cleansing, feature extraction and network architectures. (Hence 108 submissions :-));Apache 2.0;https://www.kaggle.com/prithiviraj/beginner-friendly-fastext-bilstmcnn-top-1;1.0;['vocabulary', 'gensim', 'tensorflow', 'pattern', 'keras'];['ner', 'ai', 'cnn', 'cv', 'rl', 'ml', 'nlp', 'nn', 'rnn', 'ann'];['gru', 'filter', 'test data', 'regression', 'train', 'fitting', 'model', 'epoch', 'layer', 'loss', 'lstm', 'predict', 'relu', 'understanding', 'sentiment analysis'];https://www.kaggle.com/c/movie-review-sentiment-analysis-kernels-only;0.696;0.362;2020-12-13 14:14:35;multiple data sources;['gpu, beginner, cnn, +1 morelstm'];Beginner friendly Fastext + BiLSTMCNN- Top 1%;Python notebook;2823.0;19;;
2018-07-19 17:16:34;I wanted to see if a simple n-gram approach with Logistic regression can get me somewhere in this competition as well. So far it seems to be working pretty well, but the script needs to be optimized further.;Apache 2.0;https://www.kaggle.com/tunguz/lr-with-words-and-char-n-grams;1.0;['pattern', 'sklearn'];['ai', 'cv'];['regression', 'train', 'model', 'logistic regression', 'predict'];https://www.kaggle.com/c/movie-review-sentiment-analysis-kernels-only;0.66;0.362;2020-12-13 14:14:35;Movie Review Sentiment Analysis (Kernels Only);[];LR with words and char n-grams ;Python notebook;1315.0;19;0.63503;0.63503
2017-08-29 18:03:24;Predict the effect of Genetic Variants;Apache 2.0;https://www.kaggle.com/alyosama/doc2vec-with-keras-0-77;1.0;['nltk', 'gensim', 'sklearn', 'tensorflow', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['test data', 'generation', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'lstm', 'predict', 'relu', 'understanding', 'labeled'];https://www.kaggle.com/c/msk-redefining-cancer-treatment;0.763;0.413;2020-12-13 14:17:31;Personalized Medicine: Redefining Cancer Treatment;[];Doc2Vec with Keras (0.77);Python notebook;14822.0;34;;
2017-07-05 07:42:43;In this notebook, let us build our model using LinearSVC which is best for text classification problems.;Apache 2.0;https://www.kaggle.com/bhuvaneshwaran/redefining-cancer-treatment-linear-svc;1.0;['sklearn'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['training data', 'test data', 'generation', 'train', 'model', 'layer', 'loss', 'text classification', 'predict', 'understanding', 'classification'];https://www.kaggle.com/c/msk-redefining-cancer-treatment;0.737;0.447;2020-12-13 14:17:31;Personalized Medicine: Redefining Cancer Treatment;['beginner, classification, svm'];Redefining Cancer Treatment - Linear SVC;Python notebook;7311.0;51;;
2018-06-17 22:30:33;Hello all, im a nebie here and i'll  try to explain you what i've learned so far in an understable way. Please upvote at the end if you like my kernel and encourage me.;Apache 2.0;https://www.kaggle.com/bsivavenu/cancer-treatment-with-machine-learning;1.0;['xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'dl', 'gbm', 'rl', 'ml', 'nlp', 'nn', 'ann'];['filter', 'generation', 'train', 'model', 'layer', 'loss', 'predict', 'understanding', 'classification'];https://www.kaggle.com/c/msk-redefining-cancer-treatment;0.708;0.311;2020-12-13 14:17:31;Personalized Medicine: Redefining Cancer Treatment;['beginner, linguistics'];Cancer Treatment with machine learning ;Python notebook;3681.0;11;;
2017-07-08 14:45:36;Some initial features from the Variants Note: As this is my first published Kernel, forgive my coding style and brevity.  The bulk of the features I've generated so far involve the mutations/Variants and their effects. My background is in Proteins/Neuropeptides, so I took some ideas from my Thesis, which was a number of Feature engineering libraries for Protein sequences. You can read up on feature engineering/ML with proteins/peptides in one of the papers, and the code+toolkits are all freely available (NeuroPID, ProFET, ASAP).  If you use it, please cite :).  NeuroPID: a predictor for identifying neuropeptide precursors https://www.ncbi.nlm.nih.gov/pubmed/24336809   ProFET: Feature engineering captures high-level protein functions.   * https://www.ncbi.nlm.nih.gov/pubmed/26130574    * https://github.com/ddofer/ProFET/blob/master/ProFET/feat_extract/AAlphabets.py   I'll try to add some additional techniques/tricks as the competition progresses, but no promises. (I'm lazy, and my code is not just in Python. I'm hoping to lead by example here, and that others will upload rather better code than this).;Apache 2.0;https://www.kaggle.com/danofer/genetic-variants-to-protein-features;1.0;['pattern'];['ner', 'ai', 'dl', 'ml', 'nn', 'ann'];['train', 'loss', 'filter', 'predict'];https://www.kaggle.com/c/msk-redefining-cancer-treatment;0.732;0.429;2020-12-13 14:17:31;Personalized Medicine: Redefining Cancer Treatment;['feature engineering, intermediate'];Genetic Variants to Protein Features;Python notebook;6509.0;41;;
2017-08-02 17:57:26;There are some really cool Kernels sitting out there for this competition and they are far slicker and efficient than this. This is just a brief data dive and some features using TFIDF and Truncated SVD on them.;Apache 2.0;https://www.kaggle.com/dex314/tfidf-truncatedsvd-and-light-gbm;1.0;['vocabulary', 'lightgbm', 'nltk', 'sklearn', 'pattern'];['ai', 'gbm', 'cv', 'rl', 'nn', 'ml'];['predict', 'train', 'model', 'label', 'loss'];https://www.kaggle.com/c/msk-redefining-cancer-treatment;0.754;0.393;2020-12-13 14:17:31;Personalized Medicine: Redefining Cancer Treatment;[];TFIDF, TruncatedSVD, and Light GBM;Python notebook;11521.0;27;;
2017-07-02 19:31:41;High level insight on genetic variationsNote: As this is my first published Kernel, am open to suggestions. If this helped you, some upvotes would be very much appreciated. Library and SettingsImport required library and define constants;Apache 2.0;https://www.kaggle.com/dextrousjinx/brief-insight-on-genetic-variations;1.0;['pattern', 'sklearn'];['ner', 'ai', 'rl', 'nn', 'ml'];['machine learning', 'training data', 'test data', 'train', 'model', 'label'];https://www.kaggle.com/c/msk-redefining-cancer-treatment;0.76;0.507;2020-12-13 14:17:31;Personalized Medicine: Redefining Cancer Treatment;['nlp'];Brief insight on Genetic variations;Python notebook;13593.0;111;;
2017-08-24 15:40:56;Naive check of 'Gene+Variation' values  Note about variations with pattern 'Gene1-Gene2 Fusion'   1. Naive check of combinations 'Gene + Variation'Import Pandas and read 'variants' files;Apache 2.0;https://www.kaggle.com/eavdeeva/cancer-all-gene-variation-values-are-unique;1.0;['pattern'];['ner', 'ai'];['train', 'test data', 'training data'];https://www.kaggle.com/c/msk-redefining-cancer-treatment;0.667;0.311;2020-12-13 14:17:31;Personalized Medicine: Redefining Cancer Treatment;[];Cancer. All 'Gene + Variation' values are unique;Python notebook;1538.0;11;;
2020-08-23 00:23:32;Задача:Разработать алгоритмы классификации генетических мутаций на основе клинических данных (текста). Предсказать класс, в котором была генетическая мутация.;Apache 2.0;https://www.kaggle.com/miracl16/basic-xgboost-tfidf-russian-version;1.0;['xgboost', 'sklearn', 'nltk'];['ai', 'dl', 'rl', 'cv', 'ml'];['train', 'model', 'loss', 'label', 'predict', 'classification'];https://www.kaggle.com/c/msk-redefining-cancer-treatment;0.611;0.4;2020-12-13 14:17:31;Personalized Medicine: Redefining Cancer Treatment;[];Basic XGBoost + TFIDF (russian version);Python notebook;540.0;29;;
2017-09-18 05:06:58;In this kernel we'll try some Latent Dirichlet Allocation to automatically extract the topics that characterize our text data :). This is my first one ever on Kaggle!;Apache 2.0;https://www.kaggle.com/raulitoskys/using-lda-to-extract-topics-from-the-text;1.0;['pattern', 'sklearn'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['predict', 'generation', 'train', 'fitting', 'model', 'layer', 'loss', 'understanding'];https://www.kaggle.com/c/msk-redefining-cancer-treatment;0.737;0.319;2020-12-13 14:17:31;Personalized Medicine: Redefining Cancer Treatment;[];Using LDA to Extract Topics from the Text;Python notebook;7357.0;12;;
2017-09-13 07:40:47;A simple anaysis of the dataset using nltk and Word2VecThis notebook goes over the dataset in the following order:  Read the data into a dataframe using pandas library. Cleaning unnecessary data (unique or null columns). Analyzing data distributions. Analyzing text data via keywords and summarization. Tokenizing (Lemmatization and stopwording) for further analysis. Analyzing word distributions for any surface correlations. Creating a word cloud of the whole text. Using Word2Vec to check the correlation between text and the classes.   Disclaimer: I couldn't find a way to upload the trained word2vec weight vectors to kaggle kernel, so I just attached the results as markdown. More thorough version can be found on my github. This kernel has been tested with python 3.6 (x64) on Windows.;Apache 2.0;https://www.kaggle.com/umutto/preliminary-data-analysis-using-word2vec;1.0;['tensorflow', 'sklearn', 'nltk', 'gensim'];['ner', 'ai', 'dl', 'nn', 'ann'];['train', 'model', 'clustering', 'label', 'k-means', 'predict', 'rank', 'labeled'];https://www.kaggle.com/c/msk-redefining-cancer-treatment;0.737;0.413;2020-12-13 14:17:31;Personalized Medicine: Redefining Cancer Treatment;[];Preliminary Data Analysis Using Word2Vec;Python notebook;7452.0;34;;
2018-08-18 17:51:33;Convert pickup_datetime from Object to Datetime object;Apache 2.0;https://www.kaggle.com/aiswaryaramachandran/eda-and-feature-engineering;1.0;['sklearn'];['ai', 'rl'];['filter', 'training data', 'test data', 'train', 'model', 'layer', 'label'];https://www.kaggle.com/c/new-york-city-taxi-fare-prediction;0.747;0.425;2020-12-13 14:20:01;New York City Taxi Fare Prediction;['beginner, data visualization, exploratory data analysis, +2 morefeature engineering, data cleaning'];EDA and Feature Engineering;Python notebook;9443.0;39;;
2018-09-13 19:49:21;Here, we are going to perform data cleaning, feature engineering, data visualization for which we will prefer seaborn and will train Random Forest, XGBoost & LGBM models then will compare and apply GridSearchCV parameter selection on the better one to check if it does any more improvement and at last will ensemble best predictions. Thanks to kagglers, I am going through many splendid kernels and learning new techniques and approaches and yes this is my first Kaggle competition submission, will be glad to have your suggestions :);Apache 2.0;https://www.kaggle.com/amar09/fare-prediction-stacked-ensemble-xgboost-lgbm;1.0;['xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'nn'];['test data', 'regression', 'train', 'model', 'label', 'predict', 'random forest'];https://www.kaggle.com/c/new-york-city-taxi-fare-prediction;0.732;0.362;2020-12-13 14:20:01;New York City Taxi Fare Prediction;['beginner, xgboost, ensembling'];Fare prediction: Stacked ensemble XGBoost & LGBM;Python notebook;6421.0;19;;
2018-08-27 10:30:57;"New York City Taxi Fare Prediction Playground CompetitionThis is my notebook I used to explore the NYC Taxi Fare dataset. Use this yourself to explore the dataset. If you have question, sent me a message! Have fun! Albert van Breemen 27/7/2018 Update 2018/08/27  Corrected error in calculating min/max coordinates. This error has no consequence for the remaining analysis. [Thanks to Pegah]  2018/08/10  Added visuals to analyse the importance of the direction of a trip  2018/08/08  Using the insights from this notebook, I trained a model that got a #1 position on 2018/08/07 (LB score 2.88396) Added pickup traffic density plots to see how busy it is in Manhatten by the hour  2018/08/04  Thanks for all the feedback! This notebook is becoming rather long, but there is so much fun stuff to analyse!! ;) updated the boundingbox and NYC maps, as one test point was not within the bounding box added zoomed in map of NYC added hiresolution NYC/Manhattan map plot added function to remove datapoints from water small update in datapoints per sq miles calculation  2018/07/30  Corrected 'ewr'/'lgr' typo [Thanks to Lu Mingming] Small update plot_on_map function Converted distances to miles [Thanks to sandy1112] Add Taxi pricing rules [Thanks to sandy1112] Added density plots (datapoints per sq mile)  2018/07/28  Added a graph with estimated drive time for two trips using Google Map Traffic info. This could explain how fare depends on hour of the day.  Reading data and first explorationFirst thing I like to do with a new dataset is to explore the data. This means investigating the number of features, their datatype, their meaning and statistics.";Apache 2.0;https://www.kaggle.com/breemen/nyc-taxi-fare-data-exploration;1.0;['pattern', 'sklearn'];['ner', 'ai', 'rl', 'nn', 'ml'];['training data', 'test data', 'regression', 'train', 'model', 'deep learning', 'label', 'predict', 'linear regression'];https://www.kaggle.com/c/new-york-city-taxi-fare-prediction;0.813;0.618;2020-12-13 14:20:01;New York City Taxi Fare Prediction;['data visualization, linear regression, geospatial analysis'];NYC Taxi Fare - Data Exploration;Python notebook;72513.0;614;;
2018-10-29 20:51:17;"This is an adaptation of the Coursera code (originally built with tensorflow), on this one i used Keras to make the model part simpler, maybe it can help people that are new to deep learning or anyone else that want to use Keras on this competition.Notes: Link for a tensorflow version Link for a more complete version on Github I'm not using ""passenger count"" because it something that is not supposed to really matter in this case. I've created two features derived from ""hour"" (night and late night), according to some research i did it's added an additional value if it's a business day (mon ~ fri), and it's night, also there's another added value if it's dawn. I'm binning latitudes and longitudes to make it easier to work with. Even tough deep learning is robust enough to deal with noisy data, i'm removing outliers (it may save some memory). Currently i'm using both Euclidean and Manhattan distances, it may be a bit redundant, but they have a different meaning and i'm still not sure of witch one is better(if you have some insights about this please let me know)";Apache 2.0;https://www.kaggle.com/dimitreoliveira/taxi-fare-prediction-with-keras-deep-learning;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'nn', 'rl'];['train', 'model', 'epoch', 'deep learning', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/new-york-city-taxi-fare-prediction;0.751;0.447;2020-12-13 14:20:01;New York City Taxi Fare Prediction;['gpu, beginner, deep learning, +2 morefeature engineering, data cleaning'];Taxi fare prediction with Keras deep learning;Python notebook;10476.0;51;3.58842;3.58842
2018-10-02 02:58:48;"Taxi fare predictions with deep learning and TensorflowIn this version of the code i use pandas to load the data and the Tensorflow input pandas function to feed the model.Notes: Link for a Keras version Link for a more complete version on Github I'm not using ""passenger count"" because it something that is not supposed to really matter in this case. I've created two features derived from ""hour"" (night and late night), according to some research i did it's added an additional value if it's a business day (mon ~ fri) and it's night, also there's another added value if it's dawn (late night). I'm binning latitudes and longitudes to make it easier to work with. Even tough deep learning is robust enough to deal with noisy data, i'm removing outliers (it may save some memory). Currently i'm using both Euclidean and Manhattan distances, it may be a bit redundant, but they have a different meaning and i'm still not sure of witch one is better(if you have some insights about this please let me know)";Apache 2.0;https://www.kaggle.com/dimitreoliveira/tensorflow-dnn-coursera-ml-course-tutorial;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'nn', 'ml'];['predict', 'train', 'model', 'epoch', 'deep learning', 'label', 'loss', 'understanding'];https://www.kaggle.com/c/new-york-city-taxi-fare-prediction;0.719;0.413;2020-12-13 14:20:01;New York City Taxi Fare Prediction;['beginner, deep learning, feature engineering, +2 moredata cleaning, tensorflow'];Tensorflow DNN, Coursera ml course tutorial;Python notebook;4755.0;34;;
2018-07-25 04:04:04;This is a basic Starter Kernel for the New York City Taxi Fare Prediction Playground CompetitionHere we'll use a simple linear model based on the travel vector from the taxi's pickup location to dropoff location which predicts the fare_amount of each ride. This kernel uses some pandas and mostly numpy for the critical work.  There are many higher-level libraries you could use instead, for example sklearn or statsmodels.;Apache 2.0;https://www.kaggle.com/dster/nyc-taxi-fare-starter-kernel-simple-linear-model;1.0;['statsmodels', 'sklearn'];['ner', 'ai', 'ml'];['train', 'model', 'training data', 'predict'];https://www.kaggle.com/c/new-york-city-taxi-fare-prediction;0.797;0.571;2020-12-13 14:20:01;New York City Taxi Fare Prediction;['beginner, linear regression'];NYC Taxi Fare Starter Kernel - Simple Linear Model;Python notebook;40766.0;281;5.74184;5.74184
2018-08-04 21:28:47;Load dataset First we will load the train.csv dataset. Since this dataset has 55M rows, we will only use the first 6M to build our model to prevent memory issues and speed up preprocessing and model building.;Apache 2.0;https://www.kaggle.com/gunbl4d3/xgboost-ing-taxi-fares;1.0;['xgboost', 'sklearn'];['ai', 'dl', 'gbm', 'cv', 'rl', 'nn', 'ann'];['training data', 'test data', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/new-york-city-taxi-fare-prediction;0.726;0.442;2020-12-13 14:20:01;New York City Taxi Fare Prediction;[];XGBoost'ing Taxi Fares;Python notebook;5615.0;48;3.03992;3.03992
2018-08-07 10:10:52;PART 1 --> DATA CLEANSING & EXPLORATORY DATA ANALYSIS (EDA) Will perform the following activities  Shape of train and test sets Check for NaNs and drop them (if any) Check for outliers and drop them (if any) Type conversion of relevant fields;Apache 2.0;https://www.kaggle.com/madhurisivalenka/cleansing-eda-modelling-lgbm-xgboost-starters;1.0;['xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'gbm', 'rl', 'ml', 'nn', 'ann'];['filter', 'test data', 'regression', 'train', 'model', 'label', 'predict', 'random forest'];https://www.kaggle.com/c/new-york-city-taxi-fare-prediction;0.764;0.516;2020-12-13 14:20:01;New York City Taxi Fare Prediction;['exploratory data analysis, data cleaning'];Cleansing+EDA+Modelling(LGBM + XGBoost starters)  ;Python notebook;15095.0;126;;
2018-09-25 10:23:20;0. 初めに今回はKaggleのcompetitionNew York City Taxi Fare Predictionに参加してみました。 回帰予測のチュートリアル感覚で、データ数が多いこと以外は初心者でもサクサクできたと思います。     https://www.kaggle.com/c/new-york-city-taxi-fare-prediction 今回は先輩方や同期の意見を参考にしたり、初心者なりにまとめたつもりなので温かい目で見ていってくだされば幸いです。 かつフィードバックもいただければと期待しております。 ではよろしくお願いします。 1. 前処理;Apache 2.0;https://www.kaggle.com/namakaho/nyctaxi;1.0;['lightgbm', 'sklearn', 'mxnet', 'tensorflow', 'keras'];['ai', 'dl', 'gbm', 'rl', 'nn', 'ml'];['regression', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/new-york-city-taxi-fare-prediction;0.65;0.367;2020-12-13 14:20:01;New York City Taxi Fare Prediction;['beginner, exploratory data analysis'];日本人がNYCtaxiをやってみた;Python notebook;1093.0;20;;
2018-11-26 23:57:25;Taxi Rides Time AnalysisBy Nick Brooks, July 2018;Apache 2.0;https://www.kaggle.com/nicapotato/taxi-rides-time-analysis-and-oof-lgbm;1.0;['xgboost', 'sklearn', 'lightgbm'];['ai', 'rl', 'ml', 'gbm'];['regression', 'train', 'model', 'label', 'gradient boosting', 'predict', 'understanding'];https://www.kaggle.com/c/new-york-city-taxi-fare-prediction;0.72;0.431;2020-12-13 14:20:01;New York City Taxi Fare Prediction;['data visualization, gradient boosting'];Taxi Rides Time Analysis and OOF LGBM;Python notebook;4822.0;42;;
2018-09-01 04:18:51;How to load all  55,423,855 rows of data into one single DataFrame about 2 minutes, and reload it the same next time under 5 seconds (your mileage may vary);Apache 2.0;https://www.kaggle.com/szelee/how-to-import-a-csv-file-of-55-million-rows;1.0;['xgboost'];['ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['training data', 'filter', 'train', 'understanding', 'bayesian'];https://www.kaggle.com/c/new-york-city-taxi-fare-prediction;0.801;0.543;2020-12-13 14:20:01;New York City Taxi Fare Prediction;[];How to import a CSV file of 55 million rows;Python notebook;47778.0;183;;
2018-09-10 04:03:30;Introduction: Taxi Fare PredictionWelcome to another Kaggle challenge. In this contest, the aim is to predict the fare of a taxi ride given the starting time, the starting and ending latitude / longitude, and the number of passengers. This is a supervised regression machine learning task. In this notebook, I'll provide you with a solid foundation and leave you with the challenge to better the score. Although the dataset is large, this is an approachable problem and as usual with Kaggle competitions, provides realistic practice for building a machine learning solution. The best way to learn is by doing, so let's work through a complete machine learning problem! Great resources for Kaggle competitions are the discussion forums and the kernels completed by other data scientists. I recommend using, adapting, and building on others' code, especially when you are getting started.;Apache 2.0;https://www.kaggle.com/willkoehrsen/a-walkthrough-and-a-challenge;1.0;['sklearn'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['linear regression', 'filter', 'machine learning', 'regression', 'training data', 'train', 'fitting', 'model', 'test data', 'random forest', 'neural network', 'validation data', 'label', 'gradient boosting', 'predict', 'recommend', 'classification'];https://www.kaggle.com/c/new-york-city-taxi-fare-prediction;0.757;0.501;2020-12-13 14:20:01;New York City Taxi Fare Prediction;['beginner, feature engineering'];A Walkthrough and a Challenge;Python notebook;12637.0;102;3.14868;3.14868
2019-11-07 02:25:16;Functions for anchoring offense moving left from {0,0};Apache 2.0;https://www.kaggle.com/bestpredict/location-eda-8eb410;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'rl', 'nn', 'ml'];['predict', 'train', 'model', 'epoch', 'layer', 'loss', 'relu'];https://www.kaggle.com/c/nfl-big-data-bowl-2020;0.738;0.49;2020-12-13 14:21:44;NFL Big Data Bowl;[];Location EDA 8eb410;Python notebook;7526.0;88;0.013321;0.013321
2020-01-08 20:30:33;A previous version of this code got a public LB of 0.01299 and is described in https://www.kaggle.com/c/nfl-big-data-bowl-2020/discussion/119430 Since competition end I have implemented few improvements, and in particular all piece of the transformer architecture.  The code uses keras functional model api, which makes it way ore compact than the transformer implementations one can find online.  I also included some data cleaning that was shared by top teams, namely using S = 10 * Dis, and averaging A in 2017.  The CV is improved by about 0.00025, which could bring LB around 0.01275, not top, but still of interest for a model without any feature engineering besides distance matrix computation.;Apache 2.0;https://www.kaggle.com/cpmpml/graph-transfomer;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'nlp', 'nn', 'ml'];['training data', 'regression', 'generation', 'train', 'model', 'output layer', 'epoch', 'deep learning', 'layer', 'loss', 'predict', 'relu', 'recommend'];https://www.kaggle.com/c/nfl-big-data-bowl-2020;0.747;0.528;2020-12-13 14:21:44;NFL Big Data Bowl;[];Graph Transfomer;Python notebook;9522.0;149;0.012494;0.012494
2019-10-14 05:12:43;IntroductionI will introduce a simple method using lightGBM as a starter.;Apache 2.0;https://www.kaggle.com/hukuda222/nfl-simple-model-using-lightgbm;1.0;['lightgbm', 'sklearn'];['ai', 'dl', 'gan', 'gbm', 'rl', 'nn'];['training data', 'train', 'model', 'layer', 'label', 'predict', 'rank', 'classification'];https://www.kaggle.com/c/nfl-big-data-bowl-2020;0.756;0.544;2020-12-13 14:21:44;NFL Big Data Bowl;['beginner'];NFL simple model using lightGBM;Python notebook;12069.0;188;;
2019-10-15 07:00:14;"Keras Starter & Metric CRPS & Early Stopping 🚀Intro:  Only have done some naive aggregations by PlayId Fully Connected NN Cum Sum the Softmax output and clip to 0,1 Early Stopping Support for CRPS and restoring back to the ""best"" weights A Scalable codebase that allows you to edid Please Upvote this kernel! 👍🏻";Apache 2.0;https://www.kaggle.com/kingychiu/keras-nn-starter-crps-early-stopping;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'rl', 'nn'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/nfl-big-data-bowl-2020;0.716;0.503;2020-12-13 14:21:44;NFL Big Data Bowl;['neural networks'];🏈 Keras NN Starter &  CRPS & Early Stopping 🏈;Python notebook;4392.0;105;;
2019-10-25 14:04:42;v12 : fix bugv11 : drop more features based on feature importancesv10 : drop some features based on feature importancesv9 : add feature importance plotv8 : add commentsv7 : 0.01387;Apache 2.0;https://www.kaggle.com/mrkmakr/lgbm-multiple-classifier;1.0;['tensorflow', 'lightgbm', 'sklearn', 'keras'];['dl', 'ai', 'nn', 'gbm'];['filter', 'train', 'model', 'neural network', 'layer', 'loss', 'label', 'predict'];https://www.kaggle.com/c/nfl-big-data-bowl-2020;0.721;0.475;2020-12-13 14:21:44;NFL Big Data Bowl;[];lgbm, multiple classifier ;Python notebook;4999.0;72;;
2019-10-24 17:39:30;v4 : try different architecture, Invariant to player's orderv3 : add name to nodes of neural network model;Apache 2.0;https://www.kaggle.com/mrkmakr/neural-network-with-mae-objective-0-01381;1.0;['tensorflow', 'sklearn', 'keras'];['dl', 'ner', 'ai', 'nn'];['filter', 'train', 'model', 'neural network', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/nfl-big-data-bowl-2020;0.748;0.532;2020-12-13 14:21:44;NFL Big Data Bowl;[];neural network, with mae objective, 0.01385;Python notebook;9803.0;157;0.013811;0.013811
2019-10-16 09:44:39;About NFLThe National Football League (NFL) is a professional American football league consisting of 32 teams. The NFL is one of the four major professional sports leagues in North America and the highest professional level of American football in the world. Source: Wikipedia  Rules of NFLIf you are a newbie (just like me) to the world of NFL, there you can read about the basics from this discussion thread. Competition ObjectiveIn the National Football League (NFL), roughly a third of teams’ offensive yardage comes from run plays. A running play or rushing play is a tactic in which the football is advanced up the field by a player running it rather than passing it. Competition is to develop a model to predict how many yards a team will gain on given rushing plays as they happen. We are given the data when the ball is handed off (TimeHandoff) to forecast the yardage gained on that play. Notebook objectiveObjective of the notebook is to explore the data and find some interesting insights along the way. References:This wonderful kernel by Rob is the basis for this notebook Let us first look at the top few rows to understand the data.;Apache 2.0;https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-nfl;1.0;['pattern'];['ai', 'dl', 'gan', 'rl', 'nn'];['training data', 'train', 'model', 'layer', 'label', 'predict'];https://www.kaggle.com/c/nfl-big-data-bowl-2020;0.724;0.51;2020-12-13 14:21:44;NFL Big Data Bowl;[];Simple Exploration Notebook - NFL;Python notebook;5298.0;116;;
2020-01-02 23:40:59;NFL 1st and Future - AnalyticsCan you investigate the relationship between the playing surface and the injury and performance of NFL athletes?;Apache 2.0;https://www.kaggle.com/david289/nfl-lower-limb-non-contact-injuries-analysis;1.0;['statsmodels', 'sklearn', 'pattern'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['filter', 'regression', 'train', 'model', 'understanding', 'layer', 'label', 'logistic regression', 'predict', 'recommend', 'classification'];https://www.kaggle.com/c/nfl-playing-surface-analytics;0.622;0.379;2020-12-13 14:23:02;multiple data sources;[];NFL Lower Limb  Non Contact Injuries - Analysis;Python notebook;654.0;23;;
2020-01-29 20:32:16;A journey through the data and simple models;Apache 2.0;https://www.kaggle.com/docxian/nfl-data-journey-and-simple-model;1.0;['xgboost', 'h2o'];['ner', 'ai', 'dl', 'automl', 'gbm', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'training data', 'train', 'model', 'validation data', 'layer', 'loss', 'predict'];https://www.kaggle.com/c/nfl-playing-surface-analytics;0.671;0.327;2020-12-13 14:23:02;NFL 1st and Future - Analytics;['beginner, exploratory data analysis, sports'];NFL - Data journey and simple model;R notebook;1643.0;13;;
2020-01-23 17:14:27;"By: Elijah Hall Started: 11/27/2019  Completed: 1/2/2019  Updated: 1/19/2019   To see the results in a PPT click here.  IntroductionTable of Contents Problem DescriptionIn the NFL, 12 of the 31 stadiums have fields with synthetic turf. Recent investigations of lower limb injuries among football athletes have indicated significantly higher injury rates on synthetic turf compared with natural turf (Mack et al., 2018; Loughran et al., 2019). In conjunction with the epidemiologic investigations, biomechanical studies of football cleat-surface interactions have shown that synthetic turf surfaces do not release cleats as readily as natural turf and may contribute to the incidence of non-contact lower limb injuries (Kent et al., 2015). Given these differences in cleat-turf interactions, it has yet to be determined whether player movement patterns and other measures of player performance differ across playing surfaces and how these may contribute to the incidence of lower limb injury. Below I investigate the relationship between the playing surface and the injury and performance of National Football League (NFL) athletes and examine factors that may contribute to lower extremity injuries. I also try to characterize any differences in player movement between the playing surfaces and identify specific scenarios (e.g., field surface, weather, position, play type, etc.) that interact with player movement to present an elevated risk of injury. The ChallengeNFL player tracking, also known as Next Gen Stats (NGS), is the capture of real time location data, speed and acceleration for every player, every play on every inch of the field. As part of this challenge, the NFL has provided full player tracking of on-field position for 250 players over two regular season schedules. One hundred of the athletes in the study data set sustained one or more injuries during the study period that were identified as a non-contact injury of a type that may have turf interaction as a contributing factor to injury. The remaining 150 athletes serve as a representative sample of the larger NFL population that did not sustain a non-contact lower-limb injury during the study period. Details of the surface type and environmental parameters that may influence performance and outcome are also provided. About The NFLThe National Football League is America's most popular sports league, comprised of 32 franchises that compete each year to win the Super Bowl, the world's biggest annual sporting event. Founded in 1920, the NFL developed the model for the successful modern sports league, including national and international distribution, extensive revenue sharing, competitive excellence, and strong franchises across the country. The NFL is committed to advancing progress in the diagnosis, prevention and treatment of sports-related injuries. The NFL's ongoing health and safety efforts include support for independent medical research and engineering advancements and a commitment to work to better protect players and make the game safer, including enhancements to medical protocols and improvements to how our game is taught and played. As more is learned, the league evaluates and changes rules to evolve the game and try to improve protections for players. Since 2002 alone, the NFL has made 50 rules changes intended to eliminate potentially dangerous tactics and reduce the risk of injuries. The DataData FilesThere are three files provided in the dataset, as described below:  Injury Record: The injury record file in .csv format contains information on 105 lower-limb injuries that occurred during regular season games over the two seasons. Injuries can be linked to specific records in a player history using the PlayerKey, GameID, and PlayKey fields. Play List: – The play list file contains the details for the 267,005 player-plays that make up the dataset. Each play is indexed by PlayerKey, GameID, and PlayKey fields. Details about the game and play include the player’s assigned roster position, stadium type, field type, weather, play type, position for the play, and position group. Player Track Data: player level data that describes the location, orientation, speed, and direction of each player during a play recorded at 10 Hz (i.e. 10 observations recorded per second).  Field and Key DefinitionsThe following provides a description of each field contained within the datasets and their corresponding formats and descriptions. Key Variables are designated in bold.";Apache 2.0;https://www.kaggle.com/elijah24/nfl-injuries;1.0;['statsmodels', 'xgboost', 'sklearn', 'pillow', 'tensorflow', 'pattern'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['recommend', 'test data', 'regression', 'train', 'model', 'layer', 'loss', 'label', 'logistic regression', 'predict', 'decision tree', 'classification', 'labeled'];https://www.kaggle.com/c/nfl-playing-surface-analytics;0.691;0.367;2020-12-13 14:23:02;multiple data sources;[];NFL Injuries;Python notebook;2503.0;20;;
2020-01-02 16:52:21;NFL 1st and Future - Analytics;Apache 2.0;https://www.kaggle.com/krishm/nfl-1st-and-future-analytics-simulation;1.0;['pattern'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'model', 'layer', 'clustering', 'label', 'predict', 'decision tree', 'random forest'];https://www.kaggle.com/c/nfl-playing-surface-analytics;0.654;0.346;2020-12-13 14:23:02;multiple data sources;[];NFL 1st and Future Analytics:Simulation;R notebook;1186.0;16;;
2020-01-02 21:38:53;NFL 1st and Future - Playing Surface Analytics: The ZooContributors:  Philipp Singer: https://www.kaggle.com/philippsinger Dmitry Gordeev: https://www.kaggle.com/dott1718;Apache 2.0;https://www.kaggle.com/philippsinger/nfl-playing-surface-analytics-the-zoo;1.0;['statsmodels', 'sklearn', 'pattern'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'regression', 'train', 'model', 'neural network', 'epoch', 'layer', 'loss', 'label', 'lstm', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/nfl-playing-surface-analytics;0.717;0.453;2020-12-13 14:23:02;NFL 1st and Future - Analytics;['gpu'];NFL Playing Surface Analytics: The Zoo;Python notebook;4483.0;55;;
2020-01-01 18:02:01;Injury Record: The injury record file in .csv format contains information on 105 lower-limb injuries that occurred during regular season games over the two seasons. Injuries can be linked to specific records in a player history using the PlayerKey, GameID, and PlayKey fields. ['PlayerKey', 'GameID', 'PlayKey', 'BodyPart', 'Surface', 'DM_M1',      'DM_M7', 'DM_M28', 'DM_M42'] Play List: – The play list file contains the details for the 267,005 player-plays that make up the dataset. Each play is indexed by PlayerKey, GameID, and PlayKey fields. Details about the game and play include the player’s assigned roster position, stadium type, field type, weather, play type, position for the play, and position group. ['PlayerKey', 'GameID', 'PlayKey', 'RosterPosition', 'PlayerDay',      'PlayerGame', 'StadiumType', 'FieldType', 'Temperature', 'Weather',      'PlayType', 'PlayerGamePlay', 'Position', 'PositionGroup'] Player Track Data: player level data that describes the location, orientation, speed, and direction of each player during a play recorded at 10 Hz (i.e. 10 observations recorded per second). ['PlayKey', 'time', 'event', 'x', 'y', 'dir', 'dis', 'o', 's'];Apache 2.0;https://www.kaggle.com/ravijoe/injury-analysis;1.0;['tensorflow', 'xgboost', 'sklearn'];['ner', 'ai', 'dl', 'ml', 'nn', 'ann'];['machine learning', 'train', 'model', 'layer', 'label', 'predict'];https://www.kaggle.com/c/nfl-playing-surface-analytics;0.667;0.397;2020-12-13 14:23:02;NFL 1st and Future - Analytics;['beginner, data visualization, exploratory data analysis'];Injury Analysis;Python notebook;1521.0;28;;
2020-01-03 00:36:57;Playing Surface Analysis Lateral movement and increased injury risk.This report contains my analysis for the 2019 NFL 1st and Future competition. The competition tasked data scientists to investigate the relationship between the playing surface and the injury and performance of National Football League (NFL) athletes and to examine factors that may contribute to lower extremity injuries. I propose a metric for measuring the angle between athlete's body orientation and movement direction. I categorize player movements into three groups: forward, lateral, and backpedaling. I find that increased lateral player movement is strongly correlated with plays involving non-contact (NC) lower limb injuries. I then look to see if we can find a measurable link between increased lateral movement and playing surface. I then propose a hypothesis that if injury rate is linked to playing surface, then we may see a link between playing surface and lateral movement. My findings show that there is no link between lateral movement and playing surface. Last, I offer three suggestions that I believe may help to identify players at high risk of injuries: 1) Monitor the percentage of lateral movement of players during game play and provide summary statistics on players, and play types. This could be integrated into already existing monitoring protocols.  2) Monitor  the orientation of players’ hips, shoulders and head. I also suggest collecting data that might elucidate the link between playing surface and injuries: player cleat data and dampness of playing surface could be a place to start. 3) Allow strength and conditioning coaches to play a role in injury prevention by educating them about the link between lateral movement and injuries for Linebackers, Wide Receivers and Defensive backs.  They may be able to use  data that I’ve suggested  they develop individualized workout plans.;Apache 2.0;https://www.kaggle.com/robikscube/1st-and-future-2019-playing-surface-analysis;1.0;['statsmodels', 'lightgbm', 'sklearn', 'pattern'];['ner', 'ai', 'dl', 'gbm', 'rl', 'nn', 'ann'];['filter', 'machine learning', 'regression', 'training data', 'train', 'model', 'layer', 'label', 'predict', 'recommend'];https://www.kaggle.com/c/nfl-playing-surface-analytics;0.664;0.39;2020-12-13 14:23:02;NFL 1st and Future - Analytics;[];1st and Future 2019 - Playing Surface Analysis;Python notebook;1436.0;26;;
2020-01-02 17:37:11;Injury Analysis and Training with H2O AutoML (PART I);Apache 2.0;https://www.kaggle.com/zinovadr/nfl-injury-analysis-training-with-h2o-automl;1.0;['xgboost', 'h2o'];['ner', 'ai', 'dl', 'automl', 'gbm', 'gan', 'cv', 'nn', 'ml'];['filter', 'training data', 'test data', 'neuron', 'train', 'model', 'validation data', 'layer', 'loss', 'label', 'predict', 'rectifier', 'classification'];https://www.kaggle.com/c/nfl-playing-surface-analytics;0.612;0.311;2020-12-13 14:23:02;multiple data sources;[];NFL Injury Analysis & Training with H2O AutoML;R notebook;548.0;11;;
2019-01-09 11:48:00;How Removing A 45-Year-Old Rule Would Bring Down Concussion RatesBy Alex Wainger (Data Engineer, Facebook);Apache 2.0;https://www.kaggle.com/awainger/analysis;1.0;['sklearn'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['regression', 'train', 'model', 'reward', 'layer', 'label', 'logistic regression', 'predict', 'rank'];https://www.kaggle.com/c/NFL-Punt-Analytics-Competition;0.71;0.352;2020-12-13 14:25:10;multiple data sources;[];analysis;Python notebook;3838.0;17;;
2019-01-22 14:44:46;Summary Slides PDFIntroductionSince 2002 alone, the NFL has made 50 rules changes intended to eliminate potentially dangerous tactics and reduce the risk of injuries. Yet the yearly reported concussions does not decrease. We are glad that player safety gets more and more attention. Big Data and Data Science was probably used to improve NFL athlete performance before the term became sexy.  Now it's our turn to make punts safer! Beside the challenging problem and dataset, the competition gave us a good excuse to watch as many games as possible. Previously punts were not our favorite part of the game, however as we watched them more closely we must admit they could be pretty cool! Blocked punts, fake punts, punt return TDs even the lucky out of bounds were exciting. Unfortunately injury or concussion happens way more often than blocked punts or TDs. Obviously we would not want to eliminate punts or turn it into a ceremonial play. However, things has to be changed. Low sample high diversityWe got detailed description and video footage for 37 concussions that happened during more than 6600 punt plays. The low number of control events made the task more challenging.  While 6600 punt plays might feel like a lot, with the low overall concussion probability you have to be careful to not to overfit. It is especially true when you crunch the data for a month you will likely find patterns that are not significant. The tale of the left and right gunnersWe found that 4 left gunners and 1 right gunner suffered concussions. Does it really mean that being a left gunner is more dangerous? It would be surprising, right?  The truth is that we don't know. Statistically speaking the difference is insignificant. When we check all the collisions on the field we see symmetric distributions.  On the other hand we watched the injury videos over and over again to understand the dataset and the problem better.  It became clear that there is not a single rule that fits all the incidents. Many of the injuries were unfortunate accidents (e.g. friendly fire) injured players had different activity (blocked, blocking, tackled, tackling) impact type (body or helmet) role (returner, gunner, wing, guard, line). We also hope that the recently introduced weapon as a helmet rule already reduced the most serious impacts. We could not confirm it though as we don't have concussion results for the current season. External dataThe competition provided only punt plays. However punts are not isolated. They are often the last desperate event after an exhausting drive. How successful is the punt? That depends a lot on the next drive. We used additional external data be able to better understand the game overall.  Special thanks to Maksim Horowitz for providing detailed play data for seasons 2009-2017 with more than 400,000 plays. We find it crucial to use all available data to answer game integrity related questions. Since we had to deal with different data sources and sometimes noisy free text fields we often used available aggregated statistics for sanity check. Methodology Overview the collisions frame by frame Collect more data Understand relevant medical studies Calculate important features (speed, acceleration, collision) from NGS Derive insights from detailed play descriptions and overall statistics Check the current NFL, NCAA rules and recent modifications Consult with coaches  KernelsReproducibility is crucial for research and we took it seriously. Please check out our kernels for more details with interactive plots and source code.  Exploratory Data Analysis & External Data The Speed, the Acceleration and the Collision  Example injury video;Apache 2.0;https://www.kaggle.com/gaborfodor/summary-budapest-pythons;1.0;['pattern'];['ner', 'ai', 'dl', 'rl', 'nn', 'ml'];['layer', 'classification', 'reward'];https://www.kaggle.com/c/NFL-Punt-Analytics-Competition;0.698;0.416;2020-12-13 14:25:09;multiple data sources;['data visualization, exploratory data analysis, sports'];Summary - Budapest Pythons;Python notebook;2955.0;35;;
2019-01-11 01:13:42;NFL EDA Due to a large number of animations, this notebook may take a minute or two to display fully!  So this is the first data analytics style competition that Kaggle has run, and what a way to start it! I think there will be numerous benefits to running competitions like these mainly the fact that your avoiding data leaks, your opening the competitive aspect of kaggle to people who may not have a large amount of knowledge or interest in the machine learning side of things and finally I think the noticebly short timeframe is also a positive in my opinon. I often monitor the competitions running on Kaggle and the process is quite long. Shorter competitions like this one could be a game changer (pun intended!). Now that I have finished my brief rant, I must confess that I know almost nothing about American football. I have watched two or three superbowl finals and found them to be quite a spectacle but never really understood anything about the game itself. Hopefully partaking in this competition will change that. Table of Contents1. Basic NFL Rules  2. What Causes Concussion  3. The Punt  4. EDA  4.1 Concussion EDA  4.2 Punt Returner Analysis  4.2.1 First Rule Change  4.2.2 Second Rule Change  4.3 PRG & PLG Analysis  4.3 Third Rule Change;Apache 2.0;https://www.kaggle.com/garlsham/nfl-punt-rule-changes-interactive-plots;1.0;['pattern'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'layer', 'label', 'labeled'];https://www.kaggle.com/c/NFL-Punt-Analytics-Competition;0.687;0.4;2020-12-13 14:25:09;NFL Punt Analytics Competition;['beginner, data visualization, exploratory data analysis'];NFL: Punt Rule Changes (Interactive Plots);Python notebook;2325.0;29;;
2019-01-13 17:29:45;Evolving The Punt PlayGithub Repo with Additional Code Link to Slide Deck Reducing Injuries while maintaining the integrity of the gameThe NFL Punt Analytics Competition is being held by the NFL to elicit the public's proposal for modifications to punt rules. The overarching goal of this challenge is to reduce injuries to players during punt plays. Submissions will be judged by the NFL on (1) Solution Efficacy This parameter is looking for submissions to clearly demonstrate, through analysis, an understanding for the play features associated with conncussions and how proposed rule changes will reduce these injuries. (2) Game Integrity This parameter is looking for submissions to be actionable ... ideas that the NFL could implement while maintaining the integrity of the game. One must also consider changes to game dynamics and any potential new risks to player safety as a result of downstream consequences. High Level OverviewPunt plays have the potential to be some of the most exciting and game changing moments in football. Specialized positions such as punters and punt returners have worked to hone their craft and are an essential part of the game. As part of our research for this challenge, we interviewed College Football Hall of Fame coach Frank Beamer, known for his innovative approach to special teams at the college level. He was adamant that punt plays have the potential to be the most exciting part of the game and the integrity of the game needs to be considered when implementing rule changes. We agree with Frank Beamer- it is our utmost priority to minimize the number of unnecessary dangerous plays while keeping the integrity of the game. Football is a dangerous sport, and removing all risk is impossible, but by focusing on plays that are not pivotal to the game (like short punt returns or returns for no gain), we can allow the data to speak to some of the current challenges of these football moments. Our kernel is organized similar to our overall analytical approach to the problem: Kernel Outline Section I. High Level Analysis of All Punts What are the types of results for punt plays and how common are each of them? What the distribution of return yards on punts? What are the common formations for punts and punt returns?   Section II. Focused Analysis of Punts Resulting in Concussions Which players are commonly involved in injuries? What are the types of returns which result in injuries? Clustering similar types of punt plays resulting in concussions.   What is the velocity/direction of players hurt? Looking at common trends with players changing direction prior to impact.     Section III. Analysis of Fair Catch vs. Returned What are the players' positions on the field at the time of fair catch / return What are the distances between the coverage team and the punt returner during fair catches?   Section IV. Exploration of the Routes Run by Role Types What are all routes by position? What players are injured in the play?  What are the identifiable trends? What routes do punt returners tend to take?   Section V. Using Physics to Calculate Play and Player Risk Can we calculate a heuristic that captures the risk of each pair of players in a given play? Can we aggregate risk to the play level to rank reach play's risk? What trends in the risk can be associated with certain types of plays?   Section VI Our Proposed Rule Changes Incentivize the fair catch. Expand the definition of a defenseless player to include punting team players in pursuit of the returner. Restrict double teaming gunners to balance the starting position of opposing players.   Section VII Solution Efficacy and Impact on Game Integrity Explanation of how these proposed rule changes would reduce the type of plays associated with concussions. Details about how the integrity of the game will remain intact with these changes. Possible negative impacts of the proposed rule changes.;Apache 2.0;https://www.kaggle.com/robikscube/evolving-the-punt-play-nfl-data-formal-report;1.0;['sklearn'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['linear regression', 'filter', 'machine learning', 'regression', 'train', 'model', 'layer', 'label', 'clustering', 'rank', 'understanding'];https://www.kaggle.com/c/NFL-Punt-Analytics-Competition;0.71;0.471;2020-12-13 14:25:09;multiple data sources;['data visualization, sports, physics'];Evolving the Punt Play - NFL Data Formal Report;Python notebook;3835.0;69;;
2019-12-28 07:29:47;NFL Punt analytic for concussion prevention;Apache 2.0;https://www.kaggle.com/s903124/nfl-punt-analytic-with-suggested-rule-change;1.0;['statsmodels'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['linear regression', 'regression', 'model', 'layer', 'label', 'understanding'];https://www.kaggle.com/c/NFL-Punt-Analytics-Competition;0.639;0.357;2020-12-13 14:25:10;NFL Punt Analytics Competition;[];NFL punt analytic with suggested rule change;Python notebook;893.0;18;;
2017-07-06 19:44:40;Getting Started with the NIPS 2017 Adversarial Learning ChallengesCurrent image classifiers can easily be tricked using carefully crafted adversarial images. These images add small changes to the original, correctly-classified image that are virtually imperceptible to the human eye but cause image classifiers to become wrong with high confidence in the incorrect class. There's three related adversarial learning challenges in NIPS 2017.  The first two focus on successfully generating adversarial images. The non-targeted challenge focuses on tricking the classifier with any other class, while the targeted challenge focuses on tricking the classifier into thinking the image is a specific target class. The third defense challenge focuses on training classifiers that are robust against adversarial attacks. The defense challenge is scored based on how well the classifiers work in the face of adversarial attacks from the first two challenges, and the first two challenges are scored based on how well the adversarial attacks trick the classifiers in the third challenge. Here, we'll walk through some code examples on generating non-targeted and targeted adversarial images, and then seeing how the Inception V3 model classifies them. Much of this code is based on Alex's samples. To get started, we'll import the necessary libraries and define some parameters / useful functions.;Apache 2.0;https://www.kaggle.com/benhamner/adversarial-learning-challenges-getting-started;1.0;['tensorflow'];['ner', 'ai', 'dl', 'nn', 'ann'];['train', 'model', 'layer', 'loss', 'label', 'predict', 'classification'];https://www.kaggle.com/c/nips-2017-defense-against-adversarial-attack;0.779;0.507;2020-12-13 14:26:28;multiple data sources;['classification, computer vision, gan'];Adversarial Learning Challenges - Getting Started;Python notebook;23471.0;110;;
2017-09-22 19:43:44;Getting Started with the NIPS 2017 Adversarial Learning ChallengesCurrent image classifiers can easily be tricked using carefully crafted adversarial images. These images add small changes to the original, correctly-classified image that are virtually imperceptible to the human eye but cause image classifiers to become wrong with high confidence in the incorrect class. There's three related adversarial learning challenges in NIPS 2017.  The first two focus on successfully generating adversarial images. The non-targeted challenge focuses on tricking the classifier with any other class, while the targeted challenge focuses on tricking the classifier into thinking the image is a specific target class. The third defense challenge focuses on training classifiers that are robust against adversarial attacks. The defense challenge is scored based on how well the classifiers work in the face of adversarial attacks from the first two challenges, and the first two challenges are scored based on how well the adversarial attacks trick the classifiers in the third challenge. Here, we'll walk through some code examples on generating non-targeted and targeted adversarial images, and then seeing how the Inception V3 model classifies them. Much of this code is based on Alex's samples. To get started, we'll import the necessary libraries and define some parameters / useful functions.;Apache 2.0;https://www.kaggle.com/tw0518/adversarial-learning-challenges-getting-s-51b2c7;1.0;['tensorflow'];['ner', 'ai', 'dl', 'nn', 'ann'];['train', 'model', 'layer', 'loss', 'label', 'predict', 'classification'];https://www.kaggle.com/c/nips-2017-defense-against-adversarial-attack;0.639;0.0;2020-12-13 14:26:28;multiple data sources;[];Adversarial Learning Challenges - Getting S 51b2c7;Python notebook;885.0;0;;
2018-12-26 23:39:27;"This kernel flows.... work in progress! I currently work on better story telling & visualisations. ;-) Welcome Kaggler!... Do you know what your machine model has learnt after training?   ... Does your model know what a dog is if it makes perfect predictions for dog or cat classification?   ... How vulnerable is a model with almost prefect prediction performance to hacker attacks?   ... How can we attack and defense our algorithms?   ... It's some time ago, but there was a competition on kaggle that addressed these questions and asked the community to build attacks and defenses for deep learning models. It was hosted by the google brain group  and you can find more information as well as a github repository on their own website cleverhans.io. The time when this competition was active I heard the first time about fooling machine learning models and as I always like to understand why and how, I wrote this notebook that fools a simpler model, namely logistic regression, on the MNIST digit dataset.  Do you know this guy and his horse? The man on this image was Wilhelm von Osten and his horse was named Kluger Hans (cleverhans). In years before the First World War this horse was famous as one belived that it was able to count and to do arithmetic computations. Which sounds like a miracle turned out to be a more nebulous skill of Kugler Hans: Instead of doing computations the horse analyzed the gestures and body postures of the audiance in the show. Dependent on their expressions Kluger Hans made its decisions which result to choose. Even though one is not sure about the true skills of Kluger Hans and on which factors the horse made its decisions, this is still an analogy to our loved machine learning models. Do you know what they really learn? Within this kernel I invite you to open your eyes and get to know the illusion. If you like my kernel, you can make me very happy with an upvote! ;-)";Apache 2.0;https://www.kaggle.com/allunia/how-to-attack-a-machine-learning-model;1.0;['pattern', 'skimage', 'sklearn'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'regression', 'training data', 'train', 'test data', 'model', 'deep learning', 'label', 'logistic regression', 'predict', 'classification'];https://www.kaggle.com/c/nips-2017-non-targeted-adversarial-attack;0.778;0.546;2020-12-13 14:28:32;multiple data sources;['logistic regression, advanced'];How to attack a machine learning model?;Python notebook;22656.0;193;;
2017-09-13 08:43:09;Battle Jazz GANs!!For output see https://github.com/Cpruce/Notebooks/blob/master/BattleJazzGANs.ipynb;Apache 2.0;https://www.kaggle.com/cpruce/fast-pytorch-attack-kernel;1.0;['pytorch', 'tensorflow'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nn', 'ann'];['machine learning', 'regression', 'generation', 'train', 'recognition', 'model', 'supervised learning', 'deep learning', 'reward', 'relu', 'loss', 'label', 'reinforcement learning', 'predict', 'computer vision', 'generative adversarial network', 'labeled'];https://www.kaggle.com/c/nips-2017-non-targeted-adversarial-attack;0.695;0.188;2020-12-13 14:28:32;multiple data sources;['deep learning, classification, gan, +1 morereinforcement learning'];Fast Pytorch Attack Kernel;Python notebook;2715.0;3;;
2019-02-17 04:56:48;"This kernel flows.... work in progress! I currently work on better story telling & visualisations. ;-) Welcome Kaggler!... Do you know what your machine model has learnt after training?   ... Does your model know what a dog is if it makes perfect predictions for dog or cat classification?   ... How vulnerable is a model with almost prefect prediction performance to hacker attacks?   ... How can we attack and defense our algorithms?   ... It's some time ago, but there was a competition on kaggle that addressed these questions and asked the community to build attacks and defenses for deep learning models. It was hosted by the google brain group  and you can find more information as well as a github repository on their own website cleverhans.io. The time when this competition was active I heard the first time about fooling machine learning models and as I always like to understand why and how, I wrote this notebook that fools a simpler model, namely logistic regression, on the MNIST digit dataset.  Do you know this guy and his horse? The man on this image was Wilhelm von Osten and his horse was named Kluger Hans (cleverhans). In years before the First World War this horse was famous as one belived that it was able to count and to do arithmetic computations. Which sounds like a miracle turned out to be a more nebulous skill of Kugler Hans: Instead of doing computations the horse analyzed the gestures and body postures of the audiance in the show. Dependent on their expressions Kluger Hans made its decisions which result to choose. Even though one is not sure about the true skills of Kluger Hans and on which factors the horse made its decisions, this is still an analogy to our loved machine learning models. Do you know what they really learn? Within this kernel I invite you to open your eyes and get to know the illusion. If you like my kernel, you can make me very happy with an upvote! ;-)";Apache 2.0;https://www.kaggle.com/creativebot/how-to-attack-a-machine-learning-model;1.0;['pattern', 'skimage', 'sklearn'];['ner', 'ai', 'dl', 'rl', 'nn', 'ann'];['filter', 'machine learning', 'regression', 'training data', 'train', 'test data', 'model', 'deep learning', 'label', 'logistic regression', 'predict', 'classification'];https://www.kaggle.com/c/nips-2017-non-targeted-adversarial-attack;0.569;0.0;2020-12-13 14:28:32;multiple data sources;[];How to attack a machine learning model?;Python notebook;274.0;0;;
2017-08-24 20:47:15;This notebook attempts to make adversarial examples on MNIST single layer model by implementing FGSM method. Please help in pointing out any issue. Motivation came from kernel   https://www.kaggle.com/allunia/example-attacking-logistic-regression;Apache 2.0;https://www.kaggle.com/tagore15/adversarial-mnist-images-on-single-layer-nn;1.0;['tensorflow'];['ner', 'ai', 'nn'];['regression', 'train', 'model', 'layer', 'loss', 'label', 'predict'];https://www.kaggle.com/c/nips-2017-non-targeted-adversarial-attack;0.646;0.099;2020-12-13 14:28:32;multiple data sources;[];Adversarial MNIST Images on single layer NN;Python notebook;1024.0;1;;
2020-02-13 22:05:59;"This kernel flows.... work in progress! I currently work on better story telling & visualisations. ;-) Welcome Kaggler!... Do you know what your machine model has learnt after training?   ... Does your model know what a dog is if it makes perfect predictions for dog or cat classification?   ... How vulnerable is a model with almost prefect prediction performance to hacker attacks?   ... How can we attack and defense our algorithms?   ... It's some time ago, but there was a competition on kaggle that addressed these questions and asked the community to build attacks and defenses for deep learning models. It was hosted by the google brain group  and you can find more information as well as a github repository on their own website cleverhans.io. The time when this competition was active I heard the first time about fooling machine learning models and as I always like to understand why and how, I wrote this notebook that fools a simpler model, namely logistic regression, on the MNIST digit dataset.  Do you know this guy and his horse? The man on this image was Wilhelm von Osten and his horse was named Kluger Hans (cleverhans). In years before the First World War this horse was famous as one belived that it was able to count and to do arithmetic computations. Which sounds like a miracle turned out to be a more nebulous skill of Kugler Hans: Instead of doing computations the horse analyzed the gestures and body postures of the audiance in the show. Dependent on their expressions Kluger Hans made its decisions which result to choose. Even though one is not sure about the true skills of Kluger Hans and on which factors the horse made its decisions, this is still an analogy to our loved machine learning models. Do you know what they really learn? Within this kernel I invite you to open your eyes and get to know the illusion. If you like my kernel, you can make me very happy with an upvote! ;-)";Apache 2.0;https://www.kaggle.com/utkunal/how-to-attack-a-machine-learning-model;1.0;['sklearn', 'tensorflow', 'pattern', 'keras', 'skimage'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'regression', 'training data', 'train', 'test data', 'model', 'deep learning', 'label', 'logistic regression', 'predict', 'classification'];https://www.kaggle.com/c/nips-2017-non-targeted-adversarial-attack;0.6;0.152;2020-12-13 14:28:32;multiple data sources;[];How to attack a machine learning model?;Python notebook;449.0;2;;
2017-04-30 15:37:41;I suspect that the pups will be difficult to count on the images because they are dark grey just like the rocks, they are usually very close to their mother, and they are pretty similar in shape, size, and color to the seals (see 5.jpg for example). However, all other sea lion types are light brown so they should be easier to locate and count. I explore in this notebook whether it is possible to predict the number of pups based on the number of other sea lions. That is, the pups are not directly counted but their number is inferred/estimated based on the number of males, females, juveniles, and subadult males using a regression model. This alternative approach could turn out to be more accurate than directly counting the pups and I hope some of you will find it useful to improve the overall accuracy of the counts.;Apache 2.0;https://www.kaggle.com/andraszsom/predict-the-number-of-pups;1.0;['xgboost', 'sklearn'];['ai', 'cv'];['regression', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/noaa-fisheries-steller-sea-lion-population-count;0.7;0.371;2020-12-13 14:32:38;NOAA Fisheries Steller Sea Lion Population Count;[];Predict the number of pups;Python notebook;3042.0;21;;
2017-04-15 04:00:17;Fix All The ErrorsThis notebook has two goals... =) First, to get everyone on the same page with regards to the annotated data via crowd sourcing so that the communal kernels can move towards the fun stuff (deep learning!). The second is alert the contest authorities of potential discrepancies in the provided counts.csv file. Any such issues will need to be cleared both in the training data, but especially in the private data. I guess once the contest if over, we could simply spot-check if our algorithms correctly identified sea lions or not... but it would ruin the competition because there would have to be a recount at that point. In fact, its negative effect will be experienced prior to the contest close, as people will be training on noisy data. So let's begin!;Apache 2.0;https://www.kaggle.com/authman/fix-all-the-errors;1.0;['skimage'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ann'];['training data', 'filter', 'train', 'deep learning', 'decision tree'];https://www.kaggle.com/c/noaa-fisheries-steller-sea-lion-population-count;0.659;0.268;2020-12-13 14:32:38;NOAA Fisheries Steller Sea Lion Population Count;[];Fix All The Errors;Python notebook;1312.0;7;;
2017-04-26 14:47:14;Use keras to classify Sea Lions I am using the first picture to extract Sea Lion coordinates using blob detection I extract 32 by 32 images centered on the extracted coordinates I train a simple keras model  * The test accuracy is for Sea Lions in the first image only and without negative examples;Apache 2.0;https://www.kaggle.com/jasonquick/use-keras-to-classify-sea-lions-0-91-accuracy;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ai', 'cv'];['train', 'model', 'epoch', 'layer', 'label', 'loss', 'relu', 'decision tree'];https://www.kaggle.com/c/noaa-fisheries-steller-sea-lion-population-count;0.581;0.152;2020-12-13 14:32:38;NOAA Fisheries Steller Sea Lion Population Count;[];Use keras to classify Sea Lions: 0.91 accuracy;Python notebook;331.0;2;;
2017-04-24 12:16:35;Welcome to the base Tensorflow kernel Lets get right into it:  First, we will be getting the coordinates with the method used in this kernel We need to then crop the images so that they are classified and only 32 x 32 per lion a set of 32 x 32 images per sea-lion, Per: image_id One hot encode these Use Tensorflow to build a model Train the model Plot the results;Apache 2.0;https://www.kaggle.com/kingburrito666/using-base-tensorlfow-to-count-sea-lions-1-22;1.0;['skimage', 'tensorflow', 'sklearn'];['ner', 'ai', 'cnn', 'cv', 'nn', 'ann'];['filter', 'training data', 'neuron', 'train', 'model', 'input layer', 'layer', 'loss', 'label', 'predict', 'relu', 'decision tree'];https://www.kaggle.com/c/noaa-fisheries-steller-sea-lion-population-count;0.691;0.292;2020-12-13 14:32:38;NOAA Fisheries Steller Sea Lion Population Count;[];Using base Tensorlfow to count sea-lions [1.22] ;Python notebook;2488.0;9;;
2017-05-13 06:10:38;Data Augmentation Motivation: Increase the number of training samples for non-mammal features. Input: large image Output: Smaller images for training CNN model.;Apache 2.0;https://www.kaggle.com/madplanner/data-augmentation-image-cropping-rotation-and-2d;1.0;['skimage'];['ai', 'nn', 'cnn'];['train', 'model'];https://www.kaggle.com/c/noaa-fisheries-steller-sea-lion-population-count;0.722;0.152;2020-12-13 14:32:38;NOAA Fisheries Steller Sea Lion Population Count;[];Data Augmentation: Image cropping, rotation and 2D;Python notebook;5137.0;2;;
2017-06-29 03:22:48;Use keras to count Sea LionsThis kernel is a lite version of my approach. for more information...;Apache 2.0;https://www.kaggle.com/outrunner/use-keras-to-count-sea-lions;1.0;['tensorflow', 'skimage', 'keras'];['ai', 'dl', 'cnn', 'cv', 'nn'];['regression', 'train', 'model', 'epoch', 'layer', 'vgg', 'loss', 'predict', 'relu', 'decision tree', 'ground truth'];https://www.kaggle.com/c/noaa-fisheries-steller-sea-lion-population-count;0.765;0.475;2020-12-13 14:32:38;NOAA Fisheries Steller Sea Lion Population Count;['cnn, advanced'];Use keras to count Sea Lions;Python notebook;15513.0;72;;
2017-04-02 22:45:28;Countless Sea LionsIn this challenge we are given a set of images and are asked to calculate the number of sea lions in each image, split by a few categories that are indicated in extra overlay images:  red: adult males magenta: subadult males brown: adult females blue: juveniles green: pups   In this notebook we will be looking in detail at:  numeric (counts of sea lions) feature exploration, both with correlation analysis and clustermaps marker images and how we can use them to extract location and image patches for the marked sea lions template matching to build a sea lion detector with OpenCV.  Let's get started with an initial peek at the stats of the data and later plot some sample images.;Apache 2.0;https://www.kaggle.com/philschmidt/sea-lion-correlations-cv2-template-matching;1.0;['pattern', 'skimage'];['ner', 'ai', 'cnn', 'cv', 'rl', 'nn', 'ann'];['image classification', 'predict', 'train', 'clustering', 'classification'];https://www.kaggle.com/c/noaa-fisheries-steller-sea-lion-population-count;0.743;0.456;2020-12-13 14:32:38;NOAA Fisheries Steller Sea Lion Population Count;[];Sea Lion Correlations & CV2 Template matching;Python notebook;8534.0;57;;
2017-05-02 18:29:41;Count the Sea Lions in the first image Firs part:  I am using the first picture to extract Sea Lion coordinates using blob detection   Second part:  I extract 64 by 64 images centered on the extracted coordinates In addition to the previous script, I add negative examples to the training data I train a simple keras model on the full data In the third part I will test on the training data, so overfitting is not a bug, is a feature   Third part:  Built a test set by tiling the first image Use the previously built model to decide if in each tile there is a Sea Lion I am aware that I am training and testing on the same data;Apache 2.0;https://www.kaggle.com/radustoicescu/count-the-sea-lions-in-the-first-image;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ai', 'cv'];['training data', 'train', 'fitting', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'decision tree'];https://www.kaggle.com/c/noaa-fisheries-steller-sea-lion-population-count;0.714;0.393;2020-12-13 14:32:38;NOAA Fisheries Steller Sea Lion Population Count;[];Count the Sea Lions in the first image;Python notebook;4180.0;27;;
2017-06-26 09:37:57;Get dot coordinates using blob_log from skimage library;Apache 2.0;https://www.kaggle.com/radustoicescu/get-coordinates-using-blob-detection;1.0;['skimage'];['ai', 'ml', 'cv'];['train', 'decision tree', 'label'];https://www.kaggle.com/c/noaa-fisheries-steller-sea-lion-population-count;0.758;0.437;2020-12-13 14:32:38;NOAA Fisheries Steller Sea Lion Population Count;[];Get coordinates using blob detection;Python notebook;12799.0;45;;
2017-06-02 04:53:24;Use keras to classify Sea Lions I am using the first picture to extract Sea Lion coordinates using blob detection I extract 32 by 32 images centered on the extracted coordinates I train a simple keras model  * The test accuracy is for Sea Lions in the first image only and without negative examples;Apache 2.0;https://www.kaggle.com/radustoicescu/use-keras-to-classify-sea-lions-0-91-accuracy;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ai', 'cv'];['train', 'model', 'epoch', 'layer', 'label', 'loss', 'relu', 'decision tree'];https://www.kaggle.com/c/noaa-fisheries-steller-sea-lion-population-count;0.752;0.447;2020-12-13 14:32:38;NOAA Fisheries Steller Sea Lion Population Count;[];Use keras to classify Sea Lions: 0.91 accuracy;Python notebook;10916.0;51;;
2017-04-16 13:02:12;Using pattern matching to find the dotted sea lions. With the current settings it finds most of the dots, but not all of them.;Apache 2.0;https://www.kaggle.com/ranbato/finding-the-dots;1.0;['pattern'];['ai', 'cv'];['train', 'filter'];https://www.kaggle.com/c/noaa-fisheries-steller-sea-lion-population-count;0.649;0.253;2020-12-13 14:32:38;NOAA Fisheries Steller Sea Lion Population Count;[];Finding the dots.;Python notebook;1072.0;6;;
2018-01-28 09:59:50;Nomad: an initial exploration in Python with domain knowledgeIn this kernel I'd like to introduce the basics of data exploration in Python, combined with some domain knowledge to help you get started with this Kaggle competition. - Michael Sluydts (updated 21 dec 2017) Let's start by loading the essential modules;Apache 2.0;https://www.kaggle.com/kemuel/python-exploration-with-domain-knowledge;1.0;['pattern'];['ner', 'ai', 'dl', 'gan', 'rl', 'nn', 'ml'];['machine learning', 'train', 'model', 'label', 'recommend'];https://www.kaggle.com/c/nomad2018-predict-transparent-conductors;0.711;0.429;2020-12-13 14:37:12;Nomad2018 Predicting Transparent Conductors;['beginner, data visualization'];Python exploration with domain knowledge;Python notebook;3968.0;41;;
2017-12-27 23:19:00;Exploratory data analysisGernerally within exploratory data analysis we treyt to see what the data can tell us before the actual task of of modelling or hypothesis testing. We will focus in this notebook on the features found in the train.csv file. Intially we will perform descriptive univariate analysis. Next we will study how the response variables change given a set of featuers and/or their subsets.;Apache 2.0;https://www.kaggle.com/leo1988/exploratory-data-analysis-using-plotly;1.0;['pattern', 'sklearn'];['ner', 'ai', 'cv', 'rl', 'nn', 'ann'];['linear regression', 'regression', 'train', 'fitting', 'model', 'label', 'predict', 'understanding', 'random forest'];https://www.kaggle.com/c/nomad2018-predict-transparent-conductors;0.678;0.292;2020-12-13 14:37:12;Nomad2018 Predicting Transparent Conductors;[];Exploratory data analysis using Plotly;Python notebook;1907.0;9;;
2017-12-31 12:58:03;Hey guys! In the subsequent kernel I am using the PCA algorithm in order to gain further insights into the various atom-configurations contained in the xyz-files. I hope that this might be a help for you in order to explore new features which advance you in the underlying problem statement. I like to add that I am not a domain expert in the chemistry field.;Apache 2.0;https://www.kaggle.com/maxkapsecker/pca-pattern-discovery;1.0;['pattern', 'sklearn'];['ner', 'ai', 'dl', 'rl'];['train', 'label', 'test data'];https://www.kaggle.com/c/nomad2018-predict-transparent-conductors;0.685;0.375;2020-12-13 14:37:12;Nomad2018 Predicting Transparent Conductors;['pca'];PCA & Pattern discovery;Python notebook;2196.0;22;;
2018-02-15 20:20:14;THIS NOTEBOOK CONTAINS 4 DIFFERENT REGRESSION MODELS AND THEIR AVERAGE AS OUTPUT. I COMMENTED SOME PARTS DUE TO 1-HOUR CONSTRAINT.;Apache 2.0;https://www.kaggle.com/mbkinaci/eda-xgboost-ridge-knn-extratrees-regression;1.0;['xgboost', 'sklearn'];['ner', 'ai', 'ml', 'nn', 'ann'];['regression', 'train', 'model', 'clustering', 'label', 'predict'];https://www.kaggle.com/c/nomad2018-predict-transparent-conductors;0.632;0.268;2020-12-13 14:37:12;Nomad2018 Predicting Transparent Conductors;[];EDA + XGBOOST& RIDGE&KNN&EXTRATREES REGRESSION ;Python notebook;783.0;7;;
2018-02-06 21:17:29;IntroductionI created this notebook to show what I have learned with stacking and boosting models. I currently work as a data scientist, but most of my projects don't involve boosting or stacking.;Apache 2.0;https://www.kaggle.com/srserves85/boosting-stacking-and-bayes-searching;1.0;['xgboost', 'lightgbm', 'catboost', 'sklearn', 'tensorflow', 'keras'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'nn'];['filter', 'training data', 'regression', 'test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'bayesian'];https://www.kaggle.com/c/nomad2018-predict-transparent-conductors;0.705;0.397;2020-12-13 14:37:12;multiple data sources;['data visualization, feature engineering, gradient boosting'];Boosting, Stacking, and Bayes Searching;Python notebook;3423.0;28;0.06954;0.05575
2018-01-31 15:26:54;Nomad2018 Predicting Transparent ConductorsPredict the key properties of novel transparent semiconductors  The diffrent properties of Aluminum,Gallium,Indium is given in data set. In order to reduce electric transmission loss,discovery of new transparent conductor alloy is important. The transparent conductor having characteristic good conductivity and have a low absorption. The aim is to prediction of two target properties: the formation energy (which is an indication of the stability of a new material) and the bandgap energy (which is an indication of the potential for transparency over the visible range) to facilitate the discovery of new transparent conductors;Apache 2.0;https://www.kaggle.com/sudhirnl7/simple-ann;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cv', 'nn', 'ann'];['test data', 'regression', 'train', 'model', 'epoch', 'layer', 'loss', 'predict', 'relu', 'hidden layer'];https://www.kaggle.com/c/nomad2018-predict-transparent-conductors;0.67;0.327;2020-12-13 14:37:12;Nomad2018 Predicting Transparent Conductors;['neural networks'];Simple ANN ;Python notebook;1627.0;13;0.08055;0.07377
2018-02-15 17:21:48;Nomad2018 Predicting Transparent ConductorsPredict the key properties of novel transparent semiconductors  The diffrent properties of Aluminum,Gallium,Indium is given in data set. In order to reduce electric transmission loss,discovery of new transparent conductor alloy is important. The transparent conductor having characteristic good conductivity and have a low absorption. The aim is to prediction of two target properties: the formation energy (which is an indication of the stability of a new material) and the bandgap energy (which is an indication of the potential for transparency over the visible range) to facilitate the discovery of new transparent conductors;Apache 2.0;https://www.kaggle.com/sudhirnl7/simple-electron-volt-predictor;1.0;['sklearn'];['ner', 'ai', 'cv', 'nn', 'ann'];['predict', 'test data', 'regression', 'train', 'model', 'loss'];https://www.kaggle.com/c/nomad2018-predict-transparent-conductors;0.651;0.302;2020-12-13 14:37:12;Nomad2018 Predicting Transparent Conductors;['linear regression'];Simple Electron Volt predictor;Python notebook;1125.0;10;;
2017-07-21 19:28:51;Welcome to the new competition. This notebook aims to provide data insights. Please up vote if you find this useful. Happy Kaggling!!;Apache 2.0;https://www.kaggle.com/aakashnain/eda-nytaxi;1.0;['pattern'];['ai', 'nn', 'rl'];['train', 'label', 'test data'];https://www.kaggle.com/c/nyc-taxi-trip-duration;0.715;0.435;2020-12-13 14:39:46;New York City Taxi Trip Duration;['exploratory data analysis'];EDA_NYTaxi;Python notebook;4352.0;44;;
2017-12-09 15:50:12;How does the traffic of Taxi rides change along the day? In order to answer this question, I would use K-means clustering to cluster New York into different groups based on location, and analyze the traffic into and out of every cluster as a function of the time along the day. One can expect that residential areas would have more incoming traffic in the evening, whereas commercial areas would mostly attract people during the day, and areas with rich nightlife would show more traffic in the night. This can be helpful in duration prediction, as we can learn what are the likely destinations for each area during different times of the day.;Apache 2.0;https://www.kaggle.com/drgilermo/dynamics-of-new-york-city-animation;1.0;['pattern', 'sklearn'];['ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['predict', 'train', 'label', 'k-means', 'clustering'];https://www.kaggle.com/c/nyc-taxi-trip-duration;0.789;0.567;2020-12-13 14:39:46;New York City Taxi Trip Duration;['data visualization, k-means'];Dynamics of New York city - Animation;Python notebook;31497.0;263;;
2017-07-21 17:06:54;NEW YORK CITY TAXI TRIP DURATION   Exploratory Data Analysis & Feature Engineering   by Fred Navruzov      2017-07-21;Apache 2.0;https://www.kaggle.com/frednavruzov/nyc-taxi-eda-feature-engineering;1.0;['pattern'];['ai', 'nn'];['train', 'label'];https://www.kaggle.com/c/nyc-taxi-trip-duration;0.717;0.418;2020-12-13 14:39:46;New York City Taxi Trip Duration;['beginner, data visualization, exploratory data analysis, +2 morefeature engineering, data cleaning'];NYC-TAXI-EDA-FEATURE-ENGINEERING;Python notebook;4473.0;36;;
2017-09-17 14:08:34;IntroductionIn this competition, we are challenged to build a model that predicts the total ride duration of taxi trips in New York City. There are quite a few EDA kernels and some of them are excellent. Here I try to focus more on the feature extraction. In this Kernel you could find a few general kaggle related tips and a some modeling improvement ideas as well. My main goal is to craft the best possible feature set for XGB with the given Kernel limitations. My current best submission is still based on this script. My best single model with these features reached LB 0.371. Linear combination of several models gave LB 0.368. Stacking added marginal improvement to 0.367. Please feel free to fork and use the features and search better parameters. With this simple notebook we  Explore the dataset Extract 59 useful features Create simple 80-20 train - validation set Train XGBregressor Analyze Feature Importance Score test set and submit Check XGB parameter search result for further improvements  References  I used a few feature extraction ideas from Nir Malbin's Kernel Thanks for oscarleo for this external dataset;Apache 2.0;https://www.kaggle.com/gaborfodor/from-eda-to-the-top-lb-0-367;1.0;['xgboost', 'sklearn'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn'];['filter', 'train', 'fitting', 'model', 'understanding', 'epoch', 'clustering', 'label', 'predict', 'unsupervised learning', 'decision tree', 'supervised learning', 'ground truth'];https://www.kaggle.com/c/nyc-taxi-trip-duration;0.803;0.599;2020-12-13 14:39:46;multiple data sources;['feature engineering, xgboost, geospatial analysis, +1 moreadvanced'];From EDA to the Top (LB 0.367);Python notebook;50950.0;440;;
2017-09-14 09:55:41;An MVP Aproach  1. IntroductionAs a (admittedly lazy) Data Scientist I love accessing information in the easiest way possible. Google is my best friend, for example. With the exception of a few things, there is almost nothing you can't find with a simple search.This kernel is written and developed using IPython Notebook and XGBoost, with the aim of being ready-to-submit. By that I mean any user can run each code block, submit the output, and achieve a comfortable top-half score. Breaking into the top 10% of the submissions would require quite a bit more effort and a more sophisticated approach. In the final section I include some comments and suggestions of some alterations/variations one might try to improve the score. Those suggestions, if carried out correctly, do result in a strong score on the leaderboard. This then serves as an introductory tutorial to approaching this particular problem (rather than giving the best solution outright) leaving enough room for creativity and innovation in the solution space to allow any user to better the end result. In short, the whole project is about LEARNING, sharing some ideas, and ultimately improving the degree of Data Scientists out there.  Enjoy!  1.1 The Problem  New York is riddled with one-ways, small side streets, and an almost incalculable amount of pedestrians at any given point in time. Not to mention the amount of cars/motorcycles/bicycles clogging up the roads. Combine this with a mad rush to get from point A to point B, and you'll find yourself late for whatever you need to be on time for.The solution to getting from A to B when living in a city like New York (without losing your mind) is easy: take a taxi/Uber/Lyft/etc. You don't need to stress about the traffic or pedestrians and you have a moment to do something else, like catch up on emails. Although this sounds simple enough, it doesn't mean you'll get to your destination in time. So you need to have your driver take the shortest trip possible. By shortest, we're talking time. If a route A is X kilometers *longer*, but gets you there Y minutes *faster* than route B would, rather take that one.To know which route is the best one to take, we need to be able to predict how long the trip will last when taking a specific route. Therefore, *the goal of this playground competition is to predict the the duration of each trip in the test data set, given start and end coordinates.* 1.2 The Libraries & Functions  Using Python 3.6.1, import the following libraries. Note the use of `%matplotlib inline`, allowing the display of graphs inline in iPython Notebook.Documentation Scikit-Learn Pandas Numpy XGBoost Seaborn I used Scikit-Learn (or sklearn) for a few of the machine learning operations that was carried out. Pandas is used for data manipulation. Numpy is the fundamental package for scientific computation in Python. XGBoost is the classification algorithm used to make the final predictions. Seaborn is a nice tool for data visualisation built on top of matplotlib. The import code is as follows:;Apache 2.0;https://www.kaggle.com/karelrv/nyct-from-a-to-z-with-xgboost-tutorial;1.0;['statsmodels', 'xgboost', 'sklearn', 'pattern'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'regression', 'training data', 'train', 'fitting', 'model', 'test data', 'clustering', 'label', 'predict', 'rank', 'classification', 'bayesian'];https://www.kaggle.com/c/nyc-taxi-trip-duration;0.787;0.542;2020-12-13 14:39:46;multiple data sources;['exploratory data analysis, feature engineering, xgboost'];NYCT - from A to Z with XGBoost (Tutorial);Python notebook;30174.0;182;;
2017-09-17 15:33:15;Be humble, sit down and check out the visualizationsLast Update - 15 Sept 2017 Added pairplot for feature interaction using Holoviews in second round of feature engineering Multiple Interactive histograms using Plotly to check different distance features between pickup-drop Correlation matrix heatmap using Seaborn to check the correlated variables Histogram of test and validation data using Seaborn;Apache 2.0;https://www.kaggle.com/maheshdadhich/strength-of-visualization-python-visuals-tutorial;1.0;['statsmodels', 'xgboost', 'sklearn', 'pattern'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['training data', 'test data', 'train', 'model', 'epoch', 'validation data', 'clustering', 'label', 'k-means', 'predict'];https://www.kaggle.com/c/nyc-taxi-trip-duration;0.809;0.614;2020-12-13 14:39:46;multiple data sources;['data visualization, xgboost'];Strength of visualization-python visuals tutorial;Python notebook;61072.0;565;;
2017-08-22 15:27:08;A Practical Guide to NY Taxi Data (0.379)2017/8/13 Weiying WangThe guide is aimed to assist beginners to understand the basic workflow of building a predictive model. Also I add descriptions to each steps that may save you some searching time. Hope you will find it helpful! I am welcome for any comment and suggestion that can help this kernel better. So far this competetion aroses lots of discussions and great analysis (the best analysis, I think, is probably Heads or Tails). The data provides a great opportunity of learning and applying things we learned at school. One must understand that 90% of the work is clean-up the data and acquire the relevent features, which is essential of getting a good analysis. There are already a lot of great kernels out there. Some of my features is from (Thanks for their dedication and great kernels!)  beluga Oscarleo Heads or Tails  This notebook is also available at my Github. Table of Content0. Import Modules and Data1. Features 1.1 Pickup Time and Weekend Features 1.2 Distance Features 1.2.1OSRM Features 1.2.2Appendix:Google Map API 1.2.2Other Distance Features   1.3 Location Features: K-means Clustering 1.4 Weather Features  2. Outliers 2.1 Outliers from 'trip_duration' 2.2 Outliers from Locations  3. Analysis of Features4. XGB Model: the Prediction of trip_duration 4.1 Using XGBoost Module 4.2 The Submission 4.3 Importance for each Feature;Apache 2.0;https://www.kaggle.com/onlyshadow/a-practical-guide-to-ny-taxi-data-0-379;1.0;['xgboost', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'training data', 'regression', 'test data', 'train', 'fitting', 'model', 'clustering', 'loss', 'label', 'k-means', 'predict', 'decision tree'];https://www.kaggle.com/c/nyc-taxi-trip-duration;0.733;0.416;2020-12-13 14:39:46;multiple data sources;['feature engineering, xgboost, geospatial analysis'];A Practical Guide to NY Taxi Data (0.379);Python notebook;6709.0;35;;
2020-06-05 18:22:15;Poonam Ligade 5th Sep 2017   Overview 1.1 Import Libraries 1.2 Load data sets 1.3 Visualize trips in new York city map 1.4 Explore data    Analyzing Categorical and numerical variables 2.1 Univariate Analysis 2.2 Multivariate Analysis    Feature Engineering 3.1 Date time Features 3.2 distance and Speed    Model and Prediction 4.1 Random Forest;Apache 2.0;https://www.kaggle.com/poonaml/last-cab-to-new-york-animated-heatmap-trips-folium;1.0;['pattern', 'sklearn'];['ner', 'ai', 'nn', 'rl'];['filter', 'training data', 'regression', 'test data', 'train', 'fitting', 'model', 'clustering', 'label', 'predict', 'linear regression', 'random forest'];https://www.kaggle.com/c/nyc-taxi-trip-duration;0.762;0.501;2020-12-13 14:39:46;multiple data sources;['data visualization, exploratory data analysis, random forest'];Last Cab to New York!Animated Heatmap&Trips Folium;Python notebook;14352.0;102;;
2017-09-16 09:52:29;Yellow Cabs tell The Story of New York CityIn this script we will explore the spatial and temporal behavior of the people of New York as can be inferred by examining their cab usage. The main fields of this dataset are taxi pickup time and location, as well as dropoff location and trip duration. There is a total of around 1.4 Million trips in the dataset that took place during the first half of 2016. We will see how the patterns of cab usage change throughout the year, throughout the week and throughout the day, and we will focus on difference between weekdays and weekends.;Apache 2.0;https://www.kaggle.com/selfishgene/yellow-cabs-tell-the-story-of-new-york-city;1.0;['pattern', 'sklearn'];['ai', 'rl', 'ml', 'nn', 'ann'];['train', 'model', 'label', 'predict'];https://www.kaggle.com/c/nyc-taxi-trip-duration;0.769;0.544;2020-12-13 14:39:46;New York City Taxi Trip Duration;['data visualization, geospatial analysis, advanced'];Yellow Cabs tell The Story of New York City;Python notebook;17695.0;187;;
2017-09-27 06:44:56;New York City Taxi Trip Duration This notebook goes through a simple process of extracting basic features, building a model and then make predictions. I am using the TPOT package to create a pipeline. TPOT is a Python Automated Machine Learning tool that optimizes machine learning pipelines using genetic programming. I thought it is useful to add this to the list of kernels available in this competition.;Apache 2.0;https://www.kaggle.com/sheriytm/brewed-tpot-for-nyc-with-love-lb0-37;1.0;['xgboost', 'sklearn', 'tpot'];['ner', 'ai', 'dl', 'cv', 'nn'];['machine learning', 'training data', 'test data', 'automated machine learnin', 'train', 'generation', 'model', 'clustering', 'label', 'predict', 'understanding'];https://www.kaggle.com/c/nyc-taxi-trip-duration;0.727;0.421;2020-12-13 14:39:46;multiple data sources;['data visualization, exploratory data analysis, feature engineering'];Brewed-Tpot-for-NYC-With-Love [LB0.37+];Python notebook;5733.0;37;;
2017-08-17 20:14:32;Exploratory Analysis - NYC Taxi TripÂ7-21-2017;Apache 2.0;https://www.kaggle.com/wti200/exploratory-analysis-nyc-taxi-trip;1.0;['pattern'];['ner', 'ai', 'rl', 'nn', 'ann'];['test data', 'train', 'model', 'layer', 'predict', 'relu'];https://www.kaggle.com/c/nyc-taxi-trip-duration;0.766;0.489;2020-12-13 14:39:46;multiple data sources;['data visualization, exploratory data analysis'];Exploratory Analysis - NYC Taxi Trip ;R notebook;16063.0;87;;
2019-08-14 05:41:59;This kernel contains:  How to create submission.csv;Apache 2.0;https://www.kaggle.com/anshuljdhingra/instance-segmentation;1.0;['tensorflow', 'skimage'];['ai', 'cnn', 'rl', 'nn', 'ann'];['r-cnn', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'resnet'];https://www.kaggle.com/c/open-images-2019-instance-segmentation;0.638;0.099;2020-12-13 14:40:23;Open Images 2019 - Instance Segmentation;['gpu'];Instance Segmentation;Python notebook;875.0;1;;
2019-08-15 01:13:16;This kernel contains:  How to create submission.csv;Apache 2.0;https://www.kaggle.com/iiyamaiiyama/how-to-submit-prediction;1.0;['tensorflow', 'skimage'];['ai', 'cnn', 'rl', 'nn', 'ann'];['r-cnn', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'resnet'];https://www.kaggle.com/c/open-images-2019-instance-segmentation;0.721;0.425;2020-12-13 14:40:23;Open Images 2019 - Instance Segmentation;['gpu'];How-to-submit-prediction;Python notebook;5006.0;39;0.0312;0.0426
2019-07-27 04:46:40;Need to go a long way.see you soon. :);Apache 2.0;https://www.kaggle.com/saravanakumar123/goolge-instance-segmentation-with-sample-intro;1.0;['mxnet'];['ai', 'cnn', 'cv', 'nn', 'ann'];['train', 'resnet', 'model', 'object detection'];https://www.kaggle.com/c/open-images-2019-instance-segmentation;0.714;0.357;2020-12-13 14:40:23;Open Images 2019 - Instance Segmentation;['gpu, beginner, data visualization'];Goolge Instance Segmentation with sample intro;Python notebook;4188.0;18;;
2019-10-01 03:04:37;OpenImage Challenge 2019training fasterrcnn in pytorchfiles (N is [0-9A-F]): BASE_DIR/classes-segmentation.txt   …download from https://storage.googleapis.com/openimages/v5/classes-segmentation.txt BASE_DIR/train-images-N/*.jpg   …training image from s3://open-images-dataset/tar/train_N.tar.gz BASE_DIR/mask-images-N/*.png   …mask image from https://storage.googleapis.com/openimages/v5/train-masks/train-masks-N.zip TEST_DIR/*.jpg   …test image for prediction temporary directory: TEMP_DIR/join-masks/ TEMP_DIR/output-images/;Apache 2.0;https://www.kaggle.com/tanreinama/training-fasterrnn-in-pytorch;1.0;['pytorch'];['ner', 'ai', 'dl', 'cnn', 'rl', 'nn', 'ann'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'resnet'];https://www.kaggle.com/c/open-images-2019-instance-segmentation;0.646;0.099;2020-12-13 14:40:23;multiple data sources;['gpu'];Training FasterRNN in PyTorch;Python notebook;1008.0;1;;
2019-08-10 20:31:51;Lets show some images that will be used for training;Apache 2.0;https://www.kaggle.com/volody/threshold-segmentation;1.0;['skimage'];['ai'];['train'];https://www.kaggle.com/c/open-images-2019-instance-segmentation;0.612;0.0;2020-12-13 14:40:23;Open Images 2019 - Instance Segmentation;[];Threshold Segmentation;Python notebook;552.0;0;;
2019-07-23 05:43:11;This kernel is based on pre-trained TF model from the Tensorflow Hub. The kernel was inspired by Vikram's Kernel and xhlulu Kernel. How to get predictions ?I have used Inception-ResNet. This means that the inference will be slower, but the accuracy is better as compared to MobileNet v2. If you are using Kaggle Kernels split the image id's into bunch of 25000 and run the kernels 4 times if you get error code 137 My kernel;Apache 2.0;https://www.kaggle.com/akashdeepjassal/inception-resnet-tf-hub-submission;1.0;['tensorflow'];['ai', 'nn', 'ml', 'rl'];['filter', 'train', 'model', 'predict', 'resnet'];https://www.kaggle.com/c/open-images-2019-object-detection;0.646;0.281;2020-12-13 14:41:47;multiple data sources;[];Inception Resnet TF Hub submission;Python notebook;1007.0;8;;
2019-07-23 07:39:51;This kernel is based on pre-trained TF model from the Tensorflow Hub. The kernel was inspired by Vikram's Kernel and xhlulu Kernel. How to get predictions ?I have used Inception-ResNet. This means that the inference will be slower, but the accuracy is better as compared to MobileNet v2. If you are using Kaggle Kernels split the image id's into bunch of 25000 and run the kernels 4 times if you get error code 137.;Apache 2.0;https://www.kaggle.com/akashdeepjassal/tf-hub-inception-resnet;1.0;['tensorflow'];['dl', 'ai', 'nn', 'cnn'];['train', 'resnet', 'model', 'predict'];https://www.kaggle.com/c/open-images-2019-object-detection;0.616;0.236;2020-12-13 14:41:47;Open Images 2019 - Object Detection;['gpu, beginner'];TF Hub Inception Resnet;Python notebook;590.0;5;;
2019-07-04 07:26:31;Install ImageAI (A python library built to empower developers to build applications and systems with self-contained Computer Vision capabilities http://imageai.org);Apache 2.0;https://www.kaggle.com/bitumok/kernel-from-newbie-to-newbies;1.0;['tensorflow', 'pillow'];['ner', 'ai', 'nn'];['train', 'recognition', 'model', 'label', 'predict', 'computer vision'];https://www.kaggle.com/c/open-images-2019-object-detection;0.669;0.311;2020-12-13 14:41:47;Open Images 2019 - Object Detection;['gpu, beginner'];Kernel_from newbie to newbies;Python notebook;1592.0;11;0.05123;0.05479
2019-08-17 07:20:18;"Introduction to Tensorflow Hub for Object Detection (with SSD+MobileNetV2)The purpose of this kernel is to walk you through the process of downloading a pre-trained TF model from the Tensorflow Hub, building a Tensorflow graph and performing off-the-shelf predictions. This kernel is a fork of the excellent baseline kernel by Vikram, but differs on those points:  We will be using MobileNet v2 instead of Inception-ResNet. This means that the inference will be faster*, but the accuracy ends up worse. This will focus on understanding how Tensorflow works, rather than providing a boilerplate. For a simple solution, please check out this tutorial, which is what Vikram's kernel was inspired from.  * Each image takes roughly 0.2s to process, whereas Inception-ResNet takes around 1.2s. Changelog V6: As pointed out by Nicolas in his kernel and in this discussion thread, the coordinates are inverted between the Kaggle competition and the original TF Hub graph. This version corrects this problem. Please go give them an upvote; this is a really good catch from them!  References Vikram's Original Kernel: https://www.kaggle.com/vikramtiwari/baseline-predictions-using-inception-resnet-v2 TFHub Demo: https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/object_detection.ipynb TFHub Model link: https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1 Discussion on inveted BBox: https://www.kaggle.com/c/open-images-2019-object-detection/discussion/98205 Corrected BBox: https://www.kaggle.com/nhlr21/tf-hub-bounding-boxes-coordinates-corrected/notebook";Apache 2.0;https://www.kaggle.com/jian1201/intro-to-tf-hub-for-object-detection;1.0;['tensorflow', 'keras'];['ner', 'ai', 'cnn', 'rl', 'ml', 'nn', 'ann'];['object detection', 'train', 'model', 'understanding', 'label', 'predict', 'recommend', 'resnet', 'labeled'];https://www.kaggle.com/c/open-images-2019-object-detection;0.573;0.281;2020-12-13 14:41:47;Open Images 2019 - Object Detection;['gpu'];Intro to TF Hub for Object Detection;Python notebook;292.0;8;;
2019-07-15 14:46:08;TF Hub - Bounding boxes coordinates corrected;Apache 2.0;https://www.kaggle.com/nhlr21/tf-hub-bounding-boxes-coordinates-corrected;1.0;['tensorflow'];['rl'];['model', 'predict'];https://www.kaggle.com/c/open-images-2019-object-detection;0.696;0.375;2020-12-13 14:41:47;Open Images 2019 - Object Detection;['gpu'];TF Hub - Bounding boxes coordinates corrected;Python notebook;2831.0;22;0.19233;0.20119
2019-06-26 08:37:26;Object Detection using ImageAI - Resnet50 This is is starter kernel, using a resnet50 pretrained model, based on the kernels shared by Miha Skalic: Classifier as a bounding-box predictor & Shivam Bansal : Objects + Bounding Boxes using Resnet50 - ImageAI;Apache 2.0;https://www.kaggle.com/priteshshrivastava/imageai-resnet50-2018-kernel;1.0;['tensorflow', 'keras', 'pillow'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'nn', 'ann'];['object detection', 'train', 'model', 'label', 'predict', 'resnet'];https://www.kaggle.com/c/open-images-2019-object-detection;0.652;0.302;2020-12-13 14:41:47;multiple data sources;[];ImageAI - Resnet50 [2018 Kernel];Python notebook;1131.0;10;;
2019-07-30 22:57:18;"Introduction to Tensorflow Hub for Object Detection (with SSD+MobileNetV2)The purpose of this kernel is to walk you through the process of downloading a pre-trained TF model from the Tensorflow Hub, building a Tensorflow graph and performing off-the-shelf predictions. This kernel is a fork of the excellent baseline kernel by Vikram, but differs on those points:  We will be using MobileNet v2 instead of Inception-ResNet. This means that the inference will be faster*, but the accuracy ends up worse. This will focus on understanding how Tensorflow works, rather than providing a boilerplate. For a simple solution, please check out this tutorial, which is what Vikram's kernel was inspired from.  * Each image takes roughly 0.2s to process, whereas Inception-ResNet takes around 1.2s. Changelog V6: As pointed out by Nicolas in his kernel and in this discussion thread, the coordinates are inverted between the Kaggle competition and the original TF Hub graph. This version corrects this problem. Please go give them an upvote; this is a really good catch from them!  References Vikram's Original Kernel: https://www.kaggle.com/vikramtiwari/baseline-predictions-using-inception-resnet-v2 TFHub Demo: https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/object_detection.ipynb TFHub Model link: https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1 Discussion on inveted BBox: https://www.kaggle.com/c/open-images-2019-object-detection/discussion/98205 Corrected BBox: https://www.kaggle.com/nhlr21/tf-hub-bounding-boxes-coordinates-corrected/notebook";Apache 2.0;https://www.kaggle.com/xhlulu/intro-to-tf-hub-for-object-detection;1.0;['tensorflow', 'keras'];['ner', 'ai', 'cnn', 'rl', 'ml', 'nn', 'ann'];['object detection', 'train', 'model', 'understanding', 'label', 'predict', 'recommend', 'resnet', 'labeled'];https://www.kaggle.com/c/open-images-2019-object-detection;0.783;0.557;2020-12-13 14:41:47;Open Images 2019 - Object Detection;['deep learning, cnn, neural networks, +1 morecomputer vision'];Intro to TF Hub for Object Detection;Python notebook;26891.0;226;0.19233;0.20119
2019-07-16 00:41:11;yolov3.weights file can be found in https://pjreddie.com/media/files/yolov3.weights The weight file is also (supposedly) in Kaggle dataset (which I have not found).;Apache 2.0;https://www.kaggle.com/yw6916/how-to-build-yolo-v3;1.0;['tensorflow', 'keras'];['dl', 'nn'];['layer', 'model', 'filter', 'relu'];https://www.kaggle.com/c/open-images-2019-object-detection;0.699;0.362;2020-12-13 14:41:47;Open Images 2019 - Object Detection;[];How to build yolo-v3 ;Python notebook;3018.0;19;;
2019-08-08 15:27:10;It is my very first attempt to CV. Please do upvote if you think it is a reasonable work as a newbie. I try to build a yolo-v3 based on below link, and use some useful function to visualize as well as train. Thx!;Apache 2.0;https://www.kaggle.com/yw6916/my-yolo-v3;1.0;['tensorflow', 'keras', 'pillow'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'nn', 'ann'];['filter', 'object detection', 'train', 'model', 'layer', 'label', 'predict', 'relu'];https://www.kaggle.com/c/open-images-2019-object-detection;0.645;0.292;2020-12-13 14:41:47;multiple data sources;['gpu'];My YOLO V3;Python notebook;993.0;9;;
2020-07-09 18:50:05;Open Images Instance Segmentation RVC 2020 editionOutline segmentation masks of objects in images;Apache 2.0;https://www.kaggle.com/abdullahhashmi/open-images-mask-rcnn-starter;1.0;['tensorflow', 'keras'];['ai', 'cnn', 'cv', 'nn', 'ann'];['object detection', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'resnet'];https://www.kaggle.com/c/open-images-instance-segmentation-rvc-2020;0.575;0.099;2020-12-13 14:42:27;Open Images Instance Segmentation RVC 2020 edition;[];Open Images - Mask-RCNN - Starter;Python notebook;299.0;1;;
2020-06-06 02:50:46;IntroThis notebook shows some characteristics of the images and labels used for the two contests. I've taken a small subset of training images and files from the Open Images dataset and put them here: Excerpt from OpenImages 2020 Train. Some specific objectives:  Get a feel for the the images and the objects/segments they contain. Implement some basic object detection. Look at label counts image sizes, and object relationships.  On the technical side, there are some things you might find useful:  Modeling with large datasets in Kaggle notebooks Making interactive plots with hvplot Visualizing graph networks with networkX;Apache 2.0;https://www.kaggle.com/jpmiller/open-images-eda;1.0;['skimage'];['ai', 'cnn', 'cv', 'rl', 'nn', 'ann'];['r-cnn', 'object detection', 'train', 'model', 'layer', 'label', 'labeled', 'ground truth'];https://www.kaggle.com/c/open-images-instance-segmentation-rvc-2020;0.754;0.517;2020-12-13 14:42:26;multiple data sources;['feature engineering, image data, computer vision'];Open Images EDA;Python notebook;11601.0;127;;
2020-07-05 19:10:36;IntroductionThis notebook shows some characteristics of the images and labels used for the two contests. I've taken a small subset of training images and files from the Open Images dataset and put them here: Excerpt from OpenImages 2020 Train. Some specific objectives: Get a feel for the the images and the objects/segments they contain. Implement some basic object detection. Look at label counts image sizes, and object relationships.  On the technical side, there are some things you might find useful:  Modeling with large datasets in Kaggle notebooks Making interactive plots with hvplot Visualizing graph networks with networkX;Apache 2.0;https://www.kaggle.com/mahmudds/open-images-object-detection-rvc;1.0;['skimage'];['ai', 'cnn', 'cv', 'rl', 'nn', 'ann'];['r-cnn', 'object detection', 'train', 'model', 'layer', 'label', 'labeled', 'ground truth'];https://www.kaggle.com/c/open-images-instance-segmentation-rvc-2020;0.602;0.188;2020-12-13 14:42:27;multiple data sources;[];Open Images Object Detection RVC;Python notebook;462.0;3;;
2020-07-25 19:06:00;Open Images Instance Segmentation RVC 2020 editionOutline segmentation masks of objects in images;Apache 2.0;https://www.kaggle.com/manavtrivedi/open-images-starter;1.0;['tensorflow', 'keras'];['ner', 'ai', 'cnn', 'cv', 'rl', 'nn', 'ann'];['object detection', 'train', 'model', 'epoch', 'label', 'predict', 'resnet'];https://www.kaggle.com/c/open-images-instance-segmentation-rvc-2020;0.552;0.236;2020-12-13 14:42:26;Open Images Instance Segmentation RVC 2020 edition;[];Open Images - Mask-RCNN - Starter;Python notebook;210.0;5;;
2020-05-26 22:11:52;Open Images Instance Segmentation RVC 2020 editionOutline segmentation masks of objects in images;Apache 2.0;https://www.kaggle.com/meenakshiramaswamy/open-images-mask-rcnn-starter;1.0;['tensorflow', 'keras'];['ai', 'cnn', 'cv', 'nn', 'ann'];['object detection', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'resnet'];https://www.kaggle.com/c/open-images-instance-segmentation-rvc-2020;0.67;0.311;2020-12-13 14:42:26;Open Images Instance Segmentation RVC 2020 edition;[];Open Images - Mask-RCNN - Starter;Python notebook;1633.0;11;;
2020-06-23 23:53:49;Open Images Object Detection RVC 2020 editionDetect objects in varied and complex images;Apache 2.0;https://www.kaggle.com/bryanafreeman/image-object-detection;1.0;['tensorflow', 'keras', 'pillow'];['dl', 'cnn', 'cv', 'rl', 'nn', 'ml'];['object detection', 'model', 'label', 'predict', 'resnet'];https://www.kaggle.com/c/open-images-object-detection-rvc-2020;0.697;0.346;2020-12-13 14:43:29;multiple data sources;[];Image Object Detection;Python notebook;2836.0;16;;
2020-11-26 15:58:40;Hello everyone! One way to generate new paintings is to transfer the style of the target artist (Claude Monet) to already existings images of real life. Here I randomly picked a real life image from Open Images Dataset and converted it using the painting style of Monet. This is a work in progress. Please upvote to keep this going.Thank you and stay safe!;Apache 2.0;https://www.kaggle.com/imoore/generate-paintings-by-image-style-transfer;1.0;['tensorflow', 'keras'];['ner', 'ai', 'gan', 'ml', 'nn', 'ann'];['train', 'model', 'output layer', 'layer', 'vgg', 'loss'];https://www.kaggle.com/c/open-images-object-detection-rvc-2020;0.676;0.467;2020-12-13 14:43:29;multiple data sources;['gpu, arts and entertainment, image data'];Generate Paintings By Image Style Transfer;Python notebook;1841.0;65;;
2020-06-05 20:40:48;Open Images Object Detection RVC 2020 editionDetect objects in varied and complex imagesUsing FasterRCNN+InceptionResNet V2, an SSD-based object detection model trained on Open Images V4 with ImageNet pre-trained MobileNet V2 as image feature extractor.;Apache 2.0;https://www.kaggle.com/singhuday/image-object-detection;1.0;['tensorflow'];['ai', 'dl', 'cnn', 'nn', 'ann'];['object detection', 'train', 'model', 'predict', 'resnet'];https://www.kaggle.com/c/open-images-object-detection-rvc-2020;0.595;0.099;2020-12-13 14:43:30;Open Images Object Detection RVC 2020 edition;[];Image Object Detection;Python notebook;411.0;1;;
2020-08-21 12:29:57;UPDATE:The notebook has been updated and works much faster (8x less processing time). Each slice now takes approx. 120-220 ms, compared to the 2.5 - 5 seconds processing time.;Apache 2.0;https://www.kaggle.com/aadhavvignesh/lung-segmentation-by-marker-controlled-watershed;1.0;['skimage'];['ner', 'ai', 'nn', 'ann'];['filter', 'generation', 'train', 'label', 'rank', 'labeled'];https://www.kaggle.com/c/osic-pulmonary-fibrosis-progression;0.706;0.508;2020-12-13 14:44:51;OSIC Pulmonary Fibrosis Progression;['data cleaning, image data'];Lung Segmentation by Marker-Controlled Watershed;Python notebook;3536.0;112;;
2020-09-26 21:37:46;Table of contents References Data Science Bowl 2017 - Preprocessing Tutorial by Guido Zuidhof Papers   Prepare to start Working with dicom files Loading CT-scans per patient Transforming to Hounsfield Units The voxel size CT-scan slice area and volume - EDA 3D-reconstruction of CT-scans Tissue segmentation   Generating a dataset for preprocessed files Link to public dataset;Apache 2.0;https://www.kaggle.com/allunia/pulmonary-dicom-preprocessing;1.0;['pattern', 'skimage'];['ner', 'ai', 'dl', 'gan', 'ml', 'nn', 'ann'];['filter', 'train', 'model', 'understanding', 'label', 'recommend'];https://www.kaggle.com/c/osic-pulmonary-fibrosis-progression;0.78;0.595;2020-12-13 14:44:51;multiple data sources;['beginner, data visualization, exploratory data analysis, +1 moredata cleaning'];Pulmonary Dicom Preprocessing;Python notebook;24092.0;415;;
2020-08-17 19:39:35;🩺OSIC Pulmonary Fibrosis Competition🩺 EDA and Preprocessing1. Introduction#1. Why do we do this?Pulmonary = lung | fibrosis = scar tissue => Scarring in the lungs. Over time, scarring can destroy the normal lung and make it hard for oxygen to get into your blood. Pulmonary fibrosis isn’t just one disease. It is a family of more than 200 different lung diseases that all look very much alike.   #2. EvaluationLaplace Log Likelihood (modified version): useful to evaluate a model's confidence in its decisions. The error is thresholded at 1000 ml to avoid large errors adversely penalizing results, while the confidence values are clipped at 70 ml to reflect the approximate measurement uncertainty in FVC. The final score is calculated by averaging the metric across all test set Patient_Weeks (three per patient). Note that metric values will be negative and higher is better. #3. Code CompetitionCode Competitions seem more fair to me. Keep in mind:  CPU runtime <= 9 hrs GPU runtime <= 4 hrs NO internet access (for inference, but can be used during training) Submission file name: submission.csv  #4. Competition aim:Predict how severe is going to decline the lung capacity in the lungs based on a CT (Computerised Tomography) scan + metadata of the patient. CTs can show soft tissues, blood vessels, and bones much more detailed than normal X-rays.  Lung Function: assessed based on a spirometer output which measures the FVC (forced vital capacity), meaning how much air is exhaled. Libraries 📚⬇;Apache 2.0;https://www.kaggle.com/andradaolteanu/pulmonary-fibrosis-competition-eda-dicom-prep;1.0;['skimage', 'xgboost', 'sklearn'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'nn', 'ml'];['filter', 'test data', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/osic-pulmonary-fibrosis-progression;0.761;0.6;2020-12-13 14:44:51;multiple data sources;['exploratory data analysis, data cleaning, image data, +1 moretabular data'];🩺Pulmonary Fibrosis Competition: EDA & DICOM Prep;Python notebook;13966.0;446;;
2020-07-24 03:49:21;1. End-to-end model: CT scans latent features + Tabular featuresThis model is a simple end-to-end solution that uses CT scans latent features and tabular features to generate predictions. The CT scans latent features are obtained by encoding pre-processed 3D CT scan tensors, using a pre-trained AutoEncoder for that. The tabular features are obtained by pre-processing the tabular data (more about it here). I am not including here the code used to train the AutoEncoder. I pretrained it in another notebook, and saved the weights in a public dataset. The overal model looks like the image below:  This version runs on CPU, end-to-end. However, it is slow. Improvements/next steps at the end.;Apache 2.0;https://www.kaggle.com/carlossouza/end-to-end-model-ct-scans-tabular;1.0;['pytorch', 'skimage', 'sklearn'];['ner', 'ai', 'cv', 'rl', 'nn', 'ann'];['autoencoder', 'filter', 'regression', 'train', 'model', 'neural network', 'epoch', 'deep learning', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/osic-pulmonary-fibrosis-progression;0.752;0.548;2020-12-13 14:44:51;multiple data sources;[];End-to-end model: CT scans + Tabular;Python notebook;10879.0;199;;
2020-07-28 20:24:28;1. OSIC AutoEncoder trainingThis notebooks demonstrates how to train a convolutional AutoEncoder to learn latent features from the 3D CT scans dataset. One of the main applications of AutoEncoders is dimensionality reduction. We will use them for that: reducing 3D images (preprocessed to 1 x 40 x 256 x 256 tensors) to vectors (with 10 dimensions).  Once we have the trained model, the idea is to apply it to extract these latent features and combine them with the OSIC tabular data. My first experiments had a less strangled bottleneck (started with 96 x 2 x 20 x 20), which was already a reduction of over 34:1 (the inputs are 3D images of 1 x 40 x 256 x 256). The AutoEncoder output was great, easy to see. However, using latent features of 96 x 2 x 20 x 20 meant that, in the tabular model, I had to combine 76,800 features (flattened) with the 9 tabular features. In order to have a better balance between tabular and latent features, I decide to strangle the bottleneck further, squeezing the 3D images to 10 features (already flatenned in the AutoEncoder model). As you can see below, the model learns as the loss keeps going down. However, the output of the AutoEncoder is not as visible as with the less strangled bottleneck.;Apache 2.0;https://www.kaggle.com/carlossouza/osic-autoencoder-training;1.0;['pytorch', 'skimage'];['ner', 'ai', 'rl', 'ml', 'nn', 'ann'];['autoencoder', 'filter', 'train', 'model', 'epoch', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/osic-pulmonary-fibrosis-progression;0.728;0.521;2020-12-13 14:44:51;multiple data sources;[];OSIC AutoEncoder training;Python notebook;5881.0;135;;
2020-08-16 00:22:14;"1. Probabilistic Machine Learning: A Different ApproachI'm very grateful to have entered in this competition, as it drove me to learn new things I wouldn't otherwise. As I wrote in other notebooks, my first objective was to learn how to implement AutoEncoders, and discover why generative models are so hype. After reading papers, tutorials, experimenting, analyzing the (poor) results achieved, I started asking questions. Why isn't the model learning good representation of the latent space? Btw, what the heck is a latent space? Why are generative models so cool? How do they actually work? The search for these (and many more answers) drove me to Variational AutoEncoders (which I will share my implementation here later), but most importantly, drove me to Probabilistic Machine Learning, Bayesian Inference, and the very cool field of Probabilistic Programming. As I started to deep dive into papers and books about those subjects, I realized that OSIC Pulmonary Fibrosis problem screams for applying Probabilistic Machine Learning. Mindlessly applying Deep Learning to solve this problem reminded of an oldie but goldie: if all you have is a hammer, everything looks like a nail. I'm so excited about my ""discovery"" of this new field, that I could go on and on writing about what I learned over the past month. But instead, I will leave some nice references that helped me gain insight about discriminative vs generative machine learning, deterministic vs stochastic algorithms, bayesian vs frequentist approach, and dive into a demonstration (there are many many more great readings, these are just some to get started with varied level of depth):  Probabilistic machine learning and artificial intelligence Automating Inference, Learning, and Design using Probabilistic Programming Probabilistic Programming and Bayesian Methods for Hackers Probabilistic Models of Cognition Machine Learning: A Probabilistic Perspective  My idea is to break the problem in 3 sub-problems:  Define and train a simple probabilistic model to make inferences about FVC using only tabular data (baby steps) Define and train an advanced probabilistic model (a Variational AutoEncoder) to learn latent features from the CT scans Combine the 2 models together  1.1. ToolsIMHO the mathematical tools needed are no more advanced than the tools used in Deep Learning. Unfortunately, most of the books and papers are overloaded with hardcore math that may discourage at first. But there are good exceptions (some cited above, like the excelent open books Probabilistic Programming and Bayesian Methods for Hackers, or the Probabilistic Models of Cognition), and I think everyone can learn. In terms of Probabilistic Programming Languages, there are several options. I'd say some of the obvious choices would be those 3:  As a PyTorch user (always found TF too verbose to my taste), my natural choice was Pyro. However, to my surprise, I discovered that I'd have to install it. PyMC3 and TFP work out-of-the-box in Kaggle Kernels, but Pyro doesn't. As this competition do not allow internet, I will use PyMC3. But most importantly, Kaggle please add Pyro to kernels! 1.2. Statistical Modeling ProcessIn the course Bayesian Statistics: Techniques and Models, prof Matthew Heiner summarizes the modeling process as having 8 steps:  Understand the problem Plan and collect data Explore the data Postulate the model Fit the model Check the model Iterate Use the model  We understand the problem well enoguh, and data is already collected. So, let's do a quick exploration of the tabular data and then postulate a model.";Apache 2.0;https://www.kaggle.com/carlossouza/probabilistic-machine-learning-a-diff-approach;1.0;['pytorch', 'sklearn', 'theano'];['ner', 'ai', 'dl', 'rl', 'nn'];['autoencoder', 'linear regression', 'machine learning', 'regression', 'train', 'artificial intelligence', 'model', 'deep learning', 'label', 'predict', 'recommend', 'bayesian'];https://www.kaggle.com/c/osic-pulmonary-fibrosis-progression;0.701;0.499;2020-12-13 14:44:51;OSIC Pulmonary Fibrosis Progression;['bayesian statistics'];Probabilistic Machine Learning: A Diff Approach;Python notebook;3153.0;99;-6.9569;-7.0004
2020-10-02 12:20:21;"Quick introCompetition descriptionImagine one day, your breathing became consistently labored and shallow. Months later you were finally diagnosed with pulmonary fibrosis, a disorder with no known cause and no known cure, created by scarring of the lungs. If that happened to you, you would want to know your prognosis. That’s where a troubling disease becomes frightening for the patient: outcomes can range from long-term stability to rapid deterioration, but doctors aren’t easily able to tell where an individual may fall on that spectrum. Your help, and data science, may be able to aid in this prediction, which would dramatically help both patients and clinicians. Current methods make fibrotic lung diseases difficult to treat, even with access to a chest CT scan. In addition, the wide range of varied prognoses create issues organizing clinical trials. Finally, patients suffer extreme anxiety—in addition to fibrosis-related symptoms—from the disease’s opaque path of progression. Open Source Imaging Consortium (OSIC) is a not-for-profit, co-operative effort between academia, industry and philanthropy. The group enables rapid advances in the fight against Idiopathic Pulmonary Fibrosis (IPF), fibrosing interstitial lung diseases (ILDs), and other respiratory diseases, including emphysematous conditions. Its mission is to bring together radiologists, clinicians and computational scientists from around the world to improve imaging-based treatments. In this competition, you’ll predict a patient’s severity of decline in lung function based on a CT scan of their lungs. You’ll determine lung function based on output from a spirometer, which measures the volume of air inhaled and exhaled. The challenge is to use machine learning techniques to make a prediction with the image, metadata, and baseline FVC as input. If successful, patients and their families would better understand their prognosis when they are first diagnosed with this incurable lung disease. Improved severity detection would also positively impact treatment trial design and accelerate the clinical development of novel treatments. What should I expect the data format to be & what am I predicting?Each row in the dataset contains a Patiend_ID, and a week; you must predict the FVC and a confidence. To avoid potential leakage in the timing of follow up visits, you are asked to predict every patient's FVC measurement for every possible week. Those weeks which are not in the final three visits are ignored in scoring. The final submission-file should contain a header and have the following format: Patient_Week,                 FVC,    Confidence ID00002637202176704235138_1, 2000,   100 ID00002637202176704235138_2, 2000,   100 ID00002637202176704235138_3, 2000,   100";Apache 2.0;https://www.kaggle.com/ChristianDenich/quantile-reg-lr-schedulers-checkpoints;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'nn', 'ml'];['activation function', 'filter', 'machine learning', 'training data', 'neuron', 'train', 'fitting', 'model', 'test data', 'neural network', 'epoch', 'layer', 'gradient descent', 'loss', 'label', 'predict', 'relu', 'hidden layer'];https://www.kaggle.com/c/osic-pulmonary-fibrosis-progression;0.739;0.553;2020-12-13 14:44:51;OSIC Pulmonary Fibrosis Progression;[];Quantile Reg. | LR-Schedulers| Checkpoints;Python notebook;7765.0;214;;
2020-08-21 08:19:49;Overview & Remarks Just some experiments I did with efficientnets b0-b7 and blending predictions Best LB of efficientnets was around -0.6922 Tried blending efficientnets b0-b7 in a single run but due to out-of-memory errors, it was not successful you may find the code to perform the mean blend here as well   EfficientNets are trained for 30 or 50 epochs with modified callbacks and training parameters More models are being experimented currently. Will update this notebook when I have better results!;Apache 2.0;https://www.kaggle.com/khoongweihao/efficientnets-quantile-regression-inference;1.0;['tensorflow', 'sklearn', 'keras', 'pillow'];['ner', 'ai', 'cnn', 'cv', 'ml', 'nn', 'ann'];['regression', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'resnet', 'ground truth'];https://www.kaggle.com/c/osic-pulmonary-fibrosis-progression;0.759;0.549;2020-12-13 14:44:51;multiple data sources;['gpu'];EfficientNets + Quantile Regression (Inference);Python notebook;13327.0;202;;
2020-09-01 10:52:03;OSIC Pulmonary fibrosis Progression.⚕️Plumonary fibrosis is a lung disease which occurs due to damage in tissue and damage causes tissue to thicken and patient becomes short of breath. The problem with plumonary fibrosis it can be caused by various number of factors and it is difficult for doctors to find out what is causing the problem and condition in which doctors can not find out the cause is called idiopathic plumonary fibrosis.  Symptoms Shortness of breath A dry cough Fatigue Unexplained Weight Loss Aching muscles and joints Widning and Rounding of tips of the fingers or toes.  To read more about plumonary fibrosis click here;Apache 2.0;https://www.kaggle.com/maunish/osic-super-cool-eda-and-pytorch-baseline;1.0;['pytorch', 'sklearn'];['ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/osic-pulmonary-fibrosis-progression;0.715;0.498;2020-12-13 14:44:51;OSIC Pulmonary Fibrosis Progression;['gpu, beginner, data visualization, +1 moreexploratory data analysis'];OSIC : Super Cool EDA 📊 and Pytorch baseline 🔥!;Python notebook;4310.0;98;-7.2586;-7.1057
2020-07-19 17:59:55;Decay theoryInput for test:  FVC in n week Percent in n week  Age Sex Smoking status CT in n week  Result:  FVC in any week percent in any week  FVC=a.quantile(0.75)∗(week−weektest)+FVCtestFVC=a.quantile(0.75)∗(week−weektest)+FVCtest Confidence=Percent+a.quantile(0.75)∗abs(week−weektest)Confidence=Percent+a.quantile(0.75)∗abs(week−weektest) So let's try predict coefficient a.;Apache 2.0;https://www.kaggle.com/miklgr500/linear-decay-based-on-resnet-cnn;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cnn', 'cv', 'rl', 'nn', 'ann'];['predict', 'train', 'model', 'epoch', 'layer', 'loss', 'relu'];https://www.kaggle.com/c/osic-pulmonary-fibrosis-progression;0.743;0.513;2020-12-13 14:44:51;OSIC Pulmonary Fibrosis Progression Lungs Mask;['gpu'];Linear Decay (based on ResNet CNN);Python notebook;8514.0;120;-6.8774;-6.9176
2020-08-25 06:19:43;Pulmonary Fibrosis EDAAnother image competition goes by, and this is rather interesting. I will be interested to see how well people can create their own solutions or apply solutions from Pneumothorax Segmentation competition or, if you really want to go down memory lane, perhaps Data Science Bowl 2017.;Apache 2.0;https://www.kaggle.com/nxrprime/fibrosis-eda-fast-ai;1.0;['pytorch', 'tensorflow', 'skimage'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'nlp', 'nn', 'ann'];['filter', 'neuron', 'train', 'generation', 'model', 'neural network', 'layer', 'loss', 'label', 'predict', 'classification', 'convolutional neural network'];https://www.kaggle.com/c/osic-pulmonary-fibrosis-progression;0.771;0.569;2020-12-13 14:44:51;multiple data sources;[];Fibrosis EDA (fast.ai);Python notebook;18568.0;272;;
2020-09-09 18:56:14;OSIC Pulmonary Fibrosis Progression - EDA 1. Introduction 🃏 1.1 What is Pulmonary fibrosis? Pulmonary fibrosis is a lung disease that occurs when lung tissue becomes damaged and scarred.  This thickened, stiff tissue makes it more difficult for your lungs to work properly. If you want to know further about this type lung disease, I have linked below an informative video.;Apache 2.0;https://www.kaggle.com/piantic/osic-pulmonary-fibrosis-progression-basic-eda;1.0;['pytorch'];['ner', 'ai', 'rl', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'training data', 'test data', 'train', 'label', 'predict', 'classification'];https://www.kaggle.com/c/osic-pulmonary-fibrosis-progression;0.781;0.623;2020-12-13 14:44:51;OSIC Pulmonary Fibrosis Progression;['beginner, exploratory data analysis, feature engineering'];OSIC Pulmonary Fibrosis Progression: Basic EDA!🔎;Python notebook;25226.0;662;;
2020-07-07 23:19:18;Train have 176 patients and Test only 5Welcome to the uncertainty and LB shake up world!;Apache 2.0;https://www.kaggle.com/titericz/tabular-simple-eda-linear-model;1.0;['statsmodels'];['ai', 'dl', 'rl'];['regression', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/osic-pulmonary-fibrosis-progression;0.728;0.526;2020-12-13 14:44:51;OSIC Pulmonary Fibrosis Progression;[];Tabular - Simple EDA + Linear Model;Python notebook;5855.0;144;-7.5584;-7.4686
2020-09-11 02:02:05;Loading the dataset and data preprocessing;Apache 2.0;https://www.kaggle.com/ankitdatascience/random-and-bayes-search-hyp-optimization-gpu;1.0;['xgboost', 'sklearn'];['ner', 'ai', 'cv', 'nn', 'ml'];['test data', 'train', 'fitting', 'model', 'label', 'predict', 'classification', 'bayesian'];https://www.kaggle.com/c/otto-group-product-classification-challenge;0.573;0.302;2020-12-13 14:52:36;Otto Group Product Classification Challenge;['xgboost, python, multiclass classification'];Random and Bayes Search Hyp. Optimization(GPU);Python notebook;290.0;10;;
2018-11-10 17:33:29;Representation of the target with numerical values;Apache 2.0;https://www.kaggle.com/mok0na/tc1-projet-otto-xgboost;1.0;['xgboost', 'sklearn'];['cv', 'ai', 'nn', 'gbm'];['predict', 'training data', 'test data', 'train', 'fitting', 'model', 'label', 'loss'];https://www.kaggle.com/c/otto-group-product-classification-challenge;0.678;0.302;2020-12-13 14:52:36;Otto Group Product Classification Challenge;[];TC1-projet OTTO XGBoost;Python notebook;1908.0;10;;
2018-09-15 07:10:56;If you like this kernel Greatly Appreciate to UPVOTE .Stochastic Gradient Boosting with XGBoostA simple technique for ensembling decision trees involves training trees on subsamples of the training dataset. Subsets of the the rows in the training data can be taken to train individual trees called bagging. When subsets of rows of the training data are also taken when calculating each split point, this is called random forest. These techniques can also be used in the gradient tree boosting model in a technique called stochastic gradient boosting. In this kernel I will be demonstrating stochastic gradient boosting and how to tune the sampling parameters using XGBoost with scikit-learn in Python. After reading this kernel we will get to know the following point in detail:  The rationale behind training trees on subsamples of data and how this can be used in gradient boosting. How to tune row-based subsampling in XGBoost using scikit-learn? How to tune column-based subsampling by both tree and split-point in XGBoost?  What is Stochastic Gradient Boosting? Let's understand the concept in detailGradient boosting is a greedy procedure. New decision trees are added to the model to correct the residual error of the existing model. Each decision tree is created using a greedy search procedure to select split points that best minimize an objective function. This can result in trees that use the same attributes and even the same split points again and again. Bagging is a technique where a collection of decision trees are created, each from a different random subset of rows from the training data. The effect is that better performance is achieved from the ensemble of trees because the randomness in the sample allows slightly different trees to be created, adding variance to the ensembled predictions. Random forest takes this one step further, by allowing the features (columns) to be subsampled when choosing split points, adding further variance to the ensemble of trees. These same techniques can be used in the construction of decision trees in gradient boosting in a variation called stochastic gradient boosting. It is common to use aggressive sub-samples of the training data such as 40% to 80%. OverviewIn this kernel we are going to look at the effect of different subsampling techniques in gradient boosting. We will tune three different flavors of stochastic gradient boosting supported by the XGBoost library in Python, specifically: 1.  Subsampling of rows in the dataset when creating each tree. 2. Subsampling of columns in the dataset when creating each tree. 3. Subsampling of columns for each split in the dataset when creating each tree. DatasetWe will use the Otto Group Product Classification Challenge dataset available in Kaggle which is available for free. This dataset describes the 93 obfuscated details of more than 61,000 products grouped into 10 product categories (e.g. fashion, electronics, etc.). Input attributes are counts of different events of some kind.The Otto Group is one of the world’s biggest e-commerce companies, with subsidiaries in more than 20 countries, including Crate & Barrel (USA), Otto.de (Germany) and 3 Suisses (France) selling millions of products worldwide every day, with several thousand products being added to our product line. Data fields id - an anonymous id unique to a product feat_1, feat_2, ..., feat_93 - the various features of a product target - the class of a product  Problem DescriptionThe goal is to make predictions for new products as an array of probabilities for each of the 10 categories and models are evaluated using multiclass logarithmic loss (also called cross entropy). Solution ApproachAs mentioned above let us look at the appraoches one by one.;Apache 2.0;https://www.kaggle.com/pavansanagapati/stochastic-gradient-boosting-with-xgboost;1.0;['xgboost', 'sklearn'];['ner', 'ai', 'dl', 'rl', 'cv'];['training data', 'random forest', 'train', 'model', 'understanding', 'loss', 'label', 'gradient boosting', 'predict', 'decision tree', 'classification'];https://www.kaggle.com/c/otto-group-product-classification-challenge;0.682;0.292;2020-12-13 14:52:36;Otto Group Product Classification Challenge;['gpu, feature engineering, xgboost'];Stochastic Gradient Boosting with XGBoost;Python notebook;2059.0;9;;
2018-11-16 18:22:53;DeepDream DeepDream uses a convolutional neural network to find and enhance patterns in images via algorithmic pareidolia, thus creating a dream-like hallucinogenic appearance in the deliberately over-processed images (wiki).  In this kernel I will explore DeepDream by using a both an InceptionV3 and a VGG-16 pretrained model in Keras. The choice of your convnet will affect your visualisation, as different architectures result in different learned features. Inception for example has been trained on (amongst others) many images of animals and the use of this convnet in a DeepDream often outputs pictures with a lot of eye-like features. By playing around with the different architectures, I will try to understand more on how they work. Inspiration for this kernel were kernels by Carlo Alberto and by Paul Mooney, which both use PyTorch .  Most of the code is from keras/deepdream found on the github of the Keras Team. I've also used the book Deep Learning with Python by François Chollet, which gives insights on how the DeepDream algorithm (and deep learning in general) works. In the case of DeepDream an arbitrary image is fed to the network and is analyzed. The activation of an layer is maximized and the networks is asked to enhance whatever it detected. Each layer of the network deals with features at a different level of abstraction, so the complexity of features we generate depends on which layer we choose to enhance (source). In short:  Load the original image. Define a number of processing scales (i.e. image shapes), from smallest to largest. Resize the original image to the smallest scale. For every scale, starting with the smallest (i.e. current one): Run gradient ascent Upscale image to the next scale Reinject the detail that was lost at upscaling time   Stop when we are back to the original size.  To obtain the detail lost during upscaling, we simply take the original image, shrink it down, upscale it, and compare the result to the (resized) original image.;Apache 2.0;https://www.kaggle.com/bonovandoo/deep-dreaming-dali-keras-deepdream;1.0;['pytorch', 'tensorflow', 'keras', 'pattern'];['ner', 'ai', 'rl', 'nn', 'ann'];['train', 'model', 'neural network', 'deep learning', 'layer', 'vgg', 'loss', 'convolutional neural network'];https://www.kaggle.com/c/painter-by-numbers;0.716;0.281;2020-12-13 15:04:10;multiple data sources;[];Deep Dreaming Dali (Keras DeepDream);Python notebook;4439.0;8;;
2018-10-30 23:16:47;"Goal: Create a model that can identify an artist given a painting from the ""Painter By Numbers"" datasetMethods / Tools Keras Tensorflow ResNet50 a Convolutional Neural Network (CNN) model instance in Keras   Transfer Learning  Questions1. Can a ResNet50 model be modified & retrained to classify Picasso vs Not-Picasso? similar to hot dogs or not hot dogs";Apache 2.0;https://www.kaggle.com/mfekadu/picasso-not-picasso;1.0;['pattern', 'tensorflow', 'keras'];['ner', 'ai', 'cnn', 'cv', 'nn', 'ann'];['test data', 'train', 'fitting', 'model', 'neural network', 'epoch', 'layer', 'gradient descent', 'loss', 'label', 'predict', 'understanding', 'resnet', 'convolutional neural network'];https://www.kaggle.com/c/painter-by-numbers;0.693;0.236;2020-12-13 15:04:10;multiple data sources;['beginner, deep learning, cnn, +2 morebinary classification, transfer learning'];Picasso-Not-Picasso;Python notebook;2607.0;5;;
2018-10-17 06:01:12;"This Notebook is an exploration of the ""Painter By Numbers"" datasetObservations This dataset has a lot of images  Questions / Hypotheses Is it possible to identify the artist of a painting by features related to the painting?  Would the following features be helpful? color palette dominant color etc ...";Apache 2.0;https://www.kaggle.com/mfekadu/somethingaboutimages;1.0;['mxnet'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ann'];['train', 'fitting', 'label', 'loss'];https://www.kaggle.com/c/painter-by-numbers;0.626;0.099;2020-12-13 15:04:10;Painter by Numbers;['gpu'];SomethingAboutImages;Python notebook;698.0;1;;
2017-10-18 13:01:33;OverviewThe Passenger Screening Algorithm Challenge asks the data science community to assist with improving threat detection at US airports while minimizing false positives to avoid long lines and delays. (Can I get an amen!).  This notebook is a follow up to my first effort for this contest called Exploratory Data Analysis and Example Generation (I'll call it EDA from now on).  As I mentioned in the EDA notebook, the HD-AIT system files supplied in this contest range from 10MB to approximately 2GB per subject.  In the instructions, the organizers suggest that one may even be able to win the contest with one of the smaller image suites. In that notebook, in addition to a review of the data and its vagueries, I supplied some basic building blocks for a preprocessing pipeline. In this notebook, I continue the series with a full preprocessing pipeline using the building blocks from before as well as a first pass through a CNN based on the Alexnet using Tensorflow.  Clearly, no one is going to win the contest with this method, but I thought it would be helpful to everyone working on this to have an end to end working pipeline.  I hope you find it useful, and if you do, I hope you'll give me an up vote! As previously noted, I'm not an expert on these systems or the related scans.  If you see something I've misunderstood or you think I've made an error, let me know and I'll correct it.  TSA has made it harder for people to get into this contest by disallowing even masked images to be protrayed on Kaggle, so you'll have to put these scripts in your own environment to take them around the track.  In any event, I am convinced that data science can improve the predictive veracity of these scans.  I'll get off the soap box now and move on. To begin I collect all of the imports used in the notebook at the top.  It makes it easier when you're converting to a preprocessing script.  Make sure to take note of the last import, tsahelper. You will need to install tsahelper and uncomment this line in order for this pipeline to work. The tsahelper package is made from the EDA and is now available as a pip install (no warranties!).;Apache 2.0;https://www.kaggle.com/jbfarrar/preprocessing-pipeline-and-convnet-trainer;1.0;['tensorflow', 'keras'];['ner', 'ai', 'cnn', 'gan', 'rl', 'nn', 'ann'];['regression', 'generation', 'train', 'recognition', 'model', 'neural network', 'epoch', 'layer', 'loss', 'label', 'alexnet', 'predict', 'relu'];https://www.kaggle.com/c/passenger-screening-algorithm-challenge;0.747;0.469;2020-12-13 15:06:52;Passenger Screening Algorithm Challenge;['cnn'];Preprocessing Pipeline and Convnet Trainer;Python notebook;9578.0;67;;
2017-11-05 22:20:12;The notebook is an extension of the inofficial IO functions. Here we organize the data a bit better for a standard classification / regression problem. The example creates two DataFrames. One for the input (patient ID and all associated files, and header tags) the other for the output (a single vector sized 17 with each position corresponding to one of the 'zones' mentioned in the overview. The value is then between 0 and 1 corresponding with the probability of that zone. This can thus be directly used as an input to a neural network or random forest for training.;Apache 2.0;https://www.kaggle.com/kmader/reading-and-organizing-images-and-outputs;1.0;['tensorflow', 'skimage', 'keras'];['ner', 'ai', 'gan', 'ml', 'nn', 'ann'];['regression', 'train', 'neural network', 'label', 'random forest', 'classification'];https://www.kaggle.com/c/passenger-screening-algorithm-challenge;0.726;0.281;2020-12-13 15:06:52;Passenger Screening Algorithm Challenge;[];Reading and Organizing Images and Outputs;Python notebook;5652.0;8;;
2017-12-15 14:56:55;Introduction The task is to predict whether a passenger in an airport could be a Threat because he could have any kind of dangerous object ( gun, knifes ...). This objects could be detected by a millimetre wave scanner called the High Definition-Advanced Imaging Technology (HD-AIT) system. The scanner generates a complete set of body scanner images and we want to find any kind of anomalies in the image it could think us that the passenger could have an object and it could be a threat for the rest of passengers. We are going to apply clustering techniques for detection of anomalies in the image, and previously we are going to generate a complete training dataset with image that we are viewed before checking that the passenger don't have any kind of internal object.;Apache 2.0;https://www.kaggle.com/ramirobmar/kmeans-applications;1.0;['sklearn'];['ner', 'ai', 'cv', 'nn', 'ann'];['filter', 'training data', 'generation', 'train', 'model', 'clustering', 'label', 'k-means', 'predict', 'classification'];https://www.kaggle.com/c/passenger-screening-algorithm-challenge;0.655;0.188;2020-12-13 15:06:52;multiple data sources;[];kmeans_applications;Python notebook;1201.0;3;;
2019-03-14 21:22:15;Kaggle Competition: Predict at which speed a pet is adopted;Apache 2.0;https://www.kaggle.com/alexandralorenzo/models-combination;1.0;['xgboost', 'lightgbm', 'nltk', 'sklearn', 'tensorflow', 'vocabulary'];['ner', 'ai', 'gbm', 'cv', 'rl', 'nn', 'ann'];['regression', 'train', 'fitting', 'model', 'validation data', 'loss', 'label', 'predict', 'classification', 'natural language'];https://www.kaggle.com/c/petfinder-adoption-prediction;0.717;0.469;2020-12-13 15:07:40;PetFinder.my Adoption Prediction;['feature engineering, random forest, xgboost, +1 moresvm'];Models Combination;Python notebook;4554.0;67;;
2018-12-30 13:25:16;Edit: Quadratic Kappa Metric is the same as cohen kappa metric in Sci-kit learn @ sklearn.metrics.cohen_kappa_score when weights are set to 'Quadratic'. Thanks to Johannes for figuring that out.;Apache 2.0;https://www.kaggle.com/aroraaman/quadratic-kappa-metric-explained-in-5-simple-steps;1.0;['sklearn'];['ner', 'ai', 'nn', 'ann'];['predict'];https://www.kaggle.com/c/petfinder-adoption-prediction;0.785;0.57;2020-12-13 15:07:40;PetFinder.my Adoption Prediction;['beginner'];Quadratic Kappa Metric explained in 5 simple steps;Python notebook;27940.0;275;;
2019-03-15 09:27:39;"General informationThis kernel is dedicated to EDA of PetFinder.my Adoption Prediction challenge as well as feature engineering and modelling.  (a screenshot of the PetFinder.my site) In this dataset we have lots of information: tabular data, texts and even images! This gives a lot of possibilties for feature engineering and modelling. The only limiting factor is the fact that the competition is kernel-only. On the other hand this will ensure everyone has the same computational resources. In this kernel I want to pay attention to several things:  comparing distribution of features in train and test data; exploring features and their interactions; trying various types of feature engineering; trying various models without neural nets (for now);  It is important to remember that this competition has stage 2, so our models will run against unseen data. Work still in progress";Apache 2.0;https://www.kaggle.com/artgor/exploration-of-data-step-by-step;1.0;['xgboost', 'lightgbm', 'nltk', 'catboost', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'test data', 'regression', 'random forest', 'train', 'model', 'loss', 'label', 'predict', 'rank', 'classification', 'natural language'];https://www.kaggle.com/c/petfinder-adoption-prediction;0.795;0.618;2020-12-13 15:07:40;PetFinder.my Adoption Prediction;['data visualization, exploratory data analysis, classification, +1 morefeature engineering'];Exploration of data step by step;Python notebook;38756.0;605;0.31641;0.31641
2020-07-26 15:05:10;All this code might seem a little overwhelming at first, but it is really not that complex. There are seven parts:  Preprocessing Training NN1 Training NN2 Training NN3 Image Extractor Training LightGBM Training xlearn Stacking  I'll briefly describe each of them. PreprocessingIn the preprocessing part, external data sources are loaded and the features are processed by:  scaling them appropriately building frequency encoded features of some variables binning some features scaling some features logarithmically  Furthermore, the image activations of a pretrained Densenet121 model are extracted for all features twice (once on the regular images, once on horizontally flipped images). The important variables in this section are:  train_df and test_df - Dataframes holding raw data and all processed tabular features all_cat_features - List of strings determining all available categorical features. all_num_features - List of strings determining all available numerical features. ìmg_features_train, img_features_train_flipped and ìmg_features_test - numpy arrays consisting of the 1024d image activations extracted from Densenet121 for the first image of each pet. train_text_tokens and test_text_tokens - numpy arrays consisting of tokenized words, later used in the RNN models.  Training NN1NN1 is trained with MSE loss using regular image features and a TfIdf representation of text. Important variables:  train_preds_nn_1 - (n_repeats x n_train) numpy array consisting of out-of-fold train predictions. test_preds_nn_1 - (n_repeats x n_test x n_splits) numpy array consisting of test predictions of each fold.  Training NN2NN1 is trained with MSE loss using regular image features and a non-trainable 300d crawl embedding for text. Important variables:  train_preds_nn_2 - (n_repeats x n_train) numpy array consisting of out-of-fold train predictions. test_preds_nn_2 - (n_repeats x n_test x n_splits) numpy array consisting of test predictions of each fold.  Training NN3NN3 is trained with SmoothL1 loss using horizontally flipped image features and a trainable 200d GloVe embedding for text. Important variables:  train_preds_nn_3 - (n_repeats x n_train) numpy array consisting of out-of-fold train predictions. test_preds_nn_3 - (n_repeats x n_test x n_splits) numpy array consisting of test predictions of each fold.  Image ExtractorTrains an image activation extractor NN on train + test data. Input are the 1024d Densenet121 features. The model is trained to predict Age, Breed1 and Type of pets. Important variables:  train_activations - (n_train x 80) numpy array consisting of extracted image activations for the train set. Consists of 64 activations from the first hidden layer + 16 activations of the second hidden layer for each pet. test_activations - (n_test x 80) numpy array consisting of extracted image activations for the test set. Consists of 64 activations from the first hidden layer + 16 activations of the second hidden layer for each pet.  Training LightGBMText features are represented by 120d SVD of a TfIdf matrix for the LightGBM model. The 64d activations from the first hidden layer of the image extractor NN are used to represent images. Important variables:  train_preds_lgb - (n_repeats x n_train) numpy array consisting of out-of-fold train predictions. test_preds_lgb - (n_repeats x n_test x n_splits) numpy array consisting of test predictions of each fold.  Training xlearnText features are represented by 10d SVD of a TfIdf matrix for the xlearn model. The 16d activations from the second hidden layer of the image extractor NN are used to represent images. All numerical features are binned in quantile bins and treated as categorical. . Important variables:  train_preds_ffm - (n_repeats x n_train) numpy array consisting of out-of-fold train predictions. test_preds_ffm - (n_repeats x n_test x n_splits) numpy array consisting of test predictions of each fold.  StackingCombines the previously generated predictions using a linear regression. The scores are converted to labels by following the train distribution. Important variables:  fixed_scores - the final labels for each pet.;Apache 2.0;https://www.kaggle.com/bminixhofer/5th-place-solution-code;1.0;['lightgbm', 'nltk', 'sklearn', 'pytorch', 'tensorflow', 'pattern', 'keras'];['ner', 'ai', 'dl', 'gbm', 'gan', 'cv', 'rl', 'ml', 'nn', 'rnn', 'ann'];['filter', 'machine learning', 'regression', 'test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'lstm', 'predict', 'rank', 'linear regression', 'hidden layer'];https://www.kaggle.com/c/petfinder-adoption-prediction;0.736;0.51;2020-12-13 15:07:40;multiple data sources;['deep learning, classification, feature engineering'];5th Place Solution Code;Python notebook;7262.0;116;;
2019-04-12 01:35:36;This notebook features an overview of the competition, EDA (Exploratory Data Analysis) and ensembling of different models. My goal with this kernel is too keep it concise and illustrate the basic principles behind ensembling.;Apache 2.0;https://www.kaggle.com/carlolepelaars/eda-and-ensembling;1.0;['xgboost', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'ml', 'nn', 'ann'];['machine learning', 'train', 'fitting', 'model', 'loss', 'label', 'gradient boosting', 'predict', 'random forest'];https://www.kaggle.com/c/petfinder-adoption-prediction;0.707;0.463;2020-12-13 15:07:40;PetFinder.my Adoption Prediction;['data visualization, exploratory data analysis, classification, +1 moreensembling'];EDA and Ensembling;Python notebook;3607.0;62;;
2019-01-03 20:25:59;In this kernel I want to demonstrate how to extract features from the pet images using a pretrained network. Since there are often none or multiple images of different resoltuions and aspect ratio I make the following preprocessing steps:  Take only profile picture (if existing else black) pad to square aspect ratio resize to 256;Apache 2.0;https://www.kaggle.com/christofhenkel/extract-image-features-from-pretrained-nn;1.0;['tensorflow', 'keras'];['ai', 'cv'];['train', 'layer', 'model', 'predict'];https://www.kaggle.com/c/petfinder-adoption-prediction;0.759;0.548;2020-12-13 15:07:40;PetFinder.my Adoption Prediction;['gpu'];Extract Image features from pretrained NN;Python notebook;13142.0;198;;
2019-02-03 08:23:47;Table of contents Introduction 1. Loading libraries and preparing the data 2. Data exploration 2.1 Dogs versus Cats, Breed, and Maturity Size 2.2 Age 2.3 Gender and Groups 2.4 The influence of the Fee 2.5 Health and medical status 2.6 Regional differences 2.7 Text mining the Description 2.8 Pets with a name versus pets without name   3. Baseline XGBoost model;Apache 2.0;https://www.kaggle.com/erikbruin/petfinder-my-detailed-eda-and-xgboost-baseline;1.0;['xgboost', 'lightgbm'];['ner', 'ai', 'dl', 'gbm', 'gan', 'cv', 'rl', 'nn', 'ann'];['gru', 'filter', 'train', 'model', 'label', 'predict', 'rank', 'recommend'];https://www.kaggle.com/c/petfinder-adoption-prediction;0.753;0.537;2020-12-13 15:07:40;PetFinder.my Adoption Prediction;['data visualization, exploratory data analysis, text mining'];PetFinder.my: detailed EDA and XGBoost baseline;R notebook;11131.0;169;0.30181;0.00000
2019-02-10 18:49:22;Thanks for this https://www.kaggle.com/risntforpirates/petfinder-simple-lgbm and this https://www.kaggle.com/skooch/petfinder-simple-lgbm-baseline main parts. And for this picture part: https://www.kaggle.com/christofhenkel/extract-image-features-from-pretrained-nn. Just combined two notebooks together to show how to add image features to your lbgm.;Apache 2.0;https://www.kaggle.com/myltykritik/simple-lgbm-image-features;1.0;['lightgbm', 'sklearn', 'tensorflow', 'pattern', 'keras'];['ner', 'ai', 'gbm', 'nlg', 'cv', 'rl', 'nn', 'ann'];['regression', 'train', 'model', 'layer', 'loss', 'label', 'predict'];https://www.kaggle.com/c/petfinder-adoption-prediction;0.72;0.463;2020-12-13 15:07:40;multiple data sources;['gpu'];Simple lgbm  + image features;Python notebook;4856.0;62;0.41393;0.41393
2019-01-24 03:39:49;This kernel is to demostrate an improved version of the OptimizedRounder function initially shared by Abhishek: https://www.kaggle.com/c/petfinder-adoption-prediction/discussion/76107;Apache 2.0;https://www.kaggle.com/naveenasaithambi/optimizedrounder-improved;1.0;['lightgbm', 'sklearn'];['cv', 'ai', 'rl', 'gbm'];['regression', 'train', 'model', 'loss', 'label', 'predict'];https://www.kaggle.com/c/petfinder-adoption-prediction;0.728;0.469;2020-12-13 15:07:40;PetFinder.my Adoption Prediction;['regression, optimization'];OptimizedRounder() - Improved;Python notebook;5828.0;67;;
2019-02-07 09:20:17;Links to orginal kernel https://www.kaggle.com/tunguz/annoying-ab-shreck-and-bluetooth https://www.kaggle.com/domcastro/let-s-annoy-abhishek https://www.kaggle.com/abhishek/maybe-something-interesting-here EAS - All I have done is change the parameters for the LGB. I am also abandoning the OptimizedRounder and have hand-tuned the coefficients to match the distribution of the test predictions to the distribution of the train targets. McCartney Taylor provided the tweaks to the learning rate and lambda.  Change Log   v19 - added regularization lambda (0.2) v21 - lowered lambda (0.05) v22 - lowered lambda again (0.02) v23 - lambda up to (0.075) v24 - lambda back to 0.05, commenting out tfidf code that causes error v25 - uncommenting commented out code v26 - fixed bug that was throwing error for tf-idf code v27 - examining code that had been throwing error, fixing the error lowers the score v28 - passing list of categorical features v29 - tuning params v30 - using more tfidf features v31, 32 - playing with tfidf params v35 - back to 120 tfidf svd features v36 - reverting to baseline and not using OptimizedRounder, hand-tuning coefs instead v38 - Changing lambda and learning rate.;Apache 2.0;https://www.kaggle.com/skooch/petfinder-simple-lgbm-baseline;1.0;['pattern', 'lightgbm', 'sklearn'];['ner', 'ai', 'gbm', 'nlg', 'cv', 'rl', 'nn', 'ann'];['regression', 'train', 'model', 'loss', 'label', 'predict'];https://www.kaggle.com/c/petfinder-adoption-prediction;0.741;0.486;2020-12-13 15:07:40;PetFinder.my Adoption Prediction;['gpu'];PetFinder Simple LGBM Baseline;Python notebook;8158.0;83;0.41261;0.41261
2019-12-21 18:07:11;This notebook was created as a Kaggle tutorial for a lecture at Deep Learning School;Apache 2.0;https://www.kaggle.com/vshakhray/dls-petfinder;1.0;['pytorch', 'catboost', 'sklearn'];['ner', 'ai', 'dl', 'rl', 'nn', 'ml'];['filter', 'train', 'model', 'deep learning', 'loss', 'label', 'predict', 'resnet', 'random forest'];https://www.kaggle.com/c/petfinder-adoption-prediction;0.634;0.481;2020-12-13 15:07:40;PetFinder.my Adoption Prediction;['gpu'];DLS Petfinder;Python notebook;811.0;78;;
2019-02-13 14:20:01;load core DFs (train and test):;Apache 2.0;https://www.kaggle.com/wrosinski/baselinemodeling;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'gbm', 'rl', 'ml', 'nn', 'ann'];['regression', 'train', 'model', 'loss', 'label', 'predict'];https://www.kaggle.com/c/petfinder-adoption-prediction;0.763;0.568;2020-12-13 15:07:40;PetFinder.my Adoption Prediction;[];BaselineModeling;Python notebook;14802.0;269;0.38214;0.00000
2019-10-23 04:56:08;Data Description :Much of the Text was taken from the official page  This dataset contains photos of streets, taken from the roof of a car. We're attempting to predict the position and orientation of all un-masked cars in the test images. You should also provide a confidence score indicating how sure you are of your prediction. Pose Information (train.csv) Note that rotation values are angles expressed in radians, relative to the camera. The primary data is images of cars and related pose information. The pose information is formatted as strings, as follows: model type, yaw, pitch, roll, x, y, z A concrete example with two cars in the photo: 5 0.5 0.5 0.5 0.0 0.0 0.0 32 0.25 0.25 0.25 0.5 0.4 0.7 Submissions (per sample_submission.csv) are very similar, with the addition of a confidence score, and the removal of the model type. You are not required to predict the model type of the vehicle in question. ID, PredictionString ID_1d7bc9b31,0.5 0.5 0.5 0.0 0.0 0.0 1.0 indicating that this prediction has a confidence score of 1.0. Other Data: Image Masks (test_masks.zip / train_masks.zip) Some cars in the images are not of interest (too far away, etc.). Binary masks are provided to allow competitors to remove them from consideration. Car Models 3D models of all cars of interest are available for download as pickle files - they can be compared against cars in images, used as references for rotation, etc.;Apache 2.0;https://www.kaggle.com/dataraj/eda-to-insight;1.0;['skimage'];['dl', 'ai', 'nn'];['train', 'layer', 'model', 'predict'];https://www.kaggle.com/c/pku-autonomous-driving;0.668;0.476;2020-12-13 15:26:06;Peking University/Baidu - Autonomous Driving;['data visualization, exploratory data analysis, image data'];EDA_to_Insight;Python notebook;1564.0;73;;
2019-12-25 15:41:41;If you think it's useful, give me an upvote, thanks.;Apache 2.0;https://www.kaggle.com/diegojohnson/centernet-objects-as-points;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ann'];['filter', 'object detection', 'regression', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'classification', 'ground truth'];https://www.kaggle.com/c/pku-autonomous-driving;0.747;0.509;2020-12-13 15:26:06;multiple data sources;['gpu'];CenterNet - Objects as Points;Python notebook;9651.0;114;0.001;0.001
2020-01-03 12:22:43;'EfficientDet: Scalable and Efficient Object Detection' Google's paper in Nov 20th  no official open-source now, just find some repos. https://github.com/toandaominh1997/EfficientDet.Pytorch If you think it's useful, please give me an upvote.;Apache 2.0;https://www.kaggle.com/diegojohnson/efficientdet-d1;1.0;['pytorch', 'albumentations', 'tensorflow', 'skimage'];['ner', 'ai', 'cnn', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['r-cnn', 'filter', 'object detection', 'regression', 'train', 'model', 'neural network', 'layer', 'label', 'predict', 'relu', 'classification', 'convolutional neural network'];https://www.kaggle.com/c/pku-autonomous-driving;0.736;0.416;2020-12-13 15:26:06;multiple data sources;['gpu'];EfficientDet-D1;Python notebook;7105.0;35;;
2019-11-01 01:58:45;EDA - Finding Similar Images in Train and Test DatasetsIn this notebook, we are going to use imagededup to find similar images in the test dataset of Peking University/Baidu - Autonomous Driving competition. Install imagedup;Apache 2.0;https://www.kaggle.com/ebouteillon/eda-find-similar-images-in-datasets;1.0;['tensorflow', 'keras', 'pillow'];['ai'];['train', 'test data', 'filter'];https://www.kaggle.com/c/pku-autonomous-driving;0.671;0.416;2020-12-13 15:26:06;Peking University/Baidu - Autonomous Driving;['beginner, data visualization, exploratory data analysis'];EDA - Find Similar Images In Datasets;Python notebook;1647.0;35;;
2019-11-18 08:20:49;"EDA + CenterNet BaselineReferences:  Took 3D visualization code from https://www.kaggle.com/zstusnoopy/visualize-the-location-and-3d-bounding-box-of-car CenterNet paper https://arxiv.org/pdf/1904.07850.pdf CenterNet repository https://github.com/xingyizhou/CenterNet  Change log:  v14: better inference: added optimize_xy function | LB 0.093 v15: horizontal flip augmentation | ERROR v16: faster training (made smaller padding) | LB 0.089 v17: smaller image size and better image proportions | LB 0.066 v18: image size back; changed flip probability; new visualizations | LB ?";Apache 2.0;https://www.kaggle.com/hocop1/centernet-baseline;1.0;['pytorch', 'sklearn'];['ner', 'ai', 'dl', 'cv', 'nn', 'ann'];['regression', 'train', 'model', 'epoch', 'loss', 'label', 'predict', 'relu', 'u-net', 'ground truth'];https://www.kaggle.com/c/pku-autonomous-driving;0.801;0.603;2020-12-13 15:26:06;Peking University/Baidu - Autonomous Driving;['data visualization, exploratory data analysis, image data'];CenterNet Baseline;Python notebook;46997.0;475;0.029;0.027
2020-01-04 17:19:53;IntroductionThis notebook is modification of Ruslan Baynazarov's baseline kernel ver.14 CenterNet Baseline with PL score = 0.038, The uploaded model has been trained with the code below for 6 epochs (appx.6 hours) without image augmentations. Here it is to be trained for another 3 epochs. The changes I made in the order of the perceived significance to the CV/PL score:1) changed dropout rate in the EfficientNet B0 base model from 0.2 to 0.02 2) select threshold = -1.5 to filter logits so that the ratio of number of predicted cars to number of images approximates the one of the training set 3) use test_masks to remove cars from test predictions 4) cars appearing outside of image boundaries are dropped (removed 997 cars out of 49,626 total ) 5) Removed broken images thanks to https://www.kaggle.com/c/pku-autonomous-driving/discussion/117621 6) changed StepLR learning rate scheduler to MultiStepLR (gamma=0.5) 7) pixel wise augmentations (albumentations lib) 8) normalized images with subtracting total means per channel and dividing by standard deviation All other building blocks laid out in CenterNet Baseline kernel ver.14 are intact. (preprocessing, efficientnet-B0 backbone, Adam optimizer) What did not work. using efficientnet B4, B5. The reason might be that the batch size of only 1 image could be fit to Tesla P100 GPU gradient accumulation did not improve score. Batch Normalization layers are quoted to be the possible reason was not able to change BatchNorm to GroupNorm, and I am still not sure if it would help (would be delighted if you could comment with lines of such code)  References:Took 3D visualization code from https://www.kaggle.com/zstusnoopy/visualize-the-location-and-3d-bounding-box-of-car CenterNet paper https://arxiv.org/pdf/1904.07850.pdf CenterNet repository https://github.com/xingyizhou/CenterNet Will be grateful for pointing to the bugs and advising corrections;Apache 2.0;https://www.kaggle.com/isakev/rb-s-centernet-baseline-pytorch-without-dropout;1.0;['pytorch', 'albumentations', 'sklearn'];['ner', 'ai', 'cv', 'nn', 'ann'];['filter', 'regression', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'recommend', 'ground truth'];https://www.kaggle.com/c/pku-autonomous-driving;0.681;0.39;2020-12-13 15:26:06;multiple data sources;['image data, neural networks, computer vision'];RB's CenterNet Baseline Pytorch without Dropout;Python notebook;2023.0;26;0.046;0.041
2019-12-17 10:00:52;This notebook is a sample code to calculate metrics. Since There are many ambiguous parts in official evaluation page, this is just my understanding of metrics.;Apache 2.0;https://www.kaggle.com/its7171/metrics-evaluation-script;1.0;['sklearn'];['ai'];['train', 'model', 'label', 'predict', 'understanding'];https://www.kaggle.com/c/pku-autonomous-driving;0.718;0.49;2020-12-13 15:26:06;multiple data sources;[];metrics evaluation script;Python notebook;4653.0;88;;
2020-01-05 05:01:42;Overview The objectie of this kernel is solely to illustrate the impacts of varying the number of epochs,for version 2 of the forked kernel https://www.kaggle.com/mobassir/center-resnext50-baseline The only changes are to the number of epochs As much GPU hours have been spent to illustrate the results, it will be great if you can upvote if you found this helpful in any way, including the original kernel above Thank you and happy new year!;Apache 2.0;https://www.kaggle.com/khoongweihao/autonomous-driving-epoch-on-fire-resnext50;1.0;['pytorch', 'sklearn'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn'];['test data', 'regression', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'resnet', 'classification', 'u-net', 'ground truth'];https://www.kaggle.com/c/pku-autonomous-driving;0.723;0.475;2020-12-13 15:26:06;multiple data sources;['gpu'];[Autonomous Driving] Epoch on Fire - resnext50;Python notebook;5186.0;72;0.010;0.012
2020-01-18 17:40:35;This is going to be my first ever EDA kernelI will gradually update this kernel;Apache 2.0;https://www.kaggle.com/mobassir/baidu-autonomous-driving-eda;1.0;['sklearn', 'opencv-python', 'pillow', 'pytorch', 'albumentations', 'skimage'];['ner', 'ai', 'cnn', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['gru', 'filter', 'regression', 'train', 'model', 'understanding', 'label', 'predict', 'recommend', 'classification'];https://www.kaggle.com/c/pku-autonomous-driving;0.713;0.481;2020-12-13 15:26:06;Peking University/Baidu - Autonomous Driving;['gpu'];Baidu - Autonomous Driving EDA;Python notebook;4138.0;78;;
2019-11-01 04:09:10;Peking University/Baidu - Autonomous DrivingCan you predict vehicle angle in different settings?;Apache 2.0;https://www.kaggle.com/robikscube/autonomous-driving-introduction-data-review;1.0;['tensorflow', 'keras'];['ner', 'ai', 'cv'];['train', 'model', 'predict'];https://www.kaggle.com/c/pku-autonomous-driving;0.76;0.523;2020-12-13 15:26:06;Peking University/Baidu - Autonomous Driving;['beginner, data visualization, exploratory data analysis, +1 moreimage data'];🚘 Autonomous Driving Introduction & Data Review;Python notebook;13400.0;138;;
2019-10-25 05:18:36;Visualize the location and 3d bounding box of the car;Apache 2.0;https://www.kaggle.com/zstusnoopy/visualize-the-location-and-3d-bounding-box-of-car;1.0;['tensorflow', 'keras'];['ai', 'gan', 'cv', 'rl', 'nn', 'ml'];['train', 'model', 'gru', 'predict'];https://www.kaggle.com/c/pku-autonomous-driving;0.737;0.47;2020-12-13 15:26:06;Peking University/Baidu - Autonomous Driving;[];Visualize the location and 3d bounding box of car;Python notebook;7450.0;68;;
2017-05-11 19:32:33;This is an expansion of Robin's notebook ( https://www.kaggle.com/robinkraft/making-tifs-look-normal-using-spectral/ ) to show ways how to use the spectral module to read bands, calculate the NDVI, NDWI and save the image as a high-quality jpeg.;Apache 2.0;https://www.kaggle.com/fppkaggle/making-tifs-look-normal-using-spectral-fork;1.0;['skimage', 'sklearn'];['ai'];['train'];https://www.kaggle.com/c/planet-understanding-the-amazon-from-space;0.666;0.383;2020-12-13 15:31:34;Planet: Understanding the Amazon from Space;[];"Making tifs look ""normal"" using spectral - fork";Python notebook;1493.0;24;;
2019-01-26 23:23:39;Multi-label prediction with Planet Amazon dataset;Apache 2.0;https://www.kaggle.com/hortonhearsafoo/fast-ai-v3-lesson-3-planet;1.0;['pytorch'];['ner', 'ai', 'dl', 'cnn', 'nn', 'ml'];['train', 'model', 'epoch', 'loss', 'label', 'predict', 'resnet', 'classification', 'ground truth'];https://www.kaggle.com/c/planet-understanding-the-amazon-from-space;0.743;0.449;2020-12-13 15:31:34;Planet: Understanding the Amazon from Space;['gpu'];fast.ai v3 lesson 3 planet;Python notebook;8546.0;52;;
2019-02-14 17:14:47;Data exploration and basic ConvNN for Image classificationUniversity of Waterloo Geospatial Club - Winter 2019 Slides and Kernel for the first workshop on Machine Learning for Vector data.The purpose of the workshop is to give the UWaterloo students and the members of the Geospatial Club an introduction to the most recent Machine Learning tools for analysis of Geospatial data. The workshop is held in collaboration with the Geospatial Centre at the University of Waterloo. We hope that you will learn something new from the content of this workshop. If you have questions after the workshop, then please feel free to message the Geospatial Club or the workshop presenters.  Jaydeep Mistry at jaydeep.mistry@uwaterloo.ca  Juan Carrillo at jmcarril@uwaterloo.ca      References     [1] Planet: Understanding the Amazon from Space. Featured Kaggle Competition.   [2] Kernel by Philipp Schmidt   [3] Kernel by Tuatini Godard   [4] Source code by Mikel Bober   [5] Source code by Jason Brownlee   [6] Normalized Difference Vegetation Index (NDVI)   [7] t-Distributed Stochastic Neighbor Embedding (t-SNE)   [8] Matplotlib documentation   [9] tqdm documentation   [10] Scipy documentation;Apache 2.0;https://www.kaggle.com/jcarrillo/machine-learning-for-geospatial-data-workshop-2a;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ai', 'dl', 'cv', 'rl', 'nn', 'ann'];['image classification', 'machine learning', 'train', 'model', 'neural network', 'epoch', 'layer', 'clustering', 'loss', 'label', 'predict', 'relu', 'understanding', 'classification', 'convolutional neural network'];https://www.kaggle.com/c/planet-understanding-the-amazon-from-space;0.688;0.403;2020-12-13 15:31:34;Planet: Understanding the Amazon from Space;['neural networks, multiclass classification, geospatial analysis'];Machine Learning for Geospatial Data Workshop #2A;Python notebook;2359.0;30;;
2017-06-13 18:43:41;Initial EDATake a look at the images and try out possible image processing techniques;Apache 2.0;https://www.kaggle.com/kbalkoski/initial-eda-image-processing;1.0;['pattern', 'skimage'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['train', 'label', 'filter', 'clustering'];https://www.kaggle.com/c/planet-understanding-the-amazon-from-space;0.702;0.421;2020-12-13 15:31:34;Planet: Understanding the Amazon from Space;[];Initial EDA - Image Processing;Python notebook;3226.0;37;;
2017-05-04 17:02:23;Keras + CV Thanks @anokas for the starter code at https://www.kaggle.com/anokas/planet-understanding-the-amazon-from-space/simple-keras-starter/;Apache 2.0;https://www.kaggle.com/lpachuong/keras-cv-optim;1.0;['tensorflow', 'sklearn', 'keras', 'theano'];['ai', 'rl', 'cv'];['test data', 'train', 'fitting', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'understanding'];https://www.kaggle.com/c/planet-understanding-the-amazon-from-space;0.718;0.418;2020-12-13 15:31:34;Planet: Understanding the Amazon from Space;[];Keras + CV + Optim;Python notebook;4675.0;36;;
2017-10-04 18:13:29;Starting kit for PyTorch Deep LearningWelcome to this tutorial to get started on PyTorch for this competition. PyTorch is a promising port of Facebook's Torch to Python. It's only 3 months old but has an already promising feature set. Unfortunately it's very very raw, and I had a lot of troubles to get started with very basic things:  data loading building a basic CNN training  Hopefully this will help you getting started using PyTorch on this dataset.;Apache 2.0;https://www.kaggle.com/mratsim/starting-kit-for-pytorch-deep-learning;1.0;['caffe', 'sklearn', 'pillow', 'pytorch', 'keras'];['ner', 'ai', 'cnn', 'cv', 'rl', 'ml', 'nn', 'rnn', 'ann'];['filter', 'train', 'model', 'neural network', 'epoch', 'deep learning', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/planet-understanding-the-amazon-from-space;0.786;0.495;2020-12-13 15:31:34;Planet: Understanding the Amazon from Space;[];Starting Kit for PyTorch Deep Learning;Python notebook;28851.0;94;;
2017-04-30 19:49:17;Who can save the rainforest?In this competition we are given a multilabel classification problem, where we have to decide, given an image, which labels belong to it. From the evaluation section of the competition: For each image listed in the test set, predict a space-delimited list of tags which you believe are associated with the image. There are 17 possible tags: agriculture, artisinal_mine, bare_ground, blooming, blow_down, clear, cloudy, conventional_mine, cultivation, habitation, haze, partly_cloudy, primary, road, selective_logging, slash_burn, water. In this notebook we will:  generate a fun bernoulli trial sample submission look at the actual images to get a first impression of the data cluster the images according to their pixel intensities to find potentially formed groups compute standard NDVI values for images and rank them by this index.   A standard approach to multilabel classification is to learn as many OVA (one vs all) models as there are distinct labels and then assign labels by the classifier output of each of the models, we'll get to that later. If you like it, please upvote this :) Let's dive right into the data.;Apache 2.0;https://www.kaggle.com/philschmidt/multilabel-classification-rainforest-eda;1.0;['skimage', 'sklearn'];['ner', 'ai', 'cv', 'rl', 'nn', 'ann'];['filter', 'test data', 'regression', 'train', 'fitting', 'model', 'neural network', 'clustering', 'label', 'predict', 'rank', 'classification'];https://www.kaggle.com/c/planet-understanding-the-amazon-from-space;0.773;0.52;2020-12-13 15:31:34;Planet: Understanding the Amazon from Space;[];Multilabel Classification & Rainforest EDA;Python notebook;19362.0;133;;
2017-05-10 19:26:02;This is based on our official notebook - not something I can take credit for :) https://github.com/planetlabs/planet-amazon-deforestation/blob/master/planet_chip_examples.ipynb Planet: Understanding the Amazon from Space challengeThis notebook will show you how to do some basic manipulation of the images and label files.;Apache 2.0;https://www.kaggle.com/robinkraft/getting-started-with-the-data-now-with-docs;1.0;['skimage'];['ai', 'rl', 'ml', 'nn', 'ann'];['train', 'understanding', 'label', 'classification'];https://www.kaggle.com/c/planet-understanding-the-amazon-from-space;0.776;0.51;2020-12-13 15:31:34;Planet: Understanding the Amazon from Space;[];Getting started with the data - now with docs!;Python notebook;21151.0;115;;
2020-06-05 19:58:50;Before the trip beginIf you like my work, please hit upvote since it will keep me motivated;Apache 2.0;https://www.kaggle.com/abdilatifssou/sample-use-of-efficientnetb7-achieved-97-8;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'automl', 'cnn', 'rl', 'ml', 'nn', 'ann'];['train', 'model', 'epoch', 'layer', 'label', 'loss', 'relu'];https://www.kaggle.com/c/plant-pathology-2020-fgvc7;0.632;0.421;2020-12-13 15:33:04;Plant Pathology 2020 - FGVC7;['beginner, data visualization'];Sample use of EfficientNetB7<Achieved %97.8>;Python notebook;780.0;37;;
2020-05-19 05:58:34;In this notebook, we will perform transfer learning and ensembling with EfficientNet to perform image classification for the Plant Pathology 2020 - FGVC7 competition.This is a straightforward tutorial in PyTorch! Please upvote if you found this useful :);Apache 2.0;https://www.kaggle.com/akasharidas/plant-pathology-2020-in-pytorch;1.0;['pytorch', 'albumentations', 'sklearn'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ann'];['image classification', 'filter', 'test data', 'train', 'model', 'epoch', 'loss', 'label', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/plant-pathology-2020-fgvc7;0.741;0.501;2020-12-13 15:33:04;multiple data sources;['gpu, cnn'];Plant Pathology 2020 in PyTorch - 0.974 score;Python notebook;8065.0;102;0.97035;0.97554
2020-04-20 16:26:21;if you like it ,please vote for it,good score for you ( •̀ ω •́ )✧;Apache 2.0;https://www.kaggle.com/anyexiezouqu/tpu-tensorflow2-0-978score;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'nn', 'ann'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'resnet'];https://www.kaggle.com/c/plant-pathology-2020-fgvc7;0.734;0.471;2020-12-13 15:33:04;Plant Pathology 2020 - FGVC7;['beginner, deep learning, classification, +1 moreensembling'];public first score-TPU:IncepresnetV2+ENB7;Python notebook;6777.0;69;;
2020-05-29 13:08:26;Special thanks to chris deotte's notebooks they have'been really helpful, Thanks you Grandmaster !;Apache 2.0;https://www.kaggle.com/aziz69/efficientnetb7-tpu-tta-top-1;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'ml', 'nn', 'ann'];['neuron', 'train', 'model', 'epoch', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'resnet', 'classification', 'propagation'];https://www.kaggle.com/c/plant-pathology-2020-fgvc7;0.72;0.456;2020-12-13 15:33:04;multiple data sources;['deep learning, cnn, transfer learning'];EfficientNetB7!+TPU+TTA(top 1%);Python notebook;4833.0;57;;
2020-05-28 11:31:57;Bilinear EfficientNet with Focal Loss + Label SmoothingPlant Pathology  Problem Objectives:The aim of this challenge is to build a Generalised Model for the task of Image Classification. We have to also deal with Class Imbalance Problem and detect Fine Grained details which differentiates whether the leaf is diseased or Not.Solution: i) Image Classification: EfficientNet  ii) Class Imbalance and Generalization : Focal Loss + Label Smoothing  iii) Detect Fine Grain Details: Bilinear CNN     Model: BiLinear EfficientNet with Focal Loss+ Label Smoothing  Expriments and Results: a) Selecting the Best and Efficient CNN Backbone (img size:380x380):   b) Exprimenting with Loss Functions (img size:380x380):     c) Bilinear EffcientNet (img size:760x760):     References: (1)   EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks (2)   Focal Loss for Dense Object Detection (3)   Bilinear CNNs for Fine-grained Visual Recognition (4)   Focal Loss Implementation (5)   Label Smoothing Explaination and Formulas (6)   BiLinear CNN Implementation  Contents of this Notebook 1. Loading Dependencies and Dataset   2. Functions:       i. Bilinear Function       ii. Focal Loss + Label Smoothing        iii. F1 Score Metrics   3. Model   4. Training   5. Testing and Saving Model      Note: The main purpose of this notebook is to implement the above mentioned Idea!;Apache 2.0;https://www.kaggle.com/jimitshah777/bilinear-efficientnet-focal-loss-label-smoothing;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cnn', 'cv', 'rl', 'nn', 'ann'];['image classification', 'object detection', 'train', 'recognition', 'model', 'neural network', 'epoch', 'layer', 'loss', 'label', 'predict', 'classification', 'convolutional neural network', 'propagation'];https://www.kaggle.com/c/plant-pathology-2020-fgvc7;0.694;0.379;2020-12-13 15:33:04;Plant Pathology 2020 - FGVC7;[];BiLinear EfficientNet Focal Loss+ Label Smoothing;Python notebook;2683.0;23;;
2020-04-28 07:40:42;"Image segmentation using Detectron2Using Detectron2 and mask R-CNN it is possible to isolate each leaf from the input image and extract the most prominent one for later analysis.Steps involved: Download and install detectron2 and other dependancies  Hand annotate images with the objects mask (not covered in this kernel) - google ""labelme"" and ""training detectron2 on custom dataset""  Train detectron2 (not covered in this kernel)  Load pretrained weights into detectron2  Infer image masks and identifiy prominent objects  Mask and extract from original image  Crop and rotate object to fit     To Do: Futher training of the mask R-CNN model to improve segmentation.";Apache 2.0;https://www.kaggle.com/lewisgmorris/image-segmentation-using-detectron2;1.0;['pytorch', 'detectron', 'pillow'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'ml', 'nn', 'ann'];['image segmentation', 'r-cnn', 'filter', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/plant-pathology-2020-fgvc7;0.691;0.387;2020-12-13 15:33:04;Plant Pathology 2020 - FGVC7;[];Image segmentation using Detectron2;Python notebook;2528.0;25;;
2020-05-01 13:50:56;Plant Pathology 2020 with fastai2The goal of this notebook is to showcase some of the features in the soon to be released fastai2 library and to provide a starter example for classifying categories of foliar diseases in apple trees. Changelogv10 (2020-05-1) Bug fixes. Add test data to EDA.  v8,v9 (2020-03-15) Train 5 folds. Clean up some broken parts.  v7 (2020-03-13) Resize to 1024 Less oversampling.  v6 (2020-03-13) Label smoothing. Fix validation bug.  v5 (2020-03-13) Oversampling minority class.  v4 (2020-03-12) Add competition metric to learner output. Add confusion matrix.  v3. 2020-03-12 Bigger image size.  v2. 2020-03-12 First working version;Apache 2.0;https://www.kaggle.com/lextoumbourou/plant-pathology-2020-eda-training-fastai2;1.0;['pytorch', 'sklearn'];['ner', 'ai', 'dl', 'cnn', 'rl', 'ml', 'nn', 'ann'];['test data', 'train', 'model', 'epoch', 'loss', 'label', 'predict', 'classification'];https://www.kaggle.com/c/plant-pathology-2020-fgvc7;0.705;0.427;2020-12-13 15:33:04;Plant Pathology 2020 - FGVC7;['gpu, exploratory data analysis, classification'];Plant Pathology 2020 - EDA + training (fastai2);Python notebook;3455.0;40;0.87845;0.89084
2020-05-12 08:22:16;Increasing the amount and diversity of data. Deep learning techniques have found great success when it comes to computer vision tasks namely image recognition, image segmentation, object detection, etc. Such deep learning techniques are heavily dependent on big data to avoid overfitting. So what do you do when you have limited data? Your go for Data Augmentation. Data Augmentation techniques that enhance the size and quality of training datasets such that better Deep Learning models can be built using them. In this notebook, we shall look at some of the common image augmentation techniques and some of the popular libraries which help to achieve these augmentations. Types of Augmentations There are broadly two kinds of Augmentations;Apache 2.0;https://www.kaggle.com/parulpandey/overview-of-popular-image-augmentation-packages;1.0;['opencv-python', 'pillow', 'albumentations', 'tensorflow', 'keras', 'skimage'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['image segmentation', 'filter', 'machine learning', 'training data', 'object detection', 'train', 'fitting', 'model', 'recognition', 'deep learning', 'label', 'computer vision'];https://www.kaggle.com/c/plant-pathology-2020-fgvc7;0.78;0.512;2020-12-13 15:33:04;Plant Pathology 2020 - FGVC7;['beginner, data visualization, deep learning, +2 morecomputer vision, plants'];Overview of popular Image  Augmentation packages ;Python notebook;23876.0;119;;
2020-03-11 22:55:14;Plant Pathology 2020Implemented / planned [✔] - Starter code [✔] - 5-Folds CV [✔] - Albumentations [✔] - Visualize training history [-] - Schedulers [-] - Train longer (without overfitting) [-] - Experimenting with ResNets [-] - Experimenting with EfficientNets [-] - Experimenting with SEResNeXts [-] - Experimenting with different input image size [-] - TTA [-] - OHEM [-] - Pseudo labelling [-] - Mixup [-] - Cutmix [-] - Cutout  Notebook Versions v1: Starter code v4: 5-Folds CV. The gap between local and public score seems a bit high, probably because of the small number of validation samples. I added 5-folds (for now, simple k-fold) CV to see whether it reduces the difference.  v5: More augmentations. I try to train for more epochs. To prevent overfitting, I added more augmentations. v6: Changed to softmax + cross entropy. I used Sigmoid+BCE, not sure why. Note: There was no overfit during training (v5), but the CV-LB gap is still high. v8: According to my EDA the classes are not balanced (multiple_deseases is only 5%). I replace KFold to StratifiedKFold. v9: Input image size: 256px -> 512px    Version Net #Folds #Epochs Local LB Public LB Notes     v1 Resnet-18 1 10 0.972 0.923 Starter code   v4 Resnet-18 5 5 0.950 0.941 5-folds CV   v5 Resnet-18 5 10 0.971 0.935 More augmentations   v6 Resnet-18 5 5 0.971 0.937 Softmax + CE   v8 Resnet-18 5 10 0.970 0.944 StratifiedKFold   v9 Resnet-18 5 10 n.a. n.a. 512px input;Apache 2.0;https://www.kaggle.com/pestipeti/plant-pathology-2020-pytorch;1.0;['pytorch', 'albumentations', 'sklearn'];['ner', 'ai', 'cv', 'nn', 'ann'];['filter', 'train', 'fitting', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'resnet'];https://www.kaggle.com/c/plant-pathology-2020-fgvc7;0.75;0.51;2020-12-13 15:33:04;Plant Pathology 2020 - FGVC7;['gpu, classification, computer vision'];Plant Pathology 2020 - Pytorch;Python notebook;10203.0;116;0.95197;0.96511
2020-04-03 09:04:55;Training with P100 GPUModel: EfficientNet b4 input size 320x512 (.npy files are generated by https://www.kaggle.com/welkinfeng/plant-pathology-generate-npy-data) using P100 GPU: train time: 60s / epoch, test time: 50s using single core TPU (320x320 input size): train time: 3-6mins for the first epoch, 60s for rest epoch, test time: 50s (https://www.kaggle.com/welkinfeng/plant-pathology-pytorch-tpu-efficientnet-b4) v3: 5 fold LB 0.968 v7: use weighted CE loss;Apache 2.0;https://www.kaggle.com/welkinfeng/plant-pathology-pytorch-efficientnet-b4-gpu;1.0;['pytorch', 'albumentations', 'sklearn'];['ner', 'ai', 'cv', 'rl', 'ml', 'nn', 'ann'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'rank', 'resnet'];https://www.kaggle.com/c/plant-pathology-2020-fgvc7;0.702;0.387;2020-12-13 15:33:04;multiple data sources;['gpu, deep learning, classification'];Plant Pathology: Pytorch efficientnet_b4 GPU;Python notebook;3202.0;25;0.96412;0.97302
2020-04-25 16:47:16;"About this kernelIn my last TPU kernel for the flower competition, I wrapped the very comprehensive starter kernel to show how to load TFRecords in order to predict flower categories. In this kernel, I want to show the simplest and most barebone way to load png files (instead of TFRecords). In here, I only included the commands you will need to train the model; no bells and whistles included, which means there are no util functions to display the images or preprocess the images, but just enough content for you to quickly understand how tf.data.Dataset works. If you want to dive deeper in the tf.data.Dataset way of building your input pipeline, please check out this tutorial by Martin, which I followed in order to build this kernel. References https://www.kaggle.com/mgornergoogle/getting-started-with-100-flowers-on-tpu https://codelabs.developers.google.com/codelabs/keras-flowers-data/#0";Apache 2.0;https://www.kaggle.com/xhlulu/plant-pathology-very-concise-tpu-efficientnet;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'nn', 'ann'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict'];https://www.kaggle.com/c/plant-pathology-2020-fgvc7;0.725;0.444;2020-12-13 15:33:04;Plant Pathology 2020 - FGVC7;[];Plant Pathology: Very Concise TPU EfficientNet;Python notebook;5440.0;49;;
2020-07-15 23:05:45;Visualisation of datasetTo get a feel of the data, exploratory data analysis is done. The total number of train images from each subdirectory are stored and used in the bar and pie charts;Apache 2.0;https://www.kaggle.com/apollo2506/cnn-basic-model;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'nn'];['filter', 'train', 'fitting', 'model', 'output layer', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'understanding', 'classification'];https://www.kaggle.com/c/plant-seedlings-classification;0.596;0.292;2020-12-13 15:35:24;Plant Seedlings Classification;[];CNN Basic Model;Python notebook;420.0;9;;
2018-04-06 15:54:12;Transfer learning with pretrained Keras modelsAlthough Kernel resources were increased recently we still can not train useful CNNs without GPU. Fortunately prediction is much faster (<1s/image) making it possible to run meaningful experiments with Kaggle Kernels.;Apache 2.0;https://www.kaggle.com/gaborfodor/seedlings-pretrained-keras-models;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'dl', 'cnn', 'rl', 'nn', 'ann'];['regression', 'train', 'model', 'vgg', 'label', 'predict', 'resnet', 'classification'];https://www.kaggle.com/c/plant-seedlings-classification;0.79;0.552;2020-12-13 15:35:24;multiple data sources;['deep learning, cnn, computer vision'];Seedlings - Pretrained keras models;Python notebook;33298.0;210;;
2018-03-12 10:01:09;OverviewThis is just a simple first attempt at a model using VGG16 as a basis and attempting to do classification directly on the seedling images This can be massively improved with  high-resolution images better data sampling ensuring there is no leaking between training and validation sets, sample(replace = True) is real dangerous pretrained models attention/related techniques to focus on areas;Apache 2.0;https://www.kaggle.com/kmader/pretrained-vgg16-w-attention-for-seedlings;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'nlp', 'nn', 'ann'];['test data', 'train', 'model', 'epoch', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'resnet', 'classification'];https://www.kaggle.com/c/plant-seedlings-classification;0.698;0.311;2020-12-13 15:35:24;multiple data sources;[];Pretrained-VGG16 w/Attention for Seedlings;Python notebook;2902.0;11;0.79534;0.79534
2018-02-13 02:22:27;Plant seedling recognitionClassification process will consist of next steps:  Get data — reading of images and labels Cleaning data — removing of image background, input normalization and label preparatin Model — creating training and validation sets, creating and fitting model Evaluate model — evaluation of model, make prediction;Apache 2.0;https://www.kaggle.com/nikkonst/plant-seedlings-with-cnn-and-image-processing;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cnn', 'gan', 'cv', 'rl', 'nn', 'ml'];['filter', 'test data', 'train', 'fitting', 'model', 'recognition', 'epoch', 'validation data', 'layer', 'loss', 'label', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/plant-seedlings-classification;0.743;0.431;2020-12-13 15:35:24;multiple data sources;['beginner, classification, cnn, +1 morecomputer vision'];Plant Seedlings with CNN and Image Processing;Python notebook;8618.0;42;0.95843;0.95843
2018-05-29 11:50:36;Plant Seedling Classification using Convolutional Neural NetworksThis dataset consists of a training set and a testing set of images of plant seedlings at various growth stages. Each image has its own unique ID. The dataset has 12 main plant species which we need to classify the testing set into.  For this task we will need to process and clean the data using image processing Then we will have to build a model and evaluate it. Let's get started!;Apache 2.0;https://www.kaggle.com/omkarsabnis/seedling-classification-using-cnn-v13-0-95;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'nn', 'ml'];['filter', 'train', 'fitting', 'model', 'neural network', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'classification', 'convolutional neural network'];https://www.kaggle.com/c/plant-seedlings-classification;0.731;0.403;2020-12-13 15:35:24;multiple data sources;['deep learning, cnn, computer vision'];Seedling Classification using CNN(V13 - 0.95);Python notebook;6326.0;30;;
2017-11-22 22:11:51;Nothing interesting (yet). Just reading the files with pillow and extracting the size.;Apache 2.0;https://www.kaggle.com/oysteijo/just-some-simple-train-data-investigation;1.0;['pillow'];['ai', 'rl'];['train'];https://www.kaggle.com/c/plant-seedlings-classification;0.68;0.327;2020-12-13 15:35:24;Plant Seedlings Classification;[];Just some simple train data investigation;Python notebook;1984.0;13;;
2020-02-16 03:51:02;Introduction This is a very basic implementation of convolutional neural network (CNN) without using pretrained models. Fully implemented using keras. You can learn following things by reading this.  Keras implementation of a CNN. StratidiedKFold evaluation. Utility funcitons required when working with images.  Comment your improvements and be sure the upvote.;Apache 2.0;https://www.kaggle.com/praanj/basic-keras-cnn-with-startified-kfold-evaluation;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'nn'];['train', 'model', 'neural network', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'understanding', 'classification', 'convolutional neural network'];https://www.kaggle.com/c/plant-seedlings-classification;0.61;0.352;2020-12-13 15:35:24;Plant Seedlings Classification;[];Basic keras CNN with Startified KFold evaluation;Python notebook;528.0;17;0.77959;0.77959
2020-02-17 15:56:48;Introduction This is a very basic implementation of convolutional neural network (CNN) using pretrained models VGG-19 and ResNet-50. Fully implemented using keras. You can learn following things by reading this.  Keras implementation of a CNN using VGG-19. Keras implementation of a CNN using ResNet-50. Train only the fully connected layers after above 2 models. Train last few layers of the above 2 models along with fully connected layers. StratidiedKFold evaluation. Utility funcitons required when working with images.  Comment your improvements and be sure the upvote.;Apache 2.0;https://www.kaggle.com/praanj/transfer-learning-vgg-19-resnet-50-with-kfold;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'nn'];['train', 'model', 'neural network', 'epoch', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'understanding', 'resnet', 'classification', 'convolutional neural network'];https://www.kaggle.com/c/plant-seedlings-classification;0.667;0.319;2020-12-13 15:35:24;Plant Seedlings Classification;['gpu'];Transfer learning (VGG-19, ResNet-50) with KFold;Python notebook;1536.0;12;0.63224;0.63224
2018-02-16 23:52:28;Author: Raoul Malm Abstract: Given are 4750 labeled images (1.73GB) showing plants of 12 different types, the goal is to classify correctly the species shown on the 794 images (91MB) of the test set. All images are quadratic but vary in size. We resize them such that each image has the shape (299,299,3). Next, we detect and segment the plant parts of the images, then normalize them such that each pixel is defined on the range [-1,1]. An optional step is to generate new images through rotations, translations and axis flippings, augmenting the original data. All images are then fed into a pretrained Xception model provided by keras and we extract 2048 bottleneck features for each image. Having computed these features once, we train and validate a basic logistic regression, random forest and fully connected neural network model. Finally, we predict the species classes of the test images and write the submission file. Note, that this work demonstrates just a quick and basic implementation and is not fine-tuned. Results:  Using a subset of 200 samples of each species for training and validation with a 90%/10% split, we can achieve an accuracy of 88.33% on the validation set. This takes roughly 30 minutes within the kaggle environment. Using all labeled data for training and making use of little data augmentation, we can obtain an accuracy of 90.06% on the test set. This takes several hours on my average laptop CPU. If you have more computer power you can easily improve these results.  Outline:  Libraries and settings Analyze data Manipulate data Extract bottleneck features from Xception Train and validate models Predict species and submit test results  References: Seedlings - Pretrained keras models by beluga Plant Seedlings Fun with Computer Vision by Gábor Vecsei;Apache 2.0;https://www.kaggle.com/raoulma/plants-xception-90-06-test-accuracy;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['vgg', 'logistic regression', 'predict', 'relu', 'training data', 'neuron', 'train', 'epoch', 'classification', 'labeled', 'model', 'neural network', 'layer', 'loss', 'resnet', 'test data', 'regression', 'validation data', 'label', 'computer vision', 'random forest'];https://www.kaggle.com/c/plant-seedlings-classification;0.738;0.4;2020-12-13 15:35:24;multiple data sources;['classification, computer vision'];Plants Xception 90.06% Test Accuracy;Python notebook;7545.0;29;;
2017-12-08 12:08:44;Pytorch SimpleNet + DataLoader,Kaggle Plant Seedlings Classification LB 0.945 Custom PyTorch image data loader You must run this on a GPU Work in progress|  Todo: Inference (done) Submission (done)  https://github.com/QuantScientist/Deep-Learning-Boot-Camp/tree/master/Kaggle-PyTorch Shlomo Kashani.;Apache 2.0;https://www.kaggle.com/solomonk/pytorch-simplenet-augmentation-cnn-lb-0-945;1.0;['pytorch', 'sklearn', 'pillow'];['ai', 'dl', 'cnn', 'cv', 'rl', 'nn', 'ml'];['filter', 'train', 'model', 'epoch', 'loss', 'label', 'alexnet', 'predict', 'relu', 'resnet', 'classification'];https://www.kaggle.com/c/plant-seedlings-classification;0.74;0.334;2020-12-13 15:35:24;Plant Seedlings Classification;['beginner, deep learning, cnn, +1 moreneural networks'];PyTorch SimpleNet + Augmentation CNN : LB 0.945;Python notebook;7874.0;14;;
2017-11-30 02:54:45;Pytorch Starter Pre-Trained Resnet50This kernel mostly implements the Pytorch Transfer Learning tutorial with a custom dataset class and the resnet50 pretrained model from torchvision.;Apache 2.0;https://www.kaggle.com/tylercosner/pytorch-starter-pre-trained-resnet50-torchvision;1.0;['pytorch'];['dl', 'ai', 'nn', 'rl'];['training data', 'train', 'model', 'epoch', 'validation data', 'layer', 'loss', 'label', 'predict', 'recommend', 'resnet', 'classification'];https://www.kaggle.com/c/plant-seedlings-classification;0.742;0.334;2020-12-13 15:35:24;multiple data sources;[];Pytorch Starter Pre-Trained Resnet50 (TorchVision);Python notebook;8350.0;14;;
2018-10-20 16:49:30;Danilo da Silva Authored: 2018-10-06 Contents 1. Setup 1.1 Load packages 1.2 Load files   2. Exploratory Data Analysis 2.1 Training set metadata 2.1.1 Duplicate records 2.1.2 NA records 2.1.3 Target 2.1.4 Galactic Coordinates 2.1.5 Sky Coordinates 2.1.6 DDF 2.1.7 Redshift 2.1.8 Distmod 2.1.9 MWEBV 2.1.10 Milky Way - Feature engineering   2.2 Training set 2.2.1 Passband 2.2.2 flux err 2.2.3 detected   2.3 Correlation plot  2.4 Density plot      Setup Load packages;Apache 2.0;https://www.kaggle.com/danilodiogo/the-astronomical-complete-eda-plasticc-dataset;1.0;['pattern'];['ner', 'ai', 'dl'];['train', 'label', 'filter'];https://www.kaggle.com/c/PLAsTiCC-2018;0.723;0.499;2020-12-13 15:38:22;PLAsTiCC Astronomical Classification;[];The Astronomical (complete) EDA - PLAsTiCC dataset;R notebook;5208.0;99;;
2018-10-08 18:05:56;This notebook is a very quick overview of the dataset for the PLAsTiCC Astronomical Classification competition, and intends to be a first exploration notebook to get used to the dataset. Table of contents  Data overview and target identification DDF areas Distmod and redshift Galactical versus Extragalactical sources Passband Flux time plots;Apache 2.0;https://www.kaggle.com/hrmello/dataset-overview-exploration-and-comments;1.0;['pattern'];['ner', 'ai', 'dl', 'gan', 'rl', 'nn'];['filter', 'training data', 'test data', 'train', 'model', 'epoch', 'label', 'understanding', 'classification'];https://www.kaggle.com/c/PLAsTiCC-2018;0.716;0.471;2020-12-13 15:38:22;PLAsTiCC Astronomical Classification;[];Dataset overview - Exploration and comments;Python notebook;4417.0;69;;
2018-11-13 20:32:05;IntroThis is my first kaggle competition and I have really enjoyed it so far. The following kernel has been inspired by:  https://www.kaggle.com/ogrellier/plasticc-in-a-kernel-meta-and-data https://www.kaggle.com/c/PLAsTiCC-2018/discussion/70908 https://www.kaggle.com/meaninglesslives/simple-neural-net-for-time-series-classification  Still haven't figured out the feature hidden in here https://www.kaggle.com/c/PLAsTiCC-2018/discussion/70725#416740 A big thanks to the kaggle community that makes this competition so enjoyable.;Apache 2.0;https://www.kaggle.com/iprapas/ideas-from-kernels-and-discussion-lb-1-135;1.0;['statsmodels', 'catboost', 'lightgbm', 'sklearn'];['ner', 'ai', 'gbm', 'rl', 'ml'];['filter', 'train', 'model', 'loss', 'label', 'predict', 'classification'];https://www.kaggle.com/c/PLAsTiCC-2018;0.733;0.501;2020-12-13 15:38:22;PLAsTiCC Astronomical Classification;['classification, feature engineering, astronomy'];Ideas from kernels and discussion (LB ~ 1.2);Python notebook;6682.0;102;1.16158;1.13599
2018-12-07 15:50:12;Kernels and discussions used in this kernel Olivier's kernel Alexander Firsov's kernel Iprapas' kernel Chia-Ta Tsai's kernel Lving's kernel My something different kernel My Smote the training set kernel;Apache 2.0;https://www.kaggle.com/jimpsull/collaboratingwithkagglecommunity-1-037-lb;1.0;['tensorflow', 'xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'gbm', 'cv', 'rl', 'nn', 'ml'];['filter', 'training data', 'test data', 'train', 'model', 'loss', 'label', 'predict', 'classification'];https://www.kaggle.com/c/PLAsTiCC-2018;0.708;0.472;2020-12-13 15:38:22;multiple data sources;[];CollaboratingWithKaggleCommunity (1.037 LB);Python notebook;3659.0;70;;
2018-10-02 17:08:44;Inspired by the great naitive benchmark kernel We separate the train/test metadata to galactic&extragalactic parts And train two lgb classifiers;Apache 2.0;https://www.kaggle.com/johnfarrell/plasticc-2018-metadata-simple-eda;1.0;['lightgbm', 'sklearn'];['cv', 'ai', 'rl', 'gbm'];['filter', 'train', 'model', 'loss', 'label', 'predict'];https://www.kaggle.com/c/PLAsTiCC-2018;0.689;0.413;2020-12-13 15:38:22;PLAsTiCC Astronomical Classification;[];plasticc-2018-metadata-simple-eda;Python notebook;2425.0;34;2.34127;2.36712
2018-10-23 18:52:08;This kernel is inspired by olivier's excellent kernel. In this kernel, i use skopt to find the best values for three important hyper-parameters for LGB. The score improves from 1.753 to 1.744 after parameter tuning.   Parameter Before Tuning After Tuning            Learning Rate 0.030 0.051   n_estimators 1000 1308   max_depth 3 6;Apache 2.0;https://www.kaggle.com/meaninglesslives/lgb-parameter-tuning;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'gbm', 'rl', 'nn'];['train', 'loss', 'model', 'predict'];https://www.kaggle.com/c/PLAsTiCC-2018;0.727;0.444;2020-12-13 15:38:22;PLAsTiCC Astronomical Classification;[];LGB Parameter Tuning;Python notebook;5727.0;49;1.72082;1.68659
2018-09-27 20:34:37;"Table of Contents 1  The PLAsTiCC Astronomy ""Starter Kit"" Classification Demo1.0.1  -Gautham Narayan, Renée Hložek, Emilie Ishida 201808312  Resources2.0.0.1  Useful Packages for Astrophysics - particularly feature extraction2.0.0.2  External Data Sources";Apache 2.0;https://www.kaggle.com/michaelapers/the-plasticc-astronomy-classification-demo;1.0;['sklearn'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['filter', 'recurrent neural network', 'test data', 'random forest', 'train', 'fitting', 'model', 'neural network', 'label', 'predict', 'decision tree', 'classification', 'naive bayes'];https://www.kaggle.com/c/PLAsTiCC-2018;0.74;0.502;2020-12-13 15:38:22;multiple data sources;[];plasticc_classification_demo;Python notebook;7956.0;104;;
2018-09-27 21:27:31;"The PLAsTiCC Astronomy ""Starter Kit""-Gautham Narayan, 20180831This kernel was developed for PLAsTiCC on Kaggle. The original version of this kernel is available as a Jupyter Notebook on LSST DESC GitHub.";Apache 2.0;https://www.kaggle.com/michaelapers/the-plasticc-astronomy-starter-kit;1.0;['pattern'];['ner', 'ai', 'nlu', 'dl', 'gan', 'rl', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'training data', 'test data', 'train', 'recognition', 'model', 'epoch', 'layer', 'clustering', 'label', 'predict', 'understanding', 'classification', 'labeled'];https://www.kaggle.com/c/PLAsTiCC-2018;0.786;0.575;2020-12-13 15:38:22;multiple data sources;['beginner'];plasticc_astro_starter_kit;Python notebook;29420.0;298;;
2018-11-19 02:41:27;Let us see if we can improve the basic model in several public kernels by replacing the training objective with the actual objective! Updates:  removed some nonsense features (like mjd_max) changed mjd_diff to det_mjd_diff (detected observations window length) used tensorflow eager mode as an alternative to PyTorch. Hessian is also working now. Note that Hessian is only used as weights in LightGBM/XGBoost, so its scale does not matter. However, the hyperparamter 'min_child_weight'/'min_sum_hessian_in_leaf' can mess with the Hessian scale. It is easier to simply set it to 0. Using Hessian does not seem to impact prediction quality much. learning rate scale is in line with what you can expect from vanilla LightGBM now. There does not seem to be any difference between using clipping or simple log softmax in the objective.;Apache 2.0;https://www.kaggle.com/mithrillion/know-your-objective;1.0;['xgboost', 'lightgbm', 'sklearn', 'pytorch', 'tensorflow'];['ai', 'rl', 'nn', 'gbm'];['filter', 'train', 'model', 'loss', 'label', 'predict'];https://www.kaggle.com/c/PLAsTiCC-2018;0.716;0.464;2020-12-13 15:38:22;PLAsTiCC Astronomical Classification;[];Know Your Objective;Python notebook;4446.0;63;;
2018-11-03 05:54:20;Strategies for Flux Time Series PreprocessingFrom simple to advanced methods;Apache 2.0;https://www.kaggle.com/mithrillion/strategies-for-flux-time-series-preprocessing;1.0;['pattern'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['filter', 'train', 'model', 'lstm', 'label', 'loss'];https://www.kaggle.com/c/PLAsTiCC-2018;0.723;0.492;2020-12-13 15:38:22;PLAsTiCC Astronomical Classification;['feature engineering'];Strategies for Flux Time Series Preprocessing;Python notebook;5197.0;90;;
2017-12-13 18:01:55;IntroductionThis competition is hosted by the third largest insurance company in Brazil: Porto Seguro with the task of predicting the probability that a driver will initiate an insurance claim in the next year. This notebook will aim to provide some interactive charts and analysis of the competition data by way of the Python visualisation library Plot.ly and hopefully bring some insights and beautiful plots that others can take and replicate. Plot.ly is one of the main products offered by the software company - Plotly which specializes in providing online graphical and statistical visualisations (charts and dashboards) as well as providing an API to a whole rich suite of programming languages and tools such as Python, R, Matlab, Node.js etc. Listed below for easy convenience are links to the various Plotly plots in this notebook:  Simple horizontal bar plot - Used to inspect the Target variable distribution Correlation Heatmap plot  - Inspect the correlation between the different features Scatter plot - Compare the feature importances generated by Random Forest and Gradient-Boosted model Vertical bar plot - List in Descending order, the importance of the various features 3D Scatter plot   The themes in this notebook can be briefly summarized follows: 1. Data Quality Checks - Visualising and evaluating all missing/Null values (values that are -1) 2. Feature inspection and filtering - Correlation and feature Mutual information plots against the target variable. Inspection of the Binary, categorical and other variables. 3. Feature importance ranking via learning models  /n Building a Random Forest and Gradient Boosted model to help us rank features based off the learning process. Let's Go;Apache 2.0;https://www.kaggle.com/arthurtok/interactive-porto-insights-a-plot-ly-tutorial;1.0;['sklearn'];['ner', 'ai', 'rl', 'nn', 'ann'];['filter', 'training data', 'regression', 'random forest', 'train', 'model', 'supervised learning', 'loss', 'label', 'k-nearest neighbor', 'gradient boosting', 'predict', 'rank', 'decision tree', 'classification'];https://www.kaggle.com/c/porto-seguro-safe-driver-prediction;0.799;0.607;2020-12-13 15:44:39;Porto Seguro’s Safe Driver Prediction;[];Interactive Porto Insights - A Plot.ly Tutorial;Python notebook;43846.0;505;;
2017-12-08 05:09:38;"IntroductionThe fact that the Porto Seguro competition is a binary classification task (the customer filed a claim or did not) makes it an excellent opportunity to brush up on two fundamental modelling and evaluation tasks for binary classifiers:  Logistic Regression The ROC curve  Logistic regression is a derivative of linear regression where we are interested in making binary predictions or probability predictions on the interval [0, 1] with a threshold probability to determine where we split between 0 and 1.  The ROC curve or ""receiver operating characteristic"" curve is an evaluation method we can use to assess the efficacy of a binary classification algorithm (""Receiver Operating Characteristic"", n.d.) as well as choose the optimal threshold based on our tolerance for false negatives and desire for true positives.";Apache 2.0;https://www.kaggle.com/captcalculator/logistic-regression-and-roc-curve-primer;1.0;['xgboost'];['ner', 'ai', 'dl', 'rl', 'nn', 'ml'];['linear regression', 'training data', 'test data', 'regression', 'train', 'fitting', 'model', 'neural network', 'label', 'logistic regression', 'predict', 'rank', 'understanding', 'classification', 'labeled'];https://www.kaggle.com/c/porto-seguro-safe-driver-prediction;0.787;0.509;2020-12-13 15:44:39;Porto Seguro’s Safe Driver Prediction;['beginner, classification, logistic regression'];Logistic Regression and ROC Curve Primer;R notebook;30294.0;114;;
2017-11-11 16:46:50;Target encoding with smoothingmin_samples_leaf define a threshold where prior and target mean (for a given category value) have the same weight. Below the threshold prior becomes more important and above mean becomes more important. How weight behaves against value counts is controlled by smoothing parameter;Apache 2.0;https://www.kaggle.com/ogrellier/python-target-encoding-for-categorical-features;1.0;['sklearn'];['ai', 'nn'];['train', 'model', 'label'];https://www.kaggle.com/c/porto-seguro-safe-driver-prediction;0.811;0.567;2020-12-13 15:44:39;Porto Seguro’s Safe Driver Prediction;[];Python target encoding for categorical features;Python notebook;65544.0;263;;
2017-10-17 22:04:18;Reconstruction of 'ps_reg_03'Considering, that ps_reg_03 appears to be one of the most (if not the most) predictive feature in the data set, determining how it is constructed could be an important step in building very predictive new features and improving models. The closed form guesser of Wolfram|Alpha, applied to some high precision values of ps_reg_03 reveals the following pattern: ps_reg_03=√I40, with I∈N+. In other words: I=(40∗ps_reg_03)2 yields an integer. ps_reg_03 is therefore likely a categorical feature or a combination of combinatorical features. Lets confirm this pattern for the full data set:;Apache 2.0;https://www.kaggle.com/pnagel/reconstruction-of-ps-reg-03;1.0;['pattern'];['ai', 'ml'];['training data', 'train', 'model', 'label', 'predict', 'labeled'];https://www.kaggle.com/c/porto-seguro-safe-driver-prediction;0.721;0.512;2020-12-13 15:44:39;Porto Seguro’s Safe Driver Prediction;[];Reconstruction of 'ps_reg_03';Python notebook;4937.0;118;;
2017-11-15 19:42:16;Index Imbalanced datasets The metric trap Confusion matrix Resampling Random under-sampling Random over-sampling Python imbalanced-learn module Random under-sampling and over-sampling with imbalanced-learn Under-sampling: Tomek links Under-sampling: Cluster Centroids Over-sampling: SMOTE Over-sampling followed by under-sampling Recommended reading;Apache 2.0;https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets;1.0;['xgboost', 'sklearn'];['ner', 'ai', 'dl', 'ml'];['train', 'artificial intelligence', 'model', 'fitting', 'clustering', 'loss', 'label', 'k-nearest neighbor', 'predict', 'recommend', 'classification'];https://www.kaggle.com/c/porto-seguro-safe-driver-prediction;0.847;0.625;2020-12-13 15:44:39;Porto Seguro’s Safe Driver Prediction;['beginner, feature engineering, binary classification'];Resampling strategies for imbalanced datasets;Python notebook;278198.0;691;;
2017-10-19 19:51:44;Simply loading the files without any transformation. If you wish to manipulate the data in any way, it should be done here before doing dimensionality reduction in subsequent steps.;Apache 2.0;https://www.kaggle.com/tilii7/dimensionality-reduction-pca-tsne;1.0;['sklearn'];['dl', 'ai', 'nn', 'rl'];['filter', 'training data', 'test data', 'train', 'neural network', 'epoch', 'layer', 'label', 'hidden layer', 'classification'];https://www.kaggle.com/c/porto-seguro-safe-driver-prediction;0.776;0.525;2020-12-13 15:44:39;Porto Seguro’s Safe Driver Prediction;['dimensionality reduction'];Dimensionality reduction (PCA, tSNE);Python notebook;21578.0;142;;
2017-10-14 00:58:22;Here is an example of XGBoost hyperparameter tuning by doing a grid search. For reasons of expediency, the notebook will run only a randomized grid search. However, I will provide a code for brute-force grid search as well - you only need to uncomment that portion if you decide to run this notebook locally. Although random grid search will work most of the time if you test at least 20-50 different parameter combinations, I STRONGLY recommend that you use something like Bayesian optimization for hyperparameter searching as it is more comprehensive and time-efficient. I will try to publish an example of it later.;Apache 2.0;https://www.kaggle.com/tilii7/hyperparameter-grid-search-with-xgboost;1.0;['xgboost', 'sklearn'];['ai', 'rl', 'cv', 'nn', 'ml'];['filter', 'train', 'fitting', 'model', 'predict', 'rank', 'recommend', 'bayesian'];https://www.kaggle.com/c/porto-seguro-safe-driver-prediction;0.836;0.548;2020-12-13 15:44:39;Porto Seguro’s Safe Driver Prediction;[];Hyperparameter Grid Search with XGBoost;Python notebook;169469.0;198;0.28402;0.27821
2020-11-17 11:30:01;Group the Choice and A_follower_count, then get the max, min, and mean of A_posts;Apache 2.0;https://www.kaggle.com/khotijahs1/influencers-in-social-networks;1.0;['sklearn'];['ai', 'nn', 'cv'];['test data', 'train', 'model', 'predict', 'classification'];https://www.kaggle.com/c/predict-who-is-more-influential-in-a-social-network;0.677;0.319;2020-12-13 15:55:08;Influencers in Social Networks;[]; Influencers in Social Networks;Python notebook;1889.0;12;;
2020-04-27 21:07:14;The following single model scores 0.87169 on the private leaderboard, between 12th & 13th (private).;Apache 2.0;https://www.kaggle.com/mohitsital/bayesian-optimized-lgbm;1.0;['lightgbm', 'sklearn'];['cv', 'ai', 'rl', 'gbm'];['filter', 'train', 'model', 'label', 'predict', 'bayesian'];https://www.kaggle.com/c/predict-who-is-more-influential-in-a-social-network;0.549;0.152;2020-12-13 15:55:08;Influencers in Social Networks;[];Bayesian Optimized LGBM ;Python notebook;202.0;2;;
2019-03-21 16:46:39;The following single model scores 0.87169 on the private leaderboard, between 12th & 13th (private).;Apache 2.0;https://www.kaggle.com/sdoliver/bayesian-optimized-lgbm;1.0;['lightgbm', 'sklearn'];['cv', 'ai', 'rl', 'gbm'];['filter', 'train', 'model', 'label', 'predict', 'bayesian'];https://www.kaggle.com/c/predict-who-is-more-influential-in-a-social-network;0.677;0.214;2020-12-13 15:55:08;Influencers in Social Networks;[];Bayesian Optimized LGBM ;Python notebook;1863.0;4;0.87169;0.86666
2016-08-02 09:16:33;Preprocessing/Merging People and ActivitiesThis script converts features in people and activities into integers, then merges everything into a single table. Makes it easy to drop into classifiers in Sklearn or XGBoost. Conveniently, most of the data can be easily encoded to numeric values with simple string splitting. Scored ~0.944 with Random Forest Classifier in Sklearn out of the box.;Apache 2.0;https://www.kaggle.com/jeffd23/single-unified-table-0-94-sklearn;1.0;['xgboost', 'sklearn'];['ai', 'cv'];['training data', 'train', 'model', 'label', 'predict', 'random forest'];https://www.kaggle.com/c/predicting-red-hat-business-value;0.715;0.383;2020-12-13 16:02:15;Predicting Red Hat Business Value;[];Single Unified Table ~0.94 Sklearn;Python notebook;4324.0;24;;
2016-08-25 23:02:32;I want to illustrate my approach to Red Hat Competition. I have organized this notebook in four step:  Preprocessing and data exploration Building models Assessment Scoring  Red Hat give us a lot of crypted information to catch the behavior of their customer. The goal of the challenge is to classify in the better way the customers: every activities of users have an outcome good (=1) or bad (=0). My target is to set up the best model but also find the variables that major influence the outcome of a peolple, so I decice to not use the date/group leak. Some considerations (derived from logit models)  Customer with people_char_2 = type 2 have an attitude 8 times superior to give a good outcome than customer with people_char_2 = type 1 People with people_char_7 = type 1 have an attitude 26 time superior to give a good outcome with people_char_7 = type 15 Customer with people_char_6 = type 5 have an attitude 2.5 times superior to give a good outcome than customer with people_char_6 = type 1 People with week day of date attribute on monday have an attidute 9 superior to give a good outcome than customer registrated on saturday. glm_m <- glm(outcome ~   people_class_38 + people_char_2 + people_char_7 +   people_char_6   + people_day_of_week + people_class_1 +    people_char_5   + people_char_8 + char_1 + char_2 +    char_5 + group_10 + activity_category, data = d1,family = binomial())   The covariates for the model are: people_char_2, people_char_7, people_char_6, people_day_week, people_class_1, people_class_38, people_char_5, people_char_8, char_1, char_2, char_5, group_10, activity_category. For the first, load data in R as data frame and clean the covariates:;Apache 2.0;https://www.kaggle.com/mauropelucchi/explain-red-hat-data-and-xgb-model;1.0;['xgboost', 'h2o'];['ai', 'gan', 'gbm', 'rl', 'nn'];['filter', 'training data', 'regression', 'test data', 'train', 'random forest', 'model', 'neural network', 'epoch', 'deep learning', 'validation data', 'label', 'logistic regression', 'predict', 'decision tree', 'classification'];https://www.kaggle.com/c/predicting-red-hat-business-value;0.689;0.319;2020-12-13 16:02:15;Predicting Red Hat Business Value;[];Explain Red Hat Data and XGB Model;R notebook;2402.0;12;;
2020-06-28 22:28:18;"Algorithm to compute ""optimal"" coordinates for patches/tilesSorry if the code is messy and/or unreadable! But I tried to document/comment here and there to make it a bit clearer. Also, the algorithm is not optimized in terms of run-time (it's rather slow actually), but aims to optimize the coordinates of the patches/tiles. Main sections:  Computing patch coordinates with visualization Computing patches and stitching them together with visualization";Apache 2.0;https://www.kaggle.com/akensert/panda-optimized-tiling-tf-data-dataset;1.0;['tensorflow', 'skimage'];['ai', 'cv'];['train', 'filter'];https://www.kaggle.com/c/prostate-cancer-grade-assessment;0.675;0.467;2020-12-13 16:03:25;Prostate cANcer graDe Assessment (PANDA) Challenge;[];[PANDA] Optimized tiling (+ tf.data.Dataset);Python notebook;1804.0;65;;
2020-05-03 23:41:33;Prostate cANcer graDe Assessment (PANDA) Challenge  Looking into the Effect of     IMAGE ENHANCEMENT;Apache 2.0;https://www.kaggle.com/debanga/let-s-enhance-the-images;1.0;['skimage'];['ai', 'cv', 'ml', 'nn', 'ann'];['train', 'filter'];https://www.kaggle.com/c/prostate-cancer-grade-assessment;0.666;0.465;2020-12-13 16:03:25;Prostate cANcer graDe Assessment (PANDA) Challenge;[];Let's Enhance the Images!;Python notebook;1487.0;64;;
2020-05-23 07:25:10;Prostate cANcer graDe Assessment (PANDA) ChallengeProstate cancer diagnosis using the Gleason grading system;Apache 2.0;https://www.kaggle.com/dhananjay3/panda-eda-all-you-need-to-know;1.0;['skimage'];['ner', 'ai', 'cv', 'nn', 'ann'];['test data', 'training data', 'train', 'label', 'predict'];https://www.kaggle.com/c/prostate-cancer-grade-assessment;0.7;0.48;2020-12-13 16:03:25;Prostate cANcer graDe Assessment (PANDA) Challenge;['data visualization, exploratory data analysis'];PANDA: EDA All you need to know;Python notebook;3084.0;77;;
2020-05-01 16:58:16;IntroductionThis Kernel objective is to explore the dataset for Prostate cANcer graDe Assessment (PANDA) Challenge. Prostate cancer is the second most common cancer among males worldwide that results in more than 350k deaths annually. The key to decreasing mortality is developing more precise screeening procedures and diagnostics. Diagnosis of PCa is based on the grading of prostate tissue biopsies. These tissue samples are examined by a pathologist and scored according to the Gleason grading system. In the next Figure we show the principle of Gleason grading system.  The grading process consists of finding and classifying cancer tissue into so-called Gleason patterns (3, 4, or 5) based on the architectural growth patterns of the tumor (see Figure below). Based on presence of various formations, the Gleason score is given for majority (first digit in the score) and minority Gleason score (the second digit). After the biopsy is assigned a Gleason score (a combination of the two digits), it is converted into an ISUP grade on a 1-5 scale, using the correspondence matrix shown in the next Figure.;Apache 2.0;https://www.kaggle.com/gpreda/panda-challenge-starting-eda;1.0;['pattern'];['ai', 'gan', 'rl', 'ml', 'nn', 'ann'];['train', 'label', 'predict'];https://www.kaggle.com/c/prostate-cancer-grade-assessment;0.712;0.502;2020-12-13 16:03:25;Prostate cANcer graDe Assessment (PANDA) Challenge;['beginner, exploratory data analysis'];PANDA Challenge Starting EDA;Python notebook;4011.0;104;;
2020-06-01 18:21:47;PANDA EfficientNet-B0 Baseline with 36 x tiles_256Hi everyone, I'm here to show you how to train a single efficientnet-b0 model to get LB 0.87 This is inference kernel and the Training kernel is avalilable here: https://www.kaggle.com/haqishen/train-efficientnet-b0-w-36-tiles-256-lb0-87 TTATile extraction start from different point (by adding more white padding);Apache 2.0;https://www.kaggle.com/haqishen/panda-inference-w-36-tiles-256;1.0;['pytorch', 'skimage'];['ai', 'nn', 'ml'];['train', 'model', 'predict'];https://www.kaggle.com/c/prostate-cancer-grade-assessment;0.749;0.516;2020-12-13 16:03:25;multiple data sources;['gpu'];PANDA Inference w/ 36 tiles_256;Python notebook;10098.0;125;0.91539;0.87525
2020-06-05 06:35:57;PANDA EfficientNet-B0 Baseline with 36 x tiles_256Hi everyone, I'm here to show you how to train a single efficientnet-b0 model to get LB 0.87 Inference kernel is https://www.kaggle.com/haqishen/panda-inference-w-36-tiles-256 If you find find any of the following idea helps, please upvote me, THANKS! Summary of This Baseline Using tiling method based on https://www.kaggle.com/iafoss/panda-16x128x128-tiles Simply setting the N = 36 and sz=256 then extract from median resolution   Create 6x6 big image from 36 tiles Efficientnet-B0 Binning label E.g. label = [0,0,0,0,0] means isup_grade = 0 label = [1,1,1,0,0] means isup_grade = 3 label = [1,1,1,1,1] means isup_grade = 5     BCE loss Augmentation on both tile level and big image level CosineAnnealingLR for one round  MEMOThe full training process need over 10h to run so you should run it on your own machine. Update Version 1 Baseline   Version 2, 3 Add some Markdown Text   Version 4 Fix init_lr from 3e-5 to 3e-4   Version 5 Add warmup scheduler Add training log for this version   Version 6 Fix the bug that train from scratch. Now it's train from ImageNet pretrained weights. Actually I haven't tried train from scratch yet.   Version 7, 8 Update accuracy calculate. Fix tiny bug.;Apache 2.0;https://www.kaggle.com/haqishen/train-efficientnet-b0-w-36-tiles-256-lb0-87;1.0;['pytorch', 'albumentations', 'skimage', 'sklearn'];['ai', 'cv', 'ml', 'nn', 'ann'];['train', 'model', 'epoch', 'label', 'loss'];https://www.kaggle.com/c/prostate-cancer-grade-assessment;0.768;0.569;2020-12-13 16:03:25;multiple data sources;['gpu'];Train EfficientNet-B0 w/ 36 tiles_256 [LB0.87];Python notebook;16935.0;271;;
2020-04-28 06:25:46;The code below selects 16 128x128 tiles for each image and mask based on the maximum number of tissue pixels. The kernel also provides computed image stats. Please check my kernels to see how to use this data.;Apache 2.0;https://www.kaggle.com/iafoss/panda-16x128x128-tiles;1.0;['skimage'];['ai', 'cv'];['train', 'label'];https://www.kaggle.com/c/prostate-cancer-grade-assessment;0.756;0.561;2020-12-13 16:03:25;Prostate cANcer graDe Assessment (PANDA) Challenge;['data cleaning, image data'];PANDA 16x128x128 tiles;Python notebook;12050.0;240;;
2020-05-04 06:54:37;DescriptionWelcome to Prostate cANcer graDe Assessment (PANDA) Challenge. The task of this competition is classification of images with cancer tissue. The main challenge of this task is dealing with images of extremely high resolution and large areas of empty space. So, effective locating the areas of concern and zooming them in would be the key to reach high LB score. In this competition I found a number of public kernels performing straightforward rescaling the input images to square. However, for this particular data such an approach is not very efficient because the aspect ratio and size of provided images are not consistent and vary in a wide range. As a result, the input images are deformed to large extend in a not consistent manner uppon rescaling that limits the ability of the model to learn. Moreover, the input consists of large empty areas leading to inefficient use of GPU memory and GPU time. In this kernel I propose an alternative approach based on Concatenate Tile pooling. Instead of passing an entire image as an input, N tiles are selected from each image based on the number of tissue pixels (see this kernel for description of data preparation and the corresponding dataset) and passed independently through the convolutional part. The outputs of the convolutional part is concatenated in a large single map for each image preceding pooling and FC head (see image below). Since any spatial information is eliminated by the pooling layer, the Concat Tile pooling approach is nearly identical to passing an entire image through the convolutional part, excluding predictions for nearly empty regions, which do not contribute to the final prediction, and shuffle the remaining outputs into a square map of smaller size. Below I provide just a basic kernel only illustrating this approach. In my first trial I got 0.76 LB score, top 2 at the moment, and I believe it could be easily boosted to 0.80+. I hope you would enjoy my kernel, and please also check my submission kernel implementing the tile based approach.;Apache 2.0;https://www.kaggle.com/iafoss/panda-concat-tile-pooling-starter-0-79-lb;1.0;['pytorch', 'sklearn'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['filter', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'classification'];https://www.kaggle.com/c/prostate-cancer-grade-assessment;0.771;0.573;2020-12-13 16:03:25;multiple data sources;['gpu, deep learning, classification'];PANDA concat tile pooling starter [0.79 LB];Python notebook;18398.0;289;;
2020-04-28 19:02:26;DescriptionThis kernel performs inference for PANDA concat tile pooling starter kernel with use of multiple models and 8 fold TTA. Check it for more training details. The image preprocessing pipline is provided here.;Apache 2.0;https://www.kaggle.com/iafoss/panda-concat-tile-pooling-starter-inference;1.0;['skimage'];['ai', 'dl', 'rl', 'cv', 'nn'];['filter', 'train', 'model', 'layer', 'predict', 'resnet'];https://www.kaggle.com/c/prostate-cancer-grade-assessment;0.745;0.532;2020-12-13 16:03:25;multiple data sources;['deep learning, classification'];PANDA concat tile pooling starter [inference];Python notebook;9098.0;156;0.79408;0.79309
2020-04-28 13:54:43;Quick OverviewIn this challenge, the objective is to detect and classify the severity of prostate cancer on images of prostate tissue samples. In practice, tissue samples are examined and scored by pathologists according to the so-called Gleason grading system which is later converted to an ISUP grade. But we will get into this in a bit. Let's have a quick look at the data and get an overview.;Apache 2.0;https://www.kaggle.com/iamleonie/panda-eda-visualizations-suspicious-data;1.0;['pattern', 'skimage'];['ner', 'ai', 'cv', 'nn', 'ann'];['filter', 'training data', 'train', 'model', 'label', 'labeled'];https://www.kaggle.com/c/prostate-cancer-grade-assessment;0.683;0.47;2020-12-13 16:03:25;Prostate cANcer graDe Assessment (PANDA) Challenge;['beginner, data visualization, exploratory data analysis'];PANDA: EDA, Visualizations & Suspicious Data;Python notebook;2133.0;68;;
2020-04-24 08:01:10;Table of Contents Intuition of QWK Step 1: Create the NxN histogram matrix O  Step 2: Create the Weighted Matrix w Step 3: Create the Expected Matrix  Step 4: Final Step: Weighted Kappa formula and Its python codes;Apache 2.0;https://www.kaggle.com/reighns/understanding-the-quadratic-weighted-kappa;1.0;['sklearn'];['ner', 'ai', 'ml', 'rl'];['train', 'model', 'label', 'predict', 'understanding', 'classification', 'ground truth'];https://www.kaggle.com/c/prostate-cancer-grade-assessment;0.692;0.486;2020-12-13 16:03:25;Prostate cANcer graDe Assessment (PANDA) Challenge;[];Understanding the Quadratic Weighted Kappa ;Python notebook;2582.0;84;;
2020-05-22 10:36:42;"Better image tiles - Simple heuristic to suppress blank regions As you might know, for this competition, it is critical to come up with an efficient way to pre-process the images. One of the key aspects that I show in my previous notebook https://www.kaggle.com/rftexas/gradcam-comparing-resnet-and-se-resnext is that as expected white regions don't convey any information, hence the need to get rid of them. Actually, one need to zoom enough in the biopsy image to make sure there is as little white as possible. This is why in this notebook, we will code a simple heuristic to generate better images that have no more blank parts. The algorithm is pretty simple actually: having a sliding window moving across the images and calculating for each region the proporition of white color in the image. Then select k regions with the lowest proportion of white. We will define the algorithm as follows:  Define a sliding window of a fixed size Slide the window with a certain stride For each region on which we slide, compute the amount of white pixels Do this for all the regions in the image Select the top k results where k is a hyperparameter   If you like those kinds of tutorials, upvote this notebook! It encourages me to keep writing some ;)  V5: I'll try to tackle pen markers now! Stay tuned! Contents 1. Importing dependencies 2. Compute statistics 3. Select k-best regions 4. Slide over the image 5. Show the results  5.1. Window size: 200, stride: 128 5.2. Window size: 128, stride: 64 5.3. Window size: 512, stride: 256";Apache 2.0;https://www.kaggle.com/rftexas/better-image-tiles-removing-white-spaces;1.0;['skimage'];['ner', 'ai', 'cv', 'rl', 'nn', 'ann'];['train', 'resnet', 'model', 'label'];https://www.kaggle.com/c/prostate-cancer-grade-assessment;0.691;0.476;2020-12-13 16:03:25;Prostate cANcer graDe Assessment (PANDA) Challenge;[];Better image tiles - Removing white spaces;Python notebook;2511.0;73;;
2020-04-27 06:37:58;About this notebookIn this notebook , I will start with complete explanation of everything you need know related to Prostate Cancer and its detection and I will built on that to explain the dataset and perform extensive EDA. This kernel will be a work in Progress,and I will keep on updating it as the competition progresses If you find this kernel useful, Please consider Upvoting it, it motivates me to write more Quality content;Apache 2.0;https://www.kaggle.com/rohitsingh9990/panda-eda-better-visualization-simple-baseline;1.0;['pattern', 'skimage'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['training data', 'train', 'model', 'understanding', 'deep learning', 'label', 'loss', 'recommend'];https://www.kaggle.com/c/prostate-cancer-grade-assessment;0.767;0.593;2020-12-13 16:03:25;Prostate cANcer graDe Assessment (PANDA) Challenge;['data visualization, exploratory data analysis'];PANDA - EDA + Better Visualization+Simple Baseline;Python notebook;16517.0;398;;
2020-06-24 20:17:12;About this Notebook This kernel is for kagglers like me who believe in trying a lot of things and don't fear of failing as failing is the part of learning.  Starting today, i am going to log my progress in this kernel, this kernel will be work in progress and will contain hint about a lot of things which i tried or will try in upcoming days.  This is an inference kernel where CV and LB score of various models and various image related tricks will be tracked, so that it will be easier to keep track of things which worked and which didn't work for this competition. By default i will not share any training code and keep models private, if you want the training kernel or models to be public feel free to mention in the comments section.   Please upvote this kernel if you like it . It motivates me to produce more quality content :);Apache 2.0;https://www.kaggle.com/rohitsingh9990/panda-inference-ensemble-trying-various-models;1.0;['pytorch', 'albumentations', 'skimage', 'sklearn'];['ner', 'ai', 'nn', 'cv'];['train', 'model', 'test data', 'predict'];https://www.kaggle.com/c/prostate-cancer-grade-assessment;0.731;0.472;2020-12-13 16:03:25;multiple data sources;['gpu'];PANDA - Inference (ENSEMBLE) trying various models;Python notebook;6269.0;70;0.85194;0.83392
2020-04-27 13:59:01;About this NotebookI have always seen that Kaggle competitions require a lot of domain knowledge and the main problems of a Kaggle beginner is not lack of Machine learning Knowledge but more often than not it is lack of domain knowledge.There are always a lot of great kernels regarding different ways of solving the problems but only a few handful address the problems of domain knowledge and getting started. In this notebook , I will start with complete explanation of everything you need know related to Prostate Cancer and its detection and I will built on that to explain the dataset,perform EDA and then Build a baseline model This kernel will be a work in Progress,and I will keep on updating it as the competition progresses and I learn more and more things about the data If you find this kernel useful, Please consider Upvoting it , it motivates me to write more Quality content;Apache 2.0;https://www.kaggle.com/tanulsingh077/prostate-cancer-in-depth-understanding-eda-model;1.0;['pattern'];['ner', 'ai', 'dl', 'gan', 'rl', 'nn', 'ann'];['machine learning', 'train', 'model', 'understanding', 'deep learning', 'layer', 'loss', 'label', 'predict', 'computer vision', 'recommend'];https://www.kaggle.com/c/prostate-cancer-grade-assessment;0.749;0.583;2020-12-13 16:03:25;Prostate cANcer graDe Assessment (PANDA) Challenge;['data visualization, exploratory data analysis, computer vision'];Prostate Cancer: In Depth Understanding,EDA ,Model;Python notebook;10088.0;342;;
2020-04-24 09:00:27;Getting started with the PANDA datasetThis notebook shows a few methods to load and display images from the PANDA challenge dataset. The dataset consists of around 11.000 whole-slide images (WSI) of prostate biopsies from Radboud University Medical Center and the Karolinska Institute.;Apache 2.0;https://www.kaggle.com/wouterbulten/getting-started-with-the-panda-dataset;1.0;['pattern', 'skimage'];['ner', 'ai', 'rl', 'nn', 'ann'];['train', 'label', 'deep learning', 'layer'];https://www.kaggle.com/c/prostate-cancer-grade-assessment;0.748;0.554;2020-12-13 16:03:25;Prostate cANcer graDe Assessment (PANDA) Challenge;['data visualization'];Getting started with the PANDA dataset;Python notebook;9708.0;218;;
2018-07-14 14:40:14;Import Necessary Libraries & Import .csv files into pandas DataFrames;Apache 2.0;https://www.kaggle.com/ashwiniprakash/life-insurance-assesment;1.0;['sklearn'];['dl', 'ai', 'nn', 'cv'];['machine learning', 'train', 'fitting', 'model', 'label', 'predict', 'decision tree', 'random forest'];https://www.kaggle.com/c/prudential-life-insurance-assessment;0.701;0.281;2020-12-13 16:12:52;Prudential Life Insurance Assessment;['multiclass classification'];Life Insurance Assesment;Python notebook;3105.0;8;;
2019-07-30 23:23:37;Problem StatementIn a one-click shopping world with on-demand everything, the life insurance application process is antiquated. Customers provide extensive information to identify risk classification and eligibility, including scheduling medical exams, a process that takes an average of 30 days. The result? People are turned off. That’s why only 40% of U.S. households own individual life insurance. Prudential wants to make it quicker and less labor intensive for new and existing customers to get a quote while maintaining privacy boundaries. By developing a predictive model that accurately classifies rirted tosk using a more automated approach, you can greatly impact public perception of the industry. The results will help Prudential better understand the predictive power of the data points in the existing assessment, enabling us to significantly streamline the process. For learning purpose , multiclasss classification has been converted to a two class classification problem;Apache 2.0;https://www.kaggle.com/gauravkkaushik/prudential-random-forest-and-xgb-classifier;1.0;['tensorflow', 'xgboost', 'sklearn'];['ner', 'ai', 'cv', 'rl', 'ml', 'nn', 'ann'];['training data', 'test data', 'regression', 'random forest', 'train', 'fitting', 'model', 'label', 'predict', 'decision tree', 'classification'];https://www.kaggle.com/c/prudential-life-insurance-assessment;0.655;0.253;2020-12-13 16:12:52;Prudential Life Insurance Assessment;[];Prudential_Only Random_Forest;Python notebook;1196.0;6;;
2018-10-11 06:26:43;General informationThis kernel will be dedicated to EDA and other things. Work is in progress.;Apache 2.0;https://www.kaggle.com/artgor/basic-eda;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'gbm', 'cv', 'rl', 'nn'];['regression', 'train', 'model', 'layer', 'predict'];https://www.kaggle.com/c/pubg-finish-placement-prediction;0.677;0.383;2020-12-13 16:17:21;PUBG Finish Placement Prediction (Kernels Only);['data visualization, exploratory data analysis, feature engineering, +1 moreregression'];Basic EDA;Python notebook;1863.0;24;;
2019-01-08 11:09:12;PUBG Data Exploration + Random Forest (+ Funny GIFs);Apache 2.0;https://www.kaggle.com/carlolepelaars/pubg-data-exploration-rf-funny-gifs;1.0;['sklearn'];['ner', 'ai', 'dl', 'rl', 'nn'];['filter', 'machine learning', 'training data', 'test data', 'train', 'model', 'validation data', 'layer', 'label', 'predict', 'rank', 'random forest'];https://www.kaggle.com/c/pubg-finish-placement-prediction;0.785;0.564;2020-12-13 16:17:21;PUBG Finish Placement Prediction (Kernels Only);['exploratory data analysis, feature engineering, data cleaning, +2 moreensembling, outlier analysis'];PUBG Data Exploration + RF (+ Funny GIFs);Python notebook;27797.0;254;;
2019-01-03 00:27:58;Background  As you know that, The size of the data is large and it takes a long time and memory error occurs.  So I share a study of how to save time and how to reduce memory.  This is my first field of study. So if there is a mistake or something to add, please add it as a comment.;Apache 2.0;https://www.kaggle.com/chocozzz/how-to-save-time-and-memory-with-big-datasets;1.0;['lightgbm', 'sklearn'];['ai', 'nn', 'gbm'];['train', 'model', 'filter', 'predict'];https://www.kaggle.com/c/pubg-finish-placement-prediction;0.73;0.49;2020-12-13 16:17:21;PUBG Finish Placement Prediction (Kernels Only);[];How to save time and memory with BIG Datasets;Python notebook;6219.0;88;;
2018-11-01 01:34:15;[Hyun woo kim]  - 2018-10-19 I changed the kernel to match the changed dataset. The changes are summarized in the kernel below. https://www.kaggle.com/chocozzz/updated-what-is-difference-before-data;Apache 2.0;https://www.kaggle.com/chocozzz/pubg-data-description-a-to-z-fe-with-python;1.0;['lightgbm', 'sklearn'];['ai', 'dl', 'gbm', 'rl', 'nn', 'ann'];['filter', 'regression', 'train', 'model', 'layer', 'label', 'predict', 'rank'];https://www.kaggle.com/c/pubg-finish-placement-prediction;0.77;0.514;2020-12-13 16:17:21;PUBG Finish Placement Prediction (Kernels Only);['beginner, data visualization, exploratory data analysis'];PUBG Data Description A to Z + FE with Python;Python notebook;18192.0;121;;
2020-02-28 08:07:13;"PUBG - EDA, XGBoost Author: Robert Kwiatkowski   PUBG (Player Unknown's Battlegrounds) is a hugely successful and popular online shooter game. It's of so-called ""battle royale"" type - the game ends when the last team stays alive on a map.  The difference to the normal deathmatch is that after you are killed in battle royale game you're not re-spawned anymore (perma-death). Here is the official game site. At the moment this competition was launched there were only two maps: ""Erangel"" and ""Miramar"". Currently, there is ""Vikendi"" as well but it is not included in our dataset. There were few datasets regarding this game on Kaggle before. If you want for example to see my non-parametric Survival Analysis (Kaplan-Meier method) click here. This kernel is mostly EDA oriented but we will look for some anomalies as well ( possibly cheaters). CONTENT: Database description Exploratory Data Analysis 2.1 Match types 2.2 Kills and damage dealt 2.3 Maximum distances 2.4 Driving vs. Walking 2.5 Weapons acquired 2.6 Correlation map Analysis of TOP 10% of players Baseline XGBoost and features importance   1. Database description ^ OK, let's see what's inside. I will load some basic libraries first.";Apache 2.0;https://www.kaggle.com/datark1/pubg-detailed-eda-top-10-players-and-xgb-model;1.0;['xgboost', 'sklearn'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['filter', 'training data', 'train', 'model', 'layer', 'label', 'predict', 'rank', 'understanding'];https://www.kaggle.com/c/pubg-finish-placement-prediction;0.745;0.462;2020-12-13 16:17:21;PUBG Finish Placement Prediction (Kernels Only);['data visualization, exploratory data analysis, video games'];PUBG - Detailed EDA, TOP 10% players and XGB model;Python notebook;8968.0;61;;
2018-10-18 15:53:00;ML Workflow - Data Science Approach;Apache 2.0;https://www.kaggle.com/mm5631/ml-workflow-data-science-approach;1.0;['xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'gbm', 'rl', 'nn', 'ml'];['unsupervised learning', 'filter', 'machine learning', 'regression', 'train', 'fitting', 'model', 'supervised learning', 'layer', 'loss', 'label', 'predict', 'rank', 'classification'];https://www.kaggle.com/c/pubg-finish-placement-prediction;0.709;0.416;2020-12-13 16:17:21;PUBG Finish Placement Prediction (Kernels Only);['data visualization, feature engineering, gradient boosting'];ML Workflow - Data Science Approach;Python notebook;3787.0;35;;
2018-10-09 20:13:10;Cheaters???My friend who plays PUBG said that there are cheaters in this game. If it's true, we should probably remove such players from the training dataset not to get the model confused. I learned that there are some types of cheats.   PlayerUnknown's Battlegrounds cheats explained | GamesRadar+ Aim HacksThey will take control of a players aim and automatically target it towards opponents.  Speed HacksThey usually give the player a massive speed increase, meaning they can go from one side of the map to the other in seconds.  Recoil Hacksautomatically manage the recoil. This means all they have to do is press the fire button and don’t have to adjust their mouse to account for the recoil, as the script will do it all for them and every shot will go exactly where they want it to.  Wall HacksWall hacks basically allow cheaters to see other players through walls, or add extra UI elements to reveal a players location.  How cheaters look likeNow I have some ideas about cheaters.  Acquiring 100 weapons without moving Killing 100 players without moving 100/100 kills are headshots Reviving 100 times ...  Let's take a look at the actual data.;Apache 2.0;https://www.kaggle.com/rejasupotaro/cheaters-and-zombies;1.0;['sklearn'];['ai'];['filter', 'training data', 'test data', 'train', 'model', 'layer', 'clustering', 'predict'];https://www.kaggle.com/c/pubg-finish-placement-prediction;0.743;0.51;2020-12-13 16:17:21;PUBG Finish Placement Prediction (Kernels Only);['exploratory data analysis'];Cheaters??? and Zombies!!!;Python notebook;8602.0;115;;
2018-10-19 08:36:22;Effective feature engineeringSay, you have a model which takes 1 hour to train. Do you always need to wait for 1 hour to see the impact of a newly added feature? I talked with experienced Kaggers about feature engineering. They said that you get more accurate result when you check on the actual complex model you carefully built. But, it can be another risk if longer training time reduces the number of your trials. Traid-off: Accurate result <=> The number of trials How they work on a competition is like below.  EDA Build a simple model Try various features on a simple model Build a complex model Train with promising features  They go back and forth between steps during a competition. If you successfully setup an effective environment for experiments at the beginning of the competition, it puts you at an advantage. I created a Kernel dedicated for feature engineering for this competition. I'd like to share what I've done so far.  Correlation Score gain on a simple model Feature importances of Tree models Permutation importance SHAP values Score gain on a complex model  The upper things are faster but less accurate and lower things are more accurate but slower. I'm trying from the top of the list when I come up with a new idea. 1. CorrelationThis is the simplest way to see the relation between features. In here, if the value on the target is close to 0, it means that the feature may be irrelevant to the target.;Apache 2.0;https://www.kaggle.com/rejasupotaro/effective-feature-engineering;1.0;['xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'gbm', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'regression', 'train', 'model', 'understanding', 'deep learning', 'layer', 'loss', 'label', 'predict', 'rank', 'recommend'];https://www.kaggle.com/c/pubg-finish-placement-prediction;0.778;0.566;2020-12-13 16:17:21;PUBG Finish Placement Prediction (Kernels Only);['feature engineering'];Effective Feature Engineering;Python notebook;23023.0;259;;
2018-10-31 02:55:00;What is in this kernel ?;Apache 2.0;https://www.kaggle.com/shahules/feature-engineering-and-model-stacking;1.0;['xgboost', 'sklearn'];['ai', 'rl', 'cv', 'nn', 'ann'];['filter', 'training data', 'regression', 'train', 'model', 'layer', 'loss', 'label', 'predict', 'rank'];https://www.kaggle.com/c/pubg-finish-placement-prediction;0.697;0.403;2020-12-13 16:17:21;PUBG Finish Placement Prediction (Kernels Only);['beginner, data visualization, exploratory data analysis, +1 morexgboost'];feature engineering and model Stacking;Python notebook;2839.0;30;0.04977;0.04977
2018-10-20 18:50:14;Keras Simple CNN BenchmarkI assume you are already familiar with the competition dataset. This benchmark helps you to reach 0.77 MAP@3. This kernel has three main components:  Simple configurable Convolutional Network Fast and memory efficient Image Generator Full training & submission with Kaggle Kernel  I did some paramer search but it should not be hard to improve the current score. Simplified versions could be trained without GPU.;Apache 2.0;https://www.kaggle.com/gaborfodor/black-white-cnn-lb-0-77;1.0;['tensorflow', 'keras'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'nn', 'ml'];['train', 'recognition', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/quickdraw-doodle-recognition;0.715;0.437;2020-12-13 16:18:48;multiple data sources;['gpu, deep learning, classification'];🐼Black&White CNN [LB=0.77];Python notebook;4293.0;45;;
2018-11-08 09:03:33;"Quick, Draw! Doodle Recognition Challenge""Quick, Draw!"" was released as an experimental game to educate the public in a playful way about how AI works. The game prompts users to draw an image depicting a certain category, such as ”banana,” “table,” etc. The game generated more than 1B drawings, of which a subset was publicly released as the basis for this competition’s training set. That subset contains 50M drawings encompassing 340 label categories. https://quickdraw.withgoogle.com/";Apache 2.0;https://www.kaggle.com/gaborfodor/data-reggeli;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'ml', 'nn', 'ann'];['train', 'recognition', 'model', 'neural network', 'epoch', 'validation data', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'understanding', 'resnet', 'convolutional neural network', 'ground truth'];https://www.kaggle.com/c/quickdraw-doodle-recognition;0.669;0.39;2020-12-13 16:18:48;multiple data sources;[];🥐☕Data Reggeli;Python notebook;1589.0;26;;
2018-11-25 23:04:13;Keras MobileNet BenchmarkIn a previous benchmark we used a simple three layer ConvNet. This time we use a deeper MobileNet architecture on greyscale strokes. This kernel has three main components:  MobileNet Fast and memory efficient Image Generator with temporal colored strokes Full training & submission with Kaggle Kernel  I did some paramer search but it should not be hard to improve the current score.;Apache 2.0;https://www.kaggle.com/gaborfodor/greyscale-mobilenet-lb-0-892;1.0;['tensorflow', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml'];['train', 'recognition', 'model', 'neural network', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'convolutional neural network'];https://www.kaggle.com/c/quickdraw-doodle-recognition;0.789;0.575;2020-12-13 16:18:48;multiple data sources;['gpu, deep learning, classification'];🐘Greyscale MobileNet [LB=0.892];Python notebook;32305.0;299;;
2018-11-27 03:22:53;This model combines two branches: MobileNet and Bidirectional LSTM.The Mobilenet branch is largely based on Beluga's kernel https://www.kaggle.com/gaborfodor/greyscale-mobilenet-lb-0-892 and the LSTM branch is inspired by Kevin's kernel, with modifications https://www.kaggle.com/kmader/quickdraw-baseline-lstm-reading-and-submission The performance depends on what you use for the two branches. I got up to 0.925 using this architecture. Inspired by this paper here: https://arxiv.org/abs/1804.01401;Apache 2.0;https://www.kaggle.com/huyenvyvy/fork-of-combining-cnn-and-rnn;1.0;['tensorflow', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'rnn', 'ml'];['filter', 'train', 'recognition', 'model', 'neural network', 'epoch', 'layer', 'loss', 'label', 'lstm', 'predict', 'relu', 'convolutional neural network'];https://www.kaggle.com/c/quickdraw-doodle-recognition;0.694;0.416;2020-12-13 16:18:48;multiple data sources;['gpu'];Fork of Combining CNN and RNN;Python notebook;2677.0;35;0.90512;0.90700
2018-10-18 00:48:48;I wrote this kernel to mess around with the sketch data and share my experience so far.  After exploring the website and the data, I'll use a very basic CNN to classify sketches. This model gets 0.60 on the Public LB when run with 6000 recognized images per class. Quick, DrawOk - I have to say this is kind of a fun thing. You go to the Quick Draw  website and agree to sketch several common objects. The host then gives you the object labels one by one, and you have 20 seconds to draw each one. If the AI guesses your sketch (that is, associates it with training set items of the same label) you get a check mark and move on. At the end you get something like this:   Notice that it didn't like my bird. Apparently it looked more like a dragon or a diving board(??) or a mosquito.  They're nice enough to show you how other people draw birds so you maybe learn how to draw better.;Apache 2.0;https://www.kaggle.com/jpmiller/image-based-cnn;1.0;['tensorflow', 'keras'];['ner', 'ai', 'dl', 'cnn', 'rl', 'nn'];['training data', 'test data', 'train', 'model', 'neural network', 'epoch', 'deep learning', 'layer', 'validation data', 'loss', 'label', 'predict', 'relu', 'convolutional neural network'];https://www.kaggle.com/c/quickdraw-doodle-recognition;0.776;0.497;2020-12-13 16:18:48;Quick, Draw! Doodle Recognition Challenge;['gpu, image data, neural networks, +1 moremulticlass classification'];Image-Based CNN;Python notebook;21455.0;97;0.60255;0.60563
2018-10-02 13:06:04;OverviewThe notebook is modified from one that was made for the Quick, Draw Dataset, it would actually be interesting to see how beneficial a transfer learning approach using that data as a starting point could be. This NotebookThe notebook takes and preprocesses the data from the QuickDraw Competition step (strokes) and trains an LSTM. The outcome variable (y) is always the same (category). The stroke-based LSTM. The model takes the stroke data and 'preprocesses' it a bit using 1D convolutions and then uses two stacked LSTMs followed by two dense layers to make the classification. The model can be thought to 'read' the drawing stroke by stroke. Fun ModelsAfter the classification models, we try to build a few models to understand what the LSTM actually does. Here we experiment step by step to see how the prediction changes with each stop Next StepsThe next steps could be  use more data to train include the country code (different countries draw different things, different ways) more complex models;Apache 2.0;https://www.kaggle.com/kmader/quickdraw-baseline-lstm-reading-and-submission;1.0;['tensorflow', 'sklearn', 'keras', 'pillow'];['ai', 'dl', 'rl', 'nn', 'rnn', 'ann'];['filter', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'lstm', 'predict', 'classification'];https://www.kaggle.com/c/quickdraw-doodle-recognition;0.763;0.538;2020-12-13 16:18:48;Quick, Draw! Doodle Recognition Challenge;['gpu'];QuickDraw Baseline LSTM Reading and Submission;Python notebook;14727.0;171;;
2018-10-02 12:58:29;OverviewThe notebook is modified from one that was made for the Quick, Draw Dataset, it would actually be interesting to see how beneficial a transfer learning approach using that data as a starting point could be. This NotebookThe notebook takes and preprocesses the data from the QuickDraw Competition step (strokes) and trains an a WaveNet-style classifier (wavenet in its original implemention is https://deepmind.com/blog/high-fidelity-speech-synthesis-wavenet/ is intended for synthesis, but the dilated convolution approach can be applied). We use the implementation here as a reference. Fun ModelsAfter the classification models, we try to build a few models to understand what the WaveNet actually does. Here we experiment step by step to see how the prediction changes with each stop Next StepsThe next steps could be  use more data to train include the country code (different countries draw different things, different ways) more complex models;Apache 2.0;https://www.kaggle.com/kmader/quickdraw-with-wavenet-classifier;1.0;['tensorflow', 'sklearn', 'keras', 'pillow'];['ai', 'dl', 'rl', 'nn', 'ann'];['filter', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'lstm', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/quickdraw-doodle-recognition;0.728;0.452;2020-12-13 16:18:48;Quick, Draw! Doodle Recognition Challenge;['gpu'];QuickDraw with WaveNet Classifier;Python notebook;5818.0;54;0.62536;0.62634
2018-11-26 20:42:56;This version cleaned and without validation (only 1 epoch, so don't use validation);Apache 2.0;https://www.kaggle.com/leighplt/pytorch-starter-kit;1.0;['pytorch'];['ai', 'dl', 'cv', 'ml', 'nn', 'ann'];['filter', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'resnet'];https://www.kaggle.com/c/quickdraw-doodle-recognition;0.712;0.447;2020-12-13 16:18:48;Quick, Draw! Doodle Recognition Challenge;['gpu, classification'];PyTorch. Starter kit;Python notebook;4029.0;51;0.88340;0.88434
2018-09-27 10:21:51;Convnet BaselineThis is a simple baseline which converts strokes to matplotlib figure and from there we convert it to numpy arrays. Finally the arrays are threated as images and feed into ConvNets.;Apache 2.0;https://www.kaggle.com/mihaskalic/when-in-doubt-convnets;1.0;['tensorflow', 'keras'];['ner', 'ai', 'rl', 'cv'];['predict', 'train', 'model', 'epoch', 'loss'];https://www.kaggle.com/c/quickdraw-doodle-recognition;0.712;0.455;2020-12-13 16:18:48;Quick, Draw! Doodle Recognition Challenge;['gpu'];When in doubt ... ConvNets;Python notebook;4021.0;56;0.00011;0.00000
2018-10-01 12:07:28;When asked to draw a simple shape, do you usually draw it clockwise or counterclockwise? Does it depend on the shape in question? Does it depend on your cultural background? These are the questions we rarely ask ourselves, but can potentially lead to interesting discoveries. Maybe before reading this notebook, try this yourself. Draw a circle, square and hexagon each, and see instinctively, which direction your hand is going, and then find out below if you draw the same way the majority of people from your region do. To determine how people from different parts of the world draw simple shapes, we will be using the QuickDraw dataset, which is a collection of various simple shapes people drew online when asked to do a sketch of a given object. Here we are most interested in how people draw the most basic shapes (circle, square, hexagon). The dataset includes the country code of the user as an attribute, allowing us to perform some geography / culture-based analysis on our results. The goal of our analysis is to find out if there are any differences in the direction people draw simple shapes around the world. To do so, we will have to come up with a measure of 'counterclockwiseness' for each of the sktches in the dataset. But first, let us look at in what format the drawings appear in the dataset. Let us load the hexagon drawings first:;Apache 2.0;https://www.kaggle.com/mithrillion/clockwise-or-counterclockwise;1.0;['pattern'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['train', 'label', 'filter'];https://www.kaggle.com/c/quickdraw-doodle-recognition;0.672;0.393;2020-12-13 16:18:48;Quick, Draw! Doodle Recognition Challenge;['data visualization, computer vision'];Clockwise or Counterclockwise?;Python notebook;1693.0;27;;
2018-11-18 15:59:48;Convert Strokes to RGB ImagesThis kernel explains how to pre-process the image to create rbg images, for using in the traditional pretrained networks.  We use the opencv package in python to achieve this. reference: 🐘Greyscale MobileNet [LB=0.892];Apache 2.0;https://www.kaggle.com/remidi/simple-strokes-to-rgb-kernel;1.0;['tensorflow', 'keras'];['ner', 'ai', 'cv'];['train', 'resnet', 'model'];https://www.kaggle.com/c/quickdraw-doodle-recognition;0.694;0.39;2020-12-13 16:18:48;Quick, Draw! Doodle Recognition Challenge;['image data, computer vision'];Simple Strokes to RGB Kernel;Python notebook;2658.0;26;;
2019-01-30 14:32:26;General informationIn this kernel I'll work with data from Quora Insincere Questions Classification Competition. This dataset is interesting for NLP researching. We will try to find insincere questions which aren't usefull or are even harmful. I'll do a simple EDA and try an LSTM-CNN model.;Apache 2.0;https://www.kaggle.com/artgor/eda-and-lstm-cnn;1.0;['lightgbm', 'nltk', 'theano', 'sklearn', 'tensorflow', 'keras'];['ner', 'ai', 'dl', 'cnn', 'gbm', 'gan', 'rl', 'nlp', 'nn', 'rnn', 'ml'];['gru', 'filter', 'test data', 'regression', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'lstm', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/quora-insincere-questions-classification;0.771;0.542;2020-12-13 16:20:43;Quora Insincere Questions Classification;['exploratory data analysis, deep learning, classification, +1 morenlp'];EDA and LSTM-CNN;Python notebook;18361.0;182;;
2019-01-26 03:41:06;General informationThis kernel is a fork of my Keras kernel. But this one will use Pytorch. I'll gradually introduce more complex architectures.;Apache 2.0;https://www.kaggle.com/artgor/text-modelling-in-pytorch;1.0;['lightgbm', 'nltk', 'sklearn', 'pytorch', 'tensorflow', 'keras'];['ner', 'ai', 'gbm', 'gan', 'nn', 'rnn', 'ann'];['gru', 'filter', 'test data', 'regression', 'train', 'model', 'epoch', 'loss', 'lstm', 'predict', 'relu'];https://www.kaggle.com/c/quora-insincere-questions-classification;0.775;0.569;2020-12-13 16:20:42;Quora Insincere Questions Classification;['exploratory data analysis, deep learning, classification, +2 morenlp, text mining'];Text modelling in Pytorch;Python notebook;20690.0;272;0.70076;0.70076
2019-03-16 11:35:16;There have been some issues regarding the correlation between CV and leaderboard scores in this competition. Every top-scoring public kernel has a much lower CV score than leaderboard score. It has also been very frustrating to tune a model to optimal CV score only to discover that the score on the Leaderboard is abysmal. In this kernel I am going to address this issue and propose a framework for robust local validation. The preprocessing and model architecture have stayed mostly the same as in my previous kernel. I'll also write about the impact of seeds on the score. Again, we'll start with standard imports.;Apache 2.0;https://www.kaggle.com/bminixhofer/a-validation-framework-impact-of-the-random-seed;1.0;['pytorch', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'nlu', 'dl', 'cv', 'nn', 'ml'];['gru', 'filter', 'training data', 'test data', 'train', 'model', 'neural network', 'epoch', 'loss', 'label', 'lstm', 'predict', 'relu'];https://www.kaggle.com/c/quora-insincere-questions-classification;0.741;0.532;2020-12-13 16:20:43;Quora Insincere Questions Classification;['gpu, deep learning'];A validation framework & impact of the random seed;Python notebook;8160.0;158;;
2019-02-09 10:20:22;UpdateThere was an issue with the random seed from os.random and the seed when creating the embedding matrix in version 1 - 3. Version 2 got a lucky seed and scored 0.694 for that reason. The problem is fixed since version 4. If you look at the version history you can see that the validation and training loss for version 4 and 5 are exactly the same so it is 100% reproducible now. But it dropped to 0.690 because the seed is less lucky on the Leaderboard. The CV score is even slightly better though.;Apache 2.0;https://www.kaggle.com/bminixhofer/deterministic-neural-networks-using-pytorch;1.0;['pytorch', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'rl', 'cv', 'nn'];['gru', 'test data', 'train', 'model', 'neural network', 'epoch', 'validation data', 'layer', 'loss', 'label', 'lstm', 'predict', 'relu', 'recommend'];https://www.kaggle.com/c/quora-insincere-questions-classification;0.756;0.551;2020-12-13 16:20:42;Quora Insincere Questions Classification;['gpu, beginner'];Deterministic neural networks using PyTorch;Python notebook;12236.0;206;;
2018-11-13 16:44:27;In this kernel I want to illustrate how I do come up with meaningful preprocessing when building deep learning NLP models. I start with two golden rules:  Don't use standard preprocessing steps like stemming or stopword removal when you have pre-trained embeddings   Some of you might used standard preprocessing steps when doing word count based feature extraction (e.g. TFIDF) such as removing stopwords, stemming etc.  The reason is simple: You loose valuable information, which would help your NN to figure things out.  Get your vocabulary as close to the embeddings as possible  I will focus in this notebook, how to achieve that. For an example I take the GoogleNews pretrained embeddings, there is no deeper reason for this choice.;Apache 2.0;https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings;1.0;['vocabulary', 'gensim'];['ai', 'dl', 'gan', 'rl', 'nlp', 'nn'];['train', 'model', 'deep learning'];https://www.kaggle.com/c/quora-insincere-questions-classification;0.801;0.644;2020-12-13 16:20:42;Quora Insincere Questions Classification;['beginner, deep learning, nlp'];How to: Preprocessing when using embeddings;Python notebook;46696.0;978;;
2018-12-13 12:34:08;some reference: https://www.kaggle.com/shujian/single-rnn-with-4-folds-clr by shujian https://www.kaggle.com/sudalairajkumar/a-look-at-different-embeddings by SRK https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings by Dieter https://www.kaggle.com/shujian/mix-of-nn-models-based-on-meta-embedding by shujian Tell me if missed any;Apache 2.0;https://www.kaggle.com/gmhost/gru-capsule;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'nn', 'rnn', 'rl'];['gru', 'filter', 'train', 'model', 'epoch', 'layer', 'loss', 'predict', 'relu'];https://www.kaggle.com/c/quora-insincere-questions-classification;0.779;0.577;2020-12-13 16:20:42;Quora Insincere Questions Classification;['gpu'];GRU+Capsule;Python notebook;23366.0;309;;
2019-01-19 10:07:56;PrefaceHello . This is basically cutting and pasting from the amazing kernels of this competition. Please notify me if I don't attribute something correctly.  https://www.kaggle.com/gmhost/gru-capsule How to: Preprocessing when using embeddings https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings Improve your Score with some Text Preprocessing https://www.kaggle.com/theoviel/improve-your-score-with-some-text-preprocessing Simple attention layer taken from https://github.com/mttk/rnn-classifier/blob/master/model.py https://www.kaggle.com/ziliwang/baseline-pytorch-bilstm https://www.kaggle.com/hengzheng/pytorch-starter  UPDATE: I seems that the shuffling the data doesn't add the features in the correct order. To address this issue I added a custom dataset class that can return indexes so that they can be accessed while training and properly put each feature with the corresponding sample. The training time though is increased, so you might need to make the model lighter in order to submit results.;Apache 2.0;https://www.kaggle.com/jannen/reaching-0-7-fork-from-bilstm-attention-kfold;1.0;['nltk', 'sklearn', 'pytorch', 'tensorflow', 'spacy', 'textblob', 'keras'];['ner', 'ai', 'gan', 'rl', 'nn', 'rnn', 'ann'];['gru', 'filter', 'training data', 'train', 'model', 'epoch', 'layer', 'loss', 'lstm', 'predict', 'relu'];https://www.kaggle.com/c/quora-insincere-questions-classification;0.756;0.546;2020-12-13 16:20:43;Quora Insincere Questions Classification;['gpu'];Fork_from_BiLSTM-attention-Kfold-0115 81a8d9;Python notebook;12289.0;191;0.70000;0.70000
2019-01-06 08:02:18;A Detailed Guide to understand the Word Embeddings and Embedding Layer in Keras.;Apache 2.0;https://www.kaggle.com/rajmehra03/a-detailed-explanation-of-keras-embedding-layer;1.0;['tensorflow', 'keras', 'nltk'];['ai'];['filter', 'machine learning', 'train', 'model', 'natural language processing', 'layer', 'loss', 'text classification', 'predict', 'recommend', 'sentiment analysis', 'classification', 'natural language'];https://www.kaggle.com/c/quora-insincere-questions-classification;0.816;0.605;2020-12-13 16:20:42;multiple data sources;['beginner, deep learning, nlp, +1 moretext data'];A Detailed Explanation of Keras Embedding Layer;Python notebook;78756.0;488;;
2018-11-13 04:35:15;Refer: Based on: https://www.kaggle.com/danofer/different-embeddings-with-attention-fork SRK: https://www.kaggle.com/sudalairajkumar/a-look-at-different-embeddings . There is not much changed from this kernel except the nueral net architecture and final weights of the embeddings. Code for attention layer is taken from Khoi Ngyuen: https://www.kaggle.com/suicaokhoailang/lstm-attention-baseline-0-652-lb CNN: https://www.kaggle.com/yekenot/2dcnn-textclassifier;Apache 2.0;https://www.kaggle.com/shujian/different-embeddings-with-attention-fork-fork;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'cnn', 'nlp', 'nn', 'ml'];['gru', 'filter', 'training data', 'train', 'model', 'epoch', 'layer', 'loss', 'lstm', 'predict', 'relu'];https://www.kaggle.com/c/quora-insincere-questions-classification;0.758;0.566;2020-12-13 16:20:42;Quora Insincere Questions Classification;['gpu'];Different embeddings with Attention! [Fork][Fork];Python notebook;12658.0;260;0.68404;0.68404
2018-11-16 14:06:00;I was trying to clean some of my code so I can add more models. However, this can never happen without the awesome kernels from other talented Kagglers. Forgive me if I missed any.  Based on SRK's kernel: https://www.kaggle.com/sudalairajkumar/a-look-at-different-embeddings Vladimir Demidov's 2DCNN textClassifier: https://www.kaggle.com/yekenot/2dcnn-textclassifier Attention layer from Khoi Ngyuen: https://www.kaggle.com/suicaokhoailang/lstm-attention-baseline-0-652-lb LSTM model from Strideradu: https://www.kaggle.com/strideradu/word2vec-and-gensim-go-go-go https://www.kaggle.com/danofer/different-embeddings-with-attention-fork  Some new things here:  Take average of embeddings (Unweighted DME) instead of blending predictions: https://arxiv.org/pdf/1804.07983.pdf The original paper of this idea comes from: Frustratingly Easy Meta-Embedding – Computing Meta-Embeddings by Averaging Source Word Embeddings Modified the code to choose best threshold Robust method for blending weights: sort the val score and give the final weight  Some thoughts:  Although I pulished a kernel on Transformer, I will not use it Too much randomness in CuDNN. You may get different results by just rerunning this kernel Blending rocks;Apache 2.0;https://www.kaggle.com/shujian/mix-of-nn-models-based-on-meta-embedding;1.0;['tensorflow', 'sklearn', 'keras', 'gensim'];['ai', 'nn', 'rnn', 'cnn'];['gru', 'filter', 'train', 'fitting', 'model', 'epoch', 'layer', 'loss', 'lstm', 'predict', 'relu'];https://www.kaggle.com/c/quora-insincere-questions-classification;0.745;0.539;2020-12-13 16:20:43;Quora Insincere Questions Classification;['gpu'];Mix of NN models based on Meta-embedding;Python notebook;9106.0;173;0.68557;0.68557
2018-11-25 02:20:34;I was trying to clean some of my code so I can add more models. However, this can never happen without the awesome kernels from other talented Kagglers. Forgive me if I missed any.  CLR from: https://www.kaggle.com/hireme/fun-api-keras-f1-metric-cyclical-learning-rate/code Based on SRK's kernel: https://www.kaggle.com/sudalairajkumar/a-look-at-different-embeddings Vladimir Demidov's 2DCNN textClassifier: https://www.kaggle.com/yekenot/2dcnn-textclassifier Attention layer from Khoi Ngyuen: https://www.kaggle.com/suicaokhoailang/lstm-attention-baseline-0-652-lb LSTM model from Strideradu: https://www.kaggle.com/strideradu/word2vec-and-gensim-go-go-go https://www.kaggle.com/danofer/different-embeddings-with-attention-fork https://www.kaggle.com/ryanzhang/tfidf-naivebayes-logreg-baseline Borrowed some idea from this model: https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/52644 Sentence length seems to a good feature: https://www.kaggle.com/thebrownviking20/analyzing-quora-for-the-insinceres  Some new things here:  Take average of embeddings (Unweighted DME) instead of blending predictions: https://arxiv.org/pdf/1804.07983.pdf The original paper of this idea comes from: Frustratingly Easy Meta-Embedding – Computing Meta-Embeddings by Averaging Source Word Embeddings Modified the code to choose best threshold Robust method for blending weights: sort the val score and give the final weight  Some thoughts:  Although I pulished a kernel on Transformer, I will not use it Too much randomness in CuDNN. You may get different results by just rerunning this kernel Blending rocks;Apache 2.0;https://www.kaggle.com/shujian/single-rnn-with-4-folds-clr;1.0;['tensorflow', 'sklearn', 'keras', 'gensim'];['ai', 'cnn', 'cv', 'nn', 'rnn'];['gru', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'lstm', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/quora-insincere-questions-classification;0.787;0.595;2020-12-13 16:20:42;Quora Insincere Questions Classification;['gpu'];Single RNN with 4 folds (CLR);Python notebook;30157.0;412;;
2018-12-24 23:49:52;PrefaceHello . This is basically cutting and pasting from the amazing kernels of this competition. Please notify me if I don't attribute something correctly.  https://www.kaggle.com/gmhost/gru-capsule How to: Preprocessing when using embeddings https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings Improve your Score with some Text Preprocessing https://www.kaggle.com/theoviel/improve-your-score-with-some-text-preprocessing Simple attention layer taken from https://github.com/mttk/rnn-classifier/blob/master/model.py https://www.kaggle.com/ziliwang/baseline-pytorch-bilstm https://www.kaggle.com/hengzheng/pytorch-starter  UPDATE: I seems that the shuffling the data doesn't add the features in the correct order. To address this issue I added a custom dataset class that can return indexes so that they can be accessed while training and properly put each feature with the corresponding sample. The training time though is increased, so you might need to make the model lighter in order to submit results.;Apache 2.0;https://www.kaggle.com/spirosrap/bilstm-attention-kfold-clr-extra-features-capsule;1.0;['nltk', 'sklearn', 'pytorch', 'tensorflow', 'spacy', 'textblob', 'keras'];['ai', 'gan', 'rl', 'nn', 'rnn', 'ann'];['gru', 'filter', 'training data', 'train', 'model', 'epoch', 'layer', 'loss', 'lstm', 'predict', 'relu'];https://www.kaggle.com/c/quora-insincere-questions-classification;0.748;0.535;2020-12-13 16:20:43;Quora Insincere Questions Classification;['gpu'];BiLSTM-attention-Kfold-CLR-Extra Features-capsule;Python notebook;9860.0;164;;
2018-11-08 10:37:33;Notebook Objective: Objective of the notebook is to look at the different pretrained embeddings provided in the dataset and to see how they are useful in the model building process. First let us import the necessary modules and read the input data.;Apache 2.0;https://www.kaggle.com/sudalairajkumar/a-look-at-different-embeddings;1.0;['tensorflow', 'sklearn', 'keras'];['nlp', 'ai', 'nn', 'ml'];['gru', 'predict', 'training data', 'train', 'model', 'epoch', 'layer', 'lstm', 'loss', 'relu'];https://www.kaggle.com/c/quora-insincere-questions-classification;0.809;0.646;2020-12-13 16:20:42;Quora Insincere Questions Classification;['gpu'];A look at different embeddings.!;Python notebook;62223.0;1018;0.67008;0.67008
2018-11-07 11:09:20;Notebook Objective: Objective of the notebook is to explore the data and to build a simple baseline model. Objective of the competition: In this second competition by Quora, the objective is to predict whether a question asked on Quora is sincere or not. This is a kernels only comeptition. An insincere question is defined as a question intended to make a statement rather than look for helpful answers. Some characteristics that can signify that a question is insincere:  Has a non-neutral tone Has an exaggerated tone to underscore a point about a group of people Is rhetorical and meant to imply a statement about a group of people   Is disparaging or inflammatory Suggests a discriminatory idea against a protected class of people, or seeks confirmation of a stereotype Makes disparaging attacks/insults against a specific person or group of people Based on an outlandish premise about a group of people Disparages against a characteristic that is not fixable and not measurable   Isn't grounded in reality Based on false information, or contains absurd assumptions   Uses sexual content (incest, bestiality, pedophilia) for shock value, and not to seek genuine answers  P.S: This is a work in progress. Please stay tuned.!;Apache 2.0;https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-qiqc;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'gan', 'cv', 'rl', 'nlp', 'nn', 'ml'];['filter', 'machine learning', 'regression', 'generation', 'train', 'training data', 'model', 'loss', 'label', 'logistic regression', 'predict'];https://www.kaggle.com/c/quora-insincere-questions-classification;0.782;0.61;2020-12-13 16:20:42;Quora Insincere Questions Classification;['beginner, exploratory data analysis, text data'];Simple Exploration Notebook - QIQC;Python notebook;25606.0;531;;
2019-01-28 12:13:50;In this notebook, I am going to sharing some text cleaning mostly based on bad case analyse. The cleaning methods include:  remove empty space replace strange punctuations and raplace diacritics clean numbers, split numbers and letters de-contract the contraction clean math latex clean many misspelling words spacing punctuations expect -and . fix -and . punc spacing bugs which common kernels existed spacing some connected words like whatis, whichcountry clean repeated letters in one word, like hoooooow clean some masked words like f***, st*up*id  Reference:  How to: Preprocessing when using embeddings Improve your Score with some Text Preprocessing  Cleaning text data has caused me huge time! Please UPVOTE if you find it useful;Apache 2.0;https://www.kaggle.com/sunnymarkliu/more-text-cleaning-to-increase-word-coverage;1.0;['pattern', 'vocabulary', 'gensim'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nn', 'ann'];['gru', 'generation', 'train', 'recognition', 'model', 'understanding', 'reward', 'layer', 'rectifier', 'loss', 'rank', 'recommend'];https://www.kaggle.com/c/quora-insincere-questions-classification;0.723;0.532;2020-12-13 16:20:43;Quora Insincere Questions Classification;[];More Text Cleaning To Increase Word Coverage;Python notebook;5148.0;157;;
2018-12-03 18:13:10;About the datasetAn existential problem for any major website today is how to handle toxic and divisive content. Quora wants to tackle this problem head-on to keep their platform a place where users can feel safe sharing their knowledge with the world. Quora is a platform that empowers people to learn from each other. On Quora, people can ask questions and connect with others who contribute unique insights and quality answers. A key challenge is to weed out insincere questions -- those founded upon false premises, or that intend to make a statement rather than look for helpful answers. In this competition, Kagglers will develop models that identify and flag insincere questions. To date, Quora has employed both machine learning and manual review to address this problem. With your help, they can develop more scalable methods to detect toxic and misleading content. Here's your chance to combat online trolls at scale. Help Quora uphold their policy of “Be Nice, Be Respectful” and continue to be a place for sharing and growing the world’s knowledge.;Apache 2.0;https://www.kaggle.com/thebrownviking20/analyzing-quora-for-the-insinceres;1.0;['pattern', 'spacy', 'sklearn', 'nltk'];['ner', 'ai', 'dl', 'rl', 'nn', 'ml'];['autoencoder', 'filter', 'machine learning', 'train', 'model', 'natural language processing', 'unsupervised learning', 'supervised learning', 'natural language'];https://www.kaggle.com/c/quora-insincere-questions-classification;0.749;0.549;2020-12-13 16:20:42;Quora Insincere Questions Classification;['data visualization, exploratory data analysis, text data, +1 moretext mining'];Analyzing Quora for the Insinceres;Python notebook;10146.0;200;;
2018-12-03 15:18:15;Improve your Score with some Text PreprocessingUpdated version :https://www.kaggle.com/theoviel/improve-your-score-with-text-preprocessing-v2  This kernel is an improved version of @Dieter's work. https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings  It is the preprocessing I use for my current LB score, and it has helped improving it by a bit. Feel free to use it as well, but please upvote if you do. This is also how I caught a glimpse of spelling mistakes in the database. Any feedback is appreciated !;Apache 2.0;https://www.kaggle.com/theoviel/improve-your-score-with-some-text-preprocessing;1.0;['vocabulary'];['ner', 'ai', 'gan', 'rl', 'nn', 'ann'];['rank', 'train'];https://www.kaggle.com/c/quora-insincere-questions-classification;0.782;0.608;2020-12-13 16:20:42;Quora Insincere Questions Classification;['data cleaning'];Improve your Score with some Text Preprocessing;Python notebook;25573.0;510;;
2017-04-12 16:22:19;Identifying Duplicate QuestionsWelcome to the Quora Question Pairs competition! Here, our goal is to identify which questions asked on Quora, a quasi-forum website with over 100 million visitors a month, are duplicates of questions that have already been asked. This could be useful, for example, to instantly provide answers to questions that have already been answered. We are tasked with predicting whether a pair of questions are duplicates or not, and submitting a binary prediction against the logloss metric. If you have any questions or want to discuss competitions/hardware/games/anything with other Kagglers, then join the KaggleNoobs Slack channel here. We also have regular AMAs with top Kagglers there. And as always, if this helped you, some upvotes would be very much appreciated - that's where I get my motivation! :D Let's dive right into the data!;Apache 2.0;https://www.kaggle.com/anokas/data-analysis-xgboost-starter-0-35460-lb;1.0;['xgboost', 'sklearn', 'nltk'];['ner', 'ai', 'gan', 'cv', 'rl', 'nn', 'ann'];['machine learning', 'training data', 'test data', 'train', 'model', 'loss', 'label', 'predict', 'classification'];https://www.kaggle.com/c/quora-question-pairs;0.828;0.66;2020-12-13 16:22:58;Quora Question Pairs;['data visualization, exploratory data analysis, nlp, +2 morexgboost, intermediate'];Data Analysis & XGBoost Starter (0.35460 LB);Python notebook;127006.0;1340;;
2017-04-16 21:14:34;Here's a quick attempt at exploring why the train set average response rate could be so different to that observed in the Public LB If we make the assumption that there's an underlying temporal pattern to the data, and use the qid values as a proxy for it (higher qid value implies more recent question), then re-sorting the train set by increasing qid and plotting the sliding window of mean response rate should show us some pattern.;Apache 2.0;https://www.kaggle.com/ashhafez/temporal-pattern-in-train-response-rates;1.0;['pattern'];['ai', 'rl'];['train', 'training data', 'validation data'];https://www.kaggle.com/c/quora-question-pairs;0.732;0.486;2020-12-13 16:22:58;Quora Question Pairs;[];Temporal pattern in train response rates?;Python notebook;6478.0;84;;
2017-05-12 08:46:23;I have been struggling for a while on how to spell check questions while only using allowed data/software.  Here is the solution I am using now. It is an adaptation of Peter Norvig's spell checker.  It uses word2vec ordering of words to approximate word probabilities.  Indeed, Google word2vec apparently orders words in decreasing order of frequency in the training corpus. This kernel requires to download Google's word2vec: https://github.com/mmihaltz/word2vec-GoogleNews-vectors .  I have put it in my ../data directory. I don't think that  the notebooks can run on Kaggle kernels but I share it anyway as many have already downloaded the word2vec embedding.;Apache 2.0;https://www.kaggle.com/cpmpml/spell-checker-using-word2vec;1.0;['gensim'];['dl', 'ner', 'ai', 'nn'];['rank', 'model', 'train'];https://www.kaggle.com/c/quora-question-pairs;0.794;0.566;2020-12-13 16:22:58;Quora Question Pairs;[];Spell Checker using Word2vec;Python notebook;37911.0;262;;
2017-04-01 22:29:20;The Importance of Cleaning the Text;Apache 2.0;https://www.kaggle.com/currie32/the-importance-of-cleaning-text;1.0;['nltk'];['ai', 'dl', 'rl', 'nn', 'ann'];['train', 'model', 'loss'];https://www.kaggle.com/c/quora-question-pairs;0.785;0.519;2020-12-13 16:22:58;Quora Question Pairs;[];The Importance of Cleaning  Text;Python notebook;27946.0;130;;
2017-04-27 22:16:07;Note (April 16): This notebook shows that the public test set has a lower mean label than the training set, but it does not say why, because I did not know. Ash Hafez has probably now found the reason why in the kernel Temporal pattern in train response rates?;Apache 2.0;https://www.kaggle.com/davidthaler/how-many-1-s-are-in-the-public-lb;1.0;['pattern', 'sklearn'];['ai', 'ml'];['training data', 'predict', 'train', 'label', 'loss'];https://www.kaggle.com/c/quora-question-pairs;0.768;0.5;2020-12-13 16:22:58;Quora Question Pairs;[];How many 1's are in the Public LB?;Python notebook;16851.0;101;;
2017-06-01 17:25:19;"▼ See the result at bottom directly if you're in a hurry ▼ Idea and motivationFor case like: 'Is Taiwan a good place to live ?' If we apply 'Taiwan' to word2vec directly, there are 3 cases might happen:  It works!  Taiwan is a very common word, so the word2vec method really captured its meaning in its vector space!  Somehow it works, but not very well.  Taiwan is not a very common word, so word2vec model cannot capture its meaning very well.  It fails.  Either the word is too rare or contains typo in it.   And spaCy comes to me. It has an useful attribute ""ent_type_"" for each token, it tries to estimate the word's entity type in its pre-defined categories based on the sentence's context. For example: testcase = 'Is Taiwan a good place to live ?' doc = nlp(testcase) # apply spacy on the sentense taiwan = doc[1] # word 'Taiwan' is at index 1 print(taiwan.ent_type_)  # yield ""GPE"" which means ""Countries, cities, states.""    Then we can replace the original sentence. From: 'Is Taiwan a good place to live ?' To  : 'Is country a good place to live ?'    The word ""country""'s meaning is very likely captured better than the word 'Taiwan'. Although it losses some information, but the dataset becomes less noisy. It is kind of trade off, and I believe that adding a model trained on such dataset can increase ensembling result. Requirements install spaCy and its corpus ( I use its en_core_web_md corpus )  So, you can't run it directly here :(";Apache 2.0;https://www.kaggle.com/hubert0527/spacy-name-entity-recognition;1.0;['pattern', 'tensorflow', 'spacy', 'nltk'];['ner', 'ai', 'gan', 'rl', 'ml', 'nlp', 'nn', 'ann'];['train', 'model', 'label', 'loss', 'labeled'];https://www.kaggle.com/c/quora-question-pairs;0.776;0.453;2020-12-13 16:22:58;Quora Question Pairs;[];[spaCy] Name Entity Recognition;Python notebook;21522.0;55;;
2017-03-18 23:30:10;Visualizing Word Vectors with t-SNETSNE is pretty useful when it comes to visualizing similarity between objects. It works by taking a group of high-dimensional (100 dimensions via Word2Vec) vocabulary word feature vectors, then compresses them down to 2-dimensional x,y coordinate pairs. The idea is to keep similar words close together on the plane, while maximizing the distance between dissimilar words. Steps Clean the data Build a corpus Train a Word2Vec Model Visualize t-SNE representations of the most common words   Credit: Some of the code was inspired by this awesome NLP repo.;Apache 2.0;https://www.kaggle.com/jeffd23/visualizing-word-vectors-with-t-sne;1.0;['vocabulary', 'sklearn', 'nltk', 'gensim'];['ner', 'ai', 'nlp', 'nn', 'ann'];['train', 'model', 'label'];https://www.kaggle.com/c/quora-question-pairs;0.814;0.521;2020-12-13 16:22:58;Quora Question Pairs;[];Visualizing Word Vectors with t-SNE;Python notebook;74373.0;135;;
2018-11-01 18:51:00;Simply about Word2Vec (Quora dataset)Liana Napalkova 21 October 2018 Table of contents Introduction What is Word2Vec? Training of Word2Vec Exploring the trained Word2Vec model Playing with the trained Word2Vec model  When can we use Word2Vec?  I hope you find this kernel helpful and some UPVOTES would be very much appreciated. Introduction If you have never used Word2Vec, then this notebook is for you! Here I will apply Word2Vec to the questions asked in Quora. The goal of the notebook is to better understand how Word2Vec works. Basically I wanted to resolve my personal doubts regarding Word2Vec. I will be very glad if my small analysis would be useful for someone else.;Apache 2.0;https://www.kaggle.com/liananapalkova/simply-about-word2vec;1.0;['vocabulary', 'sklearn', 'gensim'];['ai', 'nn', 'ann', 'rl'];['train', 'model', 'input layer', 'output layer', 'neural network', 'epoch', 'layer', 'label', 'hidden layer', 'recommend', 'sentiment analysis'];https://www.kaggle.com/c/quora-question-pairs;0.766;0.488;2020-12-13 16:22:58;Quora Question Pairs;['beginner, deep learning, feature engineering, +1 moreneural networks'];Simply about Word2Vec;Python notebook;15832.0;86;;
2017-04-15 00:37:24;Quora Question-pair classificationThis competition is about modelling whether a pair of questions on Quora is asking the same question. For this problem we have about 400.000 training examples. Each row consists of two sentences and a binary label that indicates to us whether the two questions were the same or not. Inspired by this nice kernel from Anisotropic I've added a few interactive 2D and 3D scatter plots. To get an insight into how the duplicates evolve over the number of words in the questions, I've added a plotly animation that encodes number of words and word share similarity in a scatter plot. We will be looking in detail at:  question pair TF-IDF encodings basic feature engineering and their embeddings in lower dimensional spaces parallel coordinates visualization model selection and evaluation + sample submission.  If you like this kernel, please upvote it :D, thanks!  Added a final section for cross-validated model selection and evaluation. We will look at standard binary classification metrics, like ROC and PR curves and their AUCs. The best (linear) model that we found then generates a submission.;Apache 2.0;https://www.kaggle.com/philschmidt/quora-eda-model-selection-roc-pr-plots;1.0;['sklearn'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ml'];['machine learning', 'training data', 'regression', 'test data', 'train', 'fitting', 'model', 'loss', 'label', 'predict', 'rank', 'classification'];https://www.kaggle.com/c/quora-question-pairs;0.79;0.564;2020-12-13 16:22:58;Quora Question Pairs;['exploratory data analysis, intermediate'];Quora EDA & Model selection (ROC, PR plots);Python notebook;33261.0;252;;
2017-03-28 06:58:48;Unusual meaning map: Treating question pairs as image / surface;Apache 2.0;https://www.kaggle.com/puneetsl/unusual-meaning-map;1.0;['xgboost', 'sklearn', 'nltk', 'gensim'];['ner', 'ai', 'gan', 'cv', 'rl', 'nn', 'ann'];['test data', 'generation', 'train', 'model', 'label', 'loss'];https://www.kaggle.com/c/quora-question-pairs;0.721;0.459;2020-12-13 16:22:58;Quora Question Pairs;[];Unusual meaning map;Python notebook;4969.0;59;;
2017-03-18 04:40:08;This script intends to be a starter script for Keras using pre-trained word embeddings. Word embedding: Word embedding is the collective name for a set of language modeling and feature learning techniques in natural language processing (NLP) where words or phrases from the vocabulary are mapped to vectors of real numbers. They are also called as word vectors. Two commonly used word embeddings are:  Google word2vec Stanford Glove  In this notebook, we will use the GloVe word vector which is downloaded from this link Let us first import the necessary packages.;Apache 2.0;https://www.kaggle.com/sudalairajkumar/keras-starter-script-with-word-embeddings;1.0;['vocabulary', 'tensorflow', 'keras'];['nlp', 'ai', 'dl'];['train', 'model', 'epoch', 'natural language processing', 'layer', 'loss', 'label', 'lstm', 'predict', 'relu', 'natural language'];https://www.kaggle.com/c/quora-question-pairs;0.74;0.47;2020-12-13 16:22:58;Quora Question Pairs;[];Keras Starter Script with Word Embeddings;Python notebook;7978.0;68;;
2017-05-25 10:43:47;In this simple exploration notebook, let us try and explore the dataset given for this competition. Update on 25 May 2017: Since there are a couple of leaky features now, let us explore the same as well in the notebook Objective: To classify whether question pairs are duplicate or not. Let us start with importing the necessary modules for exploring the data.;Apache 2.0;https://www.kaggle.com/sudalairajkumar/simple-leaky-exploration-notebook-quora;1.0;['xgboost', 'sklearn', 'nltk'];['ner', 'ai'];['predict', 'training data', 'test data', 'train', 'model', 'label', 'loss'];https://www.kaggle.com/c/quora-question-pairs;0.773;0.54;2020-12-13 16:22:58;Quora Question Pairs;[];Simple Leaky Exploration Notebook - Quora;Python notebook;19445.0;177;;
2017-11-29 15:19:50;IntroductionNatural Language Processing  (NLP) is the task of making computers understand and produce human languages. And it always starts with the corpus i.e. a body of text.;Apache 2.0;https://www.kaggle.com/alvations/basic-nlp-with-nltk;1.0;['pattern', 'vocabulary', 'sklearn', 'nltk'];['ner', 'ai', 'dl', 'rl', 'ml', 'nlp', 'nn', 'ann'];['machine learning', 'training data', 'test data', 'generation', 'train', 'model', 'validation data', 'natural language processing', 'label', 'naive bayes', 'predict', 'classification', 'natural language'];https://www.kaggle.com/c/random-acts-of-pizza;0.795;0.5;2020-12-13 16:26:53;multiple data sources;['classification, feature engineering, nlp, +1 morelinguistics'];Basic NLP with NLTK;Python notebook;38293.0;100;0.00000;0.00000
2020-09-11 08:50:52;IntroductionNatural Language Processing  (NLP) is the task of making computers understand and produce human languages. And it always starts with the corpus i.e. a body of text.;Apache 2.0;https://www.kaggle.com/koushikdeb/intro-to-terminologies-of-nlp;1.0;['pattern', 'vocabulary', 'sklearn', 'nltk'];['ner', 'ai', 'dl', 'rl', 'ml', 'nlp', 'nn', 'ann'];['machine learning', 'training data', 'test data', 'generation', 'train', 'model', 'validation data', 'natural language processing', 'label', 'naive bayes', 'predict', 'classification', 'natural language'];https://www.kaggle.com/c/random-acts-of-pizza;0.435;0.0;2020-12-13 16:26:53;multiple data sources;[];Intro to Terminologies of NLP;Python notebook;44.0;0;;
2020-04-13 06:36:36;Using 0.25 as the predicted probability for the baseline (reflecting what we know about the original distribution of classes in our training dataset).;Apache 2.0;https://www.kaggle.com/tanjinprity/ml-project-cat-and-tan;1.0;['tensorflow', 'nltk'];['dl', 'ai', 'nn'];['training data', 'predict', 'test data', 'train', 'label', 'loss'];https://www.kaggle.com/c/random-acts-of-pizza;0.481;0.0;2020-12-13 16:26:53;Random Acts of Pizza;[];ML project: Cat and Tan;Python notebook;78.0;0;;
2018-12-02 14:37:12;1. Importing libraries and loading files;Apache 2.0;https://www.kaggle.com/ynue21/random-act-of-pizza;1.0;['sklearn', 'nltk', 'gensim'];['ai', 'cv'];['filter', 'regression', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/random-acts-of-pizza;0.628;0.188;2020-12-13 16:26:53;multiple data sources;[];Random Act Of Pizza;Python notebook;734.0;3;;
2018-11-20 11:18:22;IntroductionNatural Language Processing  (NLP) is the task of making computers understand and produce human languages. And it always starts with the corpus i.e. a body of text.;Apache 2.0;https://www.kaggle.com/zahoorahmad/basic-nlp-with-nltk-fba294;1.0;['pattern', 'vocabulary', 'sklearn', 'nltk'];['ner', 'ai', 'dl', 'rl', 'ml', 'nlp', 'nn', 'ann'];['machine learning', 'training data', 'test data', 'generation', 'train', 'model', 'validation data', 'natural language processing', 'label', 'naive bayes', 'predict', 'classification', 'natural language'];https://www.kaggle.com/c/random-acts-of-pizza;0.557;0.0;2020-12-13 16:26:53;multiple data sources;[];Basic NLP with NLTK fba294;Python notebook;226.0;0;;
2019-06-08 17:57:11;This kernel is clone of this nice kernel: https://www.kaggle.com/suicaokhoailang/facenet-baseline-in-keras-0-749-lb Just add pretrained vggface model and take the average of the predictions of the two models.;Apache 2.0;https://www.kaggle.com/ateplyuk/vggface-baseline-in-keras;1.0;['sklearn', 'pillow', 'tensorflow', 'keras', 'skimage'];['ai', 'dl', 'cv', 'nn', 'ml'];['train', 'vgg', 'model', 'predict'];https://www.kaggle.com/c/recognizing-faces-in-the-wild;0.714;0.416;2020-12-13 16:27:41;multiple data sources;['gpu'];VGGFace baseline in Keras;Python notebook;4232.0;35;0.763;0.754
2019-06-23 08:16:10;This kernel is completete base on the discussion post from CVxTz and lleon: Kind of solutions Code sharing - 0.81 LB Special thanks to: TuanNguyenAnh DeepAnxiety victor borges :)!;Apache 2.0;https://www.kaggle.com/hsinwenchang/vggface-baseline-197x197;1.0;['tensorflow', 'keras', 'pillow'];['ner', 'ai', 'cv', 'ml', 'nn', 'ann'];['train', 'model', 'epoch', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'resnet'];https://www.kaggle.com/c/recognizing-faces-in-the-wild;0.729;0.405;2020-12-13 16:27:41;Northeastern SMILE Lab - Recognizing Faces in the Wild;['gpu'];VGGFace Baseline 197X197;Python notebook;6013.0;31;0.872;0.857
2019-06-05 08:00:31;The following notebook uses OpenFace as a feature extractor and then uses bcnn as way to merge these features and make a final sigmoid layer for classifying the kinship between two pair of images. Most of the code has been derived from the following resources:  https://github.com/krasserm/face-recognition : This repository has been inspired by openface which in turn has been based on facenet[https://cmusatyalab.github.io/openface/] https://github.com/tkhs3/BCNN_keras : Following the feature extraction face I have placed a BCNN(http://vis-www.cs.umass.edu/bcnn/docs/bcnn_iccv15.pdf) head The basic image generators and train val distribution has been taken from https://www.kaggle.com/suicaokhoailang/facenet-baseline-in-keras-0-749-lb For merging the feature extractor and the BCNN head, I have simply popped off some last layers from the OpenFace model and attached the BCNN head to it;Apache 2.0;https://www.kaggle.com/janpreets/just-another-feature-extractor-0-824-lb;1.0;['tensorflow', 'sklearn', 'keras', 'openface'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'nn', 'ann'];['filter', 'train', 'recognition', 'model', 'epoch', 'layer', 'loss', 'predict', 'relu', 'resnet', 'classification'];https://www.kaggle.com/c/recognizing-faces-in-the-wild;0.69;0.367;2020-12-13 16:27:41;multiple data sources;['gpu'];Just another feature extractor;Python notebook;2466.0;20;;
2019-08-10 16:55:53;Model combining Facenet and VGG in KerasThis is my single best scoring model (0.893 public leaderboard, 0.900 private leaderboard) I used this model in combination with other 36 models to get my final submission. From the 37 models that I used, 7 are public kernels (reference below) https://www.kaggle.com/shivamsarawagi/wildimagedetection-0-875 https://www.kaggle.com/hsinwenchang/vggface-baseline-197x197 https://www.kaggle.com/arjunrao2000/kinship-detection-with-vgg16 https://www.kaggle.com/leonbora/kinship-recognition-transfer-learning-vggface https://www.kaggle.com/janpreets/just-another-feature-extractor-0-824-lb https://www.kaggle.com/tenffe/vggface-cv-focal-loss https://www.kaggle.com/vaishvik25/smile I used pretrained Facenet model from this repo https://github.com/nyoki-mtl/keras-facenet).;Apache 2.0;https://www.kaggle.com/mattemilio/smile-best-who-smile-last;1.0;['tensorflow', 'skimage', 'keras', 'pillow'];['ner', 'ai', 'cv', 'nn', 'ml'];['train', 'recognition', 'model', 'epoch', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'resnet'];https://www.kaggle.com/c/recognizing-faces-in-the-wild;0.645;0.268;2020-12-13 16:27:41;multiple data sources;['gpu'];Smile best who smile last;Python notebook;988.0;7;;
2020-05-04 13:29:09;DeepFaceDeepFace is a lightweight face recognition and facial attribute analysis package for Python. You can apply facial analysis with just a few lines of code. It is fully open source and available on PyPI. All you need is to call pip install deepface command. It supports the most popular face recognition models including VGG-Face, Google FaceNet, OpenFace, Facebook DeepFace. Besides, it can analyze facial attributes such as emotion, age, gender and race prediction as well in its facial attribute analysis module. Wide documentation is available at its GitHub repo: https://github.com/serengil/deepface There are many ways to support a project - starring⭐️ it is just one.;Apache 2.0;https://www.kaggle.com/serengil/deepface-framework-for-python;1.0;['tensorflow', 'openface'];['ai', 'rl', 'nn', 'cv'];['train', 'recognition', 'model', 'vgg', 'predict'];https://www.kaggle.com/c/recognizing-faces-in-the-wild;0.696;0.268;2020-12-13 16:27:41;Northeastern SMILE Lab - Recognizing Faces in the Wild;['deep learning'];DeepFace Framework for Python;Python notebook;2805.0;7;;
2019-08-07 19:27:47;This notebook got 77.20% accuracy as a public score. Besides, it has a 72.62% accuracy on training set, 70.90% accuracy on validation set and 70.95% accuracy on cross validation set. We can clearly say that it is a generalized model and it is not over-fitted! I have used 3 different face recognition models: VGG-Face, Facenet and OpenFace. These models find the embeddings of faces. Finding distances between embeddings can give a clue to find related ones. Herein, I included both cosine or euclidean distances as a feature. I expect that GBM classifier would find the weights for these models and metrics. I also added some additional features such as age, gender and emotion. Besides, only related ones are shared as a training set. I've generated data for unrelated ones and store in the file 'train_true_negative_features.csv'. On the other hands, related ones are stored in 'train_true_positive_features.csv' whereas test set is stored in 'testset_features.csv'. You can directly load these files and skip preprocessing steps. If you wonder how these similarities calculated, the following links might help you. Face Recognition models: VGG-Face: https://sefiks.com/2018/08/06/deep-face-recognition-with-keras/ Facenet: https://sefiks.com/2018/09/03/face-recognition-with-facenet-in-keras/ OpenFace: https://sefiks.com/2019/07/21/face-recognition-with-openface-in-keras/ Additional Features: Age and gender: https://sefiks.com/2019/02/13/apparent-age-and-gender-prediction-in-keras/ Emotion: https://sefiks.com/2018/01/01/facial-expression-recognition-with-keras/;Apache 2.0;https://www.kaggle.com/serengil/finding-relative-faces;1.0;['lightgbm', 'sklearn', 'keras', 'openface'];['ner', 'ai', 'gbm', 'rl', 'ml'];['predict', 'train', 'recognition', 'model', 'vgg', 'label', 'loss'];https://www.kaggle.com/c/recognizing-faces-in-the-wild;0.657;0.346;2020-12-13 16:27:41;multiple data sources;['deep learning, gradient boosting'];Finding-Relative-Faces;Python notebook;1241.0;16;0.775;0.773
2019-05-15 13:55:03;Facenet baseline in KerasThis is a very simple baseline with no training required. Instead, we'll use the pretrained Facenet model from this repo https://github.com/nyoki-mtl/keras-facenet . First, we compute the face embeddings for each image in the test set, then we compute the Euclidean distance for each image pair in the test dataframe. Finally, we convert the distance to a probability using cumulative probabilites based on the distribution of the distance itself on the test set.;Apache 2.0;https://www.kaggle.com/suicaokhoailang/facenet-baseline-in-keras-0-749-lb;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['dl', 'ai', 'nn', 'cv'];['train', 'model', 'test data', 'predict'];https://www.kaggle.com/c/recognizing-faces-in-the-wild;0.756;0.495;2020-12-13 16:27:41;multiple data sources;['gpu'];Facenet baseline in Keras;Python notebook;12050.0;94;;
2019-05-25 09:55:28;'You seem familiar' - One-shot approach to tackle kinship problemIn this notebook we are going to solve this kinship problem using the popular one-shot learning approach and build a embedding generator to find the cosine-similarity amongst the images of people from a family. Playing with cosine similarity, we are going to design a model that is able to recognize the people of a family and people related by blood.;Apache 2.0;https://www.kaggle.com/thanatoz/one-shot-method-to-tackle-kinship-problem-keras;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'nn', 'ann'];['train', 'model', 'layer', 'vgg', 'predict', 'relu', 'understanding'];https://www.kaggle.com/c/recognizing-faces-in-the-wild;0.705;0.39;2020-12-13 16:27:41;multiple data sources;['gpu'];One-shot method to tackle kinship problem [Keras];Python notebook;3450.0;26;;
2017-12-13 03:46:55;Hello, I started studying time series one week ago and I am not an expert in machine learning. This is my first kernel! I hope to get feedback, in particular I do not know yet how to interpret the Ljung-Box test on the bottom of this notebook. For this competition I noticed a couple of kernels getting stuck with the number of visitors showing a sudden increase in July 2016. That happens simply because in July 2016 there are more restaurants in the data. For this reason I thought of using the mean of visitors and practice with a seasonal ARIMAX model.;Apache 2.0;https://www.kaggle.com/aless80/sarimax-on-mean-visits;1.0;['statsmodels', 'sklearn', 'pattern'];['ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['machine learning', 'train', 'fitting', 'model', 'label', 'predict'];https://www.kaggle.com/c/recruit-restaurant-visitor-forecasting;0.746;0.45;2020-12-13 16:32:50;Recruit Restaurant Visitor Forecasting;[];SARIMAX on mean visits;Python notebook;9266.0;53;;
2018-02-06 07:15:40;Exhaustive Weather EDA/File OverviewTable of Contents Why Should You Trust Modified Store Info Files? Files: air/hpg_store_info_with_nearest_active_station Files: air/hpg_station_distances Helper: select_stations()   File: feature_manifest Weather Feature Coverage - Visualization Using feature_manifest with air/hpg_station_distances Helpers to Analyze Coverage   It's Gettin' Hot in Here (Station Coverage Heatmaps) Filling in Missing Data Combined Coverages by Prefecture Closest Station Proximity - Visualization Distances Between Identical Stores Files: weather_stations, nearby_active_stations Mapping All Active Stations   Weather Station Background  IntroductionI'll be adding to this kernel continually, as it is absolutely still a work in progress.  My aim in this kernel is to be as detailed as possible. If you'd like a quicker overview, take a look at my other kernel.  If you have any suggestions or catch me screwing up anywhere, I'd truly love to hear about it! Thanks for your time!;Apache 2.0;https://www.kaggle.com/huntermcgushion/exhaustive-weather-eda-file-overview;1.0;['pattern'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nn', 'ann'];['filter', 'fitting', 'model', 'layer', 'label', 'recommend'];https://www.kaggle.com/c/recruit-restaurant-visitor-forecasting;0.72;0.455;2020-12-13 16:32:50;multiple data sources;[];Exhaustive Weather EDA/File Overview;Python notebook;4791.0;56;;
2018-02-06 09:03:45;In addition to the 3 models used in the surpise me 2! script, I have added a feed forward neural network for the prediction of visitors. Update: Took pointers from @aharless kernel: https://www.kaggle.com/aharless/exclude-same-wk-res-from-nitin-s-surpriseme2-w-nn;Apache 2.0;https://www.kaggle.com/nitinsurya/surprise-me-2-neural-networks-keras;1.0;['tensorflow', 'xgboost', 'sklearn', 'keras'];['ner', 'ai', 'rl', 'cv', 'nn'];['activation function', 'test data', 'neuron', 'train', 'model', 'output layer', 'neural network', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'hidden layer'];https://www.kaggle.com/c/recruit-restaurant-visitor-forecasting;0.749;0.46;2020-12-13 16:32:50;Recruit Restaurant Visitor Forecasting;['neural networks, ensembling'];Surprise Me 2! Neural Networks(keras);Python notebook;10103.0;60;0.52464;0.48196
2018-02-08 14:24:05;This is an inperfect implimentation of the 1st solution of Porto Seguro competition. https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/discussion/44629 This is not as a strong model as the original. But still it's useful to mix in ensemble. score of models trained at my local model name /local CV/public LB/private LB nr2/0.501/0.487/0.559 nr3/0.501/0.486/0.557 nr5/0.503/0.490/0.541 nr6/0.468/0.492/0.557 Model size is reduced for kernel.;Apache 2.0;https://www.kaggle.com/osciiart/denoising-autoencoder;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'rl', 'cv', 'nn'];['autoencoder', 'test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'rank', 'relu'];https://www.kaggle.com/c/recruit-restaurant-visitor-forecasting;0.734;0.418;2020-12-13 16:32:50;Recruit Restaurant Visitor Forecasting;[];Denoising Autoencoder;Python notebook;6757.0;36;0.53993;0.51404
2017-12-06 18:39:42;In this notebook I'll try the approach, which discovered in one tutorial about multivariate time series forecasting using LSTM.;Apache 2.0;https://www.kaggle.com/yekenot/explore-ts-with-lstm;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'nn', 'ml'];['regression', 'train', 'model', 'neural network', 'epoch', 'layer', 'loss', 'label', 'lstm', 'predict', 'supervised learning'];https://www.kaggle.com/c/recruit-restaurant-visitor-forecasting;0.745;0.473;2020-12-13 16:32:50;Recruit Restaurant Visitor Forecasting;[];Explore TS with LSTM;Python notebook;9122.0;71;;
2019-07-14 16:57:10;Visualizing batch effects with t-SNE.I tried to visualize inherent batch effects of the data with t-SNE. Since each image is a 512*512*6 = 1572864-dimensional vector, separately using all of the pixels as an element of a vector makes t-SNE computation too intensive. To overcome it, I simply took average of the pixel intensities for each of the six channels given for an image, therefore handled a six-dimensional vector for each image. Another thing to note is that as the objective of this kernel is to visualize the batch effects, I only exploited positive and negative control-images to exclude siRNA-related effects.;Apache 2.0;https://www.kaggle.com/apap950419/visualizing-batch-effects-with-t-sne;1.0;['sklearn'];['ai', 'dl', 'ml', 'nn', 'ann'];['train', 'label', 'test data', 'clustering'];https://www.kaggle.com/c/recursion-cellular-image-classification;0.648;0.375;2020-12-13 16:34:09;Recursion Cellular Image Classification;[];Visualizing batch effects with t-SNE;Python notebook;1051.0;22;;
2019-08-05 18:19:30;Some notesThis notebook contains EDA, EfficientNet, and Creating video from training images. Likbez on topic:  Structure of a cell: [en] playlist or [rus] playlist Generation and action of siRNAs and miRNAs:  [en] 7 min video or [rus] 5 min video Brief introduction from rxrx: https://www.rxrx.ai/  Some notes about the data (as i understood them) The images from data are generated by carrying out biological experiments using reagents known as siRNAs. Each images instance has 6 individual channel different organelles of the cells - the nucleus, endoplasmic reticulum, actin cytoskeleton, nucleolus, mitochondria, and golgi apparatus. Each six-channel image is one of the types of cells:  HUVEC RPE HepG2 U2OS  You can view all RGB images from the competition's training data in this video or short videos from each experiment in the output of this kernel.;Apache 2.0;https://www.kaggle.com/bonhart/eda-efficientnet-creating-video-pytorch;1.0;['pytorch', 'pillow'];['ner', 'ai', 'gan', 'cv', 'nn', 'ann'];['training data', 'generation', 'train', 'model', 'epoch', 'layer', 'loss', 'predict', 'classification'];https://www.kaggle.com/c/recursion-cellular-image-classification;0.651;0.375;2020-12-13 16:34:09;multiple data sources;['gpu, beginner, data visualization'];EDA->EfficientNet->Creating video [PyTorch];Python notebook;1120.0;22;0.25593;0.12953
2019-07-24 08:35:31;Citations & Resources Used most of the idea from this kernal  https://www.kaggle.com/xhlulu/aptos-2019-densenet-keras-starter Data used: converted 224x224 sized image from the kernal https://www.kaggle.com/xhlulu/recursion-2019-load-resize-and-save-images;Apache 2.0;https://www.kaggle.com/chandyalex/recursion-cellular-keras-densenet;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cv', 'rl', 'nn', 'ann'];['filter', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/recursion-cellular-image-classification;0.69;0.387;2020-12-13 16:34:09;multiple data sources;['gpu, deep learning, classification'];Recursion Cellular Keras Densenet;Python notebook;2452.0;25;0.24110;0.11306
2019-09-07 19:53:36;Because we know that each plate contains 277 distinct classes, we can boost our predictions by solving the Assignment Problem. This approach can also be combined with predicting which group a plate belongs to (see https://www.kaggle.com/zaharch/keras-model-boosted-with-plates-leak), to narrow the 1108 classes to exactly 277. However, this is left out for simplicity. Uses the Hungarian algorithm to boost results from https://www.kaggle.com/chandyalex/recursion-cellular-keras-densenet (which scores 0.113), and acheives a + 0.016 boost over the baseline.;Apache 2.0;https://www.kaggle.com/christopherberner/hungarian-algorithm-to-optimize-sirna-prediction;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cv', 'nn', 'ann'];['filter', 'train', 'model', 'layer', 'loss', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/recursion-cellular-image-classification;0.64;0.352;2020-12-13 16:34:09;multiple data sources;['gpu'];Hungarian algorithm to optimize sirna prediction;Python notebook;909.0;17;0.27006;0.12999
2019-09-11 10:00:45;Save RGB Images with PytorchMostly taken from Karl Heyer's script linked here This code saves RGB converted versions of all images in the train and test sets. The conversion is done using code from the RXRX1 Utils Repo adapted to Pytorch. Note that since this code saves images, it won't work on Kaggle read only kernels;Apache 2.0;https://www.kaggle.com/darraghdog/simple-experiment-view;1.0;['pytorch'];['ai', 'nn', 'ann', 'rl'];['train'];https://www.kaggle.com/c/recursion-cellular-image-classification;0.633;0.334;2020-12-13 16:34:09;Recursion Cellular Image Classification;[];Simple Experiment View;Python notebook;798.0;14;;
2019-07-09 00:41:36;Welcome to Recursion Cellular Image Classification competition. This starter kernel will guide you though our data and show you how to train a basic model.;Apache 2.0;https://www.kaggle.com/gidutz/starter-kernel-recursion-pharmaceuticals;1.0;['tensorflow', 'keras'];['ner', 'ai', 'nn', 'ann'];['image classification', 'generation', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'recommend', 'classification'];https://www.kaggle.com/c/recursion-cellular-image-classification;0.667;0.357;2020-12-13 16:34:09;Recursion Cellular Image Classification;['gpu'];Starter Kernel Recursion Pharmaceuticals ;Python notebook;1528.0;18;;
2019-08-10 15:23:12;See leak explanation in this post. RPE-03 and HUVEC-07 have the same pattern of controls, but not only… also the treatments are in the same pattern, only the plates are rotated. Now, there is an experiment in the test set that has the same pattern of controls… HUVEC-18. See images below to demonstrate what I said. Does HUVEC-18 also have the same pattern of treatments in some plate rotation?;Apache 2.0;https://www.kaggle.com/giuliasavorgnan/plates-leak-clear-visualization;1.0;['pattern'];['ai'];['train', 'label'];https://www.kaggle.com/c/recursion-cellular-image-classification;0.68;0.439;2020-12-13 16:34:09;Recursion Cellular Image Classification;[];Plates Leak Clear Visualization;Python notebook;1970.0;46;;
2019-09-25 21:53:34;ModelLet's define some helpful modules:  Flatten  Swish   The reason why Swish is not implemented in torch.nn can be found here.;Apache 2.0;https://www.kaggle.com/hmendonca/fold1h4r3-arcenetb4-2-256px-rcic-lb-0-9759;1.0;['pytorch', 'albumentations', 'tensorflow', 'sklearn'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'ml', 'nn', 'rnn', 'ann'];['filter', 'training data', 'test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/recursion-cellular-image-classification;0.683;0.45;2020-12-13 16:34:09;multiple data sources;['gpu'];Fold1h4r3 ArcENetB4/2 256px RCIC;Python notebook;2127.0;53;0.97590;0.94335
2019-09-17 23:16:47;Stacking the Best Models This Kernel shows how the scores can be improved using Stacking Method. Credit Goes to the following kernels ref: 1. https://www.kaggle.com/zaharch/keras-model-boosted-with-plates-leak 2. https://www.kaggle.com/xhlulu/recursion-2-headed-efficientnet-2-stage-training 3. https://www.kaggle.com/antgoldbloom/doing-inference-using-google-automl;Apache 2.0;https://www.kaggle.com/roydatascience/cellular-stacking-1-5;1.0;['keras'];['ner', 'ai', 'automl', 'ml'];['filter', 'train', 'model', 'label', 'predict', 'rank', 'classification'];https://www.kaggle.com/c/recursion-cellular-image-classification;0.695;0.4;2020-12-13 16:34:09;multiple data sources;[];Cellular Stacking 1.5;Python notebook;2758.0;29;0.31304;0.16384
2019-09-14 03:16:13;BEFORE YOU FORK, PLEASE SUPPORT AND UPVOTE;Apache 2.0;https://www.kaggle.com/tanlikesmath/rcic-fastai-starter;1.0;['pytorch', 'tensorflow', 'sklearn'];['ner', 'ai', 'dl', 'cnn', 'cv', 'ml', 'nn', 'ann'];['image classification', 'training data', 'generation', 'train', 'model', 'epoch', 'loss', 'label', 'predict', 'resnet', 'classification'];https://www.kaggle.com/c/recursion-cellular-image-classification;0.713;0.482;2020-12-13 16:34:09;Recursion Cellular Image Classification;['gpu, beginner, deep learning, +1 moreclassification'];RCIC fastai starter;Python notebook;4103.0;79;0.36903;0.19341
2019-08-19 02:43:33;"About this kernelThis is a rather quick and dirty kernel I created, with two ideas in mind: Training a ""2-headed"" network that will learn to predict siRNA using images from both sites at the same time, and split the learning process into two stages, namely first training on all data, then training the CNN on data from a single experiment at a time. The second idea comes from this thread by Phalanx. The data comes from my previous kernel on preprocessing. Here are the relevant sections:  Data Generator: The __generate_X method is pretty different, since it loads two images at the same time. Everything else is standard Model: The CNN architecture used here is EfficientNetB2. With the right learning rates and enough time, you can probably try B1-B5; they have unfortunately not succeeded in my case. The inputs are two images, i.e. from site 1 and site 2. The two images are passed through the same CNN, then global-average-pooled, and added to form a single 1280-dimensional vector, which is ultimately used to perform predictions. This means that the networks will be updated simultaneously from the gradients of both sites. Phase 1: Train the model on all data from 10 epochs, and save results to model.h5. Phase 2: Load model.h5 and train the model for 15 epochs on data from a single cell line, i.e. HEPG2, HUVEC, RPE, U2OS.  Changelog V20: Added random flipping.";Apache 2.0;https://www.kaggle.com/xhlulu/recursion-2-headed-efficientnet-2-stage-training;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cnn', 'cv', 'nn', 'ann'];['train', 'model', 'epoch', 'layer', 'loss', 'predict', 'classification'];https://www.kaggle.com/c/recursion-cellular-image-classification;0.72;0.427;2020-12-13 16:34:09;multiple data sources;['gpu, deep learning, classification, +1 morecnn'];Recursion: 2-headed EfficientNet, 2-stage training;Python notebook;4818.0;40;;
2019-08-06 02:12:45;As reported by Recursion in this post, there is a special structure in the data which simplifies predictions significantly. Assignments of sirnas to plates is not completely random in this competition. In this kernel, first I show it on the train data, and then apply the leak on the pretrained Keras model (kudos to Alex) with LB 0.113 to get score 0.207. Same model which uses 2 sites for inference gets LB score 0.231 (the original model uses only one site but I just can't hold myself on that).;Apache 2.0;https://www.kaggle.com/zaharch/keras-model-boosted-with-plates-leak;1.0;['tensorflow', 'keras'];['ner', 'ai', 'nlu', 'cv', 'nn'];['training data', 'test data', 'train', 'model', 'layer', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/recursion-cellular-image-classification;0.736;0.507;2020-12-13 16:34:09;multiple data sources;['gpu'];Keras model boosted with plates leak;Python notebook;7230.0;110;0.41409;0.23109
2019-02-07 08:27:54;CONTENTS  Reducing the memory usage Dealing with unbalanced data, using relevant evaluated measures Select the optimal classifier using classifiers' competition;Apache 2.0;https://www.kaggle.com/adamdc/classifiers-competition-for-unbalanced-data;1.0;['lightgbm', 'sklearn'];['cv', 'ai', 'nn', 'gbm'];['training data', 'train', 'model', 'loss', 'label', 'predict', 'classification'];https://www.kaggle.com/c/reducing-commercial-aviation-fatalities;0.584;0.152;2020-12-13 16:35:26;Reducing Commercial Aviation Fatalities;['gpu'];Classifiers' Competition for Unbalanced Data;Python notebook;348.0;2;;
2019-02-06 08:14:01;Starter Code : EDA and LGBM Baseline;Apache 2.0;https://www.kaggle.com/ashishpatel26/smote-with-model-lightgbm;1.0;['tensorflow', 'lightgbm', 'sklearn'];['ai', 'gbm', 'rl', 'nn', 'ann'];['filter', 'train', 'model', 'validation data', 'loss', 'label', 'gradient boosting', 'predict'];https://www.kaggle.com/c/reducing-commercial-aviation-fatalities;0.706;0.411;2020-12-13 16:35:26;Reducing Commercial Aviation Fatalities;['beginner, data visualization, exploratory data analysis, +1 moreindia'];Solved Imbalance With Model Lightgbm;Python notebook;3502.0;33;;
2019-01-19 02:07:28;INTRODUCTION Dans cet ensemble de données, vous disposez de données physiologiques réelles provenant de dix-huit pilotes qui ont été soumis à divers événements perturbateurs. L'ensemble de formation de référence comprend un ensemble d'expériences contrôlées collectées dans un environnement autre que le vol, à l'extérieur d'un simulateur de vol. L'ensemble de test (abrégé LOFT= entraînement au vol orienté ligne) consiste en un vol complet (décollage, vol et atterrissage) dans un simulateur de vol. Les pilotes ont expérimenté des distractions destinées à induire l’un des trois états cognitifs suivants: L'attention canalisée (AC) est, grosso modo, le fait d'être concentré sur une tâche à l'exclusion de toutes les autres. Cela est induit dans l’analyse comparative par le fait que les sujets jouent un jeu vidéo captivant basé sur un puzzle. L'attention détournée (AD) est le fait de faire détourner son attention par des actions ou des processus de pensée associés à une décision. Ceci est induit par le fait que les sujets effectuent une tâche de surveillance d'affichage. Périodiquement, un problème mathématique apparaissait qu'il fallait résoudre avant de revenir à la tâche de surveillance. La surprise ou le sursaut (SS) est provoquée par le fait que les sujets regardent des clips avec des craintes de saut. Pour chaque expérience, une paire de pilotes (chacun avec son propre crewidentifiant) a été enregistrée au fil du temps et soumise aux états cognitifs CA, DA ou SS. L'ensemble de formation contient trois expériences (une pour chaque État) dans lesquelles les pilotes ont expérimenté un seul de ces États. Par exemple, dans l' experimentautorité de certification =, les pilotes étaient dans un état de base (aucun événement) ou dans l'état de l'autorité de certification. L'ensemble d'essai contient une simulation de vol complète au cours de laquelle les pilotes peuvent expérimenter n'importe lequel des états (mais jamais plus d'un à la fois). Le but de cette compétition est de prédire la probabilité de chaque état pour chacun timedes ensembles de test. Chaque capteur fonctionnait à une fréquence d'échantillonnage de 256 Hz. Veuillez noter que puisqu'il s'agit de données physiologiques provenant de personnes réelles, il y aura du bruit et des artefacts dans les données. Champs de données Les variables avec le eegpréfixe sont des enregistrements électroencéphalographiques. id- (test.csv et sample_submission.csv uniquement) Identifiant unique pour une combinaison équipage + heure. Vous devez prévoir les probabilités pour chacun id. crew- un identifiant unique pour une paire de pilotes. Il y a 9 équipages dans les données. experiment- L' un des CA, DA, SSou LOFT. Les 3 premiers constituent l’ensemble d’entraînement. Ce dernier la série de test. time - secondes dans l'expérience seat - le pilote est-il assis à gauche (0) ou à droite (1) eeg_fp1 eeg_f7 eeg_f8 eeg_t4 eeg_t6 eeg_t5 eeg_t3 eeg_fp2 eeg_o1 eeg_p3 eeg_pz eeg_f3 eeg_fz eeg_f4 eeg_c4 eeg_p4 eeg_poz eeg_c3 eeg_cz eeg_o2 ecg- Signal d'électrocardiogramme à 3 points. Le capteur avait une résolution / bit de 0,012215 µV et une plage de -100 mV à + 100 mV. Les données sont fournies en microvolts. r- La respiration, une mesure de la montée et de la chute de la poitrine. Le capteur avait une résolution / bit de 0,2384186 µV et une plage de -2,0V à + 2,0V. Les données sont fournies en microvolts. gsr- Réponse galvanique de la peau, une mesure de l'activité électrodermale. Le capteur avait une résolution / bit de 0,2384186 µV et une plage de -2,0V à + 2,0V. Les données sont fournies en microvolts. event- L’état du pilote à l’heure donnée: un de A= base, B= SS, C= CA, D= DA;Apache 2.0;https://www.kaggle.com/mahmoud86/eda-rdf-boosting-kn;1.0;['xgboost'];['ner', 'ai', 'gbm', 'cv', 'nn', 'ml'];['filter', 'test data', 'train', 'model', 'support vector machines', 'label', 'k-nearest neighbor', 'gradient boosting', 'predict', 'random forest'];https://www.kaggle.com/c/reducing-commercial-aviation-fatalities;0.623;0.214;2020-12-13 16:35:26;Reducing Commercial Aviation Fatalities;[];pilote;R notebook;671.0;4;;
2018-12-28 23:04:50;Question:the test experiment field only contains 'loft';Apache 2.0;https://www.kaggle.com/plarmuseau/fork-of-aviation-second-tempt;1.0;['lightgbm', 'sklearn'];['ai', 'rl', 'gbm'];['predict', 'train', 'model', 'label', 'loss'];https://www.kaggle.com/c/reducing-commercial-aviation-fatalities;0.639;0.214;2020-12-13 16:35:26;Reducing Commercial Aviation Fatalities;[];Fork of aviation second tempt;Python notebook;889.0;4;;
2019-01-17 14:50:21;More examples and documentation are on site: https://imbalanced-learn.readthedocs.io/en/stable/user_guide.html;Apache 2.0;https://www.kaggle.com/sarmat/imbalance-learning-examples;1.0;['tensorflow', 'sklearn'];['ai', 'nn', 'ml'];['train', 'label'];https://www.kaggle.com/c/reducing-commercial-aviation-fatalities;0.589;0.188;2020-12-13 16:35:26;Reducing Commercial Aviation Fatalities;['beginner, data visualization, feature engineering'];Imbalance learning examples;Python notebook;376.0;3;;
2019-01-18 17:13:10;Introduction to physiological dataIn this example, we're given three main physiological parameters:  Respiration Electrocardiogram (ECG) Electroencephalogram (EEG)  We'll talk through each of these in turn, some of their limitations, and how to process the data. I'm not going to talk about the galvanic skin response because it's use is, suffice to say, controversial. A short note on noise sourcesBiological sensors are quite susceptible to noise from outside sources. This can include lights (flickering at 50/60Hz depending on your AC frequency), and other electrical equipment. I think it's reasonable to assume that this experiment was in a chamber with a tonne of unshielded electronic high-tech stuff, all leaking noise at various frequencies. Hopefully this would be consistent between recordings, but it does make analysis more challenging, since removing any noise will usually remove a bit of signal too. RespirationThis is a simple measure of the rise and fall of the chest. It represents muscle activity of the diapragm and abdomen. We know that when someone is physiologically stressed, this rate increases. Could be interesting. Unfortunately, when we plot this data out, it seems to be largely affected by noise.;Apache 2.0;https://www.kaggle.com/stuartbman/introduction-to-physiological-data;1.0;['pattern'];['ai', 'dl', 'rl', 'nn', 'ann'];['train', 'label', 'filter', 'layer'];https://www.kaggle.com/c/reducing-commercial-aviation-fatalities;0.7;0.397;2020-12-13 16:35:26;Reducing Commercial Aviation Fatalities;['data cleaning, medicine, signal processing'];Introduction to physiological data;Python notebook;3069.0;28;;
2019-02-02 16:16:14;Starter Code : EDA and LGBM Baseline;Apache 2.0;https://www.kaggle.com/theoviel/starter-code-eda-and-lgbm-baseline;1.0;['lightgbm', 'sklearn'];['ai', 'gbm', 'rl', 'nn', 'ann'];['filter', 'train', 'model', 'validation data', 'loss', 'label', 'gradient boosting', 'predict'];https://www.kaggle.com/c/reducing-commercial-aviation-fatalities;0.732;0.467;2020-12-13 16:35:26;Reducing Commercial Aviation Fatalities;['exploratory data analysis, gradient boosting'];Starter Code : EDA and LGBM Baseline ;Python notebook;6573.0;65;;
2019-09-14 13:02:38;Kaggle ScoresTop Scores XGBOOSTING Score :  1885869.33899  RMSE  with  XGBOOSTING regressor 09/09/2019 RandomForestScore : 1769240.65800  RMSE with RandomForest regressor 10/09/2019  Update Notes9/11/2019 Removing Outliers reduced the Training error to 0.17, yet increased the kaggle score to 1.8e6, which probably means that the number of resutrants making more than 1e7 is more frequently showing up in the test dataset, on contrary to their occurance in the training datase  Column City seems to have slight effect on Kaggle RMSE  fixed some Keras code error, Keras makes INF predictions ..... HOLLY MOLLY;Apache 2.0;https://www.kaggle.com/ahayek84/restaurant-revenue-predict;1.0;['tensorflow', 'xgboost', 'sklearn', 'keras'];['ai', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'regression', 'training data', 'train', 'test data', 'model', 'neural network', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/restaurant-revenue-prediction;0.721;0.4;2020-12-13 16:39:10;Restaurant Revenue Prediction;[];restaurant-revenue-predict;Python notebook;5001.0;29;;
2020-11-05 04:09:15;Restaurant Revenue PredictionModels used:  Lasso & Ridge Regression ElasticNet KNN Regressor Random Forest Light GBM XGBoost Ensembling;Apache 2.0;https://www.kaggle.com/allenkong/restaurant-revenue-prediction;1.0;['xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'nn'];['regression', 'train', 'fitting', 'model', 'label', 'k-nearest neighbor', 'predict', 'random forest'];https://www.kaggle.com/c/restaurant-revenue-prediction;0.64;0.302;2020-12-13 16:39:11;Restaurant Revenue Prediction;['feature engineering, random forest, xgboost, +2 moreensembling, lightgbm'];Restaurant Revenue Prediction;Python notebook;911.0;10;1741680.77896;1683846.79538
2018-07-07 09:11:19;"Final Project for CMPE 343-Business Intelligence and Applied AnalyticsIn this project we used the Kaggle Competition https://www.kaggle.com/c/restaurant-revenue-predictionContents Pre-Processing  Classification  Standartizaiton  PCA  RBF RandomForestRegressor is used to predict ""revenues"" Score of worst model Conclution";Apache 2.0;https://www.kaggle.com/celikagit/revenue-prediction-using-random-forest-regressor;1.0;['sklearn'];['ai', 'nn'];['machine learning', 'random forest', 'regression', 'train', 'fitting', 'model', 'label', 'predict', 'linear regression', 'classification'];https://www.kaggle.com/c/restaurant-revenue-prediction;0.788;0.236;2020-12-13 16:39:11;Restaurant Revenue Prediction;[]; Revenue Prediction using Random Forest Regressor;Python notebook;31230.0;5;;
2017-10-05 07:01:53;Check for Missing values and plot for each column;Apache 2.0;https://www.kaggle.com/tarunsingh/restaurant-revenue-prediction;1.0;['sklearn'];['ai', 'nn', 'ann', 'cv'];['filter', 'test data', 'regression', 'train', 'model', 'label', 'predict', 'linear regression'];https://www.kaggle.com/c/restaurant-revenue-prediction;0.731;0.311;2020-12-13 16:39:11;Restaurant Revenue Prediction;[];Restaurant Revenue Prediction;Python notebook;6336.0;11;;
2018-09-20 10:44:10;Reference:  XGBoost documentation  Model documentation 1st place XGBoost Feature Importance Rossmann Sales Top1%;Apache 2.0;https://www.kaggle.com/danspace/rossmann-store-sales-xgboost;1.0;['xgboost', 'sklearn'];['ai', 'nn', 'ann', 'rl'];['regression', 'train', 'model', 'label', 'predict', 'linear regression', 'random forest'];https://www.kaggle.com/c/rossmann-store-sales;0.741;0.393;2020-12-13 16:46:28;Rossmann Store Sales;['gpu'];rossmann store sales xgboost;Python notebook;8099.0;27;0.11586;0.10441
2017-07-19 13:33:32;Time Series Analysis and Forecasting with ProphetGoal:  Explore the data (ECDF, handle missing values etc). Analysis per store type and correlational analysis of stores activity. Perform extensive Time Series Analysis (seasonal decomposition, trends, autocorrelation). Predict next 6 weeks of sales using Prophet (Facebook methodology).;Apache 2.0;https://www.kaggle.com/elenapetrova/time-series-analysis-and-forecasts-with-prophet;1.0;['statsmodels', 'pattern'];['ner', 'ai', 'dl', 'rl', 'nn', 'ann'];['filter', 'regression', 'train', 'fitting', 'model', 'label', 'predict', 'linear regression'];https://www.kaggle.com/c/rossmann-store-sales;0.809;0.587;2020-12-13 16:46:28;Rossmann Store Sales;[]; Time Series Analysis and Forecasts with Prophet;Python notebook;62782.0;365;;
2020-07-26 19:34:10;"InceptionV3 (previously ResNet50) Keras baseline modelThis notebook takes you through some important steps in building a deep convnet in Keras for multilabel classification of brain CT scans. Update (1):  training for 4 epochs instead of 3. batch size lowered to 16 from 32. training without learning rate decay. Weighted BCE instead of ""plain"" BCE training data lowered to 80% from 90%.  Update (2):  adding competition metric for training using custom Callback for validation and test sets instead of the run() function and 'global epochs' training with ""plain"" BCE again merging TestDataGenerator and TrainDataGenerator into one adding undersampling (see inside on_epoch_end), will now run 6 epochs  Update (3):  skipping/removing windowing (value clipping), but the transformation to Hounsfield Units is kept removing initial layer (doing np.stack((img,)*3, axis=-1)) instead reducing learning rate to 5e-4 and add decay increasing batch size to 32 from 16 Increasing training set to 90% of the data (10% for validation) slight increase in undersampling fixed some hardcoding for input dims/sizes training with weighted BCE again  Update (4):  Trying out InceptionV3, instead of ResNet50 undersampling without weights adding dense layers with dropout before output clipping HUs between -50 and 450 (probably the most relevant value-space?) normalization is now mapping input to 0 to 1 range, instead of -1 to 1. doing 5 epochs instead of 6  Update (5):  Got some inspiration from this great kernel by Ryan Epp Thus I'm trying out the sigmoid (brain + subdural + bone) to see if it improves the log loss Number of epochs reduced to 4, increased undersampling, and validation predictions removed due to limited time  Update (6) (did not improve from (5)):  Going back to raw HUs (with a bit of clipping) Together with a first initial conv layer with sigmoid activation epochs increased to 6 from 4, and input size increased to (256, 256) from (224, 224) simple average of epochs (>1) for the test predictions  Update (7):  Trying windowing based on appian42's repo instead I also include some cleaning based on Jeremy's kernel (hopefully it's correct, atleast the visualization looked good =) weighted average of the epochs (>1) for the test predictions reducing number of epochs to 5  Update (8):  Removing the extra dense layer before output layer (keeping everything else the same)";Apache 2.0;https://www.kaggle.com/akensert/rsna-inceptionv3-keras-tf1-14-0;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cv', 'nn', 'ann'];['training data', 'generation', 'train', 'model', 'output layer', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'resnet', 'classification'];https://www.kaggle.com/c/rsna-intracranial-hemorrhage-detection;0.781;0.557;2020-12-13 16:47:30;RSNA Intracranial Hemorrhage Detection;[];[RSNA] InceptionV3 Keras + TF1.14.0;Python notebook;25057.0;226;;
2019-10-26 11:01:42;Hey Kaggler!This is part 2 of my eda-baseline exploration of the intracranial hemorrhage detection competition. It covers the implementation of preprocessing and data loading as well as the modelling part. Just jump into it! :-)  If you like to more about dicom, go back to the first part: https://www.kaggle.com/allunia/rsna-ih-detection-eda Table of contents Prepare to start Building up the bruteforce model Image preprocessing Custom Dataloader Preparing the dataframe Exploring train and test images Building up the brutforce model Speeding up & dealing with class imbalance Validation strategy Let it run! :-)   Building up the any-subtype network The custom loss A two output layer network;Apache 2.0;https://www.kaggle.com/allunia/rsna-ih-detection-baseline;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cnn', 'rl', 'nn', 'ann'];['filter', 'training data', 'test data', 'train', 'model', 'output layer', 'neural network', 'epoch', 'deep learning', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'resnet'];https://www.kaggle.com/c/rsna-intracranial-hemorrhage-detection;0.749;0.523;2020-12-13 16:47:30;multiple data sources;['gpu'];RSNA IH Detection Baseline;Python notebook;10147.0;138;;
2019-10-02 21:32:25;What is intracranial hemorrhage?Hmm, let's watch a video! :-);Apache 2.0;https://www.kaggle.com/allunia/rsna-ih-detection-eda;1.0;['sklearn', 'tensorflow', 'pattern', 'keras', 'skimage'];['ner', 'ai', 'rl', 'ml', 'nn', 'ann'];['filter', 'test data', 'train', 'model', 'vgg', 'loss', 'label', 'predict', 'understanding', 'resnet'];https://www.kaggle.com/c/rsna-intracranial-hemorrhage-detection;0.77;0.564;2020-12-13 16:47:30;multiple data sources;['beginner, exploratory data analysis'];RSNA IH Detection - EDA;Python notebook;18011.0;252;;
2019-10-07 02:26:41;"IntroductionThis is a simple fork of my previous kernel (https://www.kaggle.com/taindow/pytorch-efficientnet-b0), except here we make use of ResNeXt and ""weakly supervised pre-training"" as opposed to EfficientNet. See https://github.com/facebookresearch/WSL-Images for model information. Note due to the number of parameters a single sweep of the data will take approx. 4-5h.";Apache 2.0;https://www.kaggle.com/braquino/pytorch-resnext-32x8d-centercrop;1.0;['pytorch', 'albumentations'];['ai', 'dl', 'cv', 'rl', 'nn', 'rnn'];['test data', 'train', 'model', 'epoch', 'layer', 'label', 'loss'];https://www.kaggle.com/c/rsna-intracranial-hemorrhage-detection;0.736;0.489;2020-12-13 16:47:30;multiple data sources;['gpu'];Pytorch ResNeXt 32x8d CenterCrop;Python notebook;7143.0;87;0.00000;0.00000
2019-10-18 07:57:54;It's really handy to have all the DICOM info available in a single DataFrame, so let's create that! In this notebook, we'll just create the DICOM DataFrames. To see how to use them to analyze the competition data, see this followup notebook. First, we'll install the latest versions of pytorch and fastai v2 (not officially released yet) so we can use the fastai medical imaging module.;Apache 2.0;https://www.kaggle.com/jhoward/creating-a-metadata-dataframe-fastai;1.0;['pytorch'];['dl', 'nlp', 'ai', 'nn'];['train', 'label'];https://www.kaggle.com/c/rsna-intracranial-hemorrhage-detection;0.725;0.508;2020-12-13 16:47:30;RSNA Intracranial Hemorrhage Detection;['exploratory data analysis'];Creating a metadata DataFrame (fastai);Python notebook;5418.0;112;;
2019-10-18 16:29:06;In this notebook we're going to explore the important issue of windowing from a rather different direction to what you've probably seen before... and will show you a new way to handle DICOM pixel rescaling that might just give your models a boost! We'll be using the fastai.medical.imaging library here - for more information about this see the notebook Some DICOM gotchas to be aware of.;Apache 2.0;https://www.kaggle.com/jhoward/don-t-see-like-a-radiologist-fastai;1.0;['pattern'];['ner', 'ai', 'dl', 'cv', 'rl', 'nlp', 'nn', 'ann'];['train', 'model', 'neural network', 'deep learning', 'label'];https://www.kaggle.com/c/rsna-intracranial-hemorrhage-detection;0.765;0.556;2020-12-13 16:47:30;multiple data sources;['data visualization, exploratory data analysis'];DON'T see like a radiologist! (fastai);Python notebook;15665.0;224;;
2019-10-18 07:58:26;Let's explore the data, taking advantage of the features of the fastai.medical.imaging library, available in the prerelease of fastai v2. If you're interested in learning more about fastai v2, check out the dedicated forum. For a deep dive, have a look at the 10 fastai v2 code walkthru videos. The overall approach in the library is described in detail (and many parts implememted from scratch) in the course Deep Learning from the Foundations. Since this is a prerelease, it's not installed on Kaggle yet, so we'll install it and import the necessary modules.;Apache 2.0;https://www.kaggle.com/jhoward/some-dicom-gotchas-to-be-aware-of-fastai;1.0;['pytorch'];['ner', 'ai', 'dl', 'gan', 'rl', 'nlp', 'nn', 'ann'];['train', 'model', 'deep learning', 'label', 'recommend'];https://www.kaggle.com/c/rsna-intracranial-hemorrhage-detection;0.767;0.536;2020-12-13 16:47:30;multiple data sources;['exploratory data analysis'];Some DICOM gotchas to be aware of (fastai);Python notebook;16559.0;166;;
2019-09-28 23:26:16;First Impression about this RSNA Intracranial Hemorrhage </div>  Bleeding, also called hemorrhage, is the name used to describe blood loss. It can refer to blood loss inside the body, called internal bleeding, or to blood loss outside of the body, called external bleeding. In this we are working with 4 types and another any  1_epidural intraparenchymal intraventricular subarachnoid subdural any I hope this kernel helpful and some UPVOTES would be very much appreciated;Apache 2.0;https://www.kaggle.com/marcovasquez/basic-eda-data-visualization;1.0;['tensorflow', 'keras'];['ner', 'ai', 'dl', 'rl'];['train', 'model', 'layer', 'label', 'loss'];https://www.kaggle.com/c/rsna-intracranial-hemorrhage-detection;0.788;0.602;2020-12-13 16:47:30;RSNA Intracranial Hemorrhage Detection;['data visualization, image data, computer vision'];Basic EDA +  Data Visualization 🧠  ;Python notebook;30574.0;467;;
2020-03-29 11:56:44;MY PLAN Using subset of the full data but with bit large image size 256x256 Trying efficientnet (reason described below) Replacing batch normalization with group normalization for small batch size using radam instead of sgd or adam little bit of preprocessing;Apache 2.0;https://www.kaggle.com/mobassir/keras-efficientnetb4-for-intracranial-hemorrhage;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cnn', 'cv', 'rl', 'ml', 'nn', 'ann'];['machine learning', 'object detection', 'train', 'model', 'epoch', 'deep learning', 'layer', 'loss', 'label', 'predict', 'computer vision', 'recommend', 'resnet', 'relu'];https://www.kaggle.com/c/rsna-intracranial-hemorrhage-detection;0.695;0.472;2020-12-13 16:47:30;multiple data sources;['gpu'];keras Efficientnetb4 for Intracranial Hemorrhage;Python notebook;2770.0;70;;
2019-11-15 09:03:22;"This competition provides an exciting and challenging task of doing multi-label classification on a dataset with well over half a million images. There are multiple very nice notebooks which perform only 2 or 3 epochs with all the training data. In this notebook I will try out and see what the effect is of using more epochs but less steps per epoch. By averaging the predictions made during the last few epochs we should be able to achieve a nice LB score. This also should provide some alternative ways to experiment for the Kagglers that don't have the adequate computing resources available and are dependent on Kaggle Kernels. As model I will be using the EfficientNet B2 model. It should be able to provide highly accurate predictions while still being able to run within the kernel limits. With 9 hours max time for a GPU kernel you have to make some trade-offs ;-) I hope this kernel will be usefull and may'be will provide you with some new and alternative ideas to try out. If you like it..then please upvote it ;-) Any feedback or remarks are appreciated. Lets start by importing all the necessary modules. Note!! This kernel is now updated for Stage2 Training and Test data..altough with less epochs because of the increase in train and test data.";Apache 2.0;https://www.kaggle.com/rsmits/keras-efficientnet-b2-starter-code;1.0;['tensorflow', 'keras', 'pillow'];['ner', 'ai', 'cv', 'rl', 'ml', 'nn', 'ann'];['training data', 'test data', 'generation', 'train', 'fitting', 'model', 'epoch', 'validation data', 'layer', 'loss', 'label', 'predict', 'classification'];https://www.kaggle.com/c/rsna-intracranial-hemorrhage-detection;0.744;0.489;2020-12-13 16:47:30;RSNA Intracranial Hemorrhage Detection;['gpu, deep learning, classification'];Keras EfficientNet B2 Starter code;Python notebook;8924.0;87;0.06800;0.83814
2019-09-28 21:59:52;IntroductionUsing mixed precision along with efficientnet-b0 and a little bit of pre-processing, a single pass of the entire 670k image dataset should take approx. 45m (at 224x224 resolution).;Apache 2.0;https://www.kaggle.com/taindow/pytorch-efficientnet-b0-benchmark;1.0;['pytorch', 'albumentations'];['ai', 'dl', 'cv', 'rl', 'nn', 'rnn'];['test data', 'train', 'model', 'epoch', 'layer', 'label', 'loss'];https://www.kaggle.com/c/rsna-intracranial-hemorrhage-detection;0.729;0.478;2020-12-13 16:47:30;multiple data sources;['gpu'];Pytorch EfficientNet B0 Benchmark;Python notebook;6016.0;75;0.00000;0.00000
2019-09-28 15:54:06;"IntroductionThis is a simple fork of my previous kernel (https://www.kaggle.com/taindow/pytorch-efficientnet-b0), except here we make use of ResNeXt and ""weakly supervised pre-training"" as opposed to EfficientNet. See https://github.com/facebookresearch/WSL-Images for model information. Note due to the number of parameters a single sweep of the data will take approx. 4-5h.";Apache 2.0;https://www.kaggle.com/taindow/pytorch-resnext-101-32x8d-benchmark;1.0;['pytorch', 'albumentations'];['ai', 'dl', 'cv', 'rl', 'nn', 'rnn'];['test data', 'train', 'model', 'epoch', 'layer', 'label', 'loss'];https://www.kaggle.com/c/rsna-intracranial-hemorrhage-detection;0.716;0.481;2020-12-13 16:47:30;multiple data sources;['gpu'];Pytorch ResNeXt 32x8d;Python notebook;4432.0;78;0.00000;0.00000
2019-10-15 02:49:52;About this kernelIn this kernel, I go through each steps of the process for building a multi-label classifier in the RSNA Intracranial Hemorrhage competition. I will be only using a subset of the total dataset. Notes V7: I noticed that it takes roughly 1000 seconds to run 2000 iterations. Therefore, I set each batch to be 2000 iterations, so that we can estimate the total running time to be a multiple of 1000 seconds (and at every slice of 2000 iterations, we can get the validation results).;Apache 2.0;https://www.kaggle.com/xhlulu/rsna-intracranial-simple-densenet-in-keras;1.0;['tensorflow', 'keras'];['ner', 'ai', 'cv', 'nn', 'ml'];['training data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'classification'];https://www.kaggle.com/c/rsna-intracranial-hemorrhage-detection;0.743;0.496;2020-12-13 16:47:30;multiple data sources;['gpu'];RSNA Intracranial: Simple DenseNet in Keras;Python notebook;8684.0;95;;
2018-09-05 10:07:11;Approach Firstly a convolutional neural network is used to segment the image, using the bounding boxes directly as a mask.  Secondly connected components is used to separate multiple nodules. Finally a bounding box is simply drawn around every connected component.  Network The network consists of a number of residual blocks with convolutions and downsampling blocks with max pooling. At the end of the network a single upsampling layer converts the output to the same shape as the input.  As the input to the network is 256 by 256 (instead of the original 1024 by 1024) and the network downsamples a number of times without any meaningful upsampling (the final upsampling is just to match in 256 by 256 mask) the final prediction is very crude. If the network downsamples 4 times the final bounding boxes can only change with at least 16 pixels.;Apache 2.0;https://www.kaggle.com/ashishpatel26/chexnet-batch-normalization-hyparameter-tuning;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'nn', 'ann'];['machine learning', 'training data', 'regression', 'neuron', 'train', 'model', 'neural network', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'linear regression', 'classification', 'convolutional neural network', 'propagation'];https://www.kaggle.com/c/rsna-pneumonia-detection-challenge;0.716;0.408;2020-12-13 16:48:20;RSNA Pneumonia Detection Challenge;['gpu, exploratory data analysis, cnn'];ChexNet Batch Normalization Hyparameter Tuning;Python notebook;4461.0;32;0.00000;0.00000
2018-08-28 11:46:25;"RSNA Pneumonia Detection Challenge with ChexNet Why to detetct this Pneumonia accounts for over 15% of all deaths of children under 5 years old internationally. In 2015, 920,000 children under the age of 5 died from the disease.  In the United States,  pneumonia accounts for over 500,000 visits to emergency departments [1] and over 50,000 deaths in 2015 [2], keeping the ailment on the list of top 10 causes of death in the country.  Symptoms to detect Pneumonia The Diagnosis of pneumonia on CXR( is complicated because of a number of other nditions in the lungsuch as uid overload (pulmonary edema), bleeding, volume loss (atelectasis or collapse), lung cancer, or post-radiation or surgical changes.    Characteristics Pneumonia   History Underlying lung disease, contact with individuals having upper or lower respiratory infection, contact with birds/animals.   Causes Bacteria, virus, fungi; aspiration.   Body systems  Respiratory system—lungs.   Clinical symptoms High fever (sometimes with chills and rigors), cough, wheezing, breathing difficulty, chest pain.   Investigations Blood investigations—complete blood count, ESR, sputum examination and culture, chest X-ray, CT scan, bronchoscopy, thoracocentesis, pleural fluid aspiration and culture.   Treatments Appropriate antimicrobial therapy, expectorant, antipyretics and analgesics, oxygen therapy (if required), fluids.  Table References Goal of This competition In this competition, the primary endpoint will be the detection of bounding boxes corresponding to the diagnosis of pneumonia (e.g. lung infection) on chest radiographs, a special 2D high resolution grayscale medical image.  Note that pnuemonia is just one of many possible disease processes that can occur on a chest radiograph, and that any given single image may contain 0, 1 or many boxes corresponding to possible pneumonia locations.  Thanks to this kernel  https://www.kaggle.com/robikscube/eda-lets-detect-pneumonia-explore-lung-images    Data SummaryStage 1 Images - stage_1_train_images.zip and stage_1_test_images.zip images for the current stage. Filenames are also patient names.  Stage 1 Labels - stage_1_train_labels.csv and Stage 1 Sample Submission stage_1_sample_submission.csv Which provides the IDs for the test set, as well as a sample of what your submission should look like  Stage 1 Detailed Info - stage_1_detailed_class_info.csv contains detailed information about the positive and negative classes in the training set, and may be used to build more nuanced models.   File descriptions  stage_1_train.csv - the training set. Contains patientIds and bounding box / target information. stage_1_sample_submission.csv - a sample submission file in the correct format. Contains patientIds for the test set. Note that the sample submission contains one box per image, but there is no limit to the number of bounding boxes that can be assigned to a given image. stage_1_detailed_class_info.csv - provides detailed information about the type of positive or negative class for each image.  Data fields  patientId _- A patientId. Each patientId corresponds to a unique image. x_ - the upper-left x coordinate of the bounding box. y_ - the upper-left y coordinate of the bounding box. width_ - the width of the bounding box. height_ - the height of the bounding box. Target_ - the binary Target, indicating whether this sample has evidence of pneumonia.";Apache 2.0;https://www.kaggle.com/ashishpatel26/chexnet-radiologist-level-pneumonia-detection;1.0;['keras'];['ai', 'nn', 'ann', 'rl'];['train', 'model', 'neural network', 'epoch', 'layer', 'vgg', 'loss', 'label', 'predict', 'resnet', 'convolutional neural network'];https://www.kaggle.com/c/rsna-pneumonia-detection-challenge;0.76;0.458;2020-12-13 16:48:20;RSNA Pneumonia Detection Challenge;['exploratory data analysis, deep learning, classification, +1 morecnn'];CheXNet: Radiologist-Level Pneumonia Detection ;Python notebook;13366.0;58;;
2018-09-03 14:52:39;Mask-RCNN Sample Starter Model for the RSNA Pneumonia Detection Challenge MD.ai. The dataset for this challenge, created on the MD.ai platform in collaboration with the Radiological Society of North America (RSNA), the Society of Thoracic Radiology (STR), the US National Institutes of Health (NIH), and Kaggle. This notebook covers the basics of parsing the competition dataset, training using a detector basd on the Mask-RCNN algorithm for object detection and instance segmentation. Note that the Mask-RCNN detector configuration parameters have been selected to reduce training time for demonstration purposes, they are not optimal. This is based on our deep learning for medical imaging lessons:  Lesson 1. Classification of chest vs. adominal X-rays using TensorFlow/Keras Github Annotator Lesson 2. Lung X-Rays Semantic Segmentation using UNets. Github Annotator  Lesson 3. RSNA Pneumonia detection using Kaggle data format Github Annotator  Lesson 3. RSNA Pneumonia detection using MD.ai python client library Github Annotator   Copyright 2018 MD.ai, Inc. Licensed under the Apache License, Version 2.0;Apache 2.0;https://www.kaggle.com/drt2290078/mask-rcnn-sample-starter-code;1.0;['tensorflow', 'keras'];['ner', 'ai', 'cnn', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'training data', 'test data', 'object detection', 'train', 'model', 'epoch', 'deep learning', 'layer', 'validation data', 'loss', 'label', 'predict', 'resnet', 'classification', 'ground truth'];https://www.kaggle.com/c/rsna-pneumonia-detection-challenge;0.788;0.506;2020-12-13 16:48:20;RSNA Pneumonia Detection Challenge;['gpu'];Mask-RCNN Sample Starter Code ;Python notebook;30853.0;109;;
2018-10-22 18:04:47;RSNA Pneumonia Detection Challenge Sociedade Beneficente de Senhoras - Hospital Sírio-Libanês - Brazil;Apache 2.0;https://www.kaggle.com/eduardomineo/u-net-lung-segmentation-montgomery-shenzhen;1.0;['tensorflow', 'keras'];['ner', 'ai', 'cv', 'rl', 'nn', 'ann'];['image segmentation', 'test data', 'generation', 'train', 'fitting', 'model', 'neural network', 'epoch', 'layer', 'loss', 'predict', 'relu', 'u-net', 'convolutional neural network'];https://www.kaggle.com/c/rsna-pneumonia-detection-challenge;0.779;0.487;2020-12-13 16:48:20;multiple data sources;['gpu'];U-Net lung segmentation (Montgomery + Shenzhen);Python notebook;23262.0;85;;
2019-07-02 10:11:13;Mask-RCNN Starter Model for the RSNA Pneumonia Detection Challenge with transfer learning  Using pre-trained COCO weights trained on http://cocodataset.org as in https://github.com/matterport/Mask_RCNN/tree/master/samples/balloon We get the best public kernel performance so far, and also training only within the 6hrs kaggle limit.;Apache 2.0;https://www.kaggle.com/hmendonca/mask-rcnn-and-coco-transfer-learning-lb-0-155;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cnn', 'cv', 'nn', 'ann'];['filter', 'training data', 'test data', 'train', 'model', 'epoch', 'validation data', 'layer', 'loss', 'label', 'predict', 'resnet', 'ground truth'];https://www.kaggle.com/c/rsna-pneumonia-detection-challenge;0.797;0.538;2020-12-13 16:48:20;RSNA Pneumonia Detection Challenge;['gpu, deep learning, cnn, +1 moretransfer learning'];Mask-RCNN and COCO transfer learning LB:0.155;Python notebook;41117.0;170;0.10319;0.10000
2018-10-01 01:13:44;Mask-RCNN Sample Starter Model for the RSNA Pneumonia Detection Challenge MD.ai. The dataset for this challenge, created on the MD.ai platform in collaboration with the Radiological Society of North America (RSNA), the Society of Thoracic Radiology (STR), the US National Institutes of Health (NIH), and Kaggle. This notebook covers the basics of parsing the competition dataset, training using a detector basd on the Mask-RCNN algorithm for object detection and instance segmentation. Note that the Mask-RCNN detector configuration parameters have been selected to reduce training time for demonstration purposes, they are not optimal. This is based on our deep learning for medical imaging lessons:  Lesson 1. Classification of chest vs. adominal X-rays using TensorFlow/Keras Github Annotator Lesson 2. Lung X-Rays Semantic Segmentation using UNets. Github Annotator  Lesson 3. RSNA Pneumonia detection using Kaggle data format Github Annotator  Lesson 3. RSNA Pneumonia detection using MD.ai python client library Github Annotator   Copyright 2018 MD.ai, Inc. Licensed under the Apache License, Version 2.0;Apache 2.0;https://www.kaggle.com/hmendonca/mask-rcnn-with-submission;1.0;['tensorflow', 'keras'];['ner', 'ai', 'cnn', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'training data', 'test data', 'object detection', 'train', 'model', 'epoch', 'deep learning', 'layer', 'validation data', 'loss', 'label', 'predict', 'resnet', 'classification', 'ground truth'];https://www.kaggle.com/c/rsna-pneumonia-detection-challenge;0.734;0.4;2020-12-13 16:48:20;RSNA Pneumonia Detection Challenge;['gpu'];Mask-RCNN with submission;Python notebook;6790.0;29;;
2018-09-04 14:07:41;Approach Firstly a convolutional neural network is used to segment the image, using the bounding boxes directly as a mask.  Secondly connected components is used to separate multiple areas of predicted pneumonia. Finally a bounding box is simply drawn around every connected component.  Network The network consists of a number of residual blocks with convolutions and downsampling blocks with max pooling. At the end of the network a single upsampling layer converts the output to the same shape as the input.  As the input to the network is 256 by 256 (instead of the original 1024 by 1024) and the network downsamples a number of times without any meaningful upsampling (the final upsampling is just to match in 256 by 256 mask) the final prediction is very crude. If the network downsamples 4 times the final bounding boxes can only change with at least 16 pixels.;Apache 2.0;https://www.kaggle.com/jonnedtc/cnn-segmentation-connected-components;1.0;['tensorflow', 'skimage', 'keras'];['ner', 'ai', 'dl', 'nn', 'ann'];['train', 'model', 'neural network', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'convolutional neural network'];https://www.kaggle.com/c/rsna-pneumonia-detection-challenge;0.785;0.553;2020-12-13 16:48:20;RSNA Pneumonia Detection Challenge;['gpu'];CNN Segmentation + connected components;Python notebook;27883.0;212;0.00000;0.00000
2018-10-24 09:59:40;"Sections Parsing Tabular Data Parsing Metadata from DICOM Object Cleaning DICOM Metadata and Merging to Tabular Data EDA on Metadata and Initial Tabular Data ViewPosition PatientAge PatientSex PixelSpacing Initial Tabular Data Bounding Box Bounding Box Data Manipulation Bounding Box Plots   Image Intensity Distribution   Summary (TL;DR) Simple LGBM Binary Classifier";Apache 2.0;https://www.kaggle.com/jtlowery/intro-eda-with-dicom-metadata;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'gbm', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'train', 'model', 'loss', 'label', 'predict', 'understanding'];https://www.kaggle.com/c/rsna-pneumonia-detection-challenge;0.712;0.416;2020-12-13 16:48:20;RSNA Pneumonia Detection Challenge;['beginner, data visualization, exploratory data analysis, +2 moredata cleaning, image data'];Intro EDA with DICOM Metadata;Python notebook;3993.0;35;;
2018-10-27 19:25:20;OverviewThe goal is to make a simple Keras model for predicting which category an image falls in;Apache 2.0;https://www.kaggle.com/kmader/lung-opacity-classification-transfer-learning;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'rl', 'nn'];['training data', 'train', 'fitting', 'model', 'epoch', 'validation data', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'resnet', 'classification'];https://www.kaggle.com/c/rsna-pneumonia-detection-challenge;0.759;0.498;2020-12-13 16:48:20;multiple data sources;['gpu'];Lung Opacity Classification Transfer Learning;Python notebook;13274.0;98;;
2018-09-26 06:57:32;ContentsYOLO v3 for image detection Introduction Clone and Build YOLOv3 Data Migration Prepare Configuration Files for training Training model How to use trained model for test images (command line) Generate Submission Files Using YOLOv3 Python Wrapper Future works & Etc;Apache 2.0;https://www.kaggle.com/seohyeondeok/yolov3-rsna-starting-notebook;1.0;['sklearn'];['ner', 'ai', 'dl', 'cnn', 'cv', 'ml', 'nn', 'ann'];['r-cnn', 'filter', 'object detection', 'train', 'recognition', 'model', 'deep learning', 'layer', 'loss', 'label', 'predict', 'recommend', 'classification', 'labeled', 'ground truth'];https://www.kaggle.com/c/rsna-pneumonia-detection-challenge;0.78;0.53;2020-12-13 16:48:20;RSNA Pneumonia Detection Challenge;['beginner, deep learning'];YOLOv3-RSNA Starting Notebook;Python notebook;24418.0;152;;
2018-10-28 09:23:09;Approach Firstly a convolutional neural network is used to segment the image, using the bounding boxes directly as a mask.  Secondly connected components is used to separate multiple areas of predicted pneumonia. Finally a bounding box is simply drawn around every connected component.  Network The network consists of a number of residual blocks with convolutions and downsampling blocks with max pooling. At the end of the network a single upsampling layer converts the output to the same shape as the input.  As the input to the network is 256 by 256 (instead of the original 1024 by 1024) and the network downsamples a number of times without any meaningful upsampling (the final upsampling is just to match in 256 by 256 mask) the final prediction is very crude. If the network downsamples 4 times the final bounding boxes can only change with at least 16 pixels. Edit by EAS :  Change input image size to 320x320. Added transpose convolutions to allow greater flexibility in final predictions as per note above.;Apache 2.0;https://www.kaggle.com/skooch/cnn-segmentation-connected-components-320x320;1.0;['tensorflow', 'skimage', 'keras'];['ner', 'ai', 'dl', 'nn', 'ann'];['train', 'model', 'neural network', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'convolutional neural network'];https://www.kaggle.com/c/rsna-pneumonia-detection-challenge;0.721;0.403;2020-12-13 16:48:20;RSNA Pneumonia Detection Challenge;['gpu'];CNN Segmentation + connected components 320x320;Python notebook;4916.0;30;0.11553;0.07738
2018-09-02 01:30:41;Q&A with Only Pictuers! (RSNA Pneumonia Detection Challenge)This kernel poses and answers questions about the dataset using images! Questions Are the classes imbalanced? How many cases are there per image? Where is Pneumonia located? What is the age distribution by gender and target? What are the areas of the bounding boxes by gender? How is the pixel spacing distributed? How are the bounding box areas distributed by the number of boxes? Where are the outliers? What does the outliers look like? Are there images with mostly black pixels? What does the mostly black pixels look like? What does the mostly white pixel images look like? Can tradiational image processing find a bounding box around the cropped images? Can the bounding boxes be resized when cropping and resizing the cropped images? How are the bounding box aspect ratios distributed? What does the images with a high aspect ratio look like? Is there a relationship between the bounding box's aspect ratio and area?  More questions to come! 🧐;Apache 2.0;https://www.kaggle.com/thomasjpfan/q-a-with-only-pictures;1.0;['skimage', 'sklearn'];['ai', 'nn', 'ann'];['train', 'label', 'filter', 'predict'];https://www.kaggle.com/c/rsna-pneumonia-detection-challenge;0.723;0.512;2020-12-13 16:48:20;RSNA Pneumonia Detection Challenge;[];Q&A with Only Pictures!;Python notebook;5245.0;119;;
2020-10-06 21:45:27;This is a copy of v5 of@kozodoi's Label Consistency notebook. This copy has been tested by the challenge hosts (thanks to @jeffrudie ) and will be used by the hosts on the top 10 private leaderboard submissions to verify compliance with the logical consistency of labels requirements after the end of the contest.;Apache 2.0;https://www.kaggle.com/anthracene/host-confirmed-label-consistency-check;1.0;['keras'];['ner', 'ai', 'dl', 'gan', 'nn', 'ann'];['train', 'model', 'label', 'predict', 'understanding', 'labeled'];https://www.kaggle.com/c/rsna-str-pulmonary-embolism-detection;0.68;0.46;2020-12-13 16:49:33;multiple data sources;[];HOST CONFIRMED - Label Consistency Check;Python notebook;1982.0;60;;
2020-09-29 08:13:20;Simulate model predicting by taking average for each labels;Apache 2.0;https://www.kaggle.com/khyeh0719/0929-updated-rsna-competition-metric;1.0;['pytorch', 'tensorflow', 'sklearn'];['ai', 'nn'];['predict', 'train', 'model', 'label', 'loss'];https://www.kaggle.com/c/rsna-str-pulmonary-embolism-detection;0.67;0.479;2020-12-13 16:49:33;RSNA STR Pulmonary Embolism Detection;[];[0929 Updated] RSNA Competition Metric;Python notebook;1608.0;76;;
2020-09-22 20:01:18;OverviewIn this kernel, I'm going to demonstrate how to build a stratified validation splits while doing some preliminary EDA on both train and test set;Apache 2.0;https://www.kaggle.com/khyeh0719/stratified-validation-strategy;1.0;['sklearn'];['ai', 'nn'];['train', 'model', 'label'];https://www.kaggle.com/c/rsna-str-pulmonary-embolism-detection;0.654;0.439;2020-12-13 16:49:33;RSNA STR Pulmonary Embolism Detection;[];Stratified Validation Strategy;Python notebook;1185.0;46;;
2020-10-09 18:34:53;OVERVIEWIn this notebook, we will check if there is any predictive power in the meta-features that can be extracted from the DCM images. We will write a function to extract a few meta-features and pixel-based features taking advantage of the parallelization and build a cross-validation based LightGBM pipeline to predict one image-level and nine exam-level labels.;Apache 2.0;https://www.kaggle.com/kozodoi/lightgbm-on-meta-features;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'gan', 'gbm', 'cv', 'rl', 'nn'];['predict', 'test data', 'train', 'model', 'label', 'loss'];https://www.kaggle.com/c/rsna-str-pulmonary-embolism-detection;0.692;0.464;2020-12-13 16:49:33;multiple data sources;['classification, image data, lightgbm'];LightGBM on Meta-Features;Python notebook;2559.0;63;0.435;0.454
2020-09-22 20:46:48;version 3:1.update datasets 2.sampler 3.fix label bug;Apache 2.0;https://www.kaggle.com/orkatz2/pulmonary-embolism-pytorch-train;1.0;['pytorch', 'albumentations', 'skimage'];['ner', 'ai', 'cv', 'nn', 'ann'];['predict', 'train', 'model', 'epoch', 'label', 'loss', 'resnet'];https://www.kaggle.com/c/rsna-str-pulmonary-embolism-detection;0.71;0.471;2020-12-13 16:49:33;multiple data sources;['gpu, deep learning, computer vision, +1 morepython'];Pulmonary Embolism - Pytorch[Train];Python notebook;3861.0;69;;
2020-10-10 14:56:21;Mean predictionThis competition's metric is logloss.  The representative value minimizes logloss is average.;Apache 2.0;https://www.kaggle.com/osciiart/baseline-with-no-image;1.0;['sklearn'];['ai', 'cv'];['filter', 'predict', 'test data', 'train', 'label', 'loss'];https://www.kaggle.com/c/rsna-str-pulmonary-embolism-detection;0.713;0.521;2020-12-13 16:49:33;RSNA STR Pulmonary Embolism Detection;[];Baseline with No Image;Python notebook;4115.0;134;0.336;0.325
2020-10-05 04:27:40;DICOM Processing and Segmentation in Python DICOM is a pain in the neck.  It also happens to be very helpful.  As clinical radiologists, we expect post-processing, even taking them for granted. However, the magic that occurs behind the scenes is no easy feat, so let’s explore some of that magic. In this quest, we will be starting from raw DICOM images. We will extract voxel data from DICOM into numpy arrays, and then perform some low-level operations to normalize and resample the data, made possible using information in the DICOM headers. The remainder of the Quest is dedicated to visualizing the data in 1D (by histogram), 2D, and 3D. Finally, we will create segmentation masks that remove all voxel except for the lungs. Processing raw DICOM with Python is a little like excavating a dinosaur – you’ll want to have a jackhammer to dig, but also a pickaxe and even a toothbrush for the right situations. Python has all the tools, from pre-packaged imaging process packages handling gigabytes of data at once to byte-level operations on a single voxel. Import Packages;Apache 2.0;https://www.kaggle.com/redwankarimsony/rsna-str-3d-stacking-3d-plot-segmentation;1.0;['skimage', 'sklearn'];['ner', 'ai', 'dl', 'rl', 'nn', 'ann'];['machine learning', 'train', 'model', 'label', 'rank'];https://www.kaggle.com/c/rsna-str-pulmonary-embolism-detection;0.669;0.442;2020-12-13 16:49:33;RSNA STR Pulmonary Embolism Detection;[];RSNA-STR [✔️3D Stacking ✔️3D Plot ✔️Segmentation];Python notebook;1578.0;48;0.437;0.434
2020-10-24 19:23:44;"This kernel is one of the first Vision Transformer implementations, a simple way to achieve SOTA in vision classification with only a single transformer encoder, in Pytorch, based on ""https://github.com/lucidrains/vit-pytorch"" with much lower parameters. It challenges the paradigm of Convolutions for vision. It instead represents images as a set of visual tokens and applies visual transformers to find relationships between visual semantic concepts. Given an input image,it dynamically extracts a set of visual tokens from the image to obtain a compact representation for high-level semantics. Then, It uses visual transformers to operate over the visual tokens to densely model relationships between them. We replaced the attention layer with a more efficient network, called ""Linformer"". This is attention with only linear complexity in n, allowing for very long sequence lengths (1mil+) to be attended to on GPU. One can also use axial attention instead as was mention in their paper. The paper is under open review for ICLR 2021. The data management and pipeline is also based on ""https://www.kaggle.com/orkatz2/pulmonary-embolism-pytorch-train"".";Apache 2.0;https://www.kaggle.com/rythian47/vision-transformer-goodbye-cnn-training;1.0;['pytorch', 'albumentations', 'skimage', 'sklearn'];['ner', 'ai', 'cv', 'ml', 'nn', 'ann'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'lstm', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/rsna-str-pulmonary-embolism-detection;0.679;0.44;2020-12-13 16:49:33;RSNA STR Pulmonary Embolism Detection;[];Vision Transformer: goodbye_CNN[Training];Python notebook;1940.0;47;;
2020-09-19 06:37:33;PeekFirst, let's see the structure of our files.;Apache 2.0;https://www.kaggle.com/seraphwedd18/pe-detection-with-keras-model-creation;1.0;['tensorflow', 'keras'];['ner', 'ai', 'rl', 'cv', 'nn'];['filter', 'test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/rsna-str-pulmonary-embolism-detection;0.738;0.512;2020-12-13 16:49:33;RSNA STR Pulmonary Embolism Detection;['gpu, keras, transfer learning'];PE Detection with Keras - Model Creation;Python notebook;7488.0;118;;
2019-12-25 20:22:28;First questions to answer 🤔 What does a instance represent in each dataset? Dimensions of each dataset  Conclusions 💡 What features are available in the dataset? What features are categorical ? Classify samples. Could be Nominal - Ordinal - Ratios - Intervals What features are numerical ? Values discrete, continuous, time-series Which features may contain errors ? Which features contain blank, nulls or empty values ? What are the data types for the features ? Distribution of numerical features ? Distribution of categorical features ?  Assumptions 📝 Data assumptions  Drops and create ✂️ Could you drop some features ?;Apache 2.0;https://www.kaggle.com/aceconhielo/data-analysis-and-patterns-recognition;1.0;['pattern'];['ai'];['label'];https://www.kaggle.com/c/santa-2019-revenge-of-the-accountants;0.593;0.236;2020-12-13 16:50:31;Santa 2019 - Revenge of the Accountants;['data visualization'];Data analysis and patterns recognition ;Python notebook;399.0;5;;
2017-12-14 00:14:59;SummaryI tried out a neural network for classification because Machine Learning. With the large number of samples and 1000 samples per class, the task seems to be well-suited for Deep Learning. As expected, the model achieved significant results. There is still some room for improvement, so maybe combining the model with XGBoost can help there. ApproachI used the subm.csv output file from ZFTurbo's Greedy children baseline [0.8168] kernel. As features, I used the children's wishlists and their id resulting in 11 features.;Apache 2.0;https://www.kaggle.com/batzner/deep-learning-benchmark-0-0439;1.0;['tensorflow', 'xgboost', 'keras'];['ai'];['machine learning', 'training data', 'train', 'artificial intelligence', 'model', 'neural network', 'epoch', 'deep learning', 'layer', 'validation data', 'loss', 'label', 'relu', 'predict', 'rank', 'classification', 'convolutional neural network'];https://www.kaggle.com/c/santa-gift-matching;0.659;0.362;2020-12-13 16:57:44;multiple data sources;[];Deep Learning Benchmark [-0.0439];Python notebook;1312.0;19;;
2019-12-13 22:45:11;The sound track of Kaggle Competitions.;Apache 2.0;https://www.kaggle.com/mpwolke/competitions-are-rock-n-roll;1.0;['h2o', 'nltk'];['ner', 'ai', 'nlu', 'dl', 'cnn', 'gbm', 'nlg', 'cv', 'rl', 'ml', 'nlp', 'nn', 'rnn', 'ann'];['vgg', 'label', 'machine learning'];https://www.kaggle.com/c/santa-workshop-tour-2019;0.67;0.5;2020-12-13 16:58:59;Santa's Workshop Tour 2019;[];Competitions are Rock'n' Roll;Python notebook;1617.0;101;;
2020-11-18 16:26:55;Comprehensive Guide on Feature SelectionHello friends, Feature Selection is the process of selecting optimal number of features from a larger set of features. There are several advantages of this feature selection process and also there are various techniques available for this feature selection process. In this kernel, we will look at these advantages and various techniques for feature selection. So, let's get started.;Apache 2.0;https://www.kaggle.com/prashant111/comprehensive-guide-on-feature-selection;1.0;['sklearn'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['linear regression', 'filter', 'machine learning', 'regression', 'random forest', 'train', 'fitting', 'model', 'label', 'logistic regression', 'k-nearest neighbor', 'predict', 'rank', 'decision tree', 'classification'];https://www.kaggle.com/c/santander-customer-satisfaction;0.779;0.531;2020-12-13 17:05:46;multiple data sources;[];Comprehensive Guide on Feature Selection;Python notebook;23741.0;154;;
2016-04-12 11:02:24;Build an estimator trying to predict the target for each feature individually;Apache 2.0;https://www.kaggle.com/selfishgene/basic-feature-exploration;1.0;['sklearn'];['ner', 'ai'];['train', 'loss', 'label', 'predict'];https://www.kaggle.com/c/santander-customer-satisfaction;0.744;0.435;2020-12-13 17:05:46;Santander Customer Satisfaction;['beginner, exploratory data analysis, feature engineering'];Basic Feature Exploration;Python notebook;8878.0;44;;
2019-04-03 14:27:00;"Our goalIn this competition we are asked to predict if a customer will make a transaction or not regardless of the amount of money transacted. Hence our goal is to solve a binary classification problem. In the data description you can see that the features given are numeric and anonymized. Furthermore the data seems to be artificial as they state that ""the data has the same structure as our real data"". Table of contents Loading packages (complete) Sneak a peek at the data (complete) What can we say about the target? (complete) Can we find relationships between features? (complete) Baseline submission (complete) Basic feature engineering (complete) Gaussian Mixture Clustering (complete)";Apache 2.0;https://www.kaggle.com/allunia/santander-customer-transaction-eda;1.0;['sklearn'];['ner', 'ai', 'dl', 'cv', 'nn', 'ml'];['filter', 'test data', 'random forest', 'train', 'fitting', 'model', 'clustering', 'label', 'predict', 'understanding', 'classification'];https://www.kaggle.com/c/santander-customer-transaction-prediction;0.769;0.559;2020-12-13 17:07:47;Santander Customer Transaction Prediction;['data visualization, exploratory data analysis, feature engineering'];Santander Customer Transaction - EDA;Python notebook;17655.0;234;;
2019-03-31 19:40:28;"General informationIn Santander Customer Transaction Prediction competition we have a binary classification task. Train and test data have 200k samples each and we have 200 anonimyzed numerical columns. It would be interesting to try good models without overfitting and knowing the meaning of the features. In fact this competition seems to be similar to another current competition: don't overfit II, so I'll use a lot of ideas from my kernel. In this kernel I'll write the following things:  EDA on the features and trying to get some insights; Using permutation importance to select most impactful features; Comparing various models: linear models, tree based models and others; Trying various approaches to feature selection including taking top features from eli5; Hyperparameter optimization for models; Feature generation; Other things;   Work still in progress";Apache 2.0;https://www.kaggle.com/artgor/santander-eda-fe-fs-and-models;1.0;['statsmodels', 'xgboost', 'lightgbm', 'catboost', 'sklearn'];['ner', 'ai', 'gbm', 'cv', 'rl', 'nn', 'ml'];['filter', 'test data', 'regression', 'generation', 'train', 'fitting', 'model', 'loss', 'label', 'predict', 'rank', 'classification'];https://www.kaggle.com/c/santander-customer-transaction-prediction;0.76;0.552;2020-12-13 17:07:48;Santander Customer Transaction Prediction;['beginner, data visualization, exploratory data analysis, +1 moremodel explainability'];Santander EDA, FE, FS and models;Python notebook;13715.0;210;0.89385;0.89662
2019-03-02 05:40:00;"IntroductionIn this kernel, we will apply Bayesian inference on Santander Customer Transaction data, which has a binary target and 200 continuous features. We model the target as unknown Y and the features as observation X. The prior pY(y) reflects our knowledge about the unknown before observation. In this problem, Y is Bernoulli (only two classes) so it can be specified by setting the positive probability, which is usually set as the proportion of the positive class in the data. The likelihood fX|Y(x|y) models the distribution of the observation given that we know the class. The posterior pY|X(y|x) is our updated knowledge about the unknown after observation. The MAP (Maximum A Posteriori) estimator picks the class with the highest posterior probability. For binary classification, it has the same effect as setting a threshold of 0.5 for the positive posterior probability. The LMS (Least Mean Squares) estimator E[Y|X] picks the mean of the posterior distribution. For binary classification, this is just the positive posterior probability pY|X(1|x), which is what we need to submit for the competition. The Bayes rule for this problem is of the form pY|X(y|x)=pY(y)fX|Y(x|y)∑y′pY(y′)fX|Y(x|y′) Here X represents a sequence of 200 observations X0,X1,…,X199. We assume that the likelihood distributions are normal and independent. This gives us the Gaussian naive Bayes classifier (Gaussian means normal and naive means independent): pY|X0,X1,…,X199(y|x0,x1,…,x199)=pY(y)∏199i=0fXi|Y(xi|y)∑1y′=0pY(y′)∏199i=0fXi|Y(xi|y′) Note that we only require 1 number for the prior and 800 numbers for the likelihood (200 sample means and variances for each of the two classes). ""Fitting"" is just computing those numbers, and ""predicting"" is carried out according to the above formula (although we need to operate on the log scale because multiplying many small numbers poses a problem when our machine has limited precision). It is a very simple and efficient model.";Apache 2.0;https://www.kaggle.com/blackblitz/gaussian-naive-bayes;1.0;['pattern', 'sklearn'];['ner', 'ai', 'cv', 'nn', 'ann'];['training data', 'test data', 'train', 'fitting', 'model', 'label', 'predict', 'classification', 'naive bayes', 'bayesian'];https://www.kaggle.com/c/santander-customer-transaction-prediction;0.77;0.544;2020-12-13 17:07:48;Santander Customer Transaction Prediction;['beginner, exploratory data analysis, binary classification, +1 morenaive bayes'];Gaussian Naive Bayes;Python notebook;18101.0;188;0.88816;0.88955
2019-04-11 23:20:42;"The ""Magic"" of SantanderIn this kernel, we will display pictures of the Santander magic! Previously here, in ""Modified Naive Bayes"", we saw that we can model each variable separately and then combine the 200 models to score LB 0.899. We will do the same here after adding a ""magic"" feature to each variable. We will then ensemble the 200 models with logistic regression and score LB 0.920";Apache 2.0;https://www.kaggle.com/cdeotte/200-magical-models-santander-0-920;1.0;['statsmodels', 'lightgbm', 'sklearn'];['cv', 'ai', 'gbm'];['filter', 'training data', 'regression', 'test data', 'train', 'model', 'label', 'logistic regression', 'predict', 'naive bayes'];https://www.kaggle.com/c/santander-customer-transaction-prediction;0.782;0.602;2020-12-13 17:07:47;Santander Customer Transaction Prediction;[];200 Magical Models - Santander - [0.920];Python notebook;25363.0;461;0.91850;0.92022
2019-04-13 01:54:44;"Modified Naive Bayes scores 0.899 LB - SantanderIn this kernel we demonstrate that unconstrained Naive Bayes can score 0.899 LB. I call it ""unconstrained"" because it doesn't assume that each variable has a Gaussian distribution like typical Naive Bayes. Instead we allow for arbitrary distributions and we plot these distributions below. I called it ""modified"" because we don't reverse the conditional probabilities. This kernel is useful because (1) it shows that an accurate score can be achieved using a simple model that assumes the variables are independent. And (2) this kernel displays interesting EDA which provides insights about the data. Load Data";Apache 2.0;https://www.kaggle.com/cdeotte/modified-naive-bayes-santander-0-899;1.0;['sklearn'];['ai', 'cv'];['filter', 'training data', 'train', 'model', 'label', 'predict', 'naive bayes'];https://www.kaggle.com/c/santander-customer-transaction-prediction;0.779;0.586;2020-12-13 17:07:47;Santander Customer Transaction Prediction;[];Modified Naive Bayes - Santander - [0.899];Python notebook;23732.0;356;0.89804;0.89903
2019-02-15 01:10:39;Santander Customer Transaction PredictionCan you identify who will make a transaction? Version6  Ensemble : LB 0.899 LightGBM : LB 0.898 Catboost : LB 0.898;Apache 2.0;https://www.kaggle.com/chocozzz/santander-lightgbm-baseline-lb-0-899;1.0;['catboost', 'lightgbm', 'sklearn'];['ner', 'ai', 'gbm', 'cv', 'rl', 'nn'];['filter', 'test data', 'train', 'model', 'loss', 'label', 'predict'];https://www.kaggle.com/c/santander-customer-transaction-prediction;0.756;0.535;2020-12-13 17:07:48;Santander Customer Transaction Prediction;[];Santander LightGBM Baseline LB 0.899;Python notebook;12301.0;163;;
2019-02-25 00:53:13;Bayesian global optimization with gaussian processes for finding (sub-)optimal parameters of LightGBMAs many of fellow kaggler asking how did I get LightGBM parameters for the kernel Customer Transaction Prediction I published. So, I decided to publish a kernel to optimize parameters. In this kernel I use Bayesian global optimization with gaussian processes for finding optimal parameters. This optimization attempts to find the maximum value of an black box function in as few iterations as possible. In our case the black box function will be a function that I will write to optimize (maximize) the evaluation function (AUC) so that parameters get maximize AUC in training and validation, and expect to do good in the private. The final prediction will be rank average on 5 fold cross validation predictions. Continue to the end of this kernel and upvote it if you find it is interesting.  Image taken from : https://github.com/fmfn/BayesianOptimization;Apache 2.0;https://www.kaggle.com/fayzur/lgb-bayesian-parameters-finding-rank-average;1.0;['lightgbm', 'sklearn'];['ai', 'gbm', 'cv', 'rl', 'nn'];['filter', 'training data', 'test data', 'train', 'model', 'validation data', 'label', 'predict', 'rank', 'bayesian'];https://www.kaggle.com/c/santander-customer-transaction-prediction;0.745;0.546;2020-12-13 17:07:48;Santander Customer Transaction Prediction;[];LGB + Bayesian parameters finding + Rank average;Python notebook;8943.0;193;;
2019-03-22 01:57:27;"The purpose of this kernel is to boost your creativity towards feature engineering with Santander's Customer Transaction variables. If it fulfills this purpose, please, consider upvoting the kernel :) Index: Competition and Data Overview;  Defining probability in terms of frequency difference;    2.1. Building our graph    2.2 Defining the frequency ratio between right and left sides Analysing the type of graphs;    3.1 Regular features    3.2 Reversed features    3.3 Flat features    3.4 Extreme features Feature engineering    4.1 Using frequency ratio as a predictive score    4.2 Separating different populations as a gaussian mixture Summary";Apache 2.0;https://www.kaggle.com/felipemello/boosting-creativity-towards-feature-engineering;1.0;['lightgbm', 'sklearn'];['ai', 'nn', 'ml', 'gbm'];['train', 'model', 'label', 'predict'];https://www.kaggle.com/c/santander-customer-transaction-prediction;0.743;0.557;2020-12-13 17:07:48;Santander Customer Transaction Prediction;['data visualization, feature engineering'];Boosting creativity towards feature engineering;Python notebook;8560.0;228;;
2019-04-06 05:02:55;The objective of this Kernel is to show why your new engineered features might be causing overfitting or not having any impact in your score at all. If you like this kernel, please, consider upvoting. Thanks :);Apache 2.0;https://www.kaggle.com/felipemello/why-your-model-is-overfitting-not-making-progress;1.0;['catboost', 'xgboost', 'sklearn'];['ai', 'rl', 'nn', 'cv'];['filter', 'test data', 'train', 'fitting', 'model', 'label', 'predict', 'understanding'];https://www.kaggle.com/c/santander-customer-transaction-prediction;0.747;0.58;2020-12-13 17:07:47;multiple data sources;[];Why your model is overfitting/not making progress;Python notebook;9533.0;326;;
2019-04-03 18:47:18;Santander EDA and PredictionDataset used: Santander Customer Transaction Prediction  Content Introduction  Prepare the data analysis  Data exploration  Check the data  Density plots of features  Distribution of mean and std  Distribution of min and max  Distribution of skew and kurtosis  Features correlations  Duplicate values    Feature engineering Model Submission  References;Apache 2.0;https://www.kaggle.com/gpreda/santander-eda-and-prediction;1.0;['pattern', 'lightgbm', 'sklearn'];['ner', 'ai', 'gbm', 'cv', 'rl'];['filter', 'test data', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/santander-customer-transaction-prediction;0.823;0.651;2020-12-13 17:07:47;Santander Customer Transaction Prediction;['exploratory data analysis, classification, feature engineering'];Santander EDA and Prediction;Python notebook;103018.0;1125;;
2019-03-23 10:03:54;Santander Customer Transaction Prediction Can you identify who will make a transaction?   Our data science team is continually challenging our machine learning algorithms, working with the global data science community to make sure we can more accurately identify new ways to solve our most common challenge, binary classification problems such as: is a customer satisfied? Will a customer buy this product? Can a customer pay this loan? In this challenge, we invite Kagglers to help us identify which customers will make a specific transaction in the future, irrespective of the amount of money transacted. The data provided for this competition has the same structure as the real data we have available to solve this problem. The data is anonimyzed, each row containing 200 numerical values identified just with a number.</b>;Apache 2.0;https://www.kaggle.com/jesucristo/santander-magic-lgb-0-901;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'gbm', 'cv', 'rl', 'nn'];['filter', 'machine learning', 'train', 'model', 'label', 'predict', 'classification'];https://www.kaggle.com/c/santander-customer-transaction-prediction;0.774;0.549;2020-12-13 17:07:48;Santander Customer Transaction Prediction;[];Santander Magic LGB 0.901;Python notebook;20393.0;201;0.89984;0.90104
2019-03-11 04:11:08;"Introduction""Distilling the Knowledge in a Neural Network"" was introduced by Geoffrey Hinton, Oriol Vinyals, Jeff Dean in Mar 2015. In this kernel, I would like to share some experiments to distill the knowledge from a LGBM teacher (LB:0.899) to a neural network. The student network has not surpassed the teacher model yet (LB:0.894). But, I hope I can make it happen before this competition ends.";Apache 2.0;https://www.kaggle.com/mathormad/knowledge-distillation-with-nn-rankgauss;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'gbm', 'rl', 'nn'];['train', 'model', 'neural network', 'epoch', 'layer', 'loss', 'label', 'predict', 'rank', 'relu'];https://www.kaggle.com/c/santander-customer-transaction-prediction;0.756;0.545;2020-12-13 17:07:48;multiple data sources;['gpu, deep learning'];Knowledge Distillation with NN + RankGauss;Python notebook;12096.0;189;0.89748;0.89811
2019-03-10 17:50:47;Santander ML Explainability  CLEAR DATA. MADE MODEL.   last update:  10/03/2019You can Fork code  and  Follow me on:  GitHubKaggle I hope you find this kernel helpful and some UPVOTES would be very much appreciated.;Apache 2.0;https://www.kaggle.com/mjbahmani/santander-ml-explainability;1.0;['catboost', 'xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'gbm', 'cv', 'rl', 'nn', 'ml'];['filter', 'machine learning', 'test data', 'train', 'model', 'deep learning', 'loss', 'label', 'predict', 'decision tree', 'classification'];https://www.kaggle.com/c/santander-customer-transaction-prediction;0.783;0.599;2020-12-13 17:07:47;Santander Customer Transaction Prediction;['beginner, exploratory data analysis, model explainability'];Santander ML Explainability;Python notebook;26931.0;438;0.89903;0.90038
2019-03-20 19:23:39;Santander EDA, PCA and Light GBM Classification Model   In this challenge, Santander invites Kagglers to help them identify which customers will make a specific transaction in the future, irrespective of the amount of money transacted. The data provided for this competition has the same structure as the real data they have available to solve this problem.  The data is anonimyzed, each row containing 200 numerical values identified just with a number. Inspired by Jiwei Liu's Kernel. I added Data Augmentation Segment to my kernel Content - Import the Data - Data Exploration   - Check for the missing values   - Visualizing the Satendar Customer Transactions Data     - Check for Class Imbalance     - Distribution of Mean and Standard Deviation     - Distribution of Skewness     - Distribution of Kurtosis    - Principal Component Analysis  - Kernel PCA - Data Augmentation - Build the Light GBM Model;Apache 2.0;https://www.kaggle.com/roydatascience/eda-pca-simple-lgbm-on-kfold-technique;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'gbm', 'cv', 'rl'];['filter', 'test data', 'train', 'model', 'label', 'predict', 'classification'];https://www.kaggle.com/c/santander-customer-transaction-prediction;0.761;0.541;2020-12-13 17:07:48;Santander Customer Transaction Prediction;['gpu'];EDA, PCA + Simple LGBM on KFold Technique;Python notebook;14123.0;180;0.89987;0.90102
2019-03-08 01:18:49;GPU-accelerated LightGBMThis kernel explores a GPU-accelerated LGBM model to predict customer transaction. Notebook  Content Re-compile LGBM with GPU support Loading the data Training the model on CPU Training the model on GPU Submission;Apache 2.0;https://www.kaggle.com/vinhnguyen/gpu-acceleration-for-lightgbm;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'nn', 'ann'];['train', 'model', 'label', 'predict'];https://www.kaggle.com/c/santander-customer-transaction-prediction;0.76;0.542;2020-12-13 17:07:48;Santander Customer Transaction Prediction;['gpu'];GPU acceleration for LightGBM;Python notebook;13661.0;182;;
2016-11-29 19:36:52;Feature importanceI will explore the importance of the features using Univariate. Plan of attck is as follows:  Reduce training data set down to last month only (i.e. May 2016) Clean data Split up the 24 products and compute feature importance for each product Summarise findings  This is my first attempt to compute feature importance, any comments and suggestions are welcome. If you find this notebook useful, I shall be grateful for any upvote :);Apache 2.0;https://www.kaggle.com/marc000/feature-importance-v1;1.0;['sklearn'];['ai', 'dl'];['training data', 'regression', 'train', 'label', 'clustering', 'rank', 'classification'];https://www.kaggle.com/c/santander-product-recommendation;0.7;0.327;2020-12-13 17:13:05;Santander Product Recommendation;[];Feature Importance v1;Python notebook;3073.0;13;;
2016-11-28 10:52:32;Just another visualisation of the numerical variables present in the dataset..!;Apache 2.0;https://www.kaggle.com/sudalairajkumar/just-another-visualisation;1.0;['pattern'];['ai', 'ml'];['test data', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/santander-product-recommendation;0.689;0.327;2020-12-13 17:13:05;Santander Product Recommendation;[];Just Another Visualisation.!;Python notebook;2423.0;13;;
2016-11-28 11:11:50;Just planning to add the explorations that I am going to do for this competition. Happy Kaggling.!;Apache 2.0;https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-v3-0;1.0;['pattern'];['ai', 'rl', 'ml', 'nn', 'ann'];['test data', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/santander-product-recommendation;0.745;0.435;2020-12-13 17:13:04;Santander Product Recommendation;[];Simple Exploration Notebook V3.0;Python notebook;8936.0;44;;
2016-11-18 10:58:34;Santander Product Visualisation Yes, yet another visualisation notebook O_o Here I am to do a bit of visualisation  with the focus on the products -> the 'ind_xxxx' columns in the train data set Work in progress.... I will add some more comment/description as time (magically) become available!;Apache 2.0;https://www.kaggle.com/yifanxie/santander-products-visualisation;1.0;['sklearn'];['ai', 'nn'];['train', 'label'];https://www.kaggle.com/c/santander-product-recommendation;0.704;0.327;2020-12-13 17:13:05;Santander Product Recommendation;[];Santander Products Visualisation;Python notebook;3314.0;13;;
2018-07-09 00:33:23;"In this notebook, we preprocessed the data and feed the data to gradient boosting tree models, and got 1.39 on public leaderboard. the workflow is as follows:  Data preprocessing. The purpose of data preprocessing is to achieve higher time/space efficiency. What we did includes round, constant features removal, duplicate features removal, insignificant features removal, etc. The key here is to ensure the preprocessing shall not hurt the accuracy. Feature transform. The purpose of feature transform is to help the models to better grasp the information in the data, and fight overfitting. What we did includes dropping features which ""live"" on different distributions on training/testing set, adding statistical features, adding low-dimensional representation as features.  Modeling.  We used 2 models: xgboost and lightgbm. We averaged the 2 models for the final prediction.  Stay tuned, more update will come. references:  Distribution of Test vs. Training data Ensemble of LGBM and XGB predict house prices-model tuning & ensemble Stacked Regressions : Top 4% on LeaderBoard";Apache 2.0;https://www.kaggle.com/alexpengxiao/preprocessing-model-averaging-by-xgb-lgb-1-39;1.0;['xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'gbm', 'cv', 'rl', 'nn', 'ann'];['filter', 'training data', 'regression', 'test data', 'train', 'fitting', 'model', 'loss', 'gradient boosting', 'predict'];https://www.kaggle.com/c/santander-value-prediction-challenge;0.776;0.558;2020-12-13 17:15:37;Santander Value Prediction Challenge;['gpu, feature engineering, data cleaning, +1 moreensembling'];preprocessing, model averaging by xgb + lgb [1.39];Python notebook;21436.0;230;1.35641;1.40043
2018-07-11 19:48:03;I think its save to say that everyone taking part in this competition has had problems with validation. Local CV score does not at all represent the leaderboard score. Some people have even described a negative correlation. And how are we supposed to solve this problem without any idea if our model is good without submitting to the leaderboard first (and keep in mind that the public LB is evaluated only on 50% on the data too). We have to find a better way of local validation. In this kernel I try a different technique. I wouldn't dare to call it better because I have not thoroughly evaluated it but it is certainly interesting.;Apache 2.0;https://www.kaggle.com/bminixhofer/a-different-validation-technique;1.0;['xgboost', 'sklearn', 'lightgbm'];['ai', 'gbm', 'cv', 'rl', 'nn', 'ml'];['regression', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/santander-value-prediction-challenge;0.701;0.478;2020-12-13 17:15:37;Santander Value Prediction Challenge;[];A different validation technique;Python notebook;3100.0;75;;
2018-07-21 11:00:15;Please go through Giba's post and kernel  to underrstand what this leak is all about https://www.kaggle.com/titericz/the-property-by-giba (kernel) https://www.kaggle.com/c/santander-value-prediction-challenge/discussion/61329 (post) Also, go through this Jiazhen's kernel which finds more columns to exploit leak https://www.kaggle.com/johnfarrell/giba-s-property-extended-result I just exploit data property in brute force way and then fill in remaining by row non zero means! This should bring everyone on level-playing field. Let the competition begin! :D  Just some small modifications from original baseline~ The leak rows are calculated separately on train/test set To accelarate the fake rows(maybe) of testset are dropped Calculated the leaky values, correctness, for each lag Hope this can help to do some lag_selection  (Update) leak process codes to Dmitry Frumkin's fast version The result of Dmitry Frumkin's fast function and result of Mohsin Hasan's function seem slightly different Modified to make the output consistent with Mohsin Hasan's function (Seems better score);Apache 2.0;https://www.kaggle.com/johnfarrell/baseline-with-lag-select-fake-rows-dropped;1.0;['lightgbm', 'sklearn'];['ai', 'gbm'];['train', 'model', 'filter', 'predict'];https://www.kaggle.com/c/santander-value-prediction-challenge;0.729;0.475;2020-12-13 17:15:37;Santander Value Prediction Challenge;[];Baseline with Lag Select Fake Rows Dropped;Python notebook;5991.0;72;;
2018-08-01 19:41:32;"Note: This title is only meant to poke fun and I don't mean to imply that ""leak hunting"" solutions are in any way dishonest.  Here is a kernel detailing my final submission. I used an ensemble of 8 models built on 2 sets of engineered features. My cross-validation score for this method was 1.3438 and the leaderboard score is 1.37.";Apache 2.0;https://www.kaggle.com/mannyelk/an-honest-approach;1.0;['catboost', 'keras'];['ner', 'ai', 'gbm', 'cv', 'rl', 'nn', 'ml'];['filter', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/santander-value-prediction-challenge;0.712;0.472;2020-12-13 17:15:37;multiple data sources;[];An Honest Approach;R notebook;4003.0;70;1.33475;1.37078
2018-07-02 12:43:57;Train vs. Test dataset distributionsBefore getting started on this competition I quickly wanted to check the distributions of the test dataset against that of the training dataset, and if possible see how different from each other they are.;Apache 2.0;https://www.kaggle.com/nanomathias/distribution-of-test-vs-training-data;1.0;['sklearn'];['ai', 'rl', 'nn', 'cv'];['training data', 'test data', 'random forest', 'train', 'fitting', 'model', 'loss', 'label', 'predict', 'classification'];https://www.kaggle.com/c/santander-value-prediction-challenge;0.779;0.55;2020-12-13 17:15:37;Santander Value Prediction Challenge;['beginner, data visualization, exploratory data analysis, +1 moredata cleaning'];Distribution of Test vs. Training data;Python notebook;23781.0;205;;
2018-07-25 13:53:00;ObjectiveTo get an overview of all the possible feature engineering possible in this competition, I'll try to collect and benchmark everything I can find in other kernels and everything I come up with myself in this notebook. It'll be a work-in-progress as I do not have that much time on my hands as to do it in one go.;Apache 2.0;https://www.kaggle.com/nanomathias/feature-engineering-benchmarks;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ml'];['filter', 'predict', 'relu', 'autoencoder', 'training data', 'train', 'epoch', 'lstm', 'clustering', 'linear regression', 'classification', 'model', 'layer', 'loss', 'supervised learning', 'test data', 'regression', 'generation', 'fitting', 'validation data', 'label', 'k-means', 'random forest'];https://www.kaggle.com/c/santander-value-prediction-challenge;0.755;0.511;2020-12-13 17:15:37;Santander Value Prediction Challenge;['beginner, feature engineering, data cleaning'];Feature Engineering Benchmarks;Python notebook;11667.0;117;;
2018-08-17 14:25:45;Please go through Giba's post and kernel  to underrstand what this leak is all about https://www.kaggle.com/titericz/the-property-by-giba (kernel) https://www.kaggle.com/c/santander-value-prediction-challenge/discussion/61329 (post) Also, go through this Jiazhen's kernel which finds more columns to exploit leak https://www.kaggle.com/johnfarrell/giba-s-property-extended-result I just exploit data property in brute force way and then fill in remaining by row non zero means! This should bring everyone on level-playing field. Let the competition begin! :D Just some small modifications from original baseline~ The leak rows are calculated separately on train/test set Calculated the leaky values, correctness, for each lag Hope this can help to do some lag_selection  Update leak process codes to Dmitry Frumkin's fast version The result of Dmitry's original function and result of Hasan's function seem slightly different Modified to make the output consistent with Hasan's function (Seems better score);Apache 2.0;https://www.kaggle.com/nulldata/jiazhen-to-armamut-via-gurchetan1000-0-56;1.0;['pattern', 'lightgbm', 'sklearn'];['ner', 'ai', 'nn', 'gbm'];['train', 'model', 'filter', 'predict'];https://www.kaggle.com/c/santander-value-prediction-challenge;0.747;0.522;2020-12-13 17:15:37;multiple data sources;[];Jiazhen to Armamut via gurchetan1000 - 0.56;Python notebook;9437.0;136;;
2018-07-23 17:26:06;Due to leaks found in the past week, I wondered how it would modify the simple XGB scoring method demonstrated in this notebook. For this purpose I use the results found in : https://www.kaggle.com/johnfarrell/breaking-lb-fresh-start-with-lag-selection/output;Apache 2.0;https://www.kaggle.com/ogrellier/feature-scoring-vs-zeros;1.0;['xgboost', 'sklearn', 'lightgbm'];['ai', 'rl', 'gbm'];['regression', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/santander-value-prediction-challenge;0.751;0.513;2020-12-13 17:15:37;multiple data sources;[];feature_scoring_vs_zeros;Python notebook;10632.0;120;0.71326;0.66339
2018-07-04 20:35:41;Dataset Decomposition TechniquesProblem Statement: Santander Value PredictionSantander Group wants to identify the value of transactions for each potential customer. This is a first step that Santander needs to nail in order to personalize their services at scale. The dataset can be downloaded from this link. In this kernel I have explained different approaches for dataset decomposition. IntroductionThe purpose of this kernel is to walkthrough different dataset decomposition techniques and their implementations.   Decomposition of dataset into lower dimensions often becomes an important task while deailing with datasets having larger number of features. Dimensionality Reduction refers to the process of converting a dataset having vast dimensions into a dataset with lesser number of dimensions. This process is done by ensuring that the information conveyed by the original dataset is not lost. Credits:  https://www.kaggle.com/arthurtok/interactive-intro-to-dimensionality-reduction  Contents Dataset Preparation     Feature Statistics     Eigen Values and Eigen Vectors    Principal Components Analysis      4.1 Finding Right Number of Components      4.2 PCA Implementation      4.3 Variants of PCA   Truncated SVD    Fast ICA    Factor Analysis    Non-Negative Matrix Factorization   Gaussian Random Projection   Sparse Random Projection   tSNE Visualization   Baseline Model with Decomposition Features;Apache 2.0;https://www.kaggle.com/shivamb/dataset-decomposition-techniques;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'rl', 'nn', 'ann'];['test data', 'regression', 'train', 'model', 'deep learning', 'clustering', 'label', 'predict', 'random forest'];https://www.kaggle.com/c/santander-value-prediction-challenge;0.75;0.522;2020-12-13 17:15:37;Santander Value Prediction Challenge;['beginner, feature engineering, dimensionality reduction'];Dataset Decomposition Techniques;Python notebook;10457.0;136;;
2018-06-21 07:17:23;Competition Objective: In their 3rd Kaggle competition, Santander Group is asking Kagglers to help them identify the value of transactions for each potential customer. This is a first step that Santander needs to nail in order to personalize their services at scale. Objective of the Notebook: The objective of the notebook is to explore the data for this competition.! We will be using python for the same.;Apache 2.0;https://www.kaggle.com/sudalairajkumar/simple-exploration-baseline-santander-value;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'gbm', 'rl', 'nn', 'ann'];['filter', 'regression', 'train', 'model', 'label', 'predict', 'rank'];https://www.kaggle.com/c/santander-value-prediction-challenge;0.782;0.596;2020-12-13 17:15:36;Santander Value Prediction Challenge;[];Simple Exploration + Baseline - Santander Value;Python notebook;25430.0;417;;
2018-07-21 08:29:44;Please go through Giba's post and kernel  to underrstand what this leak is all about https://www.kaggle.com/titericz/the-property-by-giba (kernel) https://www.kaggle.com/c/santander-value-prediction-challenge/discussion/61329 (post) Also, go through this Jiazhen's kernel which finds more columns to exploit leak https://www.kaggle.com/johnfarrell/giba-s-property-extended-result I just exploit data property in brute force way and then fill in remaining by row non zero means! This should bring everyone on level-playing field. Let the competition begin! :D;Apache 2.0;https://www.kaggle.com/tezdhar/breaking-lb-fresh-start;1.0;['lightgbm', 'sklearn'];['ai', 'ml', 'gbm'];['train', 'model', 'predict'];https://www.kaggle.com/c/santander-value-prediction-challenge;0.779;0.571;2020-12-13 17:15:37;Santander Value Prediction Challenge;[];Breaking LB - Fresh start;Python notebook;23303.0;281;;
2018-07-01 04:46:25;OverviewThe purpose of this kernel is to take a look at the data, come up with some insights, and attempt to create a predictive model or two. So let's get started! PackagesFirst, let's load a few useful Python packages. This section will keep growing in subsequent versions of this EDA.;Apache 2.0;https://www.kaggle.com/tunguz/yaeda-yet-another-eda;1.0;['xgboost', 'sklearn', 'lightgbm'];['ai', 'rl', 'ml', 'gbm'];['test data', 'regression', 'train', 'fitting', 'model', 'label', 'predict'];https://www.kaggle.com/c/santander-value-prediction-challenge;0.74;0.521;2020-12-13 17:15:37;Santander Value Prediction Challenge;[];YAEDA - Yet Another EDA;Python notebook;7923.0;134;;
2019-07-25 15:27:38;"MotivationIn Progress In this previous kernel I ran MacroPCA on the 25 unknown given features.  Since what the features and specific rows represent are unknown, interpreting and evaluating the PCA is a little more tricky than normal.  I showed that there were a number of potentially problematic high-leverage rows though they were outnumbered by ""good"" highleverage points.  At this point it's unclear if this PCA will provide any value in making predictions. In order to try to answer this question I will run a regression on one of the total return target columns using only the PCA data and compare that to doing the same with the original data.  These checks will be done using a Random Forest Regressor and Suport Vector Regressor; these were chosen as I plan to use either extensions or similar methods for the full multi-output problem.  They also benefit from being easy and quick to run and train.";Apache 2.0;https://www.kaggle.com/rlagrois/testing-macropca-predictive-power-winton;1.0;['sklearn'];['ai', 'nn', 'rl'];['filter', 'test data', 'regression', 'train', 'fitting', 'model', 'predict', 'rank', 'random forest'];https://www.kaggle.com/c/the-winton-stock-market-challenge;0.675;0.099;2020-12-13 17:38:52;multiple data sources;[];Testing MacroPCA Predictive Power - Winton;Python notebook;1812.0;1;;
2020-09-10 18:07:11;We are going to use XGBoost regressor to predict the stock returns in the following two days. I did not see much notebook here. Let me know if it is unproper to post this note. The key ideas in this work are (1) using XGBoost to preselect the ten most important features to fight overfitting, (2) using the linear loss function instead of the conventional square loss function. The final model consistently outperforms the all-zero predict. In my test, the model also performed better than the median prediction and could rank 30th in the private leaderboard.;Apache 2.0;https://www.kaggle.com/zonghao/predicting-stock-returns-by-xgboost;1.0;['tensorflow', 'xgboost', 'sklearn'];['ai', 'dl', 'cv', 'rl', 'nn', 'rnn', 'ml'];['recurrent neural network', 'training data', 'train', 'fitting', 'model', 'neural network', 'validation data', 'loss', 'label', 'predict', 'rank', 'decision tree'];https://www.kaggle.com/c/the-winton-stock-market-challenge;0.657;0.268;2020-12-13 17:38:52;The Winton Stock Market Challenge;['finance, xgboost'];Predicting stock returns by XGBoost;Python notebook;1259.0;7;;
2019-05-06 11:43:59;General informationIn this kernel I'm working with data from TMDB Box Office Prediction Challenge. Film industry is booming, the revunues are growing, so we have a lot of data about films. Can we build models, which will be able to accurately predict film revenues? Could this models be used to make some changes in movies to increase their revenues even further? I'll try answer this questions in my kernel!  (Screenshot of the main page of https://www.themoviedb.org/);Apache 2.0;https://www.kaggle.com/artgor/eda-feature-engineering-and-model-interpretation;1.0;['xgboost', 'lightgbm', 'nltk', 'catboost', 'sklearn', 'pattern'];['ner', 'ai', 'dl', 'gbm', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'regression', 'generation', 'train', 'model', 'loss', 'label', 'predict', 'rank'];https://www.kaggle.com/c/tmdb-box-office-prediction;0.798;0.596;2020-12-13 17:40:32;multiple data sources;['beginner, data visualization, exploratory data analysis, +1 moremodel explainability'];EDA, Feature Engineering and model interpretation;Python notebook;43174.0;420;1.86310;1.86310
2019-10-04 22:07:02;Demo Notebook for quick_regression utility script;Apache 2.0;https://www.kaggle.com/chmaxx/train-12-regressors-with-just-one-line-of-code;1.0;['xgboost', 'sklearn'];['ai', 'dl', 'gbm'];['training data', 'test data', 'regression', 'train', 'model', 'predict'];https://www.kaggle.com/c/tmdb-box-office-prediction;0.659;0.357;2020-12-13 17:40:32;multiple data sources;['beginner, utility script, linear regression'];Train 12+ regressors with just one line of code;Python notebook;1291.0;18;;
2019-02-14 18:45:43;Simple tutorial of TMDB Box Office Competition using XGB, LGB and CatGB;Apache 2.0;https://www.kaggle.com/fedewole/simple-tutorial-of-tmdb-box-office-competition;1.0;['catboost', 'xgboost', 'sklearn', 'lightgbm'];['ai', 'dl', 'gbm', 'cv', 'rl', 'ml'];['test data', 'regression', 'train', 'model', 'loss', 'label', 'predict', 'recommend'];https://www.kaggle.com/c/tmdb-box-office-prediction;0.678;0.352;2020-12-13 17:40:32;TMDB Box Office Prediction;['beginner, feature engineering, data cleaning'];Simple tutorial of TMDB Box Office Competition;Python notebook;1891.0;17;;
2019-04-04 09:49:06;here the correlation is high with revenue by the budget that is 0.75;Apache 2.0;https://www.kaggle.com/joshnarani/accurate-analysis-of-box-office-predictions;1.0;['sklearn'];['dl', 'ai', 'nn', 'ann'];['linear regression', 'test data', 'regression', 'train', 'fitting', 'model', 'label', 'predict', 'decision tree'];https://www.kaggle.com/c/tmdb-box-office-prediction;0.637;0.327;2020-12-13 17:40:32;TMDB Box Office Prediction;[];Accurate analysis of box office predictions;Python notebook;857.0;13;;
2019-03-01 22:35:33;"Step by stepI will start from a basic, almost empty model, and work to gradually improve it. IMDBThe competition rules state that ""You can collect other publicly available data to use in your model predictions, but in the spirit of this competition, use only data that would have been available before a movie's release."". I have (in a separate Kernel) read the following data from imdb: year, budget, runtime, country, etc. - all data that was known before the release, and will try to merge it with the training data.";Apache 2.0;https://www.kaggle.com/liviuasnash/predict-movies-step-by-step;1.0;['catboost', 'xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'dl', 'gbm', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['training data', 'test data', 'regression', 'train', 'fitting', 'model', 'layer', 'loss', 'label', 'predict', 'rank', 'classification', 'bayesian'];https://www.kaggle.com/c/tmdb-box-office-prediction;0.677;0.327;2020-12-13 17:40:32;multiple data sources;[];Predict Movies - step by step;Python notebook;1872.0;13;1.96988;1.96988
2019-05-26 21:41:27;"TMDB Box Office Prediction EDA + ML image-source In a world... where movies made an estimated $41.7 billion in 2018, the film industry is more popular than ever. But what movies make the most money at the box office? How much does a director matter? Or the budget? For some movies, it's ""You had me at 'Hello.'"" For others, the trailer falls short of expectations and you think ""What we have here is a failure to communicate."" In this competition, you're presented with metadata on over 7,000 past films from The Movie Database to try and predict their overall worldwide box office revenue. Data points provided include cast, crew, plot keywords, budget, posters, release dates, languages, production companies, and countries. You can collect other publicly available data to use in your model predictions, but in the spirit of this competition, use only data that would have been available before a movie's release. Kernel in progress, is continuously being updated and extended";Apache 2.0;https://www.kaggle.com/praxitelisk/tmdb-box-office-prediction-eda-ml;1.0;['xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'dl', 'gbm', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'train', 'model', 'loss', 'predict', 'rank', 'random forest', 'bayesian'];https://www.kaggle.com/c/tmdb-box-office-prediction;0.705;0.362;2020-12-13 17:40:32;TMDB Box Office Prediction;['beginner, exploratory data analysis, regression'];TMDB Box Office Prediction EDA + ML;Python notebook;3459.0;19;2.09797;2.09797
2019-08-11 05:49:46;"TL;DRCherry-picked InsightsIn case you might be interested in clues to some of the preselected questions, please feel free to follow the corresponding link and start reading from the anchor section.  Let's make missing values NaNs again! Low-budget movies: how many are there? Are there more or less of them recently?  Low-ranking movies: Are there more or less of them recently?  Should we be afraid of film industry apocalypse? ;)  Given that brevity is the sister of talent, do more or less people with talent write movie overviews? And taglines?  Can revenues reveal which decades were really the greatest in cinema? Are there more sequels or movies with word ""love"" in a title? :)  Modeling Field-Aware Factorization Machines: how to make the kaggle-champ library libffm up and running, how to prepare data in the required format, how to train models using 5-fold stratified CV and early stopping, calling all command-line functions from Python LightGBM, 5-fold stratified CV, Bayesian hyperparameters search CatBoost, 5-fold stratified CV, Bayesian hyperparameters search  Kernel overview To have reliable local validation, it is important to mimic the train/test split. So, let us focus on train vs. test EDA first. Based on the EDA findings we would clean data, including filling of missing entries by querying TMDB API. Along the way we would explore potential curiosities about film industry. As a helping step, we would perform adversarial validation. EDA and data cleaning Was train/test split time-based? Budget analysis  Rating analysis Adversarial validation Popularity Analysis Overview and tagline analysis Filling in missing values using TMDB API     Next, we would perform some feature engineering.  Feature engineering Revenue and inflation Sparse categorical features based on columns like crew and cast Text-based features Features based on competition with other movies     The task at hand has quite a few categorical features with high cardinality. Factorization machines have proven itself useful in problems with huge sparsity. We would use libffm library to create a field-aware factorization machine baseline. FFM turned out not to work well enough, please see previous kernel versions for full training. On the bright side we learned how to work with the library which won a couple of competitions. Modeling Field-Aware Factorization Machines     Create gradient boosting baselines (LightGBM, CatBoost) to predict movie box office. We would tune hyperparameters of the gradient boosting models using Bayesian optimization. Modeling LightGBM CatBoost Final Predictions";Apache 2.0;https://www.kaggle.com/samusram/film-industry-curiosities-box-office-prediction;1.0;['statsmodels', 'lightgbm', 'nltk', 'catboost', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['gru', 'filter', 'training data', 'regression', 'generation', 'train', 'fitting', 'model', 'test data', 'validation data', 'loss', 'label', 'gradient boosting', 'predict', 'rank', 'natural language', 'bayesian'];https://www.kaggle.com/c/tmdb-box-office-prediction;0.706;0.39;2020-12-13 17:40:32;multiple data sources;['beginner, data visualization, exploratory data analysis, +2 morefeature engineering, data cleaning'];Film industry curiosities & box office prediction;Python notebook;3505.0;26;;
2020-12-06 04:42:49;This kernel is dedicated for TMDB revenue prediction challenge.In this kernel i have done  Getting started with TMDB Cleaning TMDB data Exploratory data analysis of TMDB data feature engineering Keras model model Evaluvation;Apache 2.0;https://www.kaggle.com/shahules/eda-feature-engineering-and-keras-model;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nn', 'ann'];['test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/tmdb-box-office-prediction;0.713;0.458;2020-12-13 17:40:32;TMDB Box Office Prediction;['gpu'];EDA,Feature engineering and keras model;Python notebook;4126.0;58;;
2019-09-20 17:32:48;TMDB Box Office Movie's Revenue Prediction My job to predict the international box office revenue for each movie in this given dataset;Apache 2.0;https://www.kaggle.com/suneelpatel/movie-s-box-office-revenue-prediction;1.0;['sklearn'];['ner', 'ai', 'dl', 'gan', 'cv', 'nn', 'ann'];['test data', 'regression', 'train', 'model', 'label', 'predict', 'linear regression', 'random forest'];https://www.kaggle.com/c/tmdb-box-office-prediction;0.624;0.327;2020-12-13 17:40:32;TMDB Box Office Prediction;['beginner, data cleaning'];Movie's_box_office_revenue_prediction;Python notebook;675.0;13;;
2018-05-29 22:12:21;A Better Scoring FunctionInspired by this R scoring function from Vicens Gaitan I implemented a scoring function in Python.  On my machine it runs 3 times faster than the one from trackml package.  On Kalggle kernels it is about 4x faster than the trackml one. I reused part of this notebook as a starting point.;Apache 2.0;https://www.kaggle.com/cpmpml/a-faster-python-scoring-function;1.0;['pattern', 'sklearn'];['ner', 'ai', 'dl', 'nn', 'ml'];['train', 'recognition', 'model', 'layer', 'clustering', 'label', 'predict'];https://www.kaggle.com/c/trackml-particle-identification;0.696;0.425;2020-12-13 17:43:28;TrackML Particle Tracking Challenge;[];A Faster Python Scoring Function;Python notebook;2824.0;39;;
2018-05-03 22:55:22;TrackML Particle Tracking ChallengeA dataset consisting of a simulation of a typical full Silicon LHC detector will be made available, listing for each event the measured 3D points (x, y , z) coordinates, an event being the recording of the collision of two bunches of protons. The ground truth is provided as separate file, indicating which hits correspond to the same particle. For each collision, about 10.000 space tracks (helicoidal trajectories originating approximately from the center of the detector), will leave about 10 precise 3D points. The core pattern recognition tracking task is to associate the 100.000 3D points into tracks. Current studies show that traditional algorithms suffer from a combinatorial explosion of the CPU time. There is a strong potential for application of Machine Learning techniques to this tracking issue. The problem can be related to representation learning, to combinatorial optimization, to clustering (associate together the hits which were deposited by the same particle), and even to time series prediction. An essential question is to efficiently exploit the a priori knowledge about geometrical constraints (structural priors) [1]. Specifically, in this competition, you’re challenged to build an algorithm that quickly reconstructs particle tracks from 3D points left in the silicon detectors [2].  [1] https://sites.google.com/site/trackmlparticle/dataset [2] https://www.kaggle.com/c/trackml-particle-identification To slake some visualization hunger, here's a plot of a few particle trajectories. We're trying to find these from only a few points left behind.;Apache 2.0;https://www.kaggle.com/jbonatt/trackml-eda-etc;1.0;['pattern'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['machine learning', 'training data', 'train', 'recognition', 'model', 'layer', 'clustering', 'label', 'predict', 'ground truth'];https://www.kaggle.com/c/trackml-particle-identification;0.74;0.488;2020-12-13 17:43:27;TrackML Particle Tracking Challenge;['beginner, data visualization, exploratory data analysis, +1 morephysics'];TrackML EDA, etc.;Python notebook;7891.0;86;;
2018-05-07 18:43:01;Visualization: True Tracks VS Clustered Hits (Predicted Tracks)I created this kernel because I wanted to know what the tracks look like, what the clusters (made w/ DBSCAN) look like, and if the clustering is working correctly (or working at all) aside from knowing the LB score. I will show plots of tracks and plots of clustered hits (or predicted tracks) on the same points. The tracks are plotted using the raw hits coordinates and also using the transformed hits coordinates (based on the DBSCAN benchmark kernel). I will also relate the plots to how the clustering is expected to work. Clustered hits are visualized for 4 different settings using DBSCAN. The code for the track visualizations are based on Joshua Bonatt's kernel: https://www.kaggle.com/jbonatt/trackml-eda-etc The code for the coordinate transformation are based on Mikhail Hushchyn's DBSCAN benchmark kernel: https://www.kaggle.com/mikhailhushchyn/dbscan-benchmark Learned how to import trackml from Wesam Elshamy's kernel: https://www.kaggle.com/wesamelshamy/trackml-problem-explanation-and-data-exploration;Apache 2.0;https://www.kaggle.com/jollibobert/true-tracks-vs-clustered-hits-predicted-tracks;1.0;['sklearn'];['ai', 'dl', 'ml', 'rl'];['train', 'layer', 'clustering', 'label', 'k-means', 'predict'];https://www.kaggle.com/c/trackml-particle-identification;0.694;0.423;2020-12-13 17:43:28;TrackML Particle Tracking Challenge;['data visualization, clustering, physics'];True Tracks VS Clustered Hits (Predicted Tracks);Python notebook;2687.0;38;;
2018-07-26 09:04:39;In this notebook, I would like to use the Hough transform to cluster hits. This notebook is therefore, get some materials from the past published kernels, In the previous notebook, we see a function relating phi and r like (where r=√x2+y2r=x2+y2−−−−−−√, ϕ=arctan2(y/x)ϕ=arctan2(y/x)): ϕnew=ϕ+i(ar+br2),ϕnew=ϕ+i(ar+br2), where ii is increased incrementally from 0 (straight tracks) to some number (curve tracks). However, the above equation is not exact to relate those two features. Instead, one might want to use the Hough transform: r2r0=cos(ϕ−θ)r2r0=cos(ϕ−θ) In the above equation, ϕϕ and rr are the original ϕϕ and rr of each hit, while r0r0 and θθ are the rr and ϕϕ of a specific point in the XY plane, that is the origin of a circle in XY plane. That circle passes through the inspected hit. Then, our clustering problem can be stated this way:  For each 12r012r0, starting from 0 (corresponding to straight tracks), to an appropriate stopping point, we calculate θ=ϕ−arccos(r2r0)θ=ϕ−arccos(r2r0) Group all hits with the near θθ and some other features to a detected track by DBSCAN. Since θθ can take very large or small values, using sin(θ)sin(θ) and cos(θ)cos(θ) is better.;Apache 2.0;https://www.kaggle.com/khahuras/0-53x-clustering-using-hough-features-basic;1.0;['sklearn'];['dl', 'ai', 'nn', 'ml'];['filter', 'train', 'model', 'layer', 'clustering', 'loss', 'label', 'predict'];https://www.kaggle.com/c/trackml-particle-identification;0.689;0.411;2020-12-13 17:43:28;TrackML Particle Tracking Challenge;[];[0.53x] Clustering using Hough features - Basic;Python notebook;2392.0;33;;
2018-05-04 14:06:20;AboutThis notebook is a basic example for looking at individual events, events, creating a solution and submitting it. It walks through some of the library function for accessing the data and writing a submission file.  This example uses DBScan to solve the tracking problem.;Apache 2.0;https://www.kaggle.com/mikhailhushchyn/dbscan-benchmark;1.0;['pattern', 'sklearn'];['ai', 'ml'];['train', 'recognition', 'model', 'layer', 'clustering', 'label', 'predict'];https://www.kaggle.com/c/trackml-particle-identification;0.748;0.463;2020-12-13 17:43:28;TrackML Particle Tracking Challenge;[];DBSCAN Benchmark;Python notebook;9733.0;62;;
2018-05-04 16:04:54;AboutThis notebook is a basic example for looking at individual events, creating a solution and submitting it. It walks through some of the library function for accessing the data and writing a submission file. This example uses the Hough transform to solve the tracking problem.;Apache 2.0;https://www.kaggle.com/mikhailhushchyn/hough-transform;1.0;['pattern'];['ai', 'ml'];['test data', 'train', 'recognition', 'model', 'layer', 'label', 'predict'];https://www.kaggle.com/c/trackml-particle-identification;0.729;0.45;2020-12-13 17:43:28;TrackML Particle Tracking Challenge;[];Hough Transform;Python notebook;6076.0;53;;
2018-05-14 19:25:51;Based on the baselineThe main difference is the use of HDBSCAN as clustering algorithm;Apache 2.0;https://www.kaggle.com/mindcool/hdbscan-clustering-ii;1.0;['pattern', 'sklearn'];['ai', 'ml'];['train', 'recognition', 'model', 'layer', 'clustering', 'label', 'predict'];https://www.kaggle.com/c/trackml-particle-identification;0.738;0.449;2020-12-13 17:43:28;TrackML Particle Tracking Challenge;[];HDBSCAN clustering II;Python notebook;7620.0;52;0.24932;0.25074
2018-07-19 19:32:13;This python notebook inspired in Grzegorz Sionkowsk algorithm to initialize the clusters with DBSCAN. After the initialization there is a post processing of clusters using  some ideas of the paper Fitting helices to data by total least squares by Yves Nievergelt and thresholds of minimum and maximum clusters sizes. The method to determine if a set of points in space fits in a helix is shown below;Apache 2.0;https://www.kaggle.com/mindcool/unrolling-of-helices-outliers-removal;1.0;['pattern', 'sklearn'];['ai', 'ml', 'rl'];['train', 'fitting', 'model', 'recognition', 'label', 'predict'];https://www.kaggle.com/c/trackml-particle-identification;0.754;0.545;2020-12-13 17:43:27;TrackML Particle Tracking Challenge;[];Unrolling of helices + outliers removal;Python notebook;11524.0;189;;
2020-03-10 04:48:03;Step 1 - Prepare training data use 10 events for training input: hit pair output: 1 if two hits are the same particle_id, 0 otherwise. feature size: 10 (5 per hit);Apache 2.0;https://www.kaggle.com/outrunner/trackml-2-solution-example;1.0;['tensorflow', 'keras'];['ai', 'ml'];['training data', 'train', 'model', 'epoch', 'layer', 'loss', 'predict', 'ground truth'];https://www.kaggle.com/c/trackml-particle-identification;0.719;0.411;2020-12-13 17:43:28;multiple data sources;[];TrackML #2 solution example;Python notebook;4726.0;33;;
2018-08-17 23:26:35;Chapter 1: IntroductionThe kernel demonstrates the clustering and expending we used to get to 7# place. Running this kernel on training event 1000 will score ~0.635 after the clustering stage, and 0.735 after expending stage. Every stage takes about 8-10 min on Kaggle, and about half the time on my laptop. In the clustering part of the kernel the algorithm uses 5.500 pairs of z0, 1/2R (more on it below). By increasing the number to about 100.000 pairs the score will plateau at about 0.765 (after expending). How does it work: In each clustering loop the algorithm try to find all tracks originating from (0,0,z0) and with a radius of 1/(2*kt). If a hit (x,y,z) is on a track the helix can be fully defined by the following features (1), (2) rr=(x^2+y^2)^0.5 theta=arctan(y/x) dtheta = arcsin(kt*rr) (1) Theta=theta+dtheta (2) (z-z0)*kt/dtheta To solve the +pi,-pi problem we use sin, cos for theta. To make (2) more uniform, we use arctan((z-z0)/(3.3*dtheta/kt)) After calculating the features, the algorithm tries to cluster all the hits with the same features. This is done by sparse binning – using np.unique. The disadvantage of sparse binning over dbscan is it’s sensitivity, the advantages are its speed and its sensitivity (almost no outliners). After clustering every hit choose if his cluster is good according to the clusters length. Every 500 loops all hits belonging to tracks which are long enough are removed from the dataset If two hits from the same detector are on the same track, the one which is closest to the track’s center of mass is chosen. The z0, kt pairs are chosen randomly. While running, the algorithm changes the bin width and the length of the minimum track to be extracted from the dataset. Expending is done by selecting the un-clustered hits which are close to the center of mass of the track.;Apache 2.0;https://www.kaggle.com/yuval6967/7th-place-clustering-extending-ml-merging-0-75;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'gbm', 'rl', 'nn', 'ml'];['filter', 'machine learning', 'training data', 'test data', 'train', 'model', 'validation data', 'layer', 'clustering', 'label', 'predict'];https://www.kaggle.com/c/trackml-particle-identification;0.68;0.39;2020-12-13 17:43:28;multiple data sources;[];7th place- clustering, extending, ML merging: 0.75;Python notebook;1978.0;26;;
2018-09-03 14:16:37;Hi there! This is my first kernel dealing with textual data so any constructive feedabacks are higly appreciated. This dataset contains data of over 7 topics namely biology, robotics, cryptography, diy, travel, cooking, robotics and physics extracted from Stack Exchange. Each of these topics except physics have been classified as to which topic data belongs. So our task is to do predictions on unseen physics questions. Since our data won't be related to each other for example tags in travel won't be related to tags in cryptography hence I will be using unsupervised learning on physics dataset which is the test dataset.;Apache 2.0;https://www.kaggle.com/akshatpathak/text-data-clustering;1.0;['sklearn', 'nltk'];['ner', 'ai', 'rl', 'ml', 'nn', 'ann'];['filter', 'test data', 'recognition', 'model', 'layer', 'clustering', 'k-means', 'predict', 'unsupervised learning', 'supervised learning'];https://www.kaggle.com/c/transfer-learning-on-stack-exchange-tags;0.718;0.292;2020-12-13 17:46:50;Transfer Learning on Stack Exchange Tags;['beginner, data visualization, data cleaning, +2 moretext data, clustering'];Text Data Clustering;Python notebook;4667.0;9;;
2016-12-06 02:54:53;Transfer Learning on Stack Exchange Tags;Apache 2.0;https://www.kaggle.com/charlescostello/transfer-learning-on-stack-exchange-tags;1.0;['pattern', 'tensorflow', 'sklearn'];['ner', 'ai', 'rl', 'ml', 'nlp', 'nn', 'ann'];['test data', 'train', 'model', 'reward', 'label', 'loss'];https://www.kaggle.com/c/transfer-learning-on-stack-exchange-tags;0.668;0.236;2020-12-13 17:46:50;Transfer Learning on Stack Exchange Tags;[];Transfer Learning on Stack Exchange Tags;Python notebook;1543.0;5;;
2017-02-24 00:28:21;Text PreprocessingText preprocessing made on the competition datasets. The preprocessing consists of 4 steps:  Removing tags and URIs from contents Removing punctuation from titles and contents Removing stopwords from titles and contents Converting the tags from string to a list of tags  This type of operations can be used as a first step for any other process regarding the competition.;Apache 2.0;https://www.kaggle.com/l3nnys/useful-text-preprocessing-on-the-datasets;1.0;['nltk'];['ml'];['filter'];https://www.kaggle.com/c/transfer-learning-on-stack-exchange-tags;0.761;0.465;2020-12-13 17:46:50;Transfer Learning on Stack Exchange Tags;[];Useful Text Preprocessing on the datasets;Python notebook;14025.0;64;;
2016-12-31 08:33:32;This is my first script, I'm analyzing the biology corpus to extract tags using tfidf score, I increased the value for words that appear in the title, and I'm evaluating the output with the corpus tags, i got a low score: 0.073, I'm going to apply advanced techniques in order to increase the score.;Apache 2.0;https://www.kaggle.com/mrtroll/analying-tfidf-biology-corpus;1.0;['nltk'];['ai', 'nn', 'ml'];['predict'];https://www.kaggle.com/c/transfer-learning-on-stack-exchange-tags;0.647;0.214;2020-12-13 17:46:50;Transfer Learning on Stack Exchange Tags;[];Analying TFIDF biology corpus;Python notebook;1032.0;4;;
2017-01-03 02:50:00;This is my first try, i'm going to try another techniques in order to increase the results.;Apache 2.0;https://www.kaggle.com/mrtroll/physic-corpus-feature-extraction-through-tfidf-v1;1.0;['nltk'];['ai', 'nn', 'ml'];['predict'];https://www.kaggle.com/c/transfer-learning-on-stack-exchange-tags;0.683;0.236;2020-12-13 17:46:50;Transfer Learning on Stack Exchange Tags;[];Physic corpus feature extraction through TFIDF v1;Python notebook;2108.0;5;;
2016-12-21 18:57:54;Introduction In this notebook, I will present the method I propose to make of this competition a supervised learning challenge. The only source of data I found and that I think it is relevant is the scientific paper stored in Springer. I used its API to create my training set. To create the model, I used binary relevance: I'm not sure it's the best way but everything in this notebook are open to debate.  List of the libraries used in this notebook;Apache 2.0;https://www.kaggle.com/pierre54/supervised-learning-binary-relevance;1.0;['sklearn', 'nltk'];['ann', 'ai', 'nn', 'ml'];['regression', 'train', 'fitting', 'model', 'predict', 'supervised learning'];https://www.kaggle.com/c/transfer-learning-on-stack-exchange-tags;0.671;0.188;2020-12-13 17:46:50;Transfer Learning on Stack Exchange Tags;[];Supervised learning / Binary relevance;Python notebook;1647.0;3;;
2016-12-21 17:02:49;Shared TagsExplore tags that are used in more than one categories I build the needed DataFrame myself. Using sklearn CountVectorizer might be a quicker and maybe more reusable solution, but I find the following lines short and intuitive enough for the task.;Apache 2.0;https://www.kaggle.com/sagado/tags-exploration-distribution-and-shared-tags;1.0;['sklearn'];['ai', 'dl', 'rl', 'nn', 'ann'];['train', 'label', 'filter'];https://www.kaggle.com/c/transfer-learning-on-stack-exchange-tags;0.657;0.292;2020-12-13 17:46:50;Transfer Learning on Stack Exchange Tags;[];Tags Exploration (distribution and shared tags);Python notebook;1257.0;9;;
2017-02-25 02:39:25;This is part of a course project on NLP and deep learning (CS224n at Stanford). We aim to leverage principles of NLP to consistently predict tags of Stack Exchange posts across disciplines.;Apache 2.0;https://www.kaggle.com/shifanmao/nlp-and-deep-learning;1.0;['sklearn', 'gensim'];['ner', 'ai', 'nlp', 'nn', 'ml'];['predict', 'train', 'model', 'deep learning', 'clustering'];https://www.kaggle.com/c/transfer-learning-on-stack-exchange-tags;0.705;0.188;2020-12-13 17:46:50;Transfer Learning on Stack Exchange Tags;[];NLP and deep learning;Python notebook;3450.0;3;;
2017-03-04 21:27:58;First time ever trying out with unstructured data. So the concept of TF-IDF, LDA seemed really awesome. shall be exploring this more. Hope you find this useful. Please do share your comments and upvote if you liked it.;Apache 2.0;https://www.kaggle.com/vasaibaby/r-cleaning-data-and-using-tf-idf;1.0;['pattern'];['ner', 'ai', 'dl', 'rl', 'ml', 'nlp', 'nn', 'ann'];['understanding', 'model', 'filter'];https://www.kaggle.com/c/transfer-learning-on-stack-exchange-tags;0.735;0.236;2020-12-13 17:46:50;Transfer Learning on Stack Exchange Tags;[];R : cleaning data, and using TF-IDF ;R notebook;7035.0;5;;
2018-12-11 07:06:07;"This solution uses Google OR-Tools to optimize the routing for Santa. OR-Tools include a ""vehicle routing library"" for solving TSPs and a convenient Python interface. Lucky for us, it's all included in Kaggle kernels! The start point for the route comes from model-based clustering. You can see from the city plot how the density of points varies quite a bit across the grid. The right clustering approach may work better than starting with a grid or k-means clustering. Also, breaking the cities into clusters can scale to millions of points on a typical machine if the need arises. Here is the overall approach:  Divide cities into clusters Get centers for each cluster Find an optimal path across centers Find start and stop points for each cluster Find an optimal segment for each cluster and assemble";Apache 2.0;https://www.kaggle.com/jpmiller/google-or-tools-w-clusters;1.0;['sklearn'];['ai', 'nn', 'rl'];['predict', 'train', 'model', 'k-means', 'clustering'];https://www.kaggle.com/c/traveling-santa-2018-prime-paths;0.747;0.502;2020-12-13 17:50:09;Traveling Santa 2018 - Prime Paths;['data visualization, optimization'];Google OR-Tools w/Clusters ❄;Python notebook;9574.0;103;;
2019-01-11 12:39:10;I'm going to feed a better initial tour found by LKH on my local machine to my previous kernel.;Apache 2.0;https://www.kaggle.com/kostyaatarik/better-input-for-aka-2-opt;0.7;['sklearn'];['ai'];[];https://www.kaggle.com/c/traveling-santa-2018-prime-paths;0.687;0.452;2020-12-13 17:50:10;multiple data sources;[];Better Input For 'aka 2-opt';Python notebook;2309.0;54;;
2019-01-13 19:08:11;I'm going to share simple but working tsp solutions optimization technique. The idea is straightforward: if you have two cities in the path that are 'close' (in distance terms) to each other you can try to reverse the order of the path between them hoping that the decrease of the total penalty in this part of the path will be greater than the increase of the length caused by the reversing itself. Also instead of just reversing the chunk of the path you can try to play with its ends. This is exactly what is called chunk_abc/chunk_acb/chunk_abcb in the code below.;Apache 2.0;https://www.kaggle.com/kostyaatarik/close-ends-chunks-optimization-aka-2-opt;0.7;['sklearn'];['ner', 'ai'];[];https://www.kaggle.com/c/traveling-santa-2018-prime-paths;0.708;0.497;2020-12-13 17:50:09;multiple data sources;[];Close Ends Chunks Optimization aka 2-opt;Python notebook;3666.0;97;;
2019-01-13 19:11:28;I'm going to share YET ANOTHER simple but working tsp solutions optimization technique. The idea is straightforward: if you have THREE cities in the path that are 'close' (in distance terms) to each other you can try to split the path by them and try different permutations of resulting chunks hoping that the decrease of the total penalty in this part of the path will be greater than the increase of the length caused by the permutation itself. Also instead of just permutating the chunks of the path you can  try to revert the order of some chunks but I won't do it in this kernel.;Apache 2.0;https://www.kaggle.com/kostyaatarik/not-a-3-and-3-halves-opt;0.7;['sklearn'];['ner', 'ai'];[];https://www.kaggle.com/c/traveling-santa-2018-prime-paths;0.705;0.509;2020-12-13 17:50:09;multiple data sources;[];Not a 3-and-3-halves-opt;Python notebook;3433.0;113;;
2019-01-13 19:14:35;This kernel is based on my previous kernel and while it shares the same idea of permutating the chunks of the path it expands it to fives of points and handles permutations much faster by moving the code that finds the best permutation of chunks to numba which is a great tool to squeeze everything you can from python. As an initial path to start optimization from I'll use the output from my another kernel.;Apache 2.0;https://www.kaggle.com/kostyaatarik/not-a-5-and-5-halves-opt;0.7;['sklearn'];['ai', 'dl'];[];https://www.kaggle.com/c/traveling-santa-2018-prime-paths;0.681;0.469;2020-12-13 17:50:10;multiple data sources;[];Not a 5-and-5-halves-opt;Python notebook;2013.0;67;;
2019-01-13 19:13:06;I'm going to feed a better initial tour found by the one of my previous kernels to another one.;Apache 2.0;https://www.kaggle.com/kostyaatarik/shame-on-me;0.7;['sklearn'];['ner', 'ai'];[];https://www.kaggle.com/c/traveling-santa-2018-prime-paths;0.72;0.48;2020-12-13 17:50:09;multiple data sources;[];shame on me;Python notebook;4898.0;77;;
2018-12-06 08:24:27;"In this kernel we try to get a basic understanding of the problem and explore a few simple solutions to see a how they differ.In case you haven't already figured it out, this is a version of the ""Traveling Salesman Problem"". May be the winning solution is going to be one of the very advanced approaches to that problem. But let us not get scared by an NP-Complete problem. We will start with some simple dumb approaches first and see where they lead us.";Apache 2.0;https://www.kaggle.com/seshadrikolluri/understanding-the-problem-and-some-sample-paths;1.0;['pattern'];['ner', 'ai', 'nn', 'ann'];['train', 'understanding'];https://www.kaggle.com/c/traveling-santa-2018-prime-paths;0.769;0.553;2020-12-13 17:50:09;Traveling Santa 2018 - Prime Paths;['data visualization'];Understanding the problem and some sample paths;Python notebook;17503.0;212;1811953.68248;1811953.68248
2020-06-09 16:07:04;COVID-19: current situation EDA including the recent updates, recovering country analysis & sigmoid fitting convergence date estimation. plotly visualization is heavy used;Apache 2.0;https://www.kaggle.com/ajaygoswami/kernel6b62964a77;1.0;['xgboost', 'catboost', 'sklearn', 'tensorflow', 'stanza'];['ner', 'ai', 'dl', 'gbm', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'test data', 'train', 'fitting', 'model', 'deep learning', 'label', 'gradient boosting', 'relu'];https://www.kaggle.com/c/trec-covid-information-retrieval;0.516;0.0;2020-12-13 17:51:06;TREC-COVID Information Retrieval;[];kernel6b62964a77;Python notebook;126.0;0;;
2020-06-03 15:09:39;TREC-COVID Search IndexThis notebook builds a search index over the TREC-COVID dataset. Background on how this search index works can be found in the CORD-19 Analysis with Sentence Embeddings notebook. Install environmentInstall the cord19q library and scispacy.;Apache 2.0;https://www.kaggle.com/davidmezzetti/trec-covid-search-index;1.0;['spacy', 'nltk'];['ner', 'ai', 'rl', 'nlp', 'nn', 'ml'];['model', 'predict'];https://www.kaggle.com/c/trec-covid-information-retrieval;0.604;0.188;2020-12-13 17:51:06;multiple data sources;['covid19'];TREC-COVID Search Index;Python notebook;481.0;3;;
2020-06-03 17:09:07;TREC-COVID SubmissionThis notebook builds a submission file using the search index build in the TREC-COVID Search Index notebook. For each topic, a query is run against the search index and the Top N search results are saved. Upon completion, a file with the search results per topic are written to an output file named submission.csv;Apache 2.0;https://www.kaggle.com/davidmezzetti/trec-covid-submission;1.0;['spacy', 'nltk'];['ner', 'ai', 'rl', 'nlp', 'nn', 'ml'];['model', 'predict'];https://www.kaggle.com/c/trec-covid-information-retrieval;0.58;0.099;2020-12-13 17:51:06;multiple data sources;['covid19'];TREC-COVID Submission;Python notebook;323.0;1;;
2020-05-27 21:05:23;What is the ACE2 receptor, how is it connected to coronavirus and why might it be key to treating COVID-19?Authors: Krishna Sriram: Postdoctoral Fellow, University of California San Diego Paul Insel: Professor of Pharmacology and Medicine, University of California San Diego Rohit Loomba: Professor of Medicine, University of California San Diego In the search for treatments for COVID-19, many researchers are focusing their attention on a specific protein that allows the virus to infect human cells. Called the angiotensin-converting enzyme 2, or ACE2 “receptor,” the protein provides the entry point for the coronavirus to hook into and infect a wide range of human cells. ACE2 is a protein on the surface of many cell types. It is an enzyme that generates small proteins – by cutting up the larger protein angiotensinogen – that then go on to regulate functions in the cell. Using the spike-like protein on its surface, the SARS-CoV-2 virus binds to ACE2 – like a key being inserted into a lock – prior to entry and infection of cells. Hence, ACE2 acts as a cellular doorway – a receptor – for the virus that causes COVID-19. https://theconversation.com/what-is-the-ace2-receptor-how-is-it-connected-to-coronavirus-and-why-might-it-be-key-to-treating-covid-19-the-experts-explain-136928;Apache 2.0;https://www.kaggle.com/mpwolke/covid-19-ace;1.0;['pattern', 'caffe', 'sklearn'];['ner', 'ai', 'nlu', 'dl', 'cnn', 'gan', 'cv', 'rl', 'nn', 'rnn', 'ml'];['filter', 'regression', 'model', 'clustering', 'label', 'predict', 'relu', 'recommend'];https://www.kaggle.com/c/trec-covid-information-retrieval;0.688;0.362;2020-12-13 17:51:06;multiple data sources;[];Covid-19 & ACE;Python notebook;2331.0;19;;
2020-05-31 00:03:29;An interpretable mortality prediction model for COVID-19 patientsYan, L., Zhang, H., Goncalves, J. et al. An interpretable mortality prediction model for COVID-19 patients. Nat Mach Intell 2, 283–288 (2020). https://doi.org/10.1038/s42256-020-0180-7 This study leverages a database of blood samples from 485 infected patients in the region of Wuhan, China, to identify crucial predictive biomarkers of disease mortality. For this purpose, machine learning tools selected three biomarkers that predict the mortality of individual patients more than 10 days in advance with more than 90% accuracy: lactic dehydrogenase (LDH), lymphocyte and high-sensitivity C-reactive protein (hs-CRP). In particular, relatively high levels of LDH alone seem to play a crucial role in distinguishing the vast majority of cases that require immediate medical attention. This finding is consistent with current medical knowledge that high LDH levels are associated with tissue breakdown occurring in various diseases, including pulmonary disorders such as pneumonia. Overall, this Article suggests a simple and operable decision rule to quickly predict patients at the highest risk, allowing them to be prioritized and potentially reducing the mortality rate.https://www.nature.com/articles/s42256-020-0180-7;Apache 2.0;https://www.kaggle.com/mpwolke/covid-19-biomarkers;1.0;['pattern', 'caffe', 'xgboost'];['ner', 'ai', 'dl', 'cnn', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['gru', 'machine learning', 'regression', 'neuron', 'train', 'fitting', 'model', 'recognition', 'understanding', 'generation', 'reward', 'layer', 'loss', 'label', 'predict', 'rank', 'decision tree', 'classification'];https://www.kaggle.com/c/trec-covid-information-retrieval;0.548;0.0;2020-12-13 17:51:06;multiple data sources;[];Covid-19 Biomarkers;Python notebook;199.0;0;;
2020-05-28 01:17:01;COVID-19 and the Cytokine Storm: The Crucial Role of IL-6Emerging data suggest that many patients infected with COVID-19 may die due to an excessive response of their immune system, characterized by the abnormal release of circulating cytokines, termed cytokine release syndrome (CRS). CRS plays a major role in the deterioration of COVID-19 patients, from pneumonia through acute respiratory distress syndrome (ARDS), cumulating in systemic inflammation and ultimately multi-system organ failure. This phenomenon of a plethora of cytokines wreaking havoc throughout the body is often vividly referred to as “cytokine storm.” https://www.enzolifesciences.com/science-center/technotes/2020/april/covid-19-and-the-cytokine-storm-the-crucial-role-of-il-6/;Apache 2.0;https://www.kaggle.com/mpwolke/covid-19-cytokine-storm;1.0;['pattern', 'caffe'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nn', 'ann'];['model', 'layer', 'predict', 'understanding', 'propagation'];https://www.kaggle.com/c/trec-covid-information-retrieval;0.542;0.0;2020-12-13 17:51:06;multiple data sources;[];Covid-19 Cytokine Storm;Python notebook;182.0;0;;
2020-05-27 23:22:14;Interleukins are a group of naturally occurring proteins that mediate communication between cells. Interleukins manage cell growth and differentiation. Interleukins are also important in regulating immune responses, such as inflammation. Interleukins are part of a bigger group of messenger molecules called cytokines. They are a part of the “inflammatory cascade” that involves the coordinated, sequential activation of immune response pathways. Cytokines are produced by a broad range of cells, including immune cells like macrophages, B lymphocytes, T lymphocytes and mast cells, as well as endothelial cells, fibroblasts, and various stromal cells.https://blog.healthmatters.io/2018/08/23/what-is-interleukin-6/ Interleukin-6 (IL-6) is an endogenous chemical which is active in inflammation, and in B cell maturation. Besides being an immune protein, it is also a pyrogen, and is responsible for fever in autoimmune, infectious or non-infectious disease;Apache 2.0;https://www.kaggle.com/mpwolke/covid-19-interleukin-6;1.0;['caffe'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nn', 'ann'];['regression', 'generation', 'train', 'loss', 'label', 'predict', 'rank'];https://www.kaggle.com/c/trec-covid-information-retrieval;0.542;0.152;2020-12-13 17:51:06;multiple data sources;[];Covid-19 Interleukin-6;Python notebook;181.0;2;;
2020-04-28 16:58:33;Install Rapids for 5x Faster SVM on GPU;Apache 2.0;https://www.kaggle.com/aerdem4/rapids-svm-on-trends-neuroimaging;1.0;['xgboost', 'sklearn'];['ai', 'ml'];['train', 'model', 'label', 'predict'];https://www.kaggle.com/c/trends-assessment-prediction;0.764;0.548;2020-12-13 17:52:38;multiple data sources;[];RAPIDS SVM on TReNDS Neuroimaging;Python notebook;14986.0;198;0.16001;0.15985
2020-05-17 18:40:33;Leave One Feature Out ImportanceIt is difficult to calculate the feature importances with traditional ways in such high dimensional data. Thanks to LOFO, we can group the features and get one importance value for the whole group. In this notebook, while each loading feature is considered as separate feature, fnc features are considered as one group. Then we calculate the feature importances for each target using a ridge regression model within cross-validation.;Apache 2.0;https://www.kaggle.com/aerdem4/trends-lofo-feature-importance;1.0;['lightgbm', 'sklearn'];['cv', 'ai', 'gbm'];['regression', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/trends-assessment-prediction;0.667;0.429;2020-12-13 17:52:38;TReNDS Neuroimaging;[];TReNDS LOFO Feature Importance;Python notebook;1532.0;41;;
2020-06-07 13:25:10;"IntroductionIn this competition a significant delta between local CV and LB scores has been reported in some cases (https://www.kaggle.com/c/trends-assessment-prediction/discussion/153256). We have many features to work with... maybe too many. Reducing variance would seem to be a good thing here and I wanted to investigate the BaggingRegressor for that. The idea is to use the BaggingRegressor to build multiple models, each considering only a fraction of the features, then combine their outputs. From the scikit-learn docs: ""A Bagging regressor is an ensemble meta-estimator that fits base regressors each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction. Such a meta-estimator can typically be used as a way to reduce the variance of a black-box estimator (e.g., a decision tree), by introducing randomization into its construction procedure and then making an ensemble out of it."" Ridge regression is known to work well on this dataset, so is used as the base regressor here. The use of the BaggingRegressor is considered as part of a high-performing ensemble, combining SVM and Ridge regression. This notebook is heavily based on @aerdem4's excellent SVM notebook and @tunguz's notebook that adds Ridge regression. Those original notebooks can be found here: https://www.kaggle.com/aerdem4/rapids-svm-on-trends-neuroimaging https://www.kaggle.com/tunguz/rapids-ensemble-for-trends-neuroimaging/ ResultsAfter doing an offline sweep of blending weights, the final weights show that for the best local CV, the BaggingRegressor was hardly used for the ""age"" target. However, the BaggingRegressor provided more benefits for the domain variables. In particular for ""domain1_var2"" and ""domain2_var2"" the BaggingRegressor almost completely replaces the basic Ridge regression method. In terms of local CV, the result is almost identical to Bojan's notebook referenced above. On the leaderboard, adding the BaggingRegressor into the ensemble scores 0.1593, an improvement over Bojan's 0.1595. So the local CV to LB delta is successfully reduced, albeit by a little. I find it particularly interesting that only considering small subsets of the features, the BaggingRegressor is competitive for the domain variables but not at all for age.";Apache 2.0;https://www.kaggle.com/andypenrose/baggingregressor-rapids-ensemble;1.0;['xgboost', 'sklearn'];['ai', 'dl', 'rl', 'cv', 'ml'];['filter', 'regression', 'train', 'model', 'label', 'predict', 'decision tree'];https://www.kaggle.com/c/trends-assessment-prediction;0.711;0.458;2020-12-13 17:52:38;multiple data sources;['gpu'];BaggingRegressor + RAPIDS Ensemble;Python notebook;3916.0;58;0.15953;0.15936
2020-06-30 13:31:44;1. Train Scores (Targets)train_scores.csv is the file which consists of target features. Those features are age, domain1_var1, domain1_var2, domain2_var1 and domain2_var2. There are 5 target features to predict and submissions are scored using feature-weighted, normalized absolute errors. score =∑fwf(∑i|yf,i−y^f,i|∑iy^f,i)=∑fwf(∑i|yf,i−y^f,i|∑iy^f,i) The weights are [.3, .175, .175, .175, .175] corresponding to features [age, domain1_var1, domain1_var2, domain2_var1, domain2_var2]. This means every targets normalized absolute error is independent from each other. They can be trained and predicted with a single model or 5 different models. Another important thing to consider is, train_scores.csv are not the original age and raw assessment values. They have been transformed and de-identified to help protect subject identity and minimize the risk of unethical usage of the data. Nonetheless, they are directly derived from the original assessment values and, thus, associations with the provided features is equally likely. Before transformation, the age in the training set is rounded to nearest year for privacy reasons. However, age is not rounded to year (higher precision) in the test set. Thus, heavily overfitting to the training set age will very likely have a negative impact on your submissions.;Apache 2.0;https://www.kaggle.com/gunesevitan/trends-neuroimaging-data-analysis-3d-features;1.0;['pattern', 'lightgbm', 'sklearn'];['ner', 'ai', 'dl', 'cnn', 'gbm', 'gan', 'rl', 'nlp', 'nn', 'ann'];['unlabeled', 'filter', 'regression', 'train', 'fitting', 'model', 'label', 'predict', 'classification', 'labeled'];https://www.kaggle.com/c/trends-assessment-prediction;0.726;0.521;2020-12-13 17:52:38;TReNDS Neuroimaging;['beginner, data visualization, exploratory data analysis'];TReNDS Neuroimaging - Data Analysis & 3D Features;Python notebook;5663.0;134;;
2020-04-27 10:18:53;I am sharing my notebook as It is a research competition, I would love if someone would be able to achieve great with the help of my simple notebook.I want to give credits to this notebook for helping me out in some visuals.  Feel free to use my notebook and please I request all of you to share your notebooks too.;Apache 2.0;https://www.kaggle.com/nischaydnk/beginners-trends-neuroimaging-decent-score;1.0;['lightgbm', 'sklearn'];['ai', 'gan', 'gbm', 'cv', 'nlp', 'nn'];['train', 'fitting', 'model', 'predict'];https://www.kaggle.com/c/trends-assessment-prediction;0.709;0.449;2020-12-13 17:52:38;TReNDS Neuroimaging;['data visualization, random forest'];Beginners (TReNDS Neuroimaging + Decent Score);Python notebook;3761.0;52;;
2020-06-19 23:37:55;This is a notebook version of the code shared by SeuTaoHis gihub repohttps://github.com/SeuTao/RSNA2019_Intracranial-Hemorrhage-DetectionI made small modifications to adapt it to Kaggle Kernel for the people who does not have local GPU .;Apache 2.0;https://www.kaggle.com/phoenix9032/seutao-3d-resnet34-model-image-tabular-monai;1.0;['pytorch', 'sklearn', 'pillow'];['ner', 'ai', 'cv', 'rl', 'nn', 'ann'];['filter', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'resnet'];https://www.kaggle.com/c/trends-assessment-prediction;0.705;0.437;2020-12-13 17:52:38;TReNDS Neuroimaging;['gpu'];SeuTao-3D Resnet34 Model Image + Tabular + Monai;Python notebook;3455.0;45;;
2020-05-27 19:16:00;Hello this complete code workflow is adopted from Y. Nakama's fantastic starter code .I have got to know about this Attention Based Interpretable Machine Learning -TabNet from https://www.kaggle.com/abhishek  and  wanted to try this out in TReNDs problem . I have limited experience in Machine Learning , so  may not have understood many places or there might be mistakes.I have used the below github repo  https://github.com/dreamquark-ai/tabnet/blob/develop/pytorch_tabnet Content is taken mainly from the original paper for TabNet . https://arxiv.org/abs/1908.07442 Note : I have not really played around with parameters of TabNet . Planning to do that in subsequent versions. Anyone interested also can try.;Apache 2.0;https://www.kaggle.com/phoenix9032/trends-google-tabnet-baseline;1.0;['pytorch', 'lightgbm', 'sklearn'];['ai', 'dl', 'gbm', 'cv', 'rl', 'nn', 'ann'];['filter', 'machine learning', 'regression', 'train', 'fitting', 'model', 'epoch', 'deep learning', 'layer', 'loss', 'label', 'predict', 'decision tree', 'classification'];https://www.kaggle.com/c/trends-assessment-prediction;0.695;0.446;2020-12-13 17:52:38;TReNDS Neuroimaging;['gpu'];TReNDS Google TabNet Baseline ;Python notebook;2754.0;50;0.17081;0.17109
2020-05-06 12:51:17;About this NotebookIn this notebook, i will try to cover following topics in as much detail as possible:  Domain Knowledge: In general, domain knowledge is important when posing the question you want answered from data, as well as understanding the limitations of the data. If you don't understand these things (e.g., if you're working with a client on a new problem), then an essential skill is being able to ask the right questions to tease these things out. Basic statistics on the dataset Extensive EDA Visualization of spatial maps Sample Submission  This kernel will be a work in Progress,and I will keep on updating it as the competition progresses Please upvote this kernel if you like it . It motivates me to produce more quality content :);Apache 2.0;https://www.kaggle.com/rohitsingh9990/trends-eda-visualization-simple-baseline;1.0;['spacy'];['ner', 'ai', 'gan', 'cv', 'rl', 'nlp', 'nn', 'ann'];['filter', 'regression', 'train', 'model', 'label', 'predict', 'understanding'];https://www.kaggle.com/c/trends-assessment-prediction;0.761;0.565;2020-12-13 17:52:38;multiple data sources;['data visualization, exploratory data analysis'];TReNDS - EDA + Visualization + Simple Baseline ;Python notebook;13846.0;255;0.16175;0.16208
2020-06-07 08:42:38;1. Introduction to PyCaretPyCaret is an open source, low-code machine learning library in Python that aims to reduce the cycle time from hypothesis to insights. It is well suited for seasoned data scientists who want to increase the productivity of their ML experiments by using PyCaret in their workflows or for citizen data scientists and those new to data science with little or no background in coding. PyCaret allows you to go from preparing your data to deploying your model within seconds using your choice of notebook environment. Please click this link to continue learning more about PyCaret. Please upvote this kernel if you like it . It motivates me to produce more quality content :);Apache 2.0;https://www.kaggle.com/rohitsingh9990/trends-pycaret-training-inference;1.0;['xgboost', 'lightgbm', 'catboost', 'sklearn', 'spacy'];['ner', 'ai', 'gbm', 'cv', 'nlp', 'nn', 'ml'];['linear regression', 'machine learning', 'test data', 'regression', 'train', 'model', 'clustering', 'support vector machines', 'label', 'gradient boosting', 'predict', 'decision tree', 'bayesian'];https://www.kaggle.com/c/trends-assessment-prediction;0.725;0.447;2020-12-13 17:52:38;TReNDS Neuroimaging;['feature engineering'];TReNDS - PyCaret (Training + Inference);Python notebook;5480.0;51;0.16146;0.16170
2020-06-17 18:36:27;About this notebook...A/c to me, this is one of the best competition on kaggle. It give you a chance to learn some cool new things on kaggle and broad you knowledge in Datascience. As already written in Introduction, Human brain research is among the most complex areas of study for scientists. We know that age and other factors can affect its function and structure, but more research is needed into what specifically occurs within the brain. With much of the research using MRI scans, data scientists are well positioned to support future insights. In particular, neuroimaging specialists look for measurable markers of behavior, health, or disorder to help identify relevant brain regions and their contribution to typical or symptomatic effects. I try my level best to give all things as simple as possible.;Apache 2.0;https://www.kaggle.com/saife245/neuroimaging-in-depth-understanding-eda-model;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cnn', 'gan', 'cv', 'rl', 'nlp', 'nn', 'ann'];['filter', 'machine learning', 'test data', 'train', 'model', 'understanding', 'neural network', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'recommend', 'classification', 'convolutional neural network'];https://www.kaggle.com/c/trends-assessment-prediction;0.694;0.482;2020-12-13 17:52:38;TReNDS Neuroimaging;['beginner, data visualization, exploratory data analysis, +1 moredeep learning'];NeuroImaging: In Depth Understanding,EDA,Model;Python notebook;2688.0;79;;
2020-05-04 08:57:01;First Look at the DataHi there,  I am currently finishing my PhD in cognitive neuroscience, so this is a nice distraction next to the writing process, so a little bit of domain knowledge might be here :) On the other hand, age prediction, resting state analysis, and structural imaging are not my area of expertise - so I don't know much about the different ICA algorithms used here. I will try to provide you with some high-level overview over the different kinds of data. And will update this notebook, when I have the time and get around to read up on some of the literature. We got many different files here, which are of course described on the Web-Page but let's see what we can learn by looking at it.  Also if you don't know too much nilearn yet, it's a great toolset and maybe you find some useful functions here! (final version so far, still missing links to more and better information - which I still might add later) Also please forgive me some weird sentences and typos :);Apache 2.0;https://www.kaggle.com/srsteinkamp/trends-eda;1.0;['pattern', 'sklearn'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ann'];['filter', 'test data', 'regression', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/trends-assessment-prediction;0.685;0.423;2020-12-13 17:52:38;TReNDS Neuroimaging;['beginner, data visualization, exploratory data analysis'];trends_EDA;Python notebook;2212.0;38;0.16618;0.16666
2020-09-01 15:56:53;About this NotebookIf anyone of you have read my previous kernels , you might know how much I love the EDA part , but it struck me that writing on one particular thing would not help me grow , so I have decided to explore untreaded territories to explore new things. For this competition people are mostly using Rapids and the tabular data . I have hardly seen any kernels using only images and both images and tabular data . Few days ago I saw Abhishek's post on LinkedIn about Tabnet and I was really curious about it , I wanted to apply the idea here on Trends data but it had already been done and didn't give good results so I dropped it. After watching Sebastian on Abhishek talks , I realized that Tabnet's potential isn't being fully utilized . This notebook presents a fully structured working pipeline for training n-folds Tabnet Regressor for this competition . This Notebook achieves 0.1620 without a lot of efforts and this notbook could beat Rapids SVM's and achieve the benchmark 0.1595 with some tweaks . I also explain the pros and cons of using Tabnets (although I don't find a lot cons 😜 ) Here is the link to Tabnet Paper If you like my efforts please leava an upvote .As I am not planning on doing this competition for now , if you all like my efforts I plan to release more public kernels on Tabnet with higher scores;Apache 2.0;https://www.kaggle.com/tanulsingh077/achieving-sota-results-with-tabnet;1.0;['pytorch', 'sklearn'];['ner', 'ai', 'dl', 'rl', 'nn', 'ann'];['predict', 'train', 'model', 'epoch', 'label', 'loss'];https://www.kaggle.com/c/trends-assessment-prediction;0.708;0.472;2020-12-13 17:52:38;TReNDS Neuroimaging;['gpu'];Achieving SOTA Results with Tabnet;Python notebook;3664.0;70;;
2020-04-24 05:22:20;Simple Baseline (not using 3D spatial map) NN model using fnc and loading optimize weighted normalized absolute errors directly 5-fold averaging;Apache 2.0;https://www.kaggle.com/ttahara/trends-simple-nn-baseline;1.0;['sklearn'];['ner', 'ai', 'cv', 'rl', 'nn', 'ml'];['test data', 'regression', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/trends-assessment-prediction;0.715;0.449;2020-12-13 17:52:38;TReNDS Neuroimaging;['gpu, neural networks'];TReNDS：Simple NN Baseline ;Python notebook;4304.0;52;0.16208;0.16194
2020-07-01 02:22:40;This is an ensemble version of @aerdem4's excellent SVM notebook that can be found here: https://www.kaggle.com/aerdem4/rapids-svm-on-trends-neuroimaging Rapids is an open-source GPU accelerated Data Sceince and Machine Learning library, developed and mainatained by Nvidia. It is designed to be compatible with many existing CPU tools, such as Pandas, scikit-learn, numpy, etc. It enables massive acceleration of many data-science and machine learning tasks, oftentimes by a factor fo 100X, or even more. Rapids is still undergoing developemnt, and as of right now it's not availabel in the Kaggle Docker environment. If you are interested in installing and riunning Rapids locally on your own machine, then you should refer to the followong instructions.;Apache 2.0;https://www.kaggle.com/tunguz/rapids-ensemble-for-trends-neuroimaging;1.0;['xgboost', 'sklearn'];['ai', 'nn', 'ml'];['machine learning', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/trends-assessment-prediction;0.752;0.512;2020-12-13 17:52:38;multiple data sources;['gpu'];RAPIDS Ensemble for TReNDS Neuroimaging;Python notebook;10887.0;118;0.15967;0.15953
2020-04-04 22:12:03;Story:I don't comment much for kernels but for this kernel I will. First of all I am very thankful to: @akensert, @ajinomoto132 and @adityaecdrid who helped me a lot in finding the mistake I was making. It was due to them that I was able to find the mistake in my training code. @akensert shared a kernel with data-processing similar to mine but a different model and loss function. This kernel was written using Tensorflow. You can checkout the kernel here: https://www.kaggle.com/akensert/complete-tf2-1-mixed-precision-implementation Please upvote @akensert's kernel mentioned above! :) Thus, my plan began to replicate the same score in pytorch. Previously I was using BCEWithLogitsLoss. The TF kernel used Cross Entropy loss. This was one of the major differences. Another major difference was using the last two hidden states instead of just the last one. So, I tried and failed. I then tried again, cleaned up my code, started comparing line-by-line and failed again. After 2 days of frustration, I made a discussion post asking for help: https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/141019 Then came @ajinomoto132. He mentioned he had replicated the model and gladly shared his code to help me out!!! His code can be found here: https://www.kaggle.com/ajinomoto132/starter-kernel-in-pytorch . Please upvote @ajinomoto132's kernel mentioned above! :) After a few more hours of struggle, I was able to find the mistake I was doing. It was a stupid mistake of not using .from_pretrained when using BertModel. Quite stupid I would say. Since the community helped me so much, I am releasing the fixed version of my code which is also much cleaner than the previous versions of my code. I love this community! Thank you for all the help!;Apache 2.0;https://www.kaggle.com/abhishek/bert-base-uncased-using-pytorch;1.0;['pytorch', 'tensorflow', 'sklearn'];['ner', 'ai', 'dl', 'gan', 'rl', 'nn'];['filter', 'test data', 'train', 'model', 'epoch', 'layer', 'loss'];https://www.kaggle.com/c/tweet-sentiment-extraction;0.774;0.569;2020-12-13 17:53:52;multiple data sources;['gpu'];BERT Base Uncased using PyTorch;Python notebook;20500.0;274;0.00000;0.00000
2020-04-16 17:34:54;"If you like it, upvote it. It's right next to ""Copy and Edit"".";Apache 2.0;https://www.kaggle.com/abhishek/roberta-on-steroids-pytorch-tpu-training;1.0;['pytorch', 'spacy', 'sklearn', 'pillow'];['ai', 'dl', 'rl', 'nlp', 'nn'];['filter', 'train', 'model', 'epoch', 'layer', 'loss', 'rank'];https://www.kaggle.com/c/tweet-sentiment-extraction;0.716;0.515;2020-12-13 17:53:52;multiple data sources;['tpu'];RoBERTa on Steroids: PyTorch TPU Training;Python notebook;4388.0;123;;
2020-04-20 19:03:57;TensorFlow roBERTa + CNN head - LB 0.712;Apache 2.0;https://www.kaggle.com/al0kharba/tensorflow-roberta-0-712;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'cnn', 'rl', 'cv', 'nn'];['predict', 'train', 'model', 'epoch', 'layer', 'loss', 'relu'];https://www.kaggle.com/c/tweet-sentiment-extraction;0.753;0.525;2020-12-13 17:53:52;multiple data sources;['gpu'];TensorFlow roBERTa - [0.712];Python notebook;11053.0;142;0.71378;0.71214
2020-04-14 04:57:52;TensorFlow roBERTa Starter - LB 0.705This notebook is a TensorFlow template for solving Kaggle's Tweet Sentiment Extraction competition as a question and answer roBERTa formulation. In this notebook, we show how to tokenize the data, create question answer targets, and how to build a custom question answer head for roBERTa in TensorFlow. Note that HuggingFace transformers don't have a TFRobertaForQuestionAnswering so we must make our own from TFRobertaModel. This notebook can achieve LB 0.715 with some modifications. Have fun experimenting! You can also run this code offline and it will save the best model weights during each of the 5 folds of training. Upload those weights to a private Kaggle dataset and attach to this notebook. Then you can run this notebook with the line model.fit() commented out, and this notebook will instead load your offline models. It will use your offline models to predict oof and predict test. Hence this notebook can easily be converted to an inference notebook. An inference notebook is advantageous because it will only take 10 minutes to commit and submit instead of 2 hours. Better to train 2 hours offline separately.;Apache 2.0;https://www.kaggle.com/cdeotte/tensorflow-roberta-0-705;1.0;['pytorch', 'tensorflow', 'sklearn', 'keras'];['ai', 'rl', 'nn', 'cv'];['filter', 'training data', 'test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'labeled'];https://www.kaggle.com/c/tweet-sentiment-extraction;0.781;0.587;2020-12-13 17:53:52;multiple data sources;['gpu'];TensorFlow roBERTa - [0.705];Python notebook;24709.0;360;0.71347;0.70907
2020-04-13 19:59:49;TensorFlow roBERTa - Unsupervised Text SelectionWow, this notebook does not use selected_text. This notebook only uses the columns text and sentiment. We train a roBERTa model to predict sentiment (pos, neg, neu) from Tweet text achieving 80% accuracy. We then display what part of the text was influencial in deciding whether the text was postive, negative, or neutral. This is unsupervised learning because we are learning the selected_text without using the selected_text. This unsupervised DL notebook is inspired by Nick's awesome unsupervised ML notebook here and it's similar to my previous unsupervised DL notebook for image recognition here;Apache 2.0;https://www.kaggle.com/cdeotte/unsupervised-text-selection;1.0;['pytorch', 'tensorflow', 'keras'];['ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['train', 'recognition', 'model', 'epoch', 'supervised learning', 'layer', 'loss', 'label', 'predict', 'unsupervised learning', 'classification'];https://www.kaggle.com/c/tweet-sentiment-extraction;0.707;0.516;2020-12-13 17:53:52;multiple data sources;['gpu'];Unsupervised Text Selection;Python notebook;3608.0;125;;
2020-04-15 14:08:00;"Several procedures come from my previous notebook (I suggest to take a look also there!): https://www.kaggle.com/doomdiskday/full-tutoria-eda-to-ensembles-embeddings-zooIntroduction""My ridiculous dog is amazing."" [sentiment: positive] With all of the tweets circulating every second it is hard to tell whether the sentiment behind a specific tweet will impact a company, or a person's, brand for being viral (positive), or devastate profit because it strikes a negative tone. Capturing sentiment in language is important in these times where decisions and reactions are created and updated in seconds. But, which words actually lead to the sentiment description? In this competition you will need to pick out the part of the tweet (word or phrase) that reflects the sentiment. Help build your skills in this important area with this broad dataset of tweets. Work on your technique to grab a top spot in this competition. What words in tweets support a positive, negative, or neutral sentiment? How can you help make that determination using machine learning tools? In this competition we've extracted support phrases from Figure Eight's Data for Everyone platform. The dataset is titled Sentiment Analysis: Emotion in Text tweets with existing sentiment labels, used here under creative commons attribution 4.0. international licence. Your objective in this competition is to construct a model that can do the same - look at the labeled sentiment for a given tweet and figure out what word or phrase best supports it. Disclaimer: The dataset for this competition contains text that may be considered profane, vulgar, or offensive. What's in the notebook? Data Cleaning Full Exploratory Data Analysis (EDA) Evaluation BL Model DNN (coming soon!)";Apache 2.0;https://www.kaggle.com/doomdiskday/full-tutorial-eda-to-dnns-all-you-need;1.0;['vocabulary', 'nltk', 'sklearn', 'pytorch', 'tensorflow', 'spacy', 'pattern', 'keras'];['ner', 'ai', 'dl', 'rl', 'nlp', 'nn', 'ml'];['machine learning', 'training data', 'train', 'model', 'epoch', 'natural language processing', 'layer', 'loss', 'label', 'lstm', 'labeled', 'predict', 'understanding', 'sentiment analysis', 'natural language'];https://www.kaggle.com/c/tweet-sentiment-extraction;0.76;0.517;2020-12-13 17:53:52;multiple data sources;['beginner, data visualization, exploratory data analysis, +1 moredeep learning'];[Full Tutorial] EDA to DNNs, all you need!;Python notebook;13434.0;127;0.69855;0.69492
2020-05-23 08:35:34;OverviewAwhile ago, I chanced upon Chris Deotte's analysis at https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/142404#809872. Found it interesting and since I had GPU to spare while training my models offline, I tried to replicate the process with Think deep.'s work at https://www.kaggle.com/seesee/faster-2x-tf-roberta. After modifying the CNN head a bit (don't ask me why, its part of my experiments), and attempting to replicate Chris' findings, I arrived at the below results in the historgram plots. In summary, the changes are:  Modified CNN layers Varied seeds and performed repeated submissions and commits for same seeds;Apache 2.0;https://www.kaggle.com/khoongweihao/tse2020-roberta-cnn-random-seed-distribution;1.0;['pytorch', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cnn', 'cv', 'rl', 'nn', 'ann'];['filter', 'training data', 'test data', 'train', 'model', 'epoch', 'validation data', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/tweet-sentiment-extraction;0.769;0.523;2020-12-13 17:53:52;multiple data sources;['gpu, data visualization, nlp'];[TSE2020] RoBERTa (CNN) & Random Seed Distribution;Python notebook;17430.0;139;0.71708;0.71136
2020-05-25 04:29:46;ObjectiveSentiment analysis is a common use case of NLP where the idea is to classify the tweet as positive, negative or neutral depending upon the text in the tweet. This problem goes a way ahead and expects us to also determine the words in the tweet which decide the polarity of the tweet. Understanding the Evaluation MetricThe metric in this competition is the word-level Jaccard score. Jaccard Score is a measure of how similar/dissimilar two sets are.  The higher the score, the more similar the two strings. The idea is to find the number of common tokens and divide it by the total number of unique tokens. Its expressed in the mathematical terms by,   Source Here is a great example to understand the Jaccard Similarity Metric in an inutitve way.Refer to the main blog for more details:FIVE MOST POPULAR SIMILARITY MEASURES IMPLEMENTATION IN PYTHON  Here is how one can implement the jaccard score in Python:;Apache 2.0;https://www.kaggle.com/parulpandey/eda-and-preprocessing-for-bert;1.0;['pytorch', 'vocabulary', 'sklearn', 'nltk'];['ner', 'ai', 'dl', 'rl', 'ml', 'nlp', 'nn', 'ann'];['filter', 'training data', 'test data', 'train', 'model', 'label', 'understanding', 'sentiment analysis'];https://www.kaggle.com/c/tweet-sentiment-extraction;0.764;0.567;2020-12-13 17:53:52;multiple data sources;['beginner, text data']; EDA and Preprocessing for BERT;Python notebook;14981.0;264;;
2020-04-22 13:07:18;Contents introduction  Loading required packages  Getting basic Ideas  Basic Cleaning   Exploratory Data analysis  Class distribution Distribution of length of tweets Distribution of number of words in tweets Distribution of target Common Stopwords Common words in tweets w/o stopwords Common bigrams in tweeets WordClouds of tweets Readability index   Hints for post-processing  analyzing jaccard similarity     Bert-Lstm Model Data preparation Model Post processing Making our submission    If you find this kernel useful,consider doing an upvote..this will motivate me create more content;Apache 2.0;https://www.kaggle.com/shahules/complete-eda-baseline-model-0-708-lb;1.0;['nltk', 'sklearn', 'tensorflow', 'textblob', 'vocabulary', 'keras'];['ner', 'ai', 'dl', 'rl', 'nn'];['train', 'fitting', 'model', 'neural network', 'epoch', 'natural language processing', 'layer', 'loss', 'label', 'lstm', 'predict', 'relu', 'natural language'];https://www.kaggle.com/c/tweet-sentiment-extraction;0.766;0.534;2020-12-13 17:53:52;multiple data sources;['gpu, exploratory data analysis, nlp, +1 morelstm'];Complete EDA & Baseline model [0.708 LB] 🐦  🐦 ;Python notebook;15990.0;162;;
2020-04-14 12:09:08;About this CompetitionYou are someone who is recently starting on NLP or has become a master ,irrespective of where you lie in the learning chain , I can bet you have worked on sentiment analysis and if not you will be going to, you just can't bypass it. Can You?. Sentiment analysis is for NLP 'what Happy Birthday to You' is for Guitar players Right? You start here   In case you are not aware about sentiment analysis here is a very good article : https://towardsdatascience.com/sentiment-analysis-concept-analysis-and-applications-6c94d6f58c17  Recently Kaggle Lauched a new competition admist the COVID-19 Scare , named Twitter Sentiment Extraction ,I know right its a twitter sentiment analysis competition,But kaggle never disappoints you,it could not have been this straightforward, afterall it has go on for two months.So what this competition asks for is not the sentiment scores but the part of the tweet (word or phrase) that reflects the sentiment., Interesting it isn't it? This competition is special,so if you want to level up your NLP skills , this competition is for you Acknowledgements https://www.kaggle.com/aashita/word-clouds-of-various-shapes --> WORDCLOUDS FUNCTION https://www.kaggle.com/rohitsingh9990/ner-training-using-spacy-0-628-lb --> For understanding how to train spacy NER on custom inputs  About this NotebookIn this kernel, I will briefly explain the structure of dataset.I will generate and analyze metafeatures. Then, I will visualize the dataset using Matplotlib, seaborn and Plotly to gain as much insight as I can . Also I will approach this problem as an NER problem to build a model  In case you are just starting with NLP here is a guide to Approach almost any NLP Problem by Grandmaster @Abhishek Thakur https://www.slideshare.net/abhishekkrthakur/approaching-almost-any-nlp-problem  This kernel is a work in Progress,and I will keep on updating it as the competition progresses and I learn more and more things about the data If you find this kernel useful, Please Upvote it , it motivates me to write more Quality content;Apache 2.0;https://www.kaggle.com/tanulsingh077/twitter-sentiment-extaction-analysis-eda-and-model;1.0;['spacy', 'nltk'];['ner', 'ai', 'gan', 'rl', 'nlp', 'nn', 'ann'];['filter', 'generation', 'train', 'recognition', 'model', 'layer', 'loss', 'label', 'predict', 'understanding', 'sentiment analysis', 'named entity recognition'];https://www.kaggle.com/c/tweet-sentiment-extraction;0.806;0.642;2020-12-13 17:53:52;multiple data sources;['beginner, data visualization, exploratory data analysis, +1 morenlp'];Twitter sentiment Extaction-Analysis,EDA and Model;Python notebook;55851.0;945;;
2017-04-24 21:43:43;Hi guys. Please take a look at some features that I've come up with and haven't seen in solutions of other participants. I hope you can fit them nicely in your models :);Apache 2.0;https://www.kaggle.com/adamsfei/only-brand-new-features;1.0;['pattern'];['ann', 'ai', 'nn', 'ml'];['train', 'model'];https://www.kaggle.com/c/two-sigma-connect-rental-listing-inquiries;0.704;0.44;2020-12-13 17:56:15;Two Sigma Connect: Rental Listing Inquiries;[];Only brand-new features!;Python notebook;3366.0;47;;
2017-02-23 15:19:42;"As you may well know in most Kaggle competitions the winners usually resort to stacking or meta-ensembling, which is a technique involving the combination of several 1st level predictive models to generate a 2nd level model which tends to outperform all of them. This usually happens because the 2nd level model is somewhat able to exploit the strengths of each 1st level model where they perform best, while smoothing the impact of their weaknesses in other parts of the dataset. There are different methods and ""schools of thought"" on how stacking can be performed. If you are interested in this topic, then I suggest you to have a look at this and this to start. Here I will show a simple technique that is known as ""Soft Voting"" and can be implemented with Sklearn VotingClassifier.";Apache 2.0;https://www.kaggle.com/den3b81/better-predictions-stacking-with-votingclassifier;1.0;['xgboost', 'sklearn'];['ner', 'ai', 'nn', 'rl'];['predict', 'training data', 'train', 'model', 'label', 'loss'];https://www.kaggle.com/c/two-sigma-connect-rental-listing-inquiries;0.817;0.427;2020-12-13 17:56:15;Two Sigma Connect: Rental Listing Inquiries;[];Better predictions: stacking with VotingClassifier;Python notebook;81633.0;40;;
2017-03-02 12:18:15;"(This post has been edited after Philippe Lonjoux's insightful comment. The amendments I made are highlighted in my answer to his comment.) Hello there! This notebook exploits the analysis I did here to boost the performance of a classifier. In particular, I will show how additional features computed from 'manager_id' can substantially improve performances by building upon the neat ""Random Forest Starter"" by Li Li";Apache 2.0;https://www.kaggle.com/den3b81/improve-perfomances-using-manager-features;1.0;['xgboost', 'sklearn'];['ner', 'ai', 'nn', 'cv'];['training data', 'train', 'model', 'validation data', 'loss', 'label', 'predict', 'rank', 'random forest'];https://www.kaggle.com/c/two-sigma-connect-rental-listing-inquiries;0.741;0.471;2020-12-13 17:56:15;Two Sigma Connect: Rental Listing Inquiries;[];Improve perfomances using manager features!;Python notebook;8063.0;69;;
2019-07-28 00:40:44;mlcourse.ai – Open Machine Learning CourseAuthor: Arseny Kravchenko. Translated and edited by Christina Butsko, Egor Polusmak, Anastasia Manokhina, Anna Larionova, Evgeny Sushko and Yuanyuan Pao. This material is subject to the terms and conditions of the Creative Commons CC BY-NC-SA 4.0 license. Free use is permitted for any non-commercial purpose.;Apache 2.0;https://www.kaggle.com/kashnitsky/topic-6-feature-engineering-and-feature-selection;1.0;['statsmodels', 'sklearn', 'simplecv', 'tensorflow', 'vocabulary', 'keras', 'skimage'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'regression', 'generation', 'train', 'random forest', 'model', 'neural network', 'layer', 'loss', 'k-means', 'gradient boosting', 'predict', 'computer vision', 'decision tree', 'resnet', 'classification', 'convolutional neural network'];https://www.kaggle.com/c/two-sigma-connect-rental-listing-inquiries;0.787;0.548;2020-12-13 17:56:15;multiple data sources;['beginner, feature engineering, learn'];Topic 6. Feature Engineering and Feature Selection;Python notebook;29647.0;197;;
2017-04-10 22:28:47;Microsoft LightGBM is a powerful, open-source boosted decision tree library similar to xgboost. In practice, it runs even faster than xgboost and achieves better performance in some cases. To install LightGBM, follow the installation guide to get the C++ distribution. The python API can then be easily built with these instructions. Some useful resources for LightGBM python API and parameter tuning: Python API Documentation: this page includes all the functions and objects List of Parameters: all possible parameters for LightGBM functions and classes Parameter Tuning Guide: the advanced parameter tuning guide for LightGBM. Since most parameters in LightGBM are similar to those in XGBoost, it should be intuitive to follow.;Apache 2.0;https://www.kaggle.com/somnisight/microsoft-lightgbm-starter;1.0;['xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'gbm', 'cv', 'rl'];['train', 'decision tree', 'label', 'loss'];https://www.kaggle.com/c/two-sigma-connect-rental-listing-inquiries;0.745;0.429;2020-12-13 17:56:15;Two Sigma Connect: Rental Listing Inquiries;[];Microsoft LightGBM Starter;Python notebook;9100.0;41;;
2017-02-10 04:07:10;It seems the current high scoring script is written in R using H2O. So let us do one in python using XGBoost. Thanks to this script for feature engineering ideas. We shall start with importing the necessary modules;Apache 2.0;https://www.kaggle.com/sudalairajkumar/xgb-starter-in-python;1.0;['xgboost', 'sklearn', 'h2o'];['ai', 'rl', 'ml', 'cv'];['predict', 'train', 'model', 'label', 'loss'];https://www.kaggle.com/c/two-sigma-connect-rental-listing-inquiries;0.774;0.54;2020-12-13 17:56:15;Two Sigma Connect: Rental Listing Inquiries;[];XGB starter in python;Python notebook;20356.0;176;0.55130;0.55209
2016-12-30 16:45:38;"As shown before, some features per id can be clustered intro groups that perform the same kind of time evolution.  Unfortunately a unique feature does not perform the same dynamics for different ids. But maybe there are groups of ids that have identical or similar features and perhaps this groups can give some insights into the ""global"" dynamics. Assumptions: NaN values make sense. An id that has always NaNs for a specific feature has no relationship with it.   Id's live in different time-zones (and have different lifetimes)";Apache 2.0;https://www.kaggle.com/allunia/feature-dynamics-looking-at-id-groups;1.0;['pattern'];['ai', 'dl'];['train', 'label'];https://www.kaggle.com/c/two-sigma-financial-modeling;0.723;0.427;2020-12-13 18:01:01;Two Sigma Financial Modeling Challenge;[];Feature Dynamics: looking at id groups;Python notebook;5174.0;40;;
2016-12-01 21:24:29;Getting insights from the Timestamp variableHere's an in-depth analysis of the Timestamp variable in this first-of-its-kind code competition. The first few code cells are just general EDA, as that's what this used to be before I decided to go more in-depth into the time aspect :) Any feedback or upvotes are very much appreciated!;Apache 2.0;https://www.kaggle.com/anokas/two-sigma-time-travel-eda;1.0;['pattern'];['ner', 'ai', 'nn'];['train', 'fitting', 'label', 'predict'];https://www.kaggle.com/c/two-sigma-financial-modeling;0.775;0.527;2020-12-13 18:01:01;Two Sigma Financial Modeling Challenge;[];Two Sigma Time Travel (EDA);Python notebook;20649.0;147;;
2017-01-10 23:32:59;First things first: I have some data analysis background from my research career in particle physics, but I am far from being an machine learning expert. So please bear with me and I am happy to receive any kind of feedback. Since the training data set (and possibly the test data as well) contain missing data, I wanted to have a closer look at this issue. I have seen that other participants propose to fill those NaNs with the mean or median for the respective column. Here I am not (yet) that much interested in filling the blanks but I rather want to know whether we can learn something more about the data when looking missing values.;Apache 2.0;https://www.kaggle.com/cgump3rt/investigate-missing-values;1.0;['pattern'];['ner', 'ai', 'nn', 'rl'];['test data', 'training data', 'machine learning', 'train', 'label'];https://www.kaggle.com/c/two-sigma-financial-modeling;0.746;0.45;2020-12-13 18:01:01;Two Sigma Financial Modeling Challenge;[];Investigate Missing Values;Python notebook;9358.0;53;;
2017-02-07 08:00:02;technical_20 and technical_30 may be the most useful features in this competition.  In this kernel I will investigate what the physical meanings of these two features.;Apache 2.0;https://www.kaggle.com/chenjx1005/physical-meanings-of-technical-20-30;1.0;['sklearn'];['ai'];['filter', 'regression', 'train', 'model', 'reward', 'predict', 'linear regression', 'bayesian'];https://www.kaggle.com/c/two-sigma-financial-modeling;0.763;0.546;2020-12-13 18:01:01;Two Sigma Financial Modeling Challenge;[];physical meanings of technical_20, 30;Python notebook;14675.0;191;;
2016-12-23 15:26:35;Simple Notebook for exploring the data ...;Apache 2.0;https://www.kaggle.com/sankhamukherjee/when-why-are-stocks-bought-and-sold;1.0;['statsmodels'];['ai', 'rl'];['train', 'model', 'label', 'predict'];https://www.kaggle.com/c/two-sigma-financial-modeling;0.755;0.469;2020-12-13 18:01:01;Two Sigma Financial Modeling Challenge;[];When/why are stocks bought and sold;Python notebook;11664.0;67;;
2017-01-04 02:04:10;From the univariate analysis notebook, https://www.kaggle.com/sudalairajkumar/two-sigma-financial-modeling/univariate-analysis-regression-lb-0-006/notebook it seems we are getting a good score if we use the variable 'technical_20' and build a model. However if we use the top 4 variables and build a model, we are getting a negative public score though our local validation score improved to 0.0195. So how do we tackle this? Also from the kagglegym api, we get the rewards (R value) for individual timestamps and finally for the whole test data set. These individual rewards are very hard to make sense since it is highly influenced by the mean target value of the given timestamp. So I thought probably looking at the cumulative R value till the given timestamp might help a little more (as mean target values are averaged over all the points till the given timestamp) to build a more robust model and here is an attempt to understand the performance of some of the top public scripts. Kindly upvote if you find this useful and / or share your comments.;Apache 2.0;https://www.kaggle.com/sudalairajkumar/am-i-over-fitting;1.0;['sklearn'];['ai', 'dl', 'ml', 'rl'];['test data', 'regression', 'train', 'fitting', 'model', 'reward', 'label', 'predict'];https://www.kaggle.com/c/two-sigma-financial-modeling;0.762;0.526;2020-12-13 18:01:01;Two Sigma Financial Modeling Challenge;[];Am I Over-fitting?;Python notebook;14272.0;144;;
2016-12-09 10:30:11;Let us do some univariate analysis in this notebook and build simple regression models.;Apache 2.0;https://www.kaggle.com/sudalairajkumar/univariate-analysis-regression-lb-0-006;1.0;['sklearn'];['ai'];['training data', 'regression', 'train', 'model', 'reward', 'label', 'predict', 'linear regression'];https://www.kaggle.com/c/two-sigma-financial-modeling;0.775;0.512;2020-12-13 18:01:01;Two Sigma Financial Modeling Challenge;[];Univariate Analysis & Regression (LB : 0.006);Python notebook;21052.0;118;;
2016-12-14 19:06:03;Some exploratory data analysis of the two sigma training dataset, focusing on portfolio or market returns;Apache 2.0;https://www.kaggle.com/ysidhu/two-sigma-portfolio-returns-eda;1.0;['statsmodels'];['ai', 'nn', 'ann', 'rl'];['training data', 'regression', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/two-sigma-financial-modeling;0.767;0.501;2020-12-13 18:01:01;Two Sigma Financial Modeling Challenge;[];Two Sigma Portfolio Returns EDA;Python notebook;16713.0;102;;
2019-02-21 19:49:14;General informationTwo Sigma Financial News Competition is a unique competitions: not only it is a Kernel-only competition, but we aren't supposed to download data and during stage two our solutions will be used to predict future real data. I'll try to do an extensive EDA for this competition and try to find some interesting things about the data. P. S. I'l learning to use plotly, so there will be interactive charts at last!;Apache 2.0;https://www.kaggle.com/artgor/eda-feature-engineering-and-everything;1.0;['xgboost', 'sklearn', 'lightgbm', 'nltk'];['ner', 'ai', 'dl', 'gbm', 'gan', 'rl', 'ml', 'nn', 'ann'];['train', 'model', 'label', 'predict'];https://www.kaggle.com/c/two-sigma-financial-news;0.825;0.641;2020-12-13 18:02:27;Two Sigma: Using News to Predict Stock Movements;['data visualization, exploratory data analysis, feature engineering, +2 morenlp, time series analysis'];EDA, feature engineering and everything;Python notebook;111929.0;926;;
2018-10-26 14:49:53;Two Sigma: Using News to Predict Stock Movements;Apache 2.0;https://www.kaggle.com/ashishpatel26/bird-eye-view-of-two-sigma-nn-approach;1.0;['tensorflow', 'xgboost', 'sklearn', 'keras'];['ner', 'ai', 'nlu', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'training data', 'train', 'fitting', 'model', 'neural network', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/two-sigma-financial-news;0.768;0.532;2020-12-13 18:02:27;Two Sigma: Using News to Predict Stock Movements;['beginner, data visualization, exploratory data analysis'];👨‍🔬 Bird Eye 👀 view of Two Sigma + NN Approach;Python notebook;17171.0;156;;
2018-09-27 19:11:52;A simple model - using the market and news data;Apache 2.0;https://www.kaggle.com/bguberfain/a-simple-model-using-the-market-and-news-data;1.0;['lightgbm'];['ai', 'rl', 'nn', 'gbm'];['regression', 'train', 'model', 'loss', 'label', 'predict'];https://www.kaggle.com/c/two-sigma-financial-news;0.803;0.573;2020-12-13 18:02:27;Two Sigma: Using News to Predict Stock Movements;[];A simple model - using the market and news data;Python notebook;51278.0;290;-0.08587;-0.08587
2018-10-17 10:22:42;Market Data Only BaselineUsing a lot of ideas from XGBoost Baseline Kernel. This is a fit of market data only (no news data used) showing relatively good results.;Apache 2.0;https://www.kaggle.com/christofhenkel/market-data-nn-baseline;1.0;['tensorflow', 'xgboost', 'sklearn', 'keras'];['dl', 'ai', 'nn', 'rl'];['predict', 'train', 'model', 'epoch', 'layer', 'loss', 'relu'];https://www.kaggle.com/c/two-sigma-financial-news;0.776;0.55;2020-12-13 18:02:27;Two Sigma: Using News to Predict Stock Movements;[];Market Data NN Baseline;Python notebook;21441.0;205;;
2018-11-09 16:01:39;Complete EDA + features engineering + voting LightGBMNguyen Dang Minh, PhD  Loading the data Exploring news data Exploring market data Preprocessing Features engineering Building model Making submission;Apache 2.0;https://www.kaggle.com/dmdm02/complete-eda-voting-lightgbm;1.0;['xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'dl', 'gbm', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'train', 'model', 'loss', 'label', 'predict', 'rank', 'classification'];https://www.kaggle.com/c/two-sigma-financial-news;0.755;0.506;2020-12-13 18:02:27;Two Sigma: Using News to Predict Stock Movements;['data visualization, exploratory data analysis, feature engineering, +1 moreensembling']; Complete EDA + voting LightGBM;Python notebook;11961.0;109;0.65113;0.65113
2018-12-20 04:32:43;1. IntroductionMain idea: use LSTM neural network to predict stock movements. Code only version of this kernel on Github: https://github.com/DmitryPukhov/marketnewslstm I used ideas and sometimes copy pasted the code from kernels: EDA, outliers: https://www.kaggle.com/artgor/eda-feature-engineering-and-everything NN: https://www.kaggle.com/christofhenkel/market-data-nn-baseline# LSTM: https://www.kaggle.com/pablocastilla, https://www.kaggle.com/sergeykalutsky/lstm-model-on-market-data#,  https://www.kaggle.com/ashkaan/lstm-baseline# News processing: https://www.kaggle.com/bguberfain/a-simple-model-using-the-market-and-news-data# Disclaimer: currently the model's performance is not perfect. ToDo:  Experiment with news resampling on different periods - 10 days. Now many market rows have empty news joined Train on random time windows instead of sampling single records. Try technical indicators on market data: MACD, RSI etc.  Work with residuals instead of raw data;Apache 2.0;https://www.kaggle.com/dmitrypukhov/eda-and-lstm-with-generator-for-market-and-news;1.0;['xgboost', 'sklearn', 'tensorflow', 'keras', 'skimage'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['test data', 'regression', 'train', 'model', 'input layer', 'output layer', 'neural network', 'epoch', 'validation data', 'layer', 'loss', 'label', 'lstm', 'predict', 'ground truth'];https://www.kaggle.com/c/two-sigma-financial-news;0.753;0.475;2020-12-13 18:02:27;Two Sigma: Using News to Predict Stock Movements;['exploratory data analysis, finance, neural networks, +1 morelstm'];EDA and LSTM with generator for market and news;Python notebook;11151.0;72;-0.14141;-0.14141
2018-09-29 19:17:15;"XGBoost BaselineThis notebook rephrases the challenge of predicting stock returns as the challenge of predicting whether a stock will go up. The evaluation  asks you to predict a confidence value between -1 and 1. The predicted confidence value gets then multiplied with the actual return. If your confidence is in the wrong direction (ie. you predict positive values while returns are actually negative), you loose on the metric. If your direction is right however, you want your confidence be as large as possible. Stocks can only go up or down, if the stock is not going up, it must go down (at least a little bit). So if we know our model confidence in the stock going up, then our new confidence is: ˆy=up−(1−up)=2∗up−1 We are left with a ""simple"" binary classification problem, for which there are a number of good tool, here we use XGBoost, but pick your poison. Edit: Updated XGB tuning to the ones suggested by https://www.kaggle.com/alluxia/lb-0-6326-tuned-xgboost-baseline";Apache 2.0;https://www.kaggle.com/jannesklaas/lb-0-63-xgboost-baseline;1.0;['xgboost', 'sklearn'];['dl', 'ai', 'nn', 'ml'];['train', 'fitting', 'model', 'predict', 'classification'];https://www.kaggle.com/c/two-sigma-financial-news;0.735;0.462;2020-12-13 18:02:27;Two Sigma: Using News to Predict Stock Movements;[];[lb>0.63]XGBoost Baseline;Python notebook;7074.0;61;0.58460;0.58460
2018-11-25 22:10:18;1. Introduction and loading dataThere are two sets of data in this 'kernels only' competition: News and Prices/Returns. The ideia is to use both sets to predict the movement of a given financial asset in the next 10 days. We have data from 2007 to 2017 for training and must predict the movement of assets from Jan 2017 to July 2019. Two Sigma and Kaggle created a custom package for this competition:;Apache 2.0;https://www.kaggle.com/jsaguiar/baseline-with-news;1.0;['xgboost', 'sklearn', 'lightgbm'];['ai', 'dl', 'gbm', 'nn', 'ann'];['predict', 'train', 'model', 'label', 'loss'];https://www.kaggle.com/c/two-sigma-financial-news;0.748;0.512;2020-12-13 18:02:27;Two Sigma: Using News to Predict Stock Movements;['finance, binary classification'];Baseline with News;Python notebook;9792.0;119;0.62770;0.62770
2018-10-12 21:39:20;EDA: What does Mktres mean?By @marketneutral There have been a few Discussion Forum questions about what transformation is used to go from Raw to Mktres returns. Using just the data, let's see if we can figure this out.;Apache 2.0;https://www.kaggle.com/marketneutral/eda-what-does-mktres-mean;1.0;['sklearn'];['ner', 'ai', 'ml'];['regression', 'train', 'model', 'label', 'bayesian'];https://www.kaggle.com/c/two-sigma-financial-news;0.727;0.497;2020-12-13 18:02:27;Two Sigma: Using News to Predict Stock Movements;['data visualization, exploratory data analysis, finance, +1 morepca'];EDA: What does Mktres mean?;Python notebook;5721.0;97;;
2018-10-16 17:48:42;"The fallacy of encoding assetCodeBy @marketneutral There have been a few kernel shares of gradient-boosted decision trees (""GBDT""; e.g., lightgbm) applied directly to the data ""as is"" in this competition. The results of this show that assetCode (and assetName), as a categorical variable, is a substantially important feature. Does this make sense? If you simply know the ticker symbol should that add predictive power to the model? On the face of it, it seems implausible and that the use of assetCode rather is simply leaking future information and producing an overfit model. I investigate this idea in this kernel. Minimal ReproductionFirst, let's do a minimal reproduction. There is no effort here to do parameter tuning, or to create a great model per se. Here we just want to fit the bare minimum GBDT model and see what features the model thinks are important. We just want to reproduce in a minimal way that the model will find assetCode and assetName to be very important.";Apache 2.0;https://www.kaggle.com/marketneutral/the-fallacy-of-encoding-assetcode;1.0;['lightgbm', 'sklearn'];['ner', 'ai', 'dl', 'gbm', 'rl', 'nn', 'ann'];['machine learning', 'regression', 'train', 'model', 'label', 'predict', 'decision tree'];https://www.kaggle.com/c/two-sigma-financial-news;0.719;0.468;2020-12-13 18:02:27;Two Sigma: Using News to Predict Stock Movements;['exploratory data analysis, feature engineering, finance'];The fallacy of encoding assetCode ;Python notebook;4748.0;66;;
2020-01-21 20:58:16;Kaggle Ultrasound Nerve Segmentation Competition (2016)as an Undergraduate Research Project.;Apache 2.0;https://www.kaggle.com/gbatchkala/urss-2019-project-review;1.0;['tensorflow', 'skimage', 'keras', 'theano'];['ner', 'ai', 'dl', 'rl', 'nn', 'ann'];['filter', 'predict', 'relu', 'machine learning', 'neuron', 'train', 'epoch', 'activation function', 'recommend', 'linear regression', 'model', 'neural network', 'layer', 'support vector machines', 'loss', 'understanding', 'resnet', 'bayesian', 'image segmentation', 'test data', 'regression', 'fitting', 'deep learning', 'label', 'computer vision', 'u-net'];https://www.kaggle.com/c/ultrasound-nerve-segmentation;0.647;0.292;2020-12-13 18:06:51;Ultrasound Nerve Segmentation;[];urss_2019_project_review;Python notebook;1028.0;9;;
2017-03-30 23:03:44;Here is the starting point for processing ultrasound nerve segmentation data from Kaggle;Apache 2.0;https://www.kaggle.com/kmader/qbi-advanced-image-segmentation;1.0;['skimage', 'sklearn'];['ner', 'ai'];['train', 'label', 'filter'];https://www.kaggle.com/c/ultrasound-nerve-segmentation;0.675;0.236;2020-12-13 18:06:51;Ultrasound Nerve Segmentation;[];QBI Advanced Image Segmentation;Python notebook;1797.0;5;;
2019-05-17 03:26:02;Hi, I am a semantic segmentation beginner.(I'm sorry for my poor English in advance) (I refered to many part of this site);Apache 2.0;https://www.kaggle.com/micajoumathematics/my-first-semantic-segmentation-keras-u-net;1.0;['skimage', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['training data', 'test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'u-net'];https://www.kaggle.com/c/ultrasound-nerve-segmentation;0.738;0.302;2020-12-13 18:06:51;Ultrasound Nerve Segmentation;['gpu, beginner'];My First Semantic Segmentation(Keras, U-net);Python notebook;7574.0;10;;
2019-09-15 16:46:41;General informationIn this kernel I work with the data from Understanding Clouds from Satellite Images competition. Shallow clouds play a huge role in determining the Earth's climate. They’re also difficult to understand and to represent in climate models. By classifying different types of cloud organization, researchers at Max Planck hope to improve our physical understanding of these clouds, which in turn will help us build better climate models. So in this competition we are tasked with multiclass segmentation task: finding 4 different cloud patterns in the images. On the other hand, we make predictions for each pair of image and label separately, so this could be treated as 4 binary segmentation tasks. It is important to notice that images (and masks) are 1400 x 2100, but predicted masks should be 350 x 525. In this kernel I'll use (or will use in next versions) the following notable libraries:  albumentations: this is a great library for image augmentation which makes it easier and more convenient catalyst: this is a great library which makes using PyTorch easier, helps with reprodicibility and contains a lot of useful utils segmentation_models_pytorch: this is a great library with convenient wrappers for models, losses and other useful things pytorch-toolbelt: this is a great library with many useful shortcuts for building pytorch models  UPD: Version 35 - changed calculation of optimal threshold and min size;Apache 2.0;https://www.kaggle.com/artgor/segmentation-in-pytorch-using-convenient-tools;1.0;['sklearn', 'opencv-python', 'pillow', 'pytorch', 'albumentations', 'tensorflow', 'pattern'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['test data', 'train', 'model', 'neural network', 'epoch', 'validation data', 'loss', 'label', 'predict', 'understanding', 'resnet'];https://www.kaggle.com/c/understanding_cloud_organization;0.807;0.623;2020-12-13 18:07:53;Understanding Clouds from Satellite Images;['data visualization, exploratory data analysis, deep learning, +1 morecomputer vision'];Segmentation in PyTorch using convenient tools;Python notebook;58907.0;672;0.63566;0.64198
2019-08-23 21:33:17;Very simple started code using Keras.Changelog:  V1: predict only 1 class (LB: 0.417) V2, V3, V4: error V5: predict 4 classes V6, V7: model changed from pretrained VGG16 to U-net model from this excellent kernel - https://www.kaggle.com/xhlulu/satellite-clouds-yet-another-u-net-boilerplate V9: model changed to pretrained IceptionResNetV2 V10: model changed to pretrained EfficientNetB4 V12: model changed to pretrained ResNet50;Apache 2.0;https://www.kaggle.com/ateplyuk/satelite-easy-starter-keras;1.0;['sklearn', 'pillow', 'albumentations', 'tensorflow', 'keras'];['ner', 'ai', 'gan', 'cv', 'rl', 'ml'];['filter', 'train', 'model', 'epoch', 'layer', 'vgg', 'loss', 'label', 'predict', 'understanding', 'resnet', 'classification', 'u-net'];https://www.kaggle.com/c/understanding_cloud_organization;0.714;0.463;2020-12-13 18:07:53;multiple data sources;['gpu'];Satelite: Easy Starter (Keras);Python notebook;4208.0;62;0.16553;0.16724
2019-10-29 18:08:16;Cloud Bounding Boxes - CV 0.58In this kernel we will attempt to create bounding boxes instead of segmentation. Currently the CV is a low 0.58 but perhaps this kernel can be improved to score higher. There is a variable TRAIN_MODELS below. If you set this variable to False then you can load oof and preds from offline training and predicting. Do this to save your GPU quota. If you want to see the models train and predict, then turn GPU on and set variable TRAIN_MODELS to True.;Apache 2.0;https://www.kaggle.com/cdeotte/cloud-bounding-boxes-lb-0-61;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'gan', 'cv', 'rl', 'nn', 'ann'];['generation', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'understanding', 'classification'];https://www.kaggle.com/c/understanding_cloud_organization;0.677;0.44;2020-12-13 18:07:53;multiple data sources;[];Cloud Bounding Boxes - CV 0.58;Python notebook;1872.0;47;0.60134;0.61146
2019-10-31 04:36:40;Train on Crops - Predict on Full - CV 0.60+In this kernel we use a trick that we learned in Kaggle's Steel Competition. Since segmentation neural networks are all convolutions, you can train with one input size and predict with a different input size (explained in detail here). First we will resize all training and test images into size 700x1050 from their original 1400x2100. Next we will train with random 352x512 crops and then feed full test images (700x1050 images) into our network and get full segmentation masks!;Apache 2.0;https://www.kaggle.com/cdeotte/train-with-crops-lb-0-63;1.0;['tensorflow', 'sklearn', 'keras', 'pillow'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'nn', 'ml'];['generation', 'train', 'model', 'neural network', 'epoch', 'layer', 'loss', 'label', 'predict', 'understanding', 'resnet', 'classification'];https://www.kaggle.com/c/understanding_cloud_organization;0.699;0.46;2020-12-13 18:07:53;multiple data sources;['gpu']; Train With Crops -  CV 0.60+;Python notebook;2968.0;60;0.62465;0.62861
2019-11-05 21:56:09;Unsupervised Masks - CV 0.60In this kernel, we create segmentation masks without using the annotators' training masks! Instead we build a classifier to classify images into Fish, Flower, Gravel, and Sugar. By looking at hundreds of images of Fish, the CNN learns to recognize Fish in the images. Even though we don't tell the network what specifically is a Fish within the image, the CNN determines where and what Fish are by understanding the similarity between many images containing Fish. This feels like magic! There is a great blog why this works here. Some of this notebook's code was taken from the blogger's GitHub here;Apache 2.0;https://www.kaggle.com/cdeotte/unsupervised-masks-cv-0-60;1.0;['pattern', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cnn', 'gan', 'cv', 'rl', 'nn', 'ann'];['training data', 'generation', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'unsupervised learning', 'understanding', 'supervised learning'];https://www.kaggle.com/c/understanding_cloud_organization;0.685;0.456;2020-12-13 18:07:53;Understanding Clouds from Satellite Images;['gpu'];Unsupervised Masks - CV 0.60;Python notebook;2227.0;57;;
2019-10-14 09:14:23;Image Segmentation From scratch using Pytorch;Apache 2.0;https://www.kaggle.com/dhananjay3/image-segmentation-from-scratch-in-pytorch;1.0;['pytorch', 'albumentations', 'sklearn'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['image segmentation', 'train', 'model', 'neural network', 'epoch', 'loss', 'label', 'predict', 'relu', 'understanding'];https://www.kaggle.com/c/understanding_cloud_organization;0.77;0.53;2020-12-13 18:07:53;multiple data sources;['gpu, beginner, deep learning'];Image Segmentation From Scratch in Pytorch;Python notebook;17825.0;153;0.61829;0.62963
2019-10-22 19:23:56;Understanding Clouds from Satellite Images Cloud Segmentation with utility scripts and KerasThis kernel is to show the new feature on Kaggle, script notebooks. I'm not doing EDA here because I already did it on my other kernel, the goal here is just to demonstrate how to use script notebook and how it can improve our work, making it faster and cleaner.I found this addition really cool as I always try to write clean and modular code, it always saves time later, this may be another push towards better software practices on data science projects.What you will find on the script I made:  All used dependencies External repository codes (need internet option ON) Seed function (to make model runs more reproducible) Segmentation functions related to this competition Multi-thread data process functions (to resize and apply transformations faster) Model evaluation (training plots) Model post-process (Set threshold and removing small masks) Prediction evaluation (Generate metrics over predictions and sample evaluation) Data generator Learning rate schedulers  If you have any request to update or add anything to the scripts please let me know in the comments.;Apache 2.0;https://www.kaggle.com/dimitreoliveira/cloud-segmentation-with-utility-scripts-and-keras;1.0;['tensorflow', 'keras'];['ner', 'ai', 'dl', 'gan', 'rl', 'nn', 'ann'];['filter', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'understanding', 'resnet', 'classification'];https://www.kaggle.com/c/understanding_cloud_organization;0.728;0.469;2020-12-13 18:07:53;multiple data sources;['gpu, deep learning, data cleaning, +2 moreneural networks, computer vision'];Cloud Segmentation with utility scripts and Keras;Python notebook;5855.0;67;0.64975;0.65323
2019-09-15 22:12:40;Understanding Clouds from Satellite Images Can you classify cloud structures from satellites?In this competition we need to analyze and process cloud images taken from satellites in order to identify cloud formations and help improve the earth's climate understanding.Dependencies;Apache 2.0;https://www.kaggle.com/dimitreoliveira/understanding-clouds-eda-and-keras-u-net;1.0;['sklearn', 'pillow', 'albumentations', 'tensorflow', 'keras'];['ner', 'ai', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'train', 'model', 'epoch', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'understanding', 'resnet', 'u-net'];https://www.kaggle.com/c/understanding_cloud_organization;0.724;0.449;2020-12-13 18:07:53;Understanding Clouds from Satellite Images;['gpu, data visualization, exploratory data analysis, +2 moredeep learning, computer vision'];Understanding Clouds - EDA and Keras U-Net;Python notebook;5394.0;52;0.61866;0.62153
2019-08-18 17:28:31;Introduction & Loading The DataClimate change is one of the most important and pressing issues of our time. In this competition, we have the opportunity to use data to understand important climatic variables. The idea is if we can understand the cloud, we can better understand our environment and how it is changing. The idea of the competition is fairly simple. There are different types or patterns of clouds, and our task is to identify them and classify these types. If you like my work please upvote this Kernel. This encourages or motivates people like me, who contributes to Kaggle on their own time with the intention to share knowledge, to continue the effort. Furthermore, if I made a mistake or can do something more, please leave a comment in the comments section to help me out. Many thanks in advance!;Apache 2.0;https://www.kaggle.com/ekhtiar/eda-find-me-in-the-clouds;1.0;['pattern'];['ai', 'dl', 'gan', 'cv', 'rl', 'ml'];['train', 'understanding', 'label', 'training data'];https://www.kaggle.com/c/understanding_cloud_organization;0.745;0.549;2020-12-13 18:07:53;Understanding Clouds from Satellite Images;['data visualization, exploratory data analysis, classification'];EDA: Find Me In The Clouds ;Python notebook;9133.0;202;;
2019-08-28 01:30:15;Understanding cloud organization with MaskRCNN using Keras/TensorflowThis kernel is a first attempt to use a MaskRCNN to solve the cloud organization classification problem. It also helps to evaluate how promising the results are within the allowed processing time on kernels as it is likely such model will take much longer to train properly. It is using the Matterplot implementation of MaskRCNN and is inspired from this kernel from the iMaterialist competition. If you are particularly interested in data cleaning for a MaskRCNN, I have also created another kernel for the Kuzushiji recognition competition which may be of help. If you find this kernel useful, please give an upvote! :);Apache 2.0;https://www.kaggle.com/frlemarchand/maskrcnn-for-cloud-classification-keras;1.0;['tensorflow', 'keras'];['ner', 'ai', 'cnn', 'gan', 'cv', 'rl', 'nn', 'ann'];['filter', 'train', 'recognition', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'understanding', 'resnet', 'classification'];https://www.kaggle.com/c/understanding_cloud_organization;0.726;0.47;2020-12-13 18:07:53;Understanding Clouds from Satellite Images;['gpu'];MaskRCNN for cloud classification (Keras);Python notebook;5566.0;68;0.57560;0.57860
2019-10-08 22:54:29;About this kernelMostly copied from xhlulu's kernel Satellite Clouds: U-Net with ResNet boilerplate. I have added some new ideas such as gradient accumulation, gamma correction from discussions and other kernels. I am new to the field of image processing. So please correct me if you have found any mistake. Thank you very much. Changelog V13: Set threshold/remove small masks/TTA of ResUnet18's prediction. V12: Save history to .csv. V11: Reset the learning parameters back to V7. Try Resnet34 encoder. Add some visualisation on test predictions. V9: Increased the initial learning rate to 0.005. Increased min_delta to 0.0005.  V7: Added gamma correction with gamma=0.8. Decreased min_delta to 0.0001. V3: Added EarlyStopping and ReduceLROnPlateau with min_delta=0.001. Increased the initial learning rate to 0.002. V2: Added gradient accumulation  References Satellite Clouds: U-Net with ResNet boilerplate: https://www.kaggle.com/xhlulu/satellite-clouds-u-net-with-resnet-boilerplate Segmentation in PyTorch using convenient tools: https://www.kaggle.com/artgor/segmentation-in-pytorch-using-convenient-tools A trick to use bigger batches for training: gradient accumulation: https://www.kaggle.com/c/understanding_cloud_organization/discussion/105614#latest-616444 [LB 0.628] simple segmentation approach: https://www.kaggle.com/c/understanding_cloud_organization/discussion/104771#latest-614917 Understanding Clouds Keras Unet: https://www.kaggle.com/saneryee/understanding-clouds-keras-unet Understanding Clouds - EDA and Keras U-Net: https://www.kaggle.com/dimitreoliveira/understanding-clouds-eda-and-keras-u-net;Apache 2.0;https://www.kaggle.com/gogo827jz/resunet-keras-with-some-new-ideas;1.0;['sklearn', 'pytorch', 'albumentations', 'tensorflow', 'keras', 'skimage'];['ner', 'ai', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'understanding', 'resnet', 'classification', 'u-net'];https://www.kaggle.com/c/understanding_cloud_organization;0.745;0.475;2020-12-13 18:07:53;multiple data sources;['gpu'];ResUNet Keras with some new ideas;Python notebook;9070.0;72;0.64505;0.65342
2019-09-17 11:39:41;General information This is my first published Kernel :) If there are any Mistakes or Errors please let met notice. Descriptions of each part will follow soon, as well as a training pipeline. With the Descriptions the aknowledgements will follow. But I want to go ahead and say thank you to xhlulu and Andrew for their amazing Kernels.;Apache 2.0;https://www.kaggle.com/jpbremer/efficient-net-b4-unet-clouds;1.0;['sklearn', 'pillow', 'pytorch', 'albumentations', 'tensorflow', 'keras', 'skimage'];['ner', 'ai', 'gan', 'cv', 'rl', 'nn', 'ann'];['filter', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'understanding', 'u-net'];https://www.kaggle.com/c/understanding_cloud_organization;0.744;0.468;2020-12-13 18:07:53;multiple data sources;[];Efficient Net B4 Unet Clouds;Python notebook;8753.0;66;;
2019-11-05 17:44:32;This kernel was forked from my  previous steel competition kernel named  Severstal: unet++ with efficientnetb4 kerasi will try to re implement that kernel again for this competition and the reason for re implementation can be understood by reading next couple of cells;Apache 2.0;https://www.kaggle.com/mobassir/deeplabv3-with-mobilenetv2;1.0;['theano', 'sklearn', 'albumentations', 'tensorflow', 'keras', 'skimage'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['image segmentation', 'filter', 'machine learning', 'train', 'model', 'understanding', 'epoch', 'deep learning', 'layer', 'relu', 'loss', 'label', 'predict', 'computer vision', 'recommend', 'resnet', 'classification', 'u-net'];https://www.kaggle.com/c/understanding_cloud_organization;0.709;0.46;2020-12-13 18:07:53;multiple data sources;['gpu'];Deeplabv3+ with mobilenetv2;Python notebook;3731.0;60;;
2019-11-18 15:03:15;this kernel was forked from here : https://www.kaggle.com/samusram/cloud-classifier-for-post-processing?scriptVersionId=20265194 highest  accuracy of that kernel was 0.629 which is same as this one : https://www.kaggle.com/artgor/segmentation-in-pytorch-using-convenient-tools?scriptVersionId=20202006 of Andrew Lukyanenko (  @artgor)  thanks a lot to them for their public kernels,i recommend everyone playing with those kernels because those kernels has got solid baseline. my special thanks goes to Andrew Lukyanenko (  @artgor) ,i learnt plenty from his works Here in this kernel i got 0.63 after trying InceptionResNetV2 so i decided to share it with you guys,please leave your precious comment below,this is just a starting,i will write my own notebook when time permits but i would like to spend more time on @artgor's kernel to observe if i can improve his work little bit,i recommend you the same. whats new here?  InceptionResNetV2 instead of densenet121 image height and width 229x229 instead of 224 version 1 has got 0.63 public lb accuracy ,so please upvote this notebok and obviously main author's notebook if you find these helpful in version 3 i will try to leave everything as it was before but 5 epochs for initial tuning and 10 epochs for fine tuning;Apache 2.0;https://www.kaggle.com/mobassir/inceptionresnetv2-for-cloud-classifier;1.0;['sklearn', 'pytorch', 'albumentations', 'tensorflow', 'pattern', 'keras'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'nn', 'ann'];['train', 'fitting', 'model', 'understanding', 'epoch', 'layer', 'loss', 'label', 'predict', 'recommend', 'resnet'];https://www.kaggle.com/c/understanding_cloud_organization;0.733;0.482;2020-12-13 18:07:53;multiple data sources;['gpu'];InceptionResNetV2 for Cloud Classifier;Python notebook;6691.0;79;0.64714;0.65547
2019-10-11 11:07:41;**this kernel was forked from here : https://www.kaggle.com/samusram/cloud-classifier-for-post-processing?scriptVersionId=20265194 i got 0.657 using densenet201(in version 3) ** i tried  efficientnetb4 but it failed for large image size,so i will try efficientnetb3 now with bce dice loss if you find this kernel useful,please upvote,your upvote motivates kagglers like us to share things publicly,thanks;Apache 2.0;https://www.kaggle.com/mobassir/keras-efficientnetb2-for-classifying-cloud;1.0;['sklearn', 'pillow', 'albumentations', 'tensorflow', 'keras'];['ner', 'ai', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'understanding'];https://www.kaggle.com/c/understanding_cloud_organization;0.778;0.559;2020-12-13 18:07:53;multiple data sources;['gpu'];keras efficientnetb2  for classifying cloud;Python notebook;23123.0;232;0.64625;0.65832
2019-09-23 13:11:40;IntroductionSince the mask we have in the labels are mostly in the rectangles (or combination of rectangles) shapes. It is interesting to see that if we post-process the random-shape masks of a segmentation model to rectangle, we can get improved performance or not? In this kernel, I show a simple way to post-process all masks to 4 choices of shapes : convex hull, approx. polygon, simple x-y rectangle and minimum-area rectangles. (credit : I took the starter code from bigsnarfdude : https://gist.github.com/bigsnarfdude/d811e31ee17495f82f10db12651ae82d ) The masks I will post-process came from my good friend Raman's great kernel : https://www.kaggle.com/samusram/cloud-classifier-for-post-processing (which is already post-process from other great kernel of Jan's https://www.kaggle.com/jpbremer/efficient-net-b4-unet-clouds :). The convex-hull post-processing currently is the best of 4 choices (not yet test polygon), still having the same LB score as original predicted masks, but with more reasonable shapes. Since this kernel does not need GPU, whenever you are run out of GPU quota you can come here just to have fun. I myself prepared this kernel when I was run out of GPU quota also :)  UPDATE on V2 :  Thanks to Ryan @ryches for his insightful suggestions. In V2, the mask touching the black stripe is removed. Additionally, this black-stripe removing process may cause some disconnect small triangle masks. Therefore, in V2, I also apply @artgor min_size remove post-processing. Now LB score improves from V1, but still not beat the original predicted masks (LB.655 vs. 650). Lastly, I add my own version of multi-color masks visualization just for fun.  UPDATE on V3 :  Now support the minimum convex-hull that enclosing the predicting mask. This convex-hull performs better than minimum-area rectangle, and got equal score to the original masks.  UPDATE V5.  Add approximate polygon post-processing using Douglas-Peucker algorithm.;Apache 2.0;https://www.kaggle.com/ratthachat/cloud-convexhull-polygon-postprocessing-no-gpu;1.0;['pytorch', 'opencv-python'];['ai', 'gan', 'cv', 'rl', 'ml', 'nn', 'ann'];['understanding', 'model', 'label', 'predict'];https://www.kaggle.com/c/understanding_cloud_organization;0.73;0.505;2020-12-13 18:07:53;multiple data sources;[];Cloud: ConvexHull& Polygon PostProcessing (No GPU);Python notebook;6254.0;108;;
2019-09-26 03:23:50;This kernel is forked from Andrew's Pytorch Kernel https://www.kaggle.com/artgor/segmentation-in-pytorch-using-convenient-tools I have done a couple things to speed things up and allow for larger models. The first one is that I resized the dataset before hand so that we do not need to do this repetitively for each epoch. This takes our epoch time down from ~23 minutes down to ~7 minutes using the same resnet 50 unet architecture. You can do whatever you like with this additional time, train more models, more epochs, larger backbones, etc. The second thing I have done is add in nvidia apex so we can do mixed precision training. This roughly halves memory usage on the GPU and allows us to fit larger models or larger batch sizes. This has allowed me to train the larger se_resnext101_32x4d backbone in a shorter amount of time while also getting a better score.;Apache 2.0;https://www.kaggle.com/ryches/turbo-charging-andrew-s-pytorch;1.0;['sklearn', 'opencv-python', 'pillow', 'pytorch', 'albumentations', 'pattern'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'ml', 'nn', 'rnn', 'ann'];['test data', 'train', 'model', 'neural network', 'epoch', 'validation data', 'layer', 'loss', 'label', 'predict', 'understanding', 'resnet'];https://www.kaggle.com/c/understanding_cloud_organization;0.724;0.482;2020-12-13 18:07:53;multiple data sources;['gpu'];Turbo Charging Andrew's Pytorch;Python notebook;5374.0;79;0.64574;0.64927
2019-09-17 14:11:35;IntroIn this notebook I'd create a classifier to distinguish types of cloud formations. Using this classifier I'd check if it improves currently the best LB score from the great public notebook by Jan.;Apache 2.0;https://www.kaggle.com/samusram/cloud-classifier-for-post-processing;1.0;['albumentations', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'gan', 'cv', 'rl', 'nn', 'ann'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'understanding'];https://www.kaggle.com/c/understanding_cloud_organization;0.757;0.523;2020-12-13 18:07:53;multiple data sources;['gpu'];Cloud Classifier for Post-processing;Python notebook;12372.0;139;0.64635;0.65545
2019-09-07 22:43:21;"About this kernel Preprocessing: Expand the train dataframe to include image ID. Also create mask_count_df which will be useful for later. Utility Functions: Mostly copied from Paul's kernel and SIIM starter code (see references). You won't need to modify those. Sample Test: Simply visualizing a sample image and its masks, Data Generator: Very long and possibly complex. If you can, skip this part of the code. If you absolute need to modify the data generation process, please take a look __generate_X and __generate_y; in theory everything else should be left as is. This code is different from my previous Keras U-Net boilerplate since it lets you reshape the input image as well as the mask, and lets you  Model Architecture: The architecture is slightly different from the other kernels, since it learns to predict all of the four masks at the same time, instead of predicting a single mask and duplicating it. It also takes as input grayscale images. Training: Running only for 25 epochs. Evaluation & Submission: The submission code is pretty messy. Essentially, I'm splitting the test dataframe into multiple chunks, then run the model and mask2rle converter on the results. I'm doing this in order to not run out of RAM as we try to convert all the masks from array to RLE.  Changelog V27: Replace ResNet-18 with ResNet-34. V25: Replace RAdam with NAdam. V22: Replace Adam with RAdam. V18: Changed the vanilla U-Net by using ResNet encoder. This is easily done using the incredible segmentation-models library made by qubvel. V15: Fixed the test image size output, which should have been 350x525 instead of 1600x2100 (which is valid for training data only). Also removed the ""Micro-EDA"" and ""Show Sample"", since artgor's  kernel already covers albumentations very well.  References segmentation-models: https://github.com/qubvel/segmentation_models EDA of albumentations: https://www.kaggle.com/artgor/segmentation-in-pytorch-using-convenient-tools Data generator: https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly RLE encoding and decoding: https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode Architecture: https://www.kaggle.com/jesperdramsch/intro-chest-xray-dicom-viz-u-nets-full-data Mask encoding: https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/data My original Kernel U-Net: https://www.kaggle.com/xhlulu/severstal-simple-keras-u-net-boilerplate";Apache 2.0;https://www.kaggle.com/xhlulu/satellite-clouds-u-net-with-resnet-encoder;1.0;['sklearn', 'pytorch', 'albumentations', 'tensorflow', 'keras'];['ner', 'ai', 'cv', 'rl', 'nn', 'ann'];['training data', 'test data', 'generation', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'resnet', 'classification', 'u-net'];https://www.kaggle.com/c/understanding_cloud_organization;0.76;0.521;2020-12-13 18:07:53;Understanding Clouds from Satellite Images;['gpu, cnn'];Satellite Clouds: U-Net with ResNet Encoder;Python notebook;13421.0;135;0.59689;0.59453
2020-05-23 14:10:20;Plan Separate features in train on categorical and numerical Extract features for using in model training Merge train and test dataset's for coding categorical features and fill NaN with mean for numerical and str 'nan' for categorical Seprate preprocessed train and test (test dataset for final prediction) Separate train on sub_train / sub_test datasets (sub_train will be trained on CV and will evaluated on sub_test) Comparison several classifiers;Apache 2.0;https://www.kaggle.com/hadjako/predict-grant-applications;1.0;['xgboost', 'sklearn'];['ai', 'nn', 'cv'];['filter', 'test data', 'regression', 'train', 'model', 'label', 'predict'];https://www.kaggle.com/c/unimelb;0.55;0.0;2020-12-13 18:08:21;Predict Grant Applications;[];Predict Grant Applications;Python notebook;203.0;0;;
2019-08-21 12:28:29;Total 252 variables in the data.;Apache 2.0;https://www.kaggle.com/tiwaris436/predict-grant-applications;1.0;['sklearn'];['ai', 'nn', 'ml'];['random forest', 'regression', 'train', 'model', 'logistic regression', 'predict', 'classification'];https://www.kaggle.com/c/unimelb;0.637;0.214;2020-12-13 18:08:21;Predict Grant Applications;[];Predict Grant Applications;Python notebook;860.0;4;;
2019-01-09 18:01:24;This is my first kernel on Kaggle. I am very excited to contribute to this competition and going back to my days of studying biomechatonics where I first met the concept of feature extraction to classify signals from sensors on human body. I made a fast literature review on feature extraction and signal classification and prepared following experiment for my first submissions. I will be updating explanatory walktrough alongside model improvements. Running and submitting from full notebook on interactive session was problemmatic due to memory troubles with the test set. I will work my way around it meanwhile you can download to use or fork to improve. Open for feedbacks to improve my first kernel. Have fun everyone!;Apache 2.0;https://www.kaggle.com/afajohn/cnn-lstm-for-signal-classification-lb-0-513;1.0;['tensorflow', 'xgboost', 'keras'];['ner', 'ai', 'dl', 'cnn', 'rl', 'nn', 'ann'];['filter', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'lstm', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/vsb-power-line-fault-detection;0.769;0.533;2020-12-13 18:09:07;VSB Power Line Fault Detection;[];CNN + LSTM for Signal Classification LB 0.513;Python notebook;17386.0;159;;
2019-01-31 13:38:23;Thanks to this kernel : https://www.kaggle.com/braquino/5-fold-lstm-attention-fully-commented-0-694;Apache 2.0;https://www.kaggle.com/ashishpatel26/redesign-stacked-lstm-advance-parameter-tuning;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cv', 'nn', 'rnn'];['test data', 'train', 'fitting', 'model', 'neural network', 'epoch', 'validation data', 'layer', 'loss', 'lstm', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/vsb-power-line-fault-detection;0.731;0.453;2020-12-13 18:09:07;multiple data sources;['gpu, beginner, cnn, +2 morebinary classification, india'];Redesign Stacked LSTM Advance Parameter Tuning;Python notebook;6349.0;55;;
2018-12-23 22:37:17;In this notebook, I made a simple lightgbm code.  This code takes less than 15min to finish all process.;Apache 2.0;https://www.kaggle.com/bluexleoxgreen/simple-feature-lightgbm-baseline;1.0;['lightgbm', 'sklearn'];['cv', 'ai', 'rl', 'gbm'];['train', 'model', 'label', 'predict'];https://www.kaggle.com/c/vsb-power-line-fault-detection;0.701;0.411;2020-12-13 18:09:07;VSB Power Line Fault Detection;['beginner, classification, feature engineering'];Simple Feature LightGBM Baseline;Python notebook;3134.0;33;;
2019-01-26 22:41:49;Meeting a Sayed Athar's request, I'm using the Kernel altered by Khoi Nguyen to explain how the whole code works.If any part is not clear, please comment.Please upvote if it was helpful.;Apache 2.0;https://www.kaggle.com/braquino/5-fold-lstm-attention-fully-commented-0-694;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cv', 'nn', 'rnn'];['test data', 'train', 'fitting', 'model', 'neural network', 'epoch', 'validation data', 'layer', 'loss', 'lstm', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/vsb-power-line-fault-detection;0.79;0.597;2020-12-13 18:09:07;VSB Power Line Fault Detection;['gpu'];5-fold LSTM Attention (fully commented);Python notebook;33498.0;426;0.60944;0.69434
2019-01-16 14:03:27;This notebook was made from scratch by me. The idea is reducing the 800,000 long mesurements to some shorter vector that is more fitted to a LSTM. This code below transform the 800.000 mesurements of the 3 diferent phases in a unique (80, 39) matrix. The matthews ocrrelation and attention functions are not mine.;Apache 2.0;https://www.kaggle.com/braquino/vsb-power-lstm-attention;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'nn'];['train', 'model', 'epoch', 'layer', 'loss', 'lstm', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/vsb-power-line-fault-detection;0.721;0.48;2020-12-13 18:09:07;VSB Power Line Fault Detection;['gpu'];VSB Power LSTM attention;Python notebook;4997.0;77;;
2019-03-09 23:21:55;"VSB Power Line Fault DetectionMedium voltage overhead power lines run for hundreds of miles to supply power to cities. These great distances make it expensive to manually inspect the lines for damage that doesn't immediately lead to a power outage, such as a tree branch hitting the line or a flaw in the insulator. These modes of damage lead to a phenomenon known as partial discharge — an electrical discharge which does not bridge the electrodes between an insulation system completely. Partial discharges slowly damage the power line, so left unrepaired they will eventually lead to a power outage or start a fire. Your challenge is to detect partial discharge patterns in signals acquired from these power lines with a new meter designed at the ENET Centre at VŠB. Effective classifiers using this data will make it possible to continuously monitor power lines for faults. ENET Centre researches and develops renewable energy resources with the goal of reducing or eliminating harmful environmental impacts. Their efforts focus on developing technology solutions around transportation and processing of energy raw materials. By developing a solution to detect partial discharge you’ll help reduce maintenance costs, and prevent power outages. The full git repo for my approach to this project is at: https://github.com/jeffreyegan/VSB_Power_Line_Fault_Detection  Data Exploration and PreparationData DescriptionFaults in electric transmission lines can lead to a destructive phenomenon called partial discharge. If left alone, partial discharges can damage equipment to the point that it stops functioning entirely. Your challenge is to detect partial discharges so that repairs can be made before any lasting harm occurs. Each signal contains 800,000 measurements of a power line's voltage, taken over 20 milliseconds. As the underlying electric grid operates at 50 Hz, this means each signal covers a single complete grid cycle. The grid itself operates on a 3-phase power scheme, and all three phases are measured simultaneously. File Descriptionsmetadata_[train/test].csv  id_measurement: the ID code for a trio of signals recorded at the same time. signal_id: the foreign key for the signal data. Each signal ID is unique across both train and test, so the first ID in train is '0' but the first ID in test is '8712'. phase: the phase ID code within the signal trio. The phases may or may not all be impacted by a fault on the line. target: 0 if the power line is undamaged, 1 if there is a fault.  [train/test].parquet : The signal data. Each column contains one signal; 800,000 int8 measurements as exported with pyarrow.parquet version 0.11. Please note that this is different than our usual data orientation of one row per observation; the switch makes it possible loading a subset of the signals efficiently. If you haven't worked with Apache Parquet before, please refer to either the Python data loading starter kernel. sample_submission.csv: a valid sample submission. Data Background InformationAs you may notice, the signal data comes from the real environment, not a lab, and they contain a lot of background noise. These signals are measured by our patented device with lower sampling rate (cost efficiency purpose) therefore I do not recommend to use any other publicly available dataset containing partial discharge patterns (PD patterns). - also we deployed the metering devices on more than 20 different locations. This implies that the spectrum of noise and quality of PD's are so different from each other, that the correct and robust classification is a still ongoing problem (the main motivation of this competition). The comparison and broadening of our view is also considered as beneficial and necessary in our research. PD pattern is therefore the main star tonight and there is a lot of literature about this phenomenon. I would recommend to read some papers, during my dissertation I tried a lot of different feature extraction models, but those based on fundamentals worked the best. In general the imbalanced dataset is very natural because PD pattern implies some degradation or damage of the observed system which is happening (fortunately) less often than the states when the system is operating correctly. In our case, the measurements on the medium voltage overhead lines, PD pattern may look like this (pd_pattern.png). But because of a lot of various noise interference (overhead lines work as a huge antena grabbing all signals around), a lot of interpolated patterns may look similar (see samples.png). To use any kind of wavelet transformation is very reasonable, butterworth filter was helpful for me to suppress the sine shape, DWT to obtain its close approximation - sometimes it is disrupted, and denoising with feature extractions are the alchemy of this competition. Load Data";Apache 2.0;https://www.kaggle.com/jeffreyegan/vsb-power-line-fault-detection-approach;1.0;['statsmodels', 'sklearn', 'pattern'];['ner', 'ai', 'gan', 'cv', 'rl', 'nn', 'ann'];['filter', 'machine learning', 'training data', 'test data', 'train', 'random forest', 'model', 'neural network', 'deep learning', 'label', 'predict', 'recommend', 'classification', 'labeled'];https://www.kaggle.com/c/vsb-power-line-fault-detection;0.717;0.442;2020-12-13 18:09:07;multiple data sources;['feature engineering, random forest, signal processing'];VSB Power Line Fault Detection Approach;Python notebook;4514.0;48;;
2019-02-23 12:19:12;Handmade feature exampleAn example of handmade features + CatBoostClassifier, for those who wants to try something other than RNN.;Apache 2.0;https://www.kaggle.com/junkoda/handmade-features;1.0;['catboost', 'tensorflow', 'sklearn'];['ai', 'cnn', 'gan', 'cv', 'nn', 'rnn'];['predict', 'training data', 'test data', 'train', 'model', 'label', 'loss'];https://www.kaggle.com/c/vsb-power-line-fault-detection;0.704;0.463;2020-12-13 18:09:07;VSB Power Line Fault Detection;[];Handmade features;Python notebook;3353.0;62;;
2019-03-27 00:25:01;This notebook contains the winning solution to the VSB Power Line Fault Detection competition. Key Information: * Simple LightGBM model * Standard 5-fold CV * Uses just 9 features * Features all calculated using the peaks in the signals * Run times:     * Generating features: ~15 minutes     * Training: ~2 minutes     * Prediction: ~10 seconds;Apache 2.0;https://www.kaggle.com/mark4h/vsb-1st-place-solution;1.0;['xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'gbm', 'cv', 'rl', 'nn', 'ml'];['filter', 'training data', 'test data', 'train', 'model', 'loss', 'label', 'predict', 'classification'];https://www.kaggle.com/c/vsb-power-line-fault-detection;0.739;0.51;2020-12-13 18:09:07;multiple data sources;[];VSB_1st_place_solution;Python notebook;7825.0;116;0.71899;0.68008
2019-01-07 08:05:56;It's kernel investigate problems of the use CNN for line fault detection.;Apache 2.0;https://www.kaggle.com/miklgr500/flatiron;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cnn', 'nn', 'rnn', 'ann'];['filter', 'train', 'model', 'epoch', 'layer', 'loss', 'predict'];https://www.kaggle.com/c/vsb-power-line-fault-detection;0.734;0.486;2020-12-13 18:09:07;VSB Power Line Fault Detection;['beginner, data visualization, deep learning, +2 morefeature engineering, cnn'];Flatiron;Python notebook;6743.0;83;0.25265;0.24055
2019-04-28 17:49:11;Introduction - 2nd EditionThe original purpose of this notebook is to understand Matthew Correlation Coefficient (MCC), especially in the context of VSB competition (If you are a VSB competitor wanting to visit the old note book, please see Section Introduction -- 1st Edition, below). However, after the competition ended, I seemed to be able to understand MCC in a more general sense. I was able to derive the MCC formula into an intuitive form which will benefit all other future usages. Therefore, I decide to revise this notebook, and hence here's 2nd Edition part.;Apache 2.0;https://www.kaggle.com/ratthachat/demythifying-matthew-correlation-coefficients-mcc;1.0;['keras'];['ner', 'ai', 'rl', 'nn', 'ann'];['predict', 'test data', 'train', 'model', 'label', 'loss', 'understanding', 'labeled'];https://www.kaggle.com/c/vsb-power-line-fault-detection;0.741;0.408;2020-12-13 18:09:07;VSB Power Line Fault Detection;[];Demythifying Matthew Correlation Coefficients (MCC;Python notebook;8049.0;32;;
2020-07-06 06:40:36;End to End Machine Learning for VSB Power Line Fault Detection  Faults in electric transmission lines can lead to a destructive phenomenon called partial discharge. If left alone, partial discharges can damage equipment to the point that it stops functioning entirely. Your challenge is to detect partial discharges so that repairs can be made before any lasting harm occurs. Each signal contains 800,000 measurements of a power line's voltage, taken over 20 milliseconds. As the underlying electric grid operates at 50 Hz, this means each signal covers a single complete grid cycle. The grid itself operates on a 3-phase power scheme, and all three phases are measured simultaneously.  The Challenge is to detect partial discharge patterns in signals acquired from these power lines with a new meter designed at the ENET Centre at VSB. Effective classifiers using this data will make it possible to continuously monitor power lines for faults. Inspired from Bruno Aquino's Kernel: https://www.kaggle.com/braquino/5-fold-lstm-attention-fully-commented-0-694 Content -  Import Library -  Define Matthews Correlation -  Create Attention Layer -  Import Data -  Define Transformations -  Prepare Training Data -  Data Exploration     - Distribution of mean values per rows     - Distribution of mean values per columns     - Distribution of S.D values per rows     - Distribution of S.D values per columns     - Distribution of Skewness values per rows     - Distribution of Skewness values per columns     - Distribution of Kurtosis values per rows     - Distribution of Kurtosis values per columns - Applying TSNE Transformation - Applying PCA Transformation> - Applying ISO Transformation - Applying LLE Transformation> - Building the RNN Model Architecture - Applying Stratified K Fold Technique - Identify the Best Threshold - Create Submission File;Apache 2.0;https://www.kaggle.com/roydatascience/eda-iso-pca-lle-stratified-lstm-attention;1.0;['pattern', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'rnn'];['filter', 'machine learning', 'training data', 'test data', 'train', 'fitting', 'model', 'neural network', 'epoch', 'layer', 'loss', 'label', 'lstm', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/vsb-power-line-fault-detection;0.707;0.44;2020-12-13 18:09:07;VSB Power Line Fault Detection;['data visualization, deep learning, classification, +2 morefeature engineering, rnn']; EDA, ISO, PCA, LLE + Stratified LSTM Attention;Python notebook;3569.0;47;0.61138;0.64619
2019-01-20 07:38:47;"TL; DRJust adding some small improvements to the original kernel. Using a 5-fold instead of a single model, also a simple threshold search instead of using a flat value.";Apache 2.0;https://www.kaggle.com/suicaokhoailang/5-fold-lstm-with-threshold-tuning-0-618-lb;1.0;['tensorflow', 'sklearn', 'keras'];['ai', 'nn', 'cv'];['train', 'model', 'epoch', 'layer', 'loss', 'lstm', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/vsb-power-line-fault-detection;0.722;0.467;2020-12-13 18:09:07;VSB Power Line Fault Detection;['gpu'];5-fold LSTM with threshold tuning [0.580 LB];Python notebook;5077.0;65;;
2019-01-31 04:26:01;"TL;DR Feature engineering: https://www.kaggle.com/braquino/5-fold-lstm-attention-fully-commented-0-694  Transformer kernel from Quora competition: https://www.kaggle.com/shujian/transformer-initial-attempt  And of course: https://arxiv.org/abs/1706.03762   Major changes to the original Transformer architecture: No decoder, basically we cut it in half. We're doing classical classification not auto-regression like in machine translation so it's not needed.  No masked attention. Like above, we do not need to ensure causality in inference like machine transalation, so we can afford to make the information flow freely.";Apache 2.0;https://www.kaggle.com/suicaokhoailang/transformer-baseline-0-672-lb;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn'];['test data', 'regression', 'train', 'fitting', 'model', 'neural network', 'epoch', 'machine translation', 'layer', 'validation data', 'loss', 'lstm', 'predict', 'relu', 'classification'];https://www.kaggle.com/c/vsb-power-line-fault-detection;0.712;0.435;2020-12-13 18:09:07;multiple data sources;['gpu'];Transformer Baseline [0.672 LB];Python notebook;3992.0;44;0.61876;0.66247
2019-02-23 13:14:53;This kernel is forked from this wonderful kernel by Bruno Aquino. I have just stacked the recurrent layers together. Additionally, I have done some feature engineering based on time series entropy and fractal dimension. This achieves an LB score of 0.699.Feature Engineering : Raphael Vallat's entropy repository;Apache 2.0;https://www.kaggle.com/tarunpaparaju/vsb-competition-attention-bilstm-with-features;1.0;['pattern', 'tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ann'];['recognition', 'logistic regression', 'predict', 'relu', 'gru', 'train', 'epoch', 'lstm', 'linear regression', 'classification', 'model', 'neural network', 'layer', 'loss', 'test data', 'regression', 'generation', 'fitting', 'validation data'];https://www.kaggle.com/c/vsb-power-line-fault-detection;0.756;0.507;2020-12-13 18:09:07;VSB Power Line Fault Detection;['gpu'];VSB Competition : Base Neural Network;Python notebook;12185.0;111;;
2020-05-14 08:24:09;The Purpose of this notebook is to do very basic comparison of all three algorithms SARIMAX, PRophet, Random forest. I have included only few columns for my analysis;Apache 2.0;https://www.kaggle.com/deeptiagl/sarimax-vs-prophet-vs-random-forest;1.0;['statsmodels', 'sklearn'];['ner', 'ai', 'cv', 'rl', 'nn', 'ml'];['regression', 'train', 'fitting', 'model', 'label', 'predict', 'random forest'];https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting;0.686;0.357;2020-12-13 18:10:03;multiple data sources;[];SARIMAX Vs Prophet Vs Random Forest;Python notebook;2261.0;18;;
2020-09-05 00:20:22;Demand Forecasting PredictionsLet's get started.  Info This notebook is for the capstone project for Udacitys Nanodegree - Machine Learning Engineer. More information about the project will be provided below.  To test the prediciton score, we will submit the predictions to the Kaggle competition by Walmart which the data originated from, see link here.;Apache 2.0;https://www.kaggle.com/ggolle/simple-walkthrough-walmart-sales-forecasting;1.0;['xgboost', 'sklearn'];['ner', 'ai', 'nn'];['linear regression', 'machine learning', 'training data', 'regression', 'test data', 'train', 'model', 'predict', 'decision tree', 'random forest'];https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting;0.635;0.34;2020-12-13 18:10:03;Walmart Recruiting - Store Sales Forecasting;['random forest, regression, xgboost'];Simple Walkthrough - Walmart Sales Forecasting;Python notebook;830.0;15;;
2020-07-09 18:58:17;Reading DataIt reads the data provided by the host;Apache 2.0;https://www.kaggle.com/ivopdm/walmart-sales-forecast;1.0;['sklearn', 'tpot'];['ner', 'ai', 'dl', 'automl', 'cv', 'nn', 'ml'];['test data', 'generation', 'train', 'model', 'predict', 'understanding'];https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting;0.578;0.253;2020-12-13 18:10:03;Walmart Recruiting - Store Sales Forecasting;[];Walmart_sales_forecast;Python notebook;316.0;6;;
2020-10-28 13:59:57;Walmart Recruiting - Store Sales Forecasting;Apache 2.0;https://www.kaggle.com/nikita171096/walmart-sales-forecast;1.0;['xgboost', 'sklearn'];['ner', 'ai', 'cv', 'rl', 'nn', 'ann'];['linear regression', 'training data', 'test data', 'regression', 'train', 'model', 'understanding', 'label', 'predict', 'decision tree', 'random forest'];https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting;0.57;0.188;2020-12-13 18:10:03;multiple data sources;['data visualization, exploratory data analysis, linear regression, +1 morexgboost'];Walmart Sales Forecast;Python notebook;275.0;3;;
2019-11-20 18:04:49;Import Libraries, Datasets & Declare Functions;Apache 2.0;https://www.kaggle.com/nitinx/storesales-randomforest-light-gbm-stacking;1.0;['xgboost', 'sklearn', 'lightgbm'];['ner', 'ai', 'dl', 'gbm', 'cv', 'nn', 'ann'];['filter', 'training data', 'regression', 'test data', 'train', 'random forest', 'model', 'label', 'predict', 'supervised learning'];https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting;0.693;0.253;2020-12-13 18:10:03;Walmart Recruiting - Store Sales Forecasting;['beginner, random forest, regression'];StoreSales - RandomForest, Light GBM & Stacking;Python notebook;2612.0;6;3211.21339;3089.50209
2020-09-07 00:29:01;Walmart Recruitng: Store Sales ForecastingTechnical exercise for Zé Delivery selection process.  Otávio Vasques | September 2020 Github | LinkedIn | Email;Apache 2.0;https://www.kaggle.com/otaviocv/walmart-recruiting-sales-forecasting-otaviocv;1.0;['catboost', 'xgboost', 'sklearn'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ann'];['filter', 'machine learning', 'regression', 'training data', 'train', 'fitting', 'model', 'test data', 'understanding', 'validation data', 'loss', 'label', 'gradient boosting', 'predict', 'rank', 'recommend'];https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting;0.54;0.188;2020-12-13 18:10:03;Walmart Recruiting - Store Sales Forecasting;[];walmart-recruiting-sales-forecasting-otaviocv;Python notebook;175.0;3;;
2020-07-10 11:55:50;HelloThis notebook is followed by the Forecasting one  in which everything it more organized.  This notebook was made within free creative, brain  stormer environment. The less the mind was concern  about formal aesthetics the more creative it is :) But don't worry, the lack of text and explanation  here is covered at Forecasting notebook. However, the art and beauty on charts are here :) Enjoy!;Apache 2.0;https://www.kaggle.com/talestsp/eda-charts-free-text-notes;1.0;['statsmodels'];['ai', 'rl', 'gan'];['train', 'model', 'filter'];https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting;0.549;0.214;2020-12-13 18:10:03;multiple data sources;[];EDA - Charts - Free Text - Notes;Python notebook;201.0;4;;
2020-07-16 10:28:30;1. Importing and cleaning the data2. Exploratory Data Analysis (EDA)3. Analysis of time series4. Metrics and application with a super simple model5. SARIMA and SARIMAX6. Random Forest and Gradient Boosting7. Conclusions and Perspectives;Apache 2.0;https://www.kaggle.com/vtaquet/1st-analysis-of-the-walmart-sales;1.0;['statsmodels', 'xgboost', 'sklearn'];['ai', 'rl', 'dl', 'cv'];['filter', 'train', 'fitting', 'model', 'label', 'gradient boosting', 'predict', 'rank', 'random forest'];https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting;0.614;0.281;2020-12-13 18:10:03;Walmart Recruiting - Store Sales Forecasting;[];1st analysis of the Walmart sales;Python notebook;570.0;8;;
2019-12-15 01:52:43;The funciton to delete the 'nan';Apache 2.0;https://www.kaggle.com/bonesliu10318/visualization-walmart-trip-type-classification;1.0;['sklearn'];['ai', 'dl', 'rl'];['filter', 'train', 'layer', 'label', 'classification'];https://www.kaggle.com/c/walmart-recruiting-trip-type-classification;0.681;0.188;2020-12-13 18:10:16;Walmart Recruiting: Trip Type Classification;[];Visualization Walmart : Trip Type Classification;Python notebook;2022.0;3;;
2020-09-22 21:09:20;The funciton to delete the 'nan';Apache 2.0;https://www.kaggle.com/sandeepsingh3480/notebook8ecd7cbceb;1.0;['sklearn'];['dl', 'ai', 'nn', 'rl'];['filter', 'train', 'layer', 'label', 'classification'];https://www.kaggle.com/c/walmart-recruiting-trip-type-classification;0.529;0.0;2020-12-13 18:10:16;Walmart Recruiting: Trip Type Classification;[];notebook8ecd7cbceb;Python notebook;151.0;0;;
2017-07-18 21:00:52;"High level insight on Wikipedia web traffic.Note: If this helped you, some upvotes would be very much appreciated. It is foolish to fear what we have yet to see and know ;)";Apache 2.0;https://www.kaggle.com/dextrousjinx/brief-insight-on-web-traffic-time-series;1.0;['pattern'];['ner', 'ai', 'nn'];['train', 'understanding', 'label'];https://www.kaggle.com/c/web-traffic-time-series-forecasting;0.711;0.416;2020-12-13 18:15:01;Web Traffic Time Series Forecasting;[];Brief insight on Web Traffic Time Series;Python notebook;3937.0;35;;
2017-08-02 06:08:55;This notebook goes over some basic visualizations of the training data for this competition. We can get some insight into how we might extend our analyses beyond simple regression models, and we can also see that there are many potential difficulties in making good predictions.;Apache 2.0;https://www.kaggle.com/muonneutrino/wikipedia-traffic-data-exploration;1.0;['statsmodels'];['ner', 'ai', 'dl', 'gan', 'rl', 'nn'];['filter', 'training data', 'regression', 'train', 'model', 'label', 'predict', 'linear regression'];https://www.kaggle.com/c/web-traffic-time-series-forecasting;0.803;0.567;2020-12-13 18:15:01;Web Traffic Time Series Forecasting;['data visualization, exploratory data analysis'];Wikipedia Traffic Data Exploration;Python notebook;50175.0;266;;
2017-08-25 18:05:46;This Notebook is to visualize the data and train an ARIMA model for each language category combined. The outputs from this model can be used as an input feature for an ensemble of models based on their page language.Note: This is an extension of currently existing kernel https://www.kaggle.com/muonneutrino/wikipedia-traffic-data-exploration;Apache 2.0;https://www.kaggle.com/screech/ensemble-of-arima-and-lstm-model-for-wiki-pages;1.0;['statsmodels', 'tensorflow', 'sklearn', 'keras'];['ai', 'nn', 'rnn', 'rl'];['training data', 'train', 'fitting', 'model', 'input layer', 'output layer', 'epoch', 'layer', 'loss', 'label', 'lstm', 'predict', 'relu'];https://www.kaggle.com/c/web-traffic-time-series-forecasting;0.764;0.444;2020-12-13 18:15:01;Web Traffic Time Series Forecasting;['nlp, lstm'];Ensemble of ARIMA and LSTM model for Wiki pages;Python notebook;15155.0;49;;
2017-08-20 17:26:22;Web Traffic Time Series Forecasting (Experimenting with different method)By Lai Yiu Ming, Tom  Introduction Competition details Load libraries and data files, file structure and content Missing values Data visualization Extreme data   Data transformation and helper functions Article names and metadata Split into train and validation dataset   Forecast methods SMAPE, the measurement Simple median model Median model - weekday, weekend and holiday ARIMA model Facebook prophet model Sample series analysis (For script reconciliation)   Selected model performance (validation score) over train dataset Simple median model Median model - weekday, weekend, holiday ARIMA model Facebook model mixed model;Apache 2.0;https://www.kaggle.com/ymlai87416/web-traffic-time-series-forecast-with-4-model;1.0;['statsmodels', 'xgboost'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['filter', 'training data', 'train', 'model', 'validation data', 'predict'];https://www.kaggle.com/c/web-traffic-time-series-forecasting;0.782;0.506;2020-12-13 18:15:01;multiple data sources;[];Web traffic time series forecast with 4 model;Python notebook;25983.0;109;;
2018-04-13 11:41:48;Predictive Analysis - Web Traffic Time Series Forecasting | Kaggle;Apache 2.0;https://www.kaggle.com/zoupet/predictive-analysis-with-different-approaches;1.0;['statsmodels', 'sklearn', 'tensorflow', 'pattern', 'keras'];['ner', 'ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'machine learning', 'regression', 'neuron', 'train', 'model', 'neural network', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/web-traffic-time-series-forecasting;0.8;0.555;2020-12-13 18:15:01;Web Traffic Time Series Forecasting;['neural networks, gradient boosting, advanced'];Predictive Analysis with different approaches;Python notebook;45233.0;221;;
2018-07-10 22:03:06;"Humpback Whale Identification - CNN with Keras This is a solution for the challenge ""Humpback Whale Identification"". It is based on a Convolutional Neural Network using Keras. During the challenge I have created multiple versions of this CNN to try and improve my results. Most of the code for those versions are still in this notebook in hidden sections of the code and commented. The version which is not commented or hidden is the one that produced my best results in the challenge. In this code I have chosen not to split the training set to create a test set, because of the characteristics of the data. Many of the classes have only one picture that corresponds to them, so randomly selecting a test set would be harmful for training. I did try data augmentation, as can be seen in previous versions of this code. However, because I was running in the Kaggle kernel, the increase in the amout of data increased the runtime and, due to kernel limitation, that resulted in a decrease in the number of iterations. The results I obtained using the augmented data were, then, worse than the ones simply using the given data.";Apache 2.0;https://www.kaggle.com/anezka/cnn-with-keras-for-humpback-whale-id;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'cnn', 'cv', 'rl', 'nn', 'ml'];['training data', 'test data', 'train', 'model', 'neural network', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'convolutional neural network'];https://www.kaggle.com/c/whale-categorization-playground;0.72;0.435;2020-12-13 18:17:20;multiple data sources;['deep learning, classification, image data, +2 morecnn, animals'];CNN with Keras for Humpback Whale ID;Python notebook;4828.0;44;;
2018-06-03 07:54:55;Installation of Resnet 50 Weight to keras;Apache 2.0;https://www.kaggle.com/ashishpatel26/whale-prediction-using-resnet-50;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'rl', 'cv'];['train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'resnet'];https://www.kaggle.com/c/whale-categorization-playground;0.713;0.397;2020-12-13 18:17:20;multiple data sources;['gpu, cnn'];Whale Prediction Using Resnet-50;Python notebook;4087.0;28;0.37962;0.37962
2018-02-24 14:49:21;"Hi, I'm happy to share some improvements. I hope it will be helpfull, as kernel of CVxTz was helpfull for me : https://www.kaggle.com/CVxTz/beating-the-baseline-keras-lb-0-38 So a big thanks to CVxTz for the very good code and to Nastika Vidwan, with their introduction of face recognition and triplet loss concepts. I'm just adding below an improvement of the last part of CVxTz'code. I suggest to replace ""Nearest Neighbor"" approach by a direct distance calculation. It boost the score of about 0,04 (from 0.38 to 0.42).  So you don't have any excuse to attend the 5th place in the challenge ...  :-) Now i'm working on other improvements, but it's now a bit difficult because of poor number of occurences of classes ... have fun :-)";Apache 2.0;https://www.kaggle.com/bibuml/beating-cvxtz-very-good-code-0-38-to-0-42;1.0;['keras', 'sklearn'];['ai', 'cv'];['predict', 'train', 'recognition', 'model', 'loss'];https://www.kaggle.com/c/whale-categorization-playground;0.646;0.236;2020-12-13 18:17:20;Humpback Whale Identification Challenge;[];Beating CVxTz very good code (0.38) to 0.42;Python notebook;1005.0;5;;
2018-01-26 07:53:28;In this notebook, I examine the provided data for Kaggle's Humpback Whale ID challenge. I also look at data augmentations in an attempt to inflate the size of the training dataset.;Apache 2.0;https://www.kaggle.com/lextoumbourou/humpback-whale-id-data-and-aug-exploration;1.0;['tensorflow', 'keras'];['dl', 'ai', 'nn', 'ann'];['image classification', 'training data', 'train', 'model', 'label', 'predict', 'classification'];https://www.kaggle.com/c/whale-categorization-playground;0.762;0.529;2020-12-13 18:17:20;Humpback Whale Identification Challenge;[];Humpback Whale ID: Data and Aug Exploration;Python notebook;14381.0;150;;
2018-06-25 22:23:23;Bounding box data for the whale flukesThis notebook explores the Humpback Whale Identification - Fluke Location dataset. This dataset is associated with the Humpback Whale Identification Challenge dataset. It contains the location of points on the edge of the fluke for 1200 pictures randomly selected from the Humpback Whale Identification Challenge training set. Points are selected to capture the leftmost and rightmost points, as well as the highest and lowest points. Additional points are added to help determine the fluke bounding box following an affine transformation on the image. The intent of this dataset is to build a model for locating the whale fluke inside the image. In the context of the Humpback Whale Identification Challenge, such a model can then be used to crop images around the region of interest.;Apache 2.0;https://www.kaggle.com/martinpiotte/bounding-box-data-for-the-whale-flukes;1.0;['keras'];['ai', 'dl', 'cv', 'rl', 'ml', 'nn', 'ann'];['train', 'model'];https://www.kaggle.com/c/whale-categorization-playground;0.722;0.471;2020-12-13 18:17:20;multiple data sources;['data visualization']; Bounding box data for the whale flukes;Python notebook;5136.0;69;;
2018-06-30 01:52:42;Bounding Box ModelThis notebook explains how to generage a bounding box model. While many of the whale pictures in the dataset are already cropped tight around the whale fluke, in some images the whale fluke occupies only a small area of the picture. Zooming in the relevant part of the picture provides greater accuracy to a classification model. To automate the process, this notebook explains how to construct a convolutional neural network (CNN) capable of estimating the whale bounding box. Using this model, whale pictures can be cropped automatically to a more uniform appearance. This facilitates training of classification models, and improves the test accuracy. Training of the bounding box model is performed over a dataset of 1200 bounding boxes for pictures selected from the Humpback Whale Identification Challenge training set. 1000 pictures are used for training, while 200 are reserved for validation.;Apache 2.0;https://www.kaggle.com/martinpiotte/bounding-box-model;1.0;['keras', 'sklearn'];['ner', 'ai', 'cnn', 'cv', 'rl', 'ml', 'nn', 'ann'];['training data', 'train', 'model', 'neural network', 'epoch', 'validation data', 'layer', 'vgg', 'loss', 'predict', 'relu', 'understanding', 'classification', 'convolutional neural network'];https://www.kaggle.com/c/whale-categorization-playground;0.781;0.556;2020-12-13 18:17:20;multiple data sources;['gpu, computer vision, animals'];Bounding Box Model;Python notebook;24816.0;224;;
2018-07-25 17:10:28;Whale Classification ModelThis notebook describes the strategy behind the 0.78563 submission to the Humpack Whale identification Challenge. It should be studied in conjunction with the Bounding Box Model notebook which describes separately the strategy for image cropping. To speed things up, the results of some slow computations are included as a dataset instead of being recomputed here. However, the code is still provided in the notebook as reference, even if it is not executed by default.;Apache 2.0;https://www.kaggle.com/martinpiotte/whale-recognition-model-with-score-0-78563;1.0;['keras'];['ner', 'ai', 'cnn', 'cv', 'rl', 'ml', 'nn', 'ann'];['filter', 'vgg', 'predict', 'relu', 'training data', 'train', 'epoch', 'classification', 'propagation', 'model', 'neural network', 'layer', 'loss', 'rank', 'resnet', 'generation', 'fitting', 'validation data', 'deep learning', 'gradient descent'];https://www.kaggle.com/c/whale-categorization-playground;0.803;0.603;2020-12-13 18:17:20;multiple data sources;['cnn, animals'];Whale Recognition Model with score 0.78563;Python notebook;49869.0;470;;
2018-01-13 22:47:06;MotivationBased on my previous analysis, it's apparent that we have a severe imbalanced classes problem. Thus, I think we need to spend some time applying transformations to observations in the smaller classes in order to create a more balanced dataset for fitting. Find small classLet's find an extremely small class to work with, perhaps one with just one image.;Apache 2.0;https://www.kaggle.com/mmrosenb/whales-some-image-processing;1.0;['pattern', 'tensorflow', 'keras'];['ner', 'ai', 'nn', 'ann'];['train', 'fitting', 'test data', 'predict'];https://www.kaggle.com/c/whale-categorization-playground;0.671;0.352;2020-12-13 18:17:20;Humpback Whale Identification Challenge;['computer vision'];Whales: Some Image Processing;Python notebook;1654.0;17;;
2018-06-14 04:14:22;Hello gens, I've tried to process images with croping and normalizing aspect ratio. There are two idea for the task  Find object boundary and crop by a window with the most amount of boundary Train 'whale tail' or 'background' by CNN with keras and zoom image by its probability.  Even though the images are already cropped as we can easily find the object (whale tail), these have indifferent information. So, I'd like to scrape off. In addition, the aspect ratio of cropped area should be normalized for inputting to Keras model.;Apache 2.0;https://www.kaggle.com/rio114/cropping-with-normlized-aspect-ratio;1.0;['tensorflow', 'keras'];['ner', 'ai', 'dl', 'cnn', 'cv', 'nn', 'ann'];['training data', 'train', 'fitting', 'model', 'epoch', 'layer', 'loss', 'label', 'predict', 'relu', 'labeled'];https://www.kaggle.com/c/whale-categorization-playground;0.714;0.319;2020-12-13 18:17:20;Humpback Whale Identification Challenge;['computer vision'];Cropping with normlized aspect ratio;Python notebook;4228.0;12;;
2018-03-30 11:28:52;"While exploring the data I found that there are 778 duplicate images. There are 3 types of data errors regarding duplicate images: 1) The same image with the corresponding Id appears multiple time. 2) The same image appears with a known whale Id and as ""new_whale"". 3) The same image appears with different Ids (ambiguous classified). The following code shows a data cleaning approach to fix the duplicate images issue.";Apache 2.0;https://www.kaggle.com/stehai/duplicate-images-data-cleaning;1.0;['tensorflow'];['ai'];['train'];https://www.kaggle.com/c/whale-categorization-playground;0.669;0.281;2020-12-13 18:17:20;Humpback Whale Identification Challenge;[];Duplicate Images - Data Cleaning;Python notebook;1583.0;8;;
2020-07-28 15:26:15;Kernel description: This kernel demonstrates application of transfer learning with VGG-16 to the given whale multi-class classfication problem. Please note that this is a solution to my university course assignment which differs in the objective from the original stated problem. The difference is that the original training data set is filtered by removing all whale individuals for which the number of images is smaller than the given threshold NUM_IMAGES_THRESHOLD. Also, all pictures annotated with 'new whale' label are excluded from the dataset. Last, there is no submission file produced by this kernel. Anyway, please consider upvoting this kernel if you liked it! PS. The Table of Contents was generated using ToC2 extension for Jupyter Notebook.;Apache 2.0;https://www.kaggle.com/timmate/transfer-learning-with-vgg-16;1.0;['tensorflow', 'sklearn', 'keras'];['ner', 'ai', 'ml', 'nn', 'ann'];['filter', 'training data', 'test data', 'train', 'model', 'epoch', 'layer', 'vgg', 'loss', 'label', 'predict', 'relu', 'propagation'];https://www.kaggle.com/c/whale-categorization-playground;0.533;0.253;2020-12-13 18:17:20;Humpback Whale Identification Challenge;['multiclass classification, transfer learning'];Transfer learning with VGG-16;Python notebook;160.0;6;;
2016-12-03 16:06:00;GENERAL DESCRIPTION:Capturing cultural diffusion by converting each cuisine to a TF-IDF vector (based on its ingredients), using PCA to obtain two vectors for visualization purposes, and clustering them by K-Means. There are several improvements that one could easily think of, but the basic results prove to be quite good - Asia for example is separate from the rest and notice how the 'filipino' cuisine is also slightly separate from the rest of Asia (it is known to be quite different from the other Asian cuisines).;Apache 2.0;https://www.kaggle.com/alonalevy/cultural-diffusion-by-recipes;1.0;['sklearn'];['ner', 'ai', 'nn'];['predict', 'train', 'label', 'k-means', 'clustering'];https://www.kaggle.com/c/whats-cooking;0.762;0.45;2020-12-13 18:21:34;What's Cooking?;[];Cultural Diffusion by Recipes;Python notebook;14362.0;53;;
2020-10-28 08:06:49;Presenting a solution to get into top 7% of leaderboard using Support Vector Classifier with an accuracy score of 0.81063;Apache 2.0;https://www.kaggle.com/anmoltripathi/what-s-cooking-top-7-solution;1.0;['pattern', 'sklearn', 'nltk'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ann'];['predict', 'training data', 'train', 'fitting', 'model', 'label', 'k-means', 'loss', 'bayesian'];https://www.kaggle.com/c/whats-cooking;0.594;0.253;2020-12-13 18:21:34;What's Cooking?;['classification, feature engineering, nlp'];What's Cooking Top 7% solution;Python notebook;407.0;6;0.81063;0.81063
2017-05-30 15:19:23;"I had the idea to apply distributed word vectors (word2vec) to this dataset. Word2vec, in a very high level, is an algorithm capable to learn the relationship between words using the context (neighbouring words), and encodes those relatinships in a vector. Using these vectors, we can cluster the words in or library, or even do operations. The classic example of the latter is; ""king - man + woman = queen."" Word2vec uses recurrent neural networks to learn, then usually works better with huge datasets (billions of words), but we will see how it performs with the cooking dataset, where each receipt will be a sentence. One of the best features of this algorithm published by Google is the speed. Other recurrent neural networks had been proposed, however they were insanely CPU time consuming. If you want more detailed information about this, I strongly suggest you to read about here, here and here : . Now let’s tackle our dataset.";Apache 2.0;https://www.kaggle.com/arunava21/word2vec-with-ingredients;1.0;['sklearn', 'gensim'];['ner', 'ai', 'dl', 'gan', 'rl', 'nn', 'ml'];['recurrent neural network', 'train', 'model', 'neural network', 'label', 'predict'];https://www.kaggle.com/c/whats-cooking;0.668;0.236;2020-12-13 18:21:34;What's Cooking?;[];Word2Vec with ingredients;Python notebook;1542.0;5;;
2017-03-25 18:53:29;"I had the idea to apply distributed word vectors (word2vec) to this dataset. Word2vec, in a very high level, is an algorithm capable to learn the relationship between words using the context (neighbouring words), and encodes those relatinships in a vector. Using these vectors, we can cluster the words in or library, or even do operations. The classic example of the latter is; ""king - man + woman = queen."" Word2vec uses recurrent neural networks to learn, then usually works better with huge datasets (billions of words), but we will see how it performs with the cooking dataset, where each receipt will be a sentence. One of the best features of this algorithm published by Google is the speed. Other recurrent neural networks had been proposed, however they were insanely CPU time consuming. If you want more detailed information about this, I strongly suggest you to read about here, here and here : . Now let’s tackle our dataset.";Apache 2.0;https://www.kaggle.com/ccorbi/word2vec-with-ingredients;1.0;['sklearn', 'gensim'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nn', 'ann'];['recurrent neural network', 'train', 'model', 'neural network', 'label', 'predict'];https://www.kaggle.com/c/whats-cooking;0.735;0.408;2020-12-13 18:21:34;What's Cooking?;[];Word2Vec with ingredients;Python notebook;7016.0;32;;
2020-10-07 20:33:00;What do we have for dinner ?;Apache 2.0;https://www.kaggle.com/cristianfat/what-do-we-have-for-dinner;1.0;['xgboost', 'sklearn'];['ner', 'ai', 'nn', 'ann'];['train', 'model', 'classification', 'predict'];https://www.kaggle.com/c/whats-cooking;0.528;0.214;2020-12-13 18:21:34;What's Cooking?;['classification, xgboost, multiclass classification, +1 moremultilabel classification'];What do we have for dinner ?;Python notebook;149.0;4;0.74778;0.74778
2017-04-24 16:09:37;GENERAL DESCRIPTION:Capturing cultural diffusion by converting each cuisine to a TF-IDF vector (based on its ingredients), using PCA to obtain two vectors for visualization purposes, and clustering them by K-Means. There are several improvements that one could easily think of, but the basic results prove to be quite good - Asia for example is separate from the rest and notice how the 'filipino' cuisine is also slightly separate from the rest of Asia (it is known to be quite different from the other Asian cuisines).;Apache 2.0;https://www.kaggle.com/eazhary/cultural-diffusion-by-recipes;1.0;['sklearn'];['ner', 'ai', 'nn'];['predict', 'train', 'label', 'k-means', 'clustering'];https://www.kaggle.com/c/whats-cooking;0.617;0.214;2020-12-13 18:21:34;What's Cooking?;[];Cultural Diffusion by Recipes;Python notebook;602.0;4;;
2018-03-30 10:29:33;"Ingredient recommender system.More like this on kachkach.com In this notebook, we will use the dataset to build an ingredient recommender system. We will go from the most basic (counting ingredient co-occurrences) to the slightly more elaborate (matrix factorization), also looking at a useful information theory metric called ""Pointwise Mutual Information"" (PMI).";Apache 2.0;https://www.kaggle.com/halflings/ingredient-recommender-system;1.0;['sklearn'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nn', 'ann'];['train', 'recommend', 'model', 'filter'];https://www.kaggle.com/c/whats-cooking;0.688;0.214;2020-12-13 18:21:34;What's Cooking?;['beginner, recommender systems'];Ingredient recommender system;Python notebook;2334.0;4;;
2018-07-13 06:51:09;If You Smelllll What The Rock Is Cooking;Apache 2.0;https://www.kaggle.com/ash316/what-is-the-rock-cooking-ensembling-network;1.0;['sklearn', 'nltk'];['ner', 'ai', 'nn', 'cv'];['filter', 'regression', 'train', 'model', 'label', 'logistic regression', 'predict'];https://www.kaggle.com/c/whats-cooking-kernels-only;0.74;0.486;2020-12-13 18:23:40;What's Cooking? (Kernels Only);['ensembling, svm'];What Is The Rock Cooking??(Ensembling & Network);Python notebook;7930.0;84;;
2018-06-29 20:37:25;Top 5 Famous Food Contain Italian, Mexican, Southern_us, Indian and Chinese;Apache 2.0;https://www.kaggle.com/ashishpatel26/scrumptious-cooking-foods;1.0;['tensorflow', 'sklearn', 'keras', 'nltk'];['ner', 'ai', 'gan', 'cv', 'rl', 'nn'];['filter', 'test data', 'regression', 'train', 'model', 'layer', 'lstm', 'label', 'predict'];https://www.kaggle.com/c/whats-cooking-kernels-only;0.633;0.34;2020-12-13 18:23:40;What's Cooking? (Kernels Only);['gpu'];Scrumptious Cooking Foods 🍕🍕🍕;Python notebook;795.0;15;0.10649;0.10649
2018-09-18 19:32:01;Let's cook modelLet's combine what we've found so far.  What are ingredients? (Preprocessing & Feature extraction) Representations for ingredients  Steps are below.  Load dataset Remove outliers Preprocess Create model Check local CV Train model Check predicted values Make submission;Apache 2.0;https://www.kaggle.com/ashishpatel26/think-differently-what-s-cooking;1.0;['keras', 'sklearn', 'nltk'];['ai', 'gbm', 'cv', 'rl', 'nn', 'ml'];['filter', 'regression', 'train', 'model', 'label', 'predict', 'classification'];https://www.kaggle.com/c/whats-cooking-kernels-only;0.636;0.327;2020-12-13 18:23:40;What's Cooking? (Kernels Only);[];Think Differently What's Cooking..✔✔✔✔;Python notebook;835.0;13;;
2018-06-27 04:58:22;"Supervised Word Embeddings ""Cuisine Similarity"" Introduction  Data Preprocessing  GloVe Word Embeddings  Similarity Queries  Cuisine Similarity  Ingredient Similarity  Recipe Similarity    Most Representative Queries  Ingredient -> Cuisine:Given an ingredient, which cuisine is most associated with it?  Cuisine -> Ingredient: Given a cuisine,  what ingredient is most associated with it?  Cuisine -> Recipe: Given a cuisine, what recipe  is most associated with it?  Recipe -> Cuisine:Given a recipe, which cuisine is most associated with it?This is exactly the problem that we are asked to solve.    Cuisine Predictions  Base Predictions  Word Embeddings as Features  Blending";Apache 2.0;https://www.kaggle.com/mmotoki/word-embeddings-cuisine-similarity;1.0;['pattern', 'vocabulary'];['ner', 'ai', 'dl', 'gan', 'cv', 'rl', 'nn', 'ml'];['machine learning', 'random forest', 'regression', 'train', 'model', 'label', 'predict', 'unsupervised learning', 'supervised learning'];https://www.kaggle.com/c/whats-cooking-kernels-only;0.733;0.444;2020-12-13 18:23:40;What's Cooking? (Kernels Only);[];"Supervised Word Embeddings ""Cuisine Similarity""";R notebook;6675.0;49;;
2018-08-09 22:47:45;Logistic Regression StarterBy Nick Brooks  This Model is Bland!In this notebook I am serving up a basic and essential model in machine learning. While it may be bland, it is easy to poke around and see what is going on inside.;Apache 2.0;https://www.kaggle.com/nicapotato/this-model-is-bland-simple-logistic-starter;1.0;['sklearn'];['dl', 'ner', 'ai', 'nn'];['machine learning', 'training data', 'regression', 'train', 'model', 'loss', 'label', 'logistic regression', 'predict'];https://www.kaggle.com/c/whats-cooking-kernels-only;0.701;0.423;2020-12-13 18:23:40;What's Cooking? (Kernels Only);['data visualization, exploratory data analysis, logistic regression, +1 moremulticlass classification'];This Model is Bland! Simple Logistic Starter;Python notebook;3125.0;38;;
2018-09-11 20:00:13;Let's cook modelLet's combine what we've found so far.  What are ingredients? (Preprocessing & Feature extraction) Representations for ingredients  Steps are below.  Load dataset Remove outliers Preprocess Create model Check local CV Train model Check predicted values Make submission;Apache 2.0;https://www.kaggle.com/rejasupotaro/let-s-cook-model;1.0;['keras', 'sklearn', 'nltk'];['ai', 'gbm', 'cv', 'rl', 'nn', 'ml'];['filter', 'regression', 'train', 'model', 'label', 'predict', 'classification'];https://www.kaggle.com/c/whats-cooking-kernels-only;0.688;0.383;2020-12-13 18:23:40;What's Cooking? (Kernels Only);[];Let's cook model;Python notebook;2366.0;24;;
2018-09-13 21:36:41;What is the best representation for ingredients?We need to convert ingredeints to numeric values so that computers can do mathematical operations. My question was what the best representation is for this dataset. I compared representations below.  CountVectorizer TfidfVectorizer TfidfVectorizer + SVD Word2Vec fastText TfidfVectorizer + fastText Pre-trained model (Module google/‌nnlm-en-dim128/1)  There is room for tuning parameters.;Apache 2.0;https://www.kaggle.com/rejasupotaro/representations-for-ingredients;1.0;['vocabulary', 'tensorflow', 'sklearn', 'gensim'];['ai', 'nn'];['filter', 'regression', 'train', 'model', 'epoch', 'label', 'predict'];https://www.kaggle.com/c/whats-cooking-kernels-only;0.652;0.292;2020-12-13 18:23:41;What's Cooking? (Kernels Only);[];Representations for ingredients;Python notebook;1127.0;9;;
2018-09-04 00:24:00;What are ingredients?In the previous kernel (https://www.kaggle.com/rejasupotaro/representations-for-ingredients), I experimented which representation is better for this dataset without looking at what ingredients itself are. Viewing ingredients, I found some interesting things which might help to understand cuisines.  Outliers Special characters Upper cases Apostrophes Hyphens Numbers Units Region names Accents Unique ingredients Language Misspellings;Apache 2.0;https://www.kaggle.com/rejasupotaro/what-are-ingredients;1.0;['sklearn', 'nltk'];['ai', 'dl', 'gan', 'ml', 'nn', 'ann'];['test data', 'regression', 'train', 'model', 'label', 'rank'];https://www.kaggle.com/c/whats-cooking-kernels-only;0.718;0.39;2020-12-13 18:23:40;What's Cooking? (Kernels Only);[];What are ingredients?;Python notebook;4610.0;26;;
2018-09-14 07:29:13;Dishes have wide number of ingredients, with some having only one ingredient to as high as 65.;Apache 2.0;https://www.kaggle.com/sathyz/simple-nn-approach-kfold;1.0;['tensorflow', 'sklearn', 'keras', 'nltk'];['ai', 'rl', 'nn', 'cv'];['train', 'model', 'epoch', 'deep learning', 'layer', 'loss', 'label', 'predict', 'relu'];https://www.kaggle.com/c/whats-cooking-kernels-only;0.651;0.302;2020-12-13 18:23:41;What's Cooking? (Kernels Only);['deep learning'];Simple NN Approach (KFold);Python notebook;1106.0;10;;
2019-11-19 21:19:10;What's Cooking:- Building a Text Classifier  This Kaggle competition asks us to predict the category of a dish's cuisine given a list of its ingredients.This Notebook explores and analyses this dataset to build a Text Classifier. It can also serve as a great starting point for learning how to explore, manipulate, transform and learn from textual data .   This Notebook is divided into the following sections:-  A Date with Data  : As they say, to know someone better you must meet him/her in person. In this section we will go on a date with data to explore and visualize it to gain insights  Experiencing the Change : As you and data fall in love, data experiences positive changes. In this section data is cleaned and pre-processed (which is a positive change) for model development. Exploring the Unknowns: As the relationship between you and data goes on, you tend to explore and dig into what suits data the most. In this section we will explore which Feature Engineering technique for representing and converting text data gives the best results. The Final Decision : Its time to build the Model   Let's Get the Party Started;Apache 2.0;https://www.kaggle.com/tanulsingh077/what-s-cooking;1.0;['keras', 'sklearn', 'nltk', 'gensim'];['ner', 'ai', 'dl', 'gbm', 'rl', 'nn', 'ml'];['filter', 'machine learning', 'regression', 'generation', 'train', 'test data', 'model', 'epoch', 'natural language processing', 'label', 'predict', 'rank', 'classification', 'natural language'];https://www.kaggle.com/c/whats-cooking-kernels-only;0.685;0.44;2020-12-13 18:23:40;What's Cooking? (Kernels Only);['data visualization, exploratory data analysis, feature engineering, +2 moretext data, multiclass classification'];What's Cooking?;Python notebook;2205.0;47;0.82139;0.82139
2018-03-02 12:18:20;I'm trying to find a statistically meaningful (if I squint and cross my fingers) way determining home court advantage and factoring it out when predicting tourney games, which have no home court (in theory). I found this paper, it's old, but it looks interesting: The Home-Court Advantage: How Large Is It, and Does It Vary From Team to Team? David A. Harville and Michael H. Smith http://www.jstor.org/stable/2685080 It contains 3 models. The first is a basic least squares estimation of team ratings, similar (but predating) Massey's '97 paper. The second model adds a universal home court coefficient. The third estimates home court and away court coefficients for each team. My stats and python skills aren't the best, so take it as a given that there's error(s), caveat lector..... (Updated: I realized I got some of the models wrong and have updated them);Apache 2.0;https://www.kaggle.com/baeng72/search-for-a-useful-home-court-advantage-estimator;1.0;['sklearn'];['ner', 'ai', 'dl', 'cv', 'rl', 'nn', 'ml'];['regression', 'model', 'loss', 'label', 'predict', 'rank'];https://www.kaggle.com/c/womens-machine-learning-competition-2018;0.614;0.236;2020-12-13 18:26:55;Google Cloud & NCAA® ML Competition 2018-Women's;[];Search for a useful home-court advantage estimator;Python notebook;572.0;5;;
2018-03-02 17:51:11;"PyMC3 StarterThis notebook is intended to show how a simple but effective model might be fit with PyMC3.  We will model the ""strength"" of team as being normally distributed around 0, and assume that each game the probability of a team winning is the (logit of the) difference of the strengths. Specifically, if team i has strength ti, then the chance of beating team j is p(outcomei,j=1)∼Bernoulli(p=11+exp(ti−tj)). The maximum likelihood estimator of this model would be 1-hot encoding all the teams and fitting logistic regression to it.  This would likely be overfit.  By using PyMC3, we will also get uncertainty bounds on the strength of each team, so we can optimize to some other fitness function if we want.";Apache 2.0;https://www.kaggle.com/colincarroll/pymc3-starter;1.0;['theano'];['ai', 'gan', 'rl', 'nn', 'ml'];['regression', 'fitting', 'model', 'logistic regression', 'rank'];https://www.kaggle.com/c/womens-machine-learning-competition-2018;0.65;0.214;2020-12-13 18:26:55;Google Cloud & NCAA® ML Competition 2018-Women's;[];PyMC3 Starter;Python notebook;1084.0;4;;
2018-02-23 06:59:21;Collaborative FilteringThis is a starter notebook forked from last year's competition. This is an implementation of Collaborative filtering starter with Keras. Uses only the win(1) and loss(0) label of each match and categorical encoding of team Ids as training data. Essentially the formula used is shown below: Model prediction = Dot product of the 2 teams in each match (embedding vectors)+ (Team1 bias) + (Team2 bias);Apache 2.0;https://www.kaggle.com/dicksonchin93/collaborative-filterings;1.0;['tensorflow', 'keras'];['ai', 'nn'];['filter', 'training data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'predict'];https://www.kaggle.com/c/womens-machine-learning-competition-2018;0.593;0.152;2020-12-13 18:26:55;Google Cloud & NCAA® ML Competition 2018-Women's;[];Collaborative Filterings..;Python notebook;401.0;2;0.00000;0.00000
2018-02-13 01:11:14;OverviewThis is a starter notebook inspired by last year's Logistic Regression on Tournament Seeds by Kasper P. Lauritzen starter kernel. It creates a basic logistic regression model based on the seed differences between teams. Note that the predictions for Stage 1's sample submissions file are already based on known outcomes, and the Tourney data this model is trained on includes that data. For Stage 2, you will be predicting future outcomes based on the teams selected for the tournament on March 12.;Apache 2.0;https://www.kaggle.com/juliaelliott/basic-starter-kernel-ncaa-women-s-dataset;1.0;['sklearn'];['ai', 'nn', 'cv'];['training data', 'regression', 'train', 'model', 'loss', 'label', 'logistic regression', 'predict'];https://www.kaggle.com/c/womens-machine-learning-competition-2018;0.73;0.469;2020-12-13 18:26:55;Google Cloud & NCAA® ML Competition 2018-Women's;[];Basic Starter Kernel - NCAA Women's Dataset;Python notebook;6225.0;67;;
2018-02-24 17:01:55;From the relationship between SeedDiff and Season with diff_score. I will create a model to predict diff_score. for any value of SeedDiff and Season.;Apache 2.0;https://www.kaggle.com/octaviosantana/creating-new-feature;1.0;['sklearn'];['ai', 'nn', 'cv'];['predict', 'train', 'model', 'label', 'loss'];https://www.kaggle.com/c/womens-machine-learning-competition-2018;0.598;0.188;2020-12-13 18:26:55;Google Cloud & NCAA® ML Competition 2018-Women's;[];Creating  New Feature;Python notebook;436.0;3;0.00000;0.00000
2018-03-14 23:03:18;First we import some datasets of interest;Apache 2.0;https://www.kaggle.com/therealdaita/ncaa-womens-keras-network;1.0;['keras', 'sklearn'];['ner', 'ai', 'gan', 'cv', 'rl', 'nn'];['training data', 'regression', 'train', 'model', 'loss', 'label', 'predict'];https://www.kaggle.com/c/womens-machine-learning-competition-2018;0.629;0.236;2020-12-13 18:26:55;Google Cloud & NCAA® ML Competition 2018-Women's;[];NCAA Womens - Keras Network;Python notebook;737.0;5;0.00000;0.00000
2019-02-15 19:20:51;OverviewThis is a starter notebook inspired by the 2017 Logistic Regression on Tournament Seeds by Kasper P. Lauritzen starter kernel. It creates a basic logistic regression model based on the seed differences between teams. Note that the predictions for Stage 1's sample submissions file are already based on known outcomes, and the Tourney data this model is trained on includes that data. For Stage 2, you will be predicting future outcomes based on the teams selected for the tournament on March 18.;Apache 2.0;https://www.kaggle.com/addisonhoward/basic-starter-kernel-ncaa-women-s-dataset-2019;1.0;['sklearn'];['ai', 'nn', 'cv'];['training data', 'regression', 'train', 'model', 'loss', 'label', 'logistic regression', 'predict'];https://www.kaggle.com/c/womens-machine-learning-competition-2019;0.649;0.268;2020-12-13 18:28:45;Google Cloud & NCAA® ML Competition 2019-Women's;[];Basic Starter Kernel - NCAA Women's Dataset 2019;Python notebook;1083.0;7;0.00000;0.00000
2019-02-24 07:22:00;Feel free to upvote kernel and good luck;Apache 2.0;https://www.kaggle.com/duketemon/random-forest;1.0;['sklearn'];['ai', 'cv'];['loss', 'model', 'fitting', 'predict'];https://www.kaggle.com/c/womens-machine-learning-competition-2019;0.665;0.334;2020-12-13 18:28:45;Google Cloud & NCAA® ML Competition 2019-Women's;['beginner, feature engineering, random forest'];Random Forest;Python notebook;1460.0;14;;
2019-02-28 07:24:56;Feel free to upvote kernel and good luck;Apache 2.0;https://www.kaggle.com/hamidhaghshenas/adaboostclassifier;1.0;['sklearn'];['ai', 'cv'];['loss', 'model', 'fitting', 'predict'];https://www.kaggle.com/c/womens-machine-learning-competition-2019;0.662;0.334;2020-12-13 18:28:45;Google Cloud & NCAA® ML Competition 2019-Women's;[];AdaBoostClassifier;Python notebook;1369.0;14;0.00000;0.00000
2019-03-22 06:00:33;This kernel base on Alexander Teplyuk here I tuned min_data_in_leaf to 120, add random state and shuffle = True;Apache 2.0;https://www.kaggle.com/hsinwenchang/lgbm-parameter-tuning;1.0;['lightgbm', 'sklearn'];['cv', 'ai', 'rl', 'gbm'];['predict', 'train', 'model', 'label', 'loss'];https://www.kaggle.com/c/womens-machine-learning-competition-2019;0.611;0.188;2020-12-13 18:28:45;Google Cloud & NCAA® ML Competition 2019-Women's;['gpu'];LGBM parameter tuning;Python notebook;540.0;3;0.00000;0.00000
2019-05-15 17:00:24;Introduction: One notable difference between the men's and women's March Madness tournament is that the top 16 seeds in the women’s tournament will host 3 other teams for rounds 1 and 2. In other words, seeds 1-4 in every region will be guaranteed a home game for round 1, and if they win, round 2 will also be a home game. The goal of this Kernel is to show how important it is to account for these home games in your model. Some of the ideas for this kernal were inspired by this article and it is worth a read: https://audacityofhoops.blogspot.com/2010/04/opponent-adjusted-four-factors.html Step 1: Build a simple model with raw un-weighted 4 Factor Stats.Predict on 2018 Data and get a baseline log loss. Step 2: Weight the 4 factor stats when a team is playing a home game. Rerun the model, and compare the log loss scores.;Apache 2.0;https://www.kaggle.com/mattjburrill/home-court-advantage-weighted-4-factors;1.0;['sklearn'];['ner', 'ai', 'dl', 'gan', 'nn', 'ml'];['train', 'loss', 'model', 'predict'];https://www.kaggle.com/c/womens-machine-learning-competition-2019;0.55;0.0;2020-12-13 18:28:45;Google Cloud & NCAA® ML Competition 2019-Women's;[];Home Court Advantage- Weighted 4 Factors ;Python notebook;205.0;0;;
2019-04-09 01:44:39;Congraturations on Baylor University and thanks for hosting this exciting competition! I ended up in the bronze medal, but want to share my simple solution, based on starter kernel. My solution is not complicated: It predicts the probability of the occurrence of the upset, which means that the low seed rank team beats the high seed rank team, aggregating past game results;Apache 2.0;https://www.kaggle.com/takaishikawa/no-ml-modeling;1.0;['sklearn'];['ai'];['filter', 'train', 'model', 'loss', 'predict', 'rank'];https://www.kaggle.com/c/womens-machine-learning-competition-2019;0.565;0.152;2020-12-13 18:28:45;Google Cloud & NCAA® ML Competition 2019-Women's;[];No ML Modeling;Python notebook;256.0;2;0.36313;0.36313
2019-08-28 08:12:31;In this Notebook, I will be classifying reviews as positive or negative using 2 different concepts of Natural Language Procession -  The first one involves creating the classical bag of words model The second one involves involves creating a bag of vectors model i.e. each word is converted into a vector(Word to Vec)  The advantage of converting words to vector is that semantically similar words are placed near to each other and words opposite in meaning are placed further apart. In the project, the accuracy in predicting the sentiment of the reviews remains almost the same with both the approaches but it is found that when the amount of training data is increased, the word2vec approach performs better.  P.S. - Google Search utlises the word2vec approach.;Apache 2.0;https://www.kaggle.com/harshitmakkar/nlp-word2vec;1.0;['nltk', 'gensim', 'sklearn', 'tensorflow', 'vocabulary', 'keras'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nlp', 'nn', 'ann'];['unlabeled', 'recognition', 'predict', 'relu', 'gru', 'training data', 'train', 'epoch', 'clustering', 'recommend', 'classification', 'labeled', 'model', 'neural network', 'layer', 'loss', 'rank', 'understanding', 'generation', 'fitting', 'label', 'k-means', 'random forest', 'natural language'];https://www.kaggle.com/c/word2vec-nlp-tutorial;0.69;0.311;2020-12-13 18:30:04;Bag of Words Meets Bags of Popcorn;[];NLP - Word2Vec;Python notebook;2467.0;11;;
2019-08-01 06:13:07;This is my first nlp kernel writtern for the Bag of Words Meets Bags of Popcorn competetion. If you Like the notebook and think that it helped you,  please upvote.  Table of Content Data Preprocessing Data Cleaning and Text Preprocessing Word Vectors   Modeling RNN Model Architecture LSTM Model GRU Model   Model Evaluation   Prediction & Submission;Apache 2.0;https://www.kaggle.com/jiaofenx/imdb-review-word2vec-rnn-tutorial;1.0;['nltk', 'gensim', 'sklearn', 'tensorflow', 'vocabulary', 'keras'];['ai', 'rl', 'ml', 'nlp', 'nn', 'rnn', 'ann'];['unlabeled', 'gru', 'filter', 'test data', 'train', 'fitting', 'model', 'epoch', 'layer', 'loss', 'label', 'lstm', 'predict', 'labeled'];https://www.kaggle.com/c/word2vec-nlp-tutorial;0.628;0.253;2020-12-13 18:30:04;Bag of Words Meets Bags of Popcorn;[];IMDB Review - Word2Vec RNN Tutorial;Python notebook;733.0;6;0.78768;0.78768
2019-12-17 11:28:22;The following code follows along the very old tutorial in kaggle but updated to latest versions of libraries and python 3 https://www.kaggle.com/c/word2vec-nlp-tutorial/overview;Apache 2.0;https://www.kaggle.com/john77eipe/nlp-word2vec-bag-of-words-meets-bags-of-pop;1.0;['vocabulary', 'sklearn', 'nltk', 'gensim'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nlp', 'nn', 'ann'];['unlabeled', 'training data', 'random forest', 'train', 'fitting', 'model', 'understanding', 'neural network', 'reward', 'clustering', 'loss', 'label', 'k-means', 'labeled', 'predict', 'recommend', 'classification', 'natural language'];https://www.kaggle.com/c/word2vec-nlp-tutorial;0.582;0.214;2020-12-13 18:30:04;Bag of Words Meets Bags of Popcorn;[];NLP: Word2Vec (Bag of Words Meets Bags of Pop);Python notebook;334.0;4;;
2018-10-10 19:37:14;There is equal distribution of data;Apache 2.0;https://www.kaggle.com/parveshdhawan/bag-of-words-meets-bags-of-popcorn;1.0;['vocabulary', 'sklearn', 'nltk'];['ner', 'ai', 'dl', 'gan', 'rl', 'ml', 'nn', 'ann'];['unlabeled', 'machine learning', 'random forest', 'regression', 'train', 'model', 'loss', 'label', 'logistic regression', 'naive bayes', 'predict', 'classification', 'labeled'];https://www.kaggle.com/c/word2vec-nlp-tutorial;0.645;0.236;2020-12-13 18:30:04;Bag of Words Meets Bags of Popcorn;['beginner, classification, nlp'];Bag of Words Meets Bags of Popcorn;Python notebook;1002.0;5;0.88356;0.88356
2019-11-20 03:36:58;Predict Sentiment Analysis over Movie Reviews;Apache 2.0;https://www.kaggle.com/rajspd/sentiment-analysis-in-20-lines-score-0-854;1.0;['tensorflow', 'keras', 'nltk'];['ai', 'rl', 'nlp', 'nn', 'ml'];['unlabeled', 'gru', 'filter', 'test data', 'train', 'model', 'epoch', 'layer', 'loss', 'label', 'lstm', 'predict', 'relu', 'sentiment analysis', 'labeled'];https://www.kaggle.com/c/word2vec-nlp-tutorial;0.609;0.214;2020-12-13 18:30:04;Bag of Words Meets Bags of Popcorn;['beginner, deep learning, classification'];Sentiment Analysis - In 20 Lines - Score 0.854;Python notebook;520.0;4;;
2019-11-17 18:48:41;From Words to Paragraphs, Attempt 2: Clustering;Apache 2.0;https://www.kaggle.com/revanthrex/sentiment-analysis-with-word2vec;1.0;['vocabulary', 'sklearn', 'nltk', 'gensim'];['ner', 'ai', 'dl', 'rl', 'nlp', 'nn', 'ml'];['unlabeled', 'training data', 'train', 'fitting', 'model', 'clustering', 'label', 'k-means', 'predict', 'random forest', 'labeled'];https://www.kaggle.com/c/word2vec-nlp-tutorial;0.593;0.253;2020-12-13 18:30:04;Bag of Words Meets Bags of Popcorn;[];Sentiment Analysis with Word2Vec;Python notebook;400.0;6;;
2019-09-18 09:15:00;First we import important packages like pandas,nltk,re,os  we use pandas to handle our dataset it is used to take input of test and training data then  we import stopwords to remove usnecessary words like is,are,names etc from the dataset we use re to keep only words i will explain this in details where we use re. then we import os for setting directory some worldcloud and barplot visualization;Apache 2.0;https://www.kaggle.com/rohandx1996/google-movie-reviews-sentiment-deep-stack-models;1.0;['nltk', 'sklearn', 'tensorflow', 'pattern', 'keras'];['ner', 'ai', 'dl', 'cnn', 'rl', 'nlp', 'nn', 'ml'];['unlabeled', 'activation function', 'filter', 'training data', 'train', 'fitting', 'model', 'output layer', 'neural network', 'epoch', 'layer', 'loss', 'label', 'lstm', 'predict', 'relu', 'classification', 'labeled'];https://www.kaggle.com/c/word2vec-nlp-tutorial;0.719;0.455;2020-12-13 18:30:04;multiple data sources;['gpu, deep learning, feature engineering, +1 morenlp'];Google movie reviews sentiment Deep stack models ;Python notebook;4734.0;56;;
2019-01-15 15:43:10;Creating Features from a Bag of Words (Using scikit-learn);Apache 2.0;https://www.kaggle.com/sameerdev7/93-f-score-bag-of-words-m-bags-of-popcorn-with-rf;1.0;['sklearn', 'nltk'];['ner', 'ai', 'rl', 'nlp', 'nn', 'ml'];['training data', 'test data', 'train', 'fitting', 'model', 'label', 'predict', 'random forest', 'labeled'];https://www.kaggle.com/c/word2vec-nlp-tutorial;0.707;0.319;2020-12-13 18:30:04;multiple data sources;['gpu, beginner, classification, +1 morefeature engineering'];.93 f-score Bag of Words M Bags of Popcorn with RF;Python notebook;3610.0;12;0.97076;0.97076
2018-10-02 03:21:09;The key idea of this kernel is mainly from https://github.com/bluelight773/Kaggle_IMDB_Bags_of_Popcorn/blob/master/imdb.py. The purpose is to demo the effectiveness of sequence models in semantic anlaysis and sentiment classification.;Apache 2.0;https://www.kaggle.com/xchmiao/popcorn-rnn-model;1.0;['tensorflow', 'sklearn', 'keras', 'nltk'];['ner', 'ai', 'cnn', 'nlp', 'nn', 'rnn', 'ml'];['unlabeled', 'gru', 'filter', 'test data', 'train', 'fitting', 'model', 'epoch', 'layer', 'loss', 'label', 'lstm', 'predict', 'relu', 'classification', 'labeled'];https://www.kaggle.com/c/word2vec-nlp-tutorial;0.713;0.346;2020-12-13 18:30:04;Bag of Words Meets Bags of Popcorn;['gpu'];Popcorn RNN model;Python notebook;4125.0;16;;
2017-05-24 10:09:35;In this notebook, we'll show how to explore data in the TFRecord format on a smaller scale. To reach the scalability that TensorFlow/Google Cloud can do, please refer to the code in their github https://github.com/google/youtube-8m;Apache 2.0;https://www.kaggle.com/ayanzadeh93/starter-explore-youtube8m-sample-data-1ef63e;1.0;['tensorflow', 'sklearn'];['dl', 'ai', 'nn'];['train', 'label', 'filter'];https://www.kaggle.com/c/youtube8m;0.586;0.099;2020-12-13 18:41:49;Google Cloud & YouTube-8M Video Understanding Challenge;[];Starter: Explore Youtube8M sample data 1ef63e;Python notebook;358.0;1;;
2017-03-13 09:19:12;IntroductionThis notebook is going to detail my initial EDA attempts on this problem. For a great introduction on the problem see here (I have borrowed the starting code to base this off..): https://www.kaggle.com/wendykan/youtube8m/starter-explore-youtube8m-sample-data Things to do: Average RGB/audio for the most popular labels Try and measure the similarity of some of the labels What next? Video recognition seems to be bloody tough;Apache 2.0;https://www.kaggle.com/evanmiller/basic-eda;1.0;['tensorflow'];['ner', 'ai', 'nn'];['train', 'recognition', 'label'];https://www.kaggle.com/c/youtube8m;0.686;0.253;2020-12-13 18:41:49;Google Cloud & YouTube-8M Video Understanding Challenge;[];Basic EDA;Python notebook;2281.0;6;;
2017-05-20 11:22:50;In this notebook, we'll show how to explore data in the TFRecord format on a smaller scale. To reach the scalability that TensorFlow/Google Cloud can do, please refer to the code in their github https://github.com/google/youtube-8m;Apache 2.0;https://www.kaggle.com/hagerrady/starter-explore-youtube8m-sample-data;1.0;['tensorflow', 'sklearn'];['dl', 'ai', 'nn'];['train', 'label', 'filter'];https://www.kaggle.com/c/youtube8m;0.555;0.099;2020-12-13 18:41:49;Google Cloud & YouTube-8M Video Understanding Challenge;[];Starter: Explore Youtube8M sample data;Python notebook;221.0;1;;
2017-03-13 11:04:52;YouTube8M EDAThe YouTube8M challenge is a multi-class classification problem, where we are asked to predict for each video, given video & frame level audio and frame RGB features, to which group of categories it belongs to. For this task it is important to know:  the total number of classes/video categories the distribution of classes in the training set  In the first part I'll be focusing on how to take apart detailed information about the labels for the training data. Especially taking into account frequent patterns that occur in the data. We will also be looking at co-dependencies of the most frequent label categories. I've added a small section about the dependence of different video categories to the number of labels for each sample.;Apache 2.0;https://www.kaggle.com/philschmidt/youtube8m-eda;1.0;['pattern', 'tensorflow'];['ner', 'ai', 'gan', 'nn', 'ml'];['training data', 'train', 'model', 'label', 'predict', 'classification'];https://www.kaggle.com/c/youtube8m;0.756;0.446;2020-12-13 18:41:49;Google Cloud & YouTube-8M Video Understanding Challenge;[];YouTube8M EDA;Python notebook;12254.0;50;;
2017-06-11 15:04:10;To explore and understand the youtube 8m dataset. Credit to Wendy Kan;Apache 2.0;https://www.kaggle.com/veerabhadrappa/youtube8m-explorer;1.0;['tensorflow', 'sklearn'];['dl', 'ai', 'nn'];['train', 'label', 'filter'];https://www.kaggle.com/c/youtube8m;0.598;0.099;2020-12-13 18:41:49;Google Cloud & YouTube-8M Video Understanding Challenge;[];Youtube8M Explorer;Python notebook;432.0;1;;
2017-08-25 17:28:50;In this notebook, we'll show how to explore data in the TFRecord format on a smaller scale. To reach the scalability that TensorFlow/Google Cloud can do, please refer to the code in their github https://github.com/google/youtube-8m;Apache 2.0;https://www.kaggle.com/wendykan/starter-explore-youtube8m-sample-data;1.0;['tensorflow', 'sklearn'];['dl', 'ai', 'nn'];['train', 'label', 'filter'];https://www.kaggle.com/c/youtube8m;0.796;0.521;2020-12-13 18:41:49;Google Cloud & YouTube-8M Video Understanding Challenge;[];Starter: Explore Youtube8M sample data;Python notebook;40487.0;135;;
2017-04-21 12:15:41;youtube video classification kernel, just trying to follow the examples from tutorials;Apache 2.0;https://www.kaggle.com/xbldev/test-notebook-for-google-youtube-classification;1.0;['tensorflow', 'sklearn'];['ner', 'ai', 'nn'];['train', 'label', 'classification'];https://www.kaggle.com/c/youtube8m;0.656;0.214;2020-12-13 18:41:49;Google Cloud & YouTube-8M Video Understanding Challenge;[];Test notebook for google youtube classification;Python notebook;1233.0;4;;
2017-03-24 18:54:49;process frame_level records, convert data into numpy arrayTested in python 3.5 local. Mostly copy-and-paste of starter code clips. Scratches only. Comments and refinement welcome.;Apache 2.0;https://www.kaggle.com/xpeuler/frame2nparray;1.0;['tensorflow'];['ai', 'dl', 'rl'];['train', 'model', 'label'];https://www.kaggle.com/c/youtube8m;0.665;0.302;2020-12-13 18:41:49;Google Cloud & YouTube-8M Video Understanding Challenge;[];frame2nparray;Python notebook;1453.0;10;;
2018-06-14 10:17:34;Problem Understanding The YouTube8M challenge is a multi-class classification problem, where we are asked to predict for each video, given video & frame level audio and frame RGB features, to which group of categories it belongs to. I have divided entire task into two parts  Simple Data Exploration,  Labels/classes study of sample videos.  Created a Bi-LSTM multilabel neural model by randomly created sample data.  Lets first explore the labels for the training data, their distribution and frequent patterns and co-occurance of the most frequent label categories. Since we have been given sample dataset  here, so all my exploration will be done on sample data, we can do the same anlaysis on large corpus using GCloud ML Engine;Apache 2.0;https://www.kaggle.com/amansrivastava/exploration-bi-lstm-model;1.0;['pattern', 'vocabulary', 'tensorflow', 'keras'];['ai', 'nn', 'ml', 'rl'];['training data', 'test data', 'train', 'model', 'input layer', 'epoch', 'deep learning', 'layer', 'validation data', 'loss', 'label', 'lstm', 'predict', 'relu', 'understanding', 'classification'];https://www.kaggle.com/c/youtube8m-2018;0.739;0.444;2020-12-13 18:43:34;The 2nd YouTube-8M Video Understanding Challenge;['data visualization, deep learning, lstm'];Exploration + Bi-LSTM Model;Python notebook;7708.0;49;;
2020-04-26 17:01:36;This notebook explores the data (TFRecord format) using a subsample of the YouTube-8M video & frame-level data. To work with the entire dataset, please refer to the Starter code on the YouTube-8M github repo.;Apache 2.0;https://www.kaggle.com/duboviy/starter-kernel-yt8m-2018-sample-data;1.0;['vocabulary', 'tensorflow', 'sklearn'];['ner', 'ai', 'dl', 'rl', 'nn', 'ml'];['train', 'training data', 'label', 'filter'];https://www.kaggle.com/c/youtube8m-2018;0.468;0.253;2020-12-13 18:43:34;The 2nd YouTube-8M Video Understanding Challenge;[];Starter Kernel: YT8M 2018 Sample Data;Python notebook;66.0;6;;
2018-07-18 09:26:48;In this notebook, you will learn easy way to extract video and audio dataset from given data;Apache 2.0;https://www.kaggle.com/jameschien/newbie-easy-way-for-loading-video-frame-tfrecord;1.0;['tensorflow'];['ner', 'ai', 'dl', 'rl'];['train', 'label'];https://www.kaggle.com/c/youtube8m-2018;0.64;0.099;2020-12-13 18:43:34;The 2nd YouTube-8M Video Understanding Challenge;[];newbie-easy way for loading video&frame tfrecord;Python notebook;904.0;1;;
2018-05-22 19:05:37;This notebook explores the data (TFRecord format) using a subsample of the YouTube-8M video & frame-level data. To work with the entire dataset, please refer to the Starter code on the YouTube-8M github repo.;Apache 2.0;https://www.kaggle.com/juliaelliott/starter-kernel-yt8m-2018-sample-data;1.0;['vocabulary', 'tensorflow', 'sklearn'];['ner', 'ai', 'dl', 'nn', 'ml'];['train', 'label', 'filter'];https://www.kaggle.com/c/youtube8m-2018;0.759;0.505;2020-12-13 18:43:34;The 2nd YouTube-8M Video Understanding Challenge;[];Starter Kernel: YT8M 2018 Sample Data;Python notebook;12998.0;107;;
2018-07-19 13:35:32;"overviewResently, I'm working to learn tensorflow.data API (tf.data) to figure out data importing problem on tensorflow task, especially importing TFRecord file data. And, I find tf.data and TFRecord are very powerful. Then I will use tf.data API to import data, e.g.train00.tfrecord.  Although YouTube-8M Tensorflow Starter Code has readers.py to import data, it's really confusing. Note that; some API maybe throw-out errors, you should update your tensorflow. The  tf.parse_single_sequence_example will get error under tensorflow-1.4, so I update to tensorflow-1.9, everything is OK.";Apache 2.0;https://www.kaggle.com/machineheart/the-tools-of-import-data;1.0;['vocabulary', 'tensorflow'];['dl', 'ai', 'nn', 'rl'];['train', 'label', 'training data', 'epoch'];https://www.kaggle.com/c/youtube8m-2018;0.584;0.099;2020-12-13 18:43:34;The 2nd YouTube-8M Video Understanding Challenge;[];The tools of  import data;Python notebook;347.0;1;;
2018-05-27 19:59:38;IntroducionThis simple script shows how to train a model using Keras framework and TF records format as source. TODO:  write inference part of the script  Note:  This is a demo with limited data, you will have to dowload data and run scripts locally You will need need to export the TensorfFow MetaGraph from Keras models to be eligible for ranking.;Apache 2.0;https://www.kaggle.com/mihaskalic/training-video-level-classifier-with-keras;1.0;['tensorflow', 'keras'];['ner', 'ai', 'dl', 'rl'];['train', 'model', 'epoch', 'layer', 'label', 'loss', 'rank', 'relu'];https://www.kaggle.com/c/youtube8m-2018;0.743;0.413;2020-12-13 18:43:34;The 2nd YouTube-8M Video Understanding Challenge;[];training video level classifier with Keras;Python notebook;8642.0;34;;
2018-06-28 20:33:53;This code shows how to download the tfrecords files using url to your own computer. In the kernel because of the gaierror error,the outputs are not correct.;Apache 2.0;https://www.kaggle.com/ozlemy/download-training-videos-for-windows;1.0;['vocabulary'];['ner', 'ai', 'dl', 'rl', 'ml', 'nn', 'ann'];['train', 'label'];https://www.kaggle.com/c/youtube8m-2018;0.648;0.292;2020-12-13 18:43:34;The 2nd YouTube-8M Video Understanding Challenge;[];Download Training Videos for Windows;Python notebook;1046.0;9;;
2018-07-31 01:13:51;Lets first read the data from the video file;Apache 2.0;https://www.kaggle.com/plumeria/8m-video-understanding-challenge;1.0;['vocabulary', 'tensorflow'];['ai', 'dl', 'ml', 'rl'];['train', 'label', 'filter'];https://www.kaggle.com/c/youtube8m-2018;0.622;0.236;2020-12-13 18:43:34;The 2nd YouTube-8M Video Understanding Challenge;['gpu, beginner, data visualization'];8M Video Understanding Challenge;Python notebook;651.0;5;;
2019-08-13 12:29:55;The 3rd YouTube-8M Video Understanding ChallengeIn this competition, you will predict the Class labels of YouTube video segments. We provide you extracted frame-level features. The feature data and detailed feature information can be found on the YouTube-8M dataset webpage. The training dataset in this competition contains videos and labels that are publicly available on YouTube, while the test data is not publicly available. The test data also has anonymized video IDs to ensure the fairness of the competition. File descriptionsframe-level data  You may download to your local computer with instructions here Total size of 1.53TB (Large file warning!) Each video has a. id: unique id for the video, in train set it is a YouTube video id, and in test/validation they are anonymized. b. labels: list of labels of that video.   c. Each frame has rgb: float array of length 1024,   d. Each frame has audio: float array of length 128  A subset of the validation set videos are provided with segment-level labels. In addition to id, labels and the frame level features described above, they come with a. segment_start_times: list of segment start times.   b. segment_end_times: list of segment end times.   c. segment_labels: list of segment labels.   d. segment_scores: list of binary values indicating positive or negative corresponding to the segment labels.  Files are in TFRecords format, TensorFlow python readers are available in the github repo.   frame-sample.zip - a sample of frame-level data including train00 and train01 validate-sample.zip - a sample of validation set data including validate00 and validate01 vocabulary.csv - the full data dictionary for label names and their descriptions sample_submission.csv - a sample submission file in the correct format  For each Class, submit a space-delimited list of the segments your model predicts as having that class, ordered by confidence (highest first).  IMPORTANT: In order to minimize submission file sizes, for segment predictions, you should only include the video id and the segment start time, but not the segment end time. (These are not needed, since all segments are 5 seconds in duration.);Apache 2.0;https://www.kaggle.com/anshuljdhingra/3rd-youtube-video-understanding;1.0;['vocabulary', 'tensorflow'];['ner', 'ai', 'dl', 'rl', 'nn'];['filter', 'training data', 'regression', 'test data', 'train', 'model', 'lstm', 'label', 'predict', 'understanding'];https://www.kaggle.com/c/youtube8m-2019;0.567;0.099;2020-12-13 18:45:07;The 3rd YouTube-8M Video Understanding Challenge;[];3rd Youtube Video Understanding;Python notebook;265.0;1;;
2019-07-04 09:10:27;Access to original videos to give a simple impression on annotations...;Apache 2.0;https://www.kaggle.com/frostxu/annotation-analysis-help-to-understand;1.0;['vocabulary', 'tensorflow'];['ai', 'nn', 'ann', 'rl'];['train', 'label'];https://www.kaggle.com/c/youtube8m-2019;0.682;0.34;2020-12-13 18:45:07;The 3rd YouTube-8M Video Understanding Challenge;[];Annotation Analysis: Help to Understand;Python notebook;2095.0;15;;
2019-06-27 17:19:08;This notebook explores the data (TFRecord format) using a subsample of the YouTube-8M frame-level and validate data.  To work with the entire dataset, please refer to the Starter code on the YouTube-8M github repo;Apache 2.0;https://www.kaggle.com/inversion/starter-kernel-yt8m-2019-sample-data;1.0;['vocabulary', 'tensorflow', 'sklearn'];['ner', 'ai', 'ml'];['train', 'label', 'filter'];https://www.kaggle.com/c/youtube8m-2019;0.744;0.446;2020-12-13 18:45:07;The 3rd YouTube-8M Video Understanding Challenge;[];Starter Kernel: YT8M 2019 Sample Data;Python notebook;8834.0;50;;
2019-07-20 21:16:16;**This notebook is based on @inversion's Starter Kernel. It extracts the data from TFRecord format using a subsample of the YouTube-8M frame-level and validate data. Corrections made over prev version.;Apache 2.0;https://www.kaggle.com/isikkuntay/train-set-for-nn-under-construction;1.0;['vocabulary', 'tensorflow'];['ai', 'dl', 'nn', 'rnn', 'ann'];['train', 'label', 'validation data'];https://www.kaggle.com/c/youtube8m-2019;0.646;0.236;2020-12-13 18:45:07;The 3rd YouTube-8M Video Understanding Challenge;[];train set for NN - under construction;Python notebook;1011.0;5;;
2019-12-10 16:48:10;The 3rd YouTube-8M Video Understanding ChallengeIn this competition, you will predict the Class labels of YouTube video segments. We provide you extracted frame-level features. The feature data and detailed feature information can be found on the YouTube-8M dataset webpage. The training dataset in this competition contains videos and labels that are publicly available on YouTube, while the test data is not publicly available. The test data also has anonymized video IDs to ensure the fairness of the competition. File descriptionsframe-level data  You may download to your local computer with instructions here Total size of 1.53TB (Large file warning!) Each video has a. id: unique id for the video, in train set it is a YouTube video id, and in test/validation they are anonymized. b. labels: list of labels of that video.   c. Each frame has rgb: float array of length 1024,   d. Each frame has audio: float array of length 128  A subset of the validation set videos are provided with segment-level labels. In addition to id, labels and the frame level features described above, they come with a. segment_start_times: list of segment start times.   b. segment_end_times: list of segment end times.   c. segment_labels: list of segment labels.   d. segment_scores: list of binary values indicating positive or negative corresponding to the segment labels.  Files are in TFRecords format, TensorFlow python readers are available in the github repo.   frame-sample.zip - a sample of frame-level data including train00 and train01 validate-sample.zip - a sample of validation set data including validate00 and validate01 vocabulary.csv - the full data dictionary for label names and their descriptions sample_submission.csv - a sample submission file in the correct format  For each Class, submit a space-delimited list of the segments your model predicts as having that class, ordered by confidence (highest first).  IMPORTANT: In order to minimize submission file sizes, for segment predictions, you should only include the video id and the segment start time, but not the segment end time. (These are not needed, since all segments are 5 seconds in duration.);Apache 2.0;https://www.kaggle.com/jagannathrk/analysis-youtube8m-2019;1.0;['vocabulary', 'tensorflow'];['ner', 'ai', 'dl', 'rl', 'nn'];['filter', 'training data', 'regression', 'test data', 'train', 'model', 'lstm', 'label', 'predict', 'understanding'];https://www.kaggle.com/c/youtube8m-2019;0.552;0.099;2020-12-13 18:45:07;The 3rd YouTube-8M Video Understanding Challenge;[];Analysis YouTube8m 2019 📹;Python notebook;210.0;1;;
2019-07-10 05:42:23;The 3rd YouTube-8M Video Understanding ChallengeIn this competition, you will predict the Class labels of YouTube video segments. We provide you extracted frame-level features. The feature data and detailed feature information can be found on the YouTube-8M dataset webpage. The training dataset in this competition contains videos and labels that are publicly available on YouTube, while the test data is not publicly available. The test data also has anonymized video IDs to ensure the fairness of the competition. File descriptionsframe-level data  You may download to your local computer with instructions here Total size of 1.53TB (Large file warning!) Each video has a. id: unique id for the video, in train set it is a YouTube video id, and in test/validation they are anonymized. b. labels: list of labels of that video.   c. Each frame has rgb: float array of length 1024,   d. Each frame has audio: float array of length 128  A subset of the validation set videos are provided with segment-level labels. In addition to id, labels and the frame level features described above, they come with a. segment_start_times: list of segment start times.   b. segment_end_times: list of segment end times.   c. segment_labels: list of segment labels.   d. segment_scores: list of binary values indicating positive or negative corresponding to the segment labels.  Files are in TFRecords format, TensorFlow python readers are available in the github repo.   frame-sample.zip - a sample of frame-level data including train00 and train01 validate-sample.zip - a sample of validation set data including validate00 and validate01 vocabulary.csv - the full data dictionary for label names and their descriptions sample_submission.csv - a sample submission file in the correct format  For each Class, submit a space-delimited list of the segments your model predicts as having that class, ordered by confidence (highest first).  IMPORTANT: In order to minimize submission file sizes, for segment predictions, you should only include the video id and the segment start time, but not the segment end time. (These are not needed, since all segments are 5 seconds in duration.);Apache 2.0;https://www.kaggle.com/jesucristo/analysis-youtube8m-2019;1.0;['vocabulary', 'tensorflow'];['ner', 'ai', 'dl', 'rl', 'nn'];['filter', 'training data', 'regression', 'test data', 'train', 'model', 'lstm', 'label', 'predict', 'understanding'];https://www.kaggle.com/c/youtube8m-2019;0.769;0.501;2020-12-13 18:45:07;The 3rd YouTube-8M Video Understanding Challenge;['data visualization'];Analysis YouTube8m 2019 📹;Python notebook;17232.0;102;;
2019-09-06 04:58:16;The 3rd YouTube-8M Video Understanding ChallengeIn this competition, you will predict the Class labels of YouTube video segments. We provide you extracted frame-level features. The feature data and detailed feature information can be found on the YouTube-8M dataset webpage. The training dataset in this competition contains videos and labels that are publicly available on YouTube, while the test data is not publicly available. The test data also has anonymized video IDs to ensure the fairness of the competition. File descriptionsframe-level data  You may download to your local computer with instructions here Total size of 1.53TB (Large file warning!) Each video has a. id: unique id for the video, in train set it is a YouTube video id, and in test/validation they are anonymized. b. labels: list of labels of that video.   c. Each frame has rgb: float array of length 1024,   d. Each frame has audio: float array of length 128  A subset of the validation set videos are provided with segment-level labels. In addition to id, labels and the frame level features described above, they come with a. segment_start_times: list of segment start times.   b. segment_end_times: list of segment end times.   c. segment_labels: list of segment labels.   d. segment_scores: list of binary values indicating positive or negative corresponding to the segment labels.  Files are in TFRecords format, TensorFlow python readers are available in the github repo.   frame-sample.zip - a sample of frame-level data including train00 and train01 validate-sample.zip - a sample of validation set data including validate00 and validate01 vocabulary.csv - the full data dictionary for label names and their descriptions sample_submission.csv - a sample submission file in the correct format  For each Class, submit a space-delimited list of the segments your model predicts as having that class, ordered by confidence (highest first).  IMPORTANT: In order to minimize submission file sizes, for segment predictions, you should only include the video id and the segment start time, but not the segment end time. (These are not needed, since all segments are 5 seconds in duration.);Apache 2.0;https://www.kaggle.com/pavanchalla/analysis-youtube8m-2019;1.0;['vocabulary', 'tensorflow'];['ner', 'ai', 'dl', 'rl', 'nn'];['filter', 'training data', 'regression', 'test data', 'train', 'model', 'label', 'predict', 'understanding'];https://www.kaggle.com/c/youtube8m-2019;0.56;0.099;2020-12-13 18:45:07;The 3rd YouTube-8M Video Understanding Challenge;[];Analysis YouTube8m 2019 📹;Python notebook;239.0;1;;
2019-08-07 03:10:28;This kernel takes a trip through the the life-journey of a batch of chocolate muffins.  Starting from the time that they were not even recognizable as eggs in a mixing bowl, to being spooned into a baking pan, the oven, and finally the big Peak Muffinmoment when they are presented in unmistakable muffin wrappers.  By the end, they they look extremely muffin-like. This kernel borrows from https://www.kaggle.com/jesucristo/analysis-youtube8m-2019, which itself seems to borrow from https://www.kaggle.com/inversion/starter-kernel-yt8m-2019-sample-data;Apache 2.0;https://www.kaggle.com/senorcampos/the-peak-muffin-moment;1.0;['vocabulary', 'tensorflow'];['ner', 'ai', 'rl', 'nn', 'ml'];['filter', 'train', 'neural network', 'validation data', 'label'];https://www.kaggle.com/c/youtube8m-2019;0.677;0.371;2020-12-13 18:45:07;The 3rd YouTube-8M Video Understanding Challenge;[];The Peak Muffin Moment 📹;Python notebook;1874.0;21;;
2018-01-23 11:06:57;The following notebook introduces ML-Ensemble, a Python library for memory-efficient parallel ensemble learning with a Scikit-learn API. ML-Ensemble also deploys a neural network-like API for building ensembles of several layers, and can accomodate a great variety of ensemble architectures. For more information, see ml-ensemble.com or visit the github repository.;Apache 2.0;https://www.kaggle.com/flennerhag/ml-ensemble-scikit-learn-style-ensemble-learning;1.0;['xgboost', 'sklearn'];['ner', 'ai', 'gbm', 'cv', 'rl', 'nn', 'ml'];['training data', 'train', 'fitting', 'model', 'neural network', 'layer', 'label', 'predict'];https://www.kaggle.com/c/zillow-prize-1;0.775;0.472;2020-12-13 18:50:10;Zillow Prize: Zillow’s Home Value Prediction (Zestimate);['ensembling'];ML-Ensemble: Scikit-learn style ensemble learning ;Python notebook;21046.0;70;;
2017-11-11 05:10:27;Zillow House EDA：The Fast &  Curious JourneyMajin Buu - UPDATED Year Build Error, 9 Sept 2017 UPDATE: Multiplicative Model  1 First Step 1.1 Load libraries and helper functions 1.2 Load data 1.3 Check the Memory Usage 1.4 DataType Converting 1.5 DateTime Parsing   2 Univariable Analysis 2.1 Basic Statistic using Pandas and Numpy 2.2 The Distribution of our target variables (logerror)     3 Multivariate Analysis 3.1 Target Variable Distribution Join Fips by Bokeh 3.2 Geographic Location by Folium and Cluster by KMeans 3.3 Where are the Perfect Estimation area ?   4 Time Series Approach 4.1 Aggragation & Visualization Time Series Components Combining Time Series Components   4.2 Moving Average Smoothing / Random Walk and Stationarity 4.3 Prophet Forecasting     Reference  In this Notebook, you will discover time series forecasting. After reading this Notebook, you will know:  Basic Time Series analysis, and time series forecasting.  The Time Series components to consider in time series data. Examples of Time Series to make your understanding concrete. Time Series Libararies  Let’s get started. NOTE - Please UPVOTING if you like, all your support is my motivation to update the notebook.;Apache 2.0;https://www.kaggle.com/kueipo/simple-eda-geo-data-time-series;1.0;['statsmodels', 'sklearn', 'pattern'];['ner', 'ai', 'rl', 'nn', 'ann'];['filter', 'train', 'model', 'label', 'predict', 'understanding'];https://www.kaggle.com/c/zillow-prize-1;0.759;0.486;2020-12-13 18:50:10;Zillow Prize: Zillow’s Home Value Prediction (Zestimate);['exploratory data analysis, clustering'];Simple EDA Geo Data & Time Series;Python notebook;13154.0;84;;
2017-09-15 15:38:18;Dealing with Missing Values One of the first steps in building a good predictive model is to carefully handle missing values at the start.  There's quite a lot of missing data in this dataset, so in this kernel I've illustrated various ways that we can impute missing values by carefully using the data we already have and I've outlined some key assumptions and rationale made in filling these missing values. I think some of these approaches are better than filling in missing values with the medians for the fields (for example) or letting models deal with them in their default manner (xgboost for instance will have all the missing values as another category) After investigating the data in some detail there also appears to be some fields which represent similar if not the same information which I think we can probably be remove as they are redundant. There are also potentially some inconsistent fields and potentially incorrect data that I discovered on the way and outlined this in this notebook The approaches use to deal with missing values also have to be made to the test data consistently - but I've not illustrated here in the interest of the kernel speed. Ideally after each step taken to deal with missing values you would probably want to carry out some cross-validation to see if it has helped improve your model - I haven't done this here but it would be interested to know if any of the adjustments do help improve the score so please comment if they do! As always if you found the kernel useful please upvote :);Apache 2.0;https://www.kaggle.com/nikunjm88/carefully-dealing-with-missing-values;1.0;['xgboost', 'sklearn'];['ner', 'ai', 'dl', 'rl', 'nn', 'ann'];['test data', 'regression', 'train', 'fitting', 'model', 'label', 'predict'];https://www.kaggle.com/c/zillow-prize-1;0.771;0.45;2020-12-13 18:50:10;Zillow Prize: Zillow’s Home Value Prediction (Zestimate);[];Carefully dealing with missing values;Python notebook;18413.0;53;;
2017-09-27 11:02:12;This notebook creates some additional features based off the raw variables and then uses XGBoost to determine their value;Apache 2.0;https://www.kaggle.com/nikunjm88/creating-additional-features;1.0;['xgboost', 'sklearn'];['ai', 'nn'];['train', 'model', 'label'];https://www.kaggle.com/c/zillow-prize-1;0.753;0.507;2020-12-13 18:50:10;Zillow Prize: Zillow’s Home Value Prediction (Zestimate);['xgboost, intermediate'];Creating Additional Features;Python notebook;11132.0;110;;
2017-06-03 15:40:10;In this notebook, let us try and explore the data given for Zillow prize competition. Before we dive deep into the data, let us know a little more about the competition. Zillow: Zillow is an online real estate database company founded in 2006 - Wikipedia Zestimate: “Zestimates” are estimated home values based on 7.5 million statistical and machine learning models that analyze hundreds of data points on each property. And, by continually improving the median margin of error (from 14% at the onset to 5% today), Objective: Building a model to improve the Zestimate residual error. The competition is in two stages. This public competition will go on till Jan 2018 and has $50,000 in prize. Please make sure to read about the Prize details and Competition overview since it is quite different in this one. Let us first import the necessary modules.;Apache 2.0;https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-zillow-prize;1.0;['pattern', 'xgboost', 'sklearn'];['ai'];['machine learning', 'train', 'model', 'label', 'predict', 'understanding'];https://www.kaggle.com/c/zillow-prize-1;0.818;0.649;2020-12-13 18:50:10;Zillow Prize: Zillow’s Home Value Prediction (Zestimate);['data visualization, exploratory data analysis'];Simple Exploration Notebook - Zillow Prize;Python notebook;85814.0;1068;;
2017-06-19 14:02:42;The notebook covers Following Topics - Missing Value Analysis - Correlation Analysis - Top Contributing Features (Through XGBoost) - Correlation Analysis  - Multicollinearity Analysis - Univariate Analysis  - Bivariate Analysis;Apache 2.0;https://www.kaggle.com/viveksrinivasan/zillow-eda-on-missing-values-multicollinearity;1.0;['statsmodels', 'xgboost', 'sklearn'];['ai', 'dl'];['train', 'model', 'label', 'filter'];https://www.kaggle.com/c/zillow-prize-1;0.774;0.524;2020-12-13 18:50:10;Zillow Prize: Zillow’s Home Value Prediction (Zestimate);['exploratory data analysis, xgboost'];Zillow EDA On Missing Values & Multicollinearity;Python notebook;20298.0;140;;
