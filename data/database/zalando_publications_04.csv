title;category;subcategory;authors;publicate_at;year;link;date;ml_score;text;tags
Contextual BERT: Conditioning the Language Model Using a Global State;Education & Research;Machine Learning;Denk, Peleteiro;Accepted to Coling – TextGraphs-14 workshop (2020);2020;https://arxiv.org/abs/2010.15778;29.10.20;1;BERT is a popular language model whose main pre-training task is to fill in the blank, i.e., predicting a word that was masked out of a sentence, based on the remaining words. In some applications, however, having an additional context can help the model make the right prediction, e.g., by taking the domain or the time of writing into account. This motivates us to advance the BERT architecture by adding a global state for conditioning on a fixed-sized context. We present our two novel approaches and apply them to an industry use-case, where we complete fashion outfits with missing articles, conditioned on a specific customer. An experimental comparison to other methods from the literature shows that our methods improve personalization significantly.;NLP
Towards User-in-the-Loop Online Fashion Size Recommendation with Low Cognitive Load;Wholesale & Retail;Machine Learning;Lefakis, Koriagin, Lasserre, Shirvany;FashionxRecsys (2020);2020;https://research.zalando.com/welcome/mission/publications/;;0.5;;Recommender
Personalized Size Recommendations with Human in the Loop;Wholesale & Retail;Machine Learning;Lefakis, Koriagin, Lasserre, Shirvany;2nd ICML Workshop on Human in the Loop Learning (2020);2020;https://research.zalando.com/welcome/mission/publications/;;0.5;;Recommender
Task-Aware Representation of Sentences for Generic Text Classification;Education & Research;Machine Learning;Halder, Akbik, Krapac, Vollgraf;Accepted to Cooling (2020);2020;https://research.zalando.com/welcome/mission/publications/;;0.5;;Classifier
Outfit Generation and Recommendation – An Experimental Study;Wholesale & Retail;Machine Learning;Celikik, Kirmse, Denk, Gagliardi, Mbarek, Pham, Peleteiro;Accepted to FashionxRecsys (2020);2020;https://research.zalando.com/welcome/mission/publications/;;0.5;;Recommender
Learning Size and Fit from Fashion Images;Wholesale & Retail;Machine Learning;Karessli, Guigourès, Shirvany;Springer’s Special Issue on Fashion Recommender Systems (2020);2020;https://research.zalando.com/welcome/mission/publications/;;1;;CV, Classification
Meta-learning for Size and Fit Recommendation in Fashion;Education & Research;Machine Learning;Lasserre, Sheikh, Koriagin, Bergmann, Vollgraf, Shirvany;Society for Industrial and Applied Mathematics (SIAM). In Proceedings of the 2020 SIAM International Conference on Data Mining (SDM), Cincinnati, Ohio (2020);2020;https://epubs.siam.org/doi/pdf/10.1137/1.9781611976236.7;;1;Fashion e-commerce has enjoyed an exponential growth inthe last few years. A key challenge of the market players is tooffer customers a personalized experience and to suggest rel-evant articles.  In that respect, although product recommen-dation is a well-studied field, size and fit recommendation isstill in its infancy.  The size and fit topic is a very challeng-ing problem as data is extremely sparse and noisy.  Most ap-proaches so far have exploited traditional machine learningtechniques.  In this work, we bring forward a meta-learningapproach  using  an  underlying  deep  neural  network.   Theadvantage of such an approach lies in its ability to exploitlarge scale data, learn across fashion categories, and absorbnew data efficiently without re-training.  We benchmark ourmethod  against  3  recent  methods  proven  successful  in  thedomain, and demonstrate various strengths of the proposedapproach.   To  that  end,  we  use  a  large-scale  anonymizeddataset of about 9.4 million customer-size interactions, col-lected over 5 years from around 384k custome;DL, Recommender
SizeNet: Weakly Supervised Learning of Visual Size and Fit in Fashion Images;Education & Research;Machine Learning;Karessli, Guigourès, Shirvany;CVPR 2019, Workshop on Focus on Fashion and Subjective Search - Understanding Subjective Attributes of Data (FFSS-USAD) (12/2019);2019;https://arxiv.org/abs/1905.11784;28.05.19;1;Finding clothes that fit is a hot topic in the e-commerce fashion industry. Most approaches addressing this problem are based on statistical methods relying on historical data of articles purchased and returned to the store. Such approaches suffer from the cold start problem for the thousands of articles appearing on the shopping platforms every day, for which no prior purchase history is available. We propose to employ visual data to infer size and fit characteristics of fashion articles. We introduce SizeNet, a weakly-supervised teacher-student training framework that leverages the power of statistical models combined with the rich visual information from article images to learn visual cues for size and fit characteristics, capable of tackling the challenging cold start problem. Detailed experiments are performed on thousands of textile garments, including dresses, trousers, knitwear, tops, etc. from hundreds of different brands.;Supervised Learning, CV, Pattern Recognition
Transform the Set: Memory Attentive Generation of Guided and Unguided Image Collages;Education & Research;Machine Learning;Jetchev, Bergmann, Yildirim;NeurIPS 2019 Workshop on Machine Learning for Creativity and Design (12/2019);2019;https://arxiv.org/abs/1910.07236;16.10.19;1;"Cutting and pasting image segments feels intuitive: the choice of source templates gives artists flexibility in recombining existing source material. Formally, this process takes an image set as input and outputs a collage of the set elements. Such selection from sets of source templates does not fit easily in classical convolutional neural models requiring inputs of fixed size. Inspired by advances in attention and set-input machine learning, we present a novel architecture that can generate in one forward pass image collages of source templates using set-structured representations. This paper has the following contributions: (i) a novel framework for image generation called Memory Attentive Generation of Image Collages (MAGIC) which gives artists new ways to create digital collages; (ii) from the machine-learning perspective, we show a novel Generative Adversarial Networks (GAN) architecture that uses Set-Transformer layers and set-pooling to blend sets of random image samples - a hybrid non-parametric approach.";GAN, CV, Pattern Recognition
Generating High-Resolution Fashion Model Images Wearing Custom Outfits;Wholesale & Retail;Machine Learning;Yildirim, Jetchev, Vollgraf, Bergmann;ICCV 2019, Workshop on Computer Vision for Fashion, Art and Design;2019;https://arxiv.org/abs/1908.08847;23.08.19;1;Visualizing an outfit is an essential part of shopping for clothes. Due to the combinatorial aspect of combining fashion articles, the available images are limited to a pre-determined set of outfits. In this paper, we broaden these visualizations by generating high-resolution images of fashion models wearing a custom outfit under an input body pose. We show that our approach can not only transfer the style and the pose of one generated outfit to another, but also create realistic images of human bodies and garments.;GAN, CV, Pattern Recognition
Eigendecompositions of Transfer Operators in Reproducing Kernel Hilbert Spaces;Education & Research;Machine Learning;Klus (ext.), Schuster, Muandet (ext.);Journal of Nonlinear Science (2019);2019;https://link.springer.com/article/10.1007/s00332-019-09574-z;21.08.19;0;Transfer operators such as the Perron–Frobenius or Koopman operator play an important role in the global analysis of complex dynamical systems. The eigenfunctions of these operators can be used to detect metastable sets, to project the dynamics onto the dominant slow processes, or to separate superimposed signals. We propose kernel transfer operators, which extend transfer operator theory to reproducing kernel Hilbert spaces and show that these operators are related to Hilbert space representations of conditional distributions, known as conditional mean embeddings. The proposed numerical methods to compute empirical estimates of these kernel transfer operators subsume existing data-driven methods for the approximation of transfer operators such as extended dynamic mode decomposition and its variants. One main benefit of the presented kernel-based approaches is that they can be applied to any domain where a similarity measure given by a kernel is available. Furthermore, we provide elementary results on eigendecompositions of finite-rank RKHS operators. We illustrate the results with the aid of guiding examples and highlight potential applications in molecular dynamics as well as video and text data analysis.;
A Deep Learning System for Predicting Size and Fit in Fashion E-Commerce;Wholesale & Retail;Machine Learning;Sheikh, Guigourès, Koriagin, Ho, Shirvany, Vollgraf, Bergmann;Thirteenth ACM Conference on Recommender Systems / RecSys '19 (07/2019);2019;https://arxiv.org/abs/1907.09844;23.07.19;1;Personalized size and fit recommendations bear crucial significance for any fashion e-commerce platform. Predicting the correct fit drives customer satisfaction and benefits the business by reducing costs incurred due to size-related returns. Traditional collaborative filtering algorithms seek to model customer preferences based on their previous orders. A typical challenge for such methods stems from extreme sparsity of customer-article orders. To alleviate this problem, we propose a deep learning based content-collaborative methodology for personalized size and fit recommendation. Our proposed method can ingest arbitrary customer and article data and can model multiple individuals or intents behind a single account. The method optimizes a global set of parameters to learn population-level abstractions of size and fit relevant information from observed customer-article interactions. It further employs customer and article specific embedding variables to learn their properties. Together with learned entity embeddings, the method maps additional customer and article attributes into a latent space to derive personalized recommendations. Application of our method to two publicly available datasets demonstrate an improvement over the state-of-the-art published results. On two proprietary datasets, one containing fit feedback from fashion experts and the other involving customer purchases, we further outperform comparable methodologies, including a recent Bayesian approach for size recommendation.;DL, Recommender
Learning Set-equivariant Functions with SWARM Mappings;Education & Research;Machine Learning;Vollgraf;Arxiv (06/2019);2019;https://arxiv.org/abs/1906.09400;22.06.19;1;In this work we propose a new neural network architecture that efficiently implements and learns general purpose set-equivariant functions. Such a function f maps a set of entities x = {x1, . . . , xn} from one domain to a set of same cardinality y = f (x) = {y1, . . . , yn} in another domain regardless of the ordering of the entities. The architecture is based on a gated recurrent network which is iteratively applied to all entities individually and at the same time syncs with the progression of the whole population. In reminiscence to this pattern, which can be frequently observed in nature, we call our approach SWARM mapping. Set-equivariant and generally permutation invariant functions are important building blocks for many state of the art machine learning approaches. Even in applications where the permutation invariance is not of primary interest, as to be seen in the recent success of attention based transformer models (Vaswani et. al. 2017). Accordingly, we demonstrate the power and usefulness of SWARM mappings in different applications. We compare the performance of our approach with another recently proposed set-equivariant function, the Set Transformer (Lee this http URL. 2018) and we demonstrate that models solely based on SWARM layers gives state of the art results.;RNN
A Bandit Framework for Optimal Selection of Reinforcement Learning Agents;Education & Research;Machine Learning;Merentitis, Rasul, Vollgraf, Sheikh, Bergmann;NeurIPS 2018 Workshop on Deep Reinforcement Learning (12/2018);2018;https://arxiv.org/abs/1902.03657;10.02.19;1;Deep Reinforcement Learning has been shown to be very successful in complex games, e.g. Atari or Go. These games have clearly defined rules, and hence allow simulation. In many practical applications, however, interactions with the environment are costly and a good simulator of the environment is not available. Further, as environments differ by application, the optimal inductive bias (architecture, hyperparameters, etc.) of a reinforcement agent depends on the application. In this work, we propose a multi-arm bandit framework that selects from a set of different reinforcement learning agents to choose the one with the best inductive bias. To alleviate the problem of sparse rewards, the reinforcement learning agents are augmented with surrogate rewards. This helps the bandit framework to select the best agents early, since these rewards are smoother and less sparse than the environment reward. The bandit has the double objective of maximizing the reward while the agents are learning and selecting the best agent after a finite number of learning steps. Our experimental results on standard environments show that the proposed framework is able to consistently select the optimal agent after a finite number of steps, while collecting more cumulative reward compared to selecting a sub-optimal architecture or uniformly alternating between different agents.;DL, RL
Copy the Old or Paint Anew? An Adversarial Framework for (non-) Parametric Image Stylization;Education & Research;Machine Learning;Jetchev, Bergmann, Yildirim;NeurIPS 2018 Workshop on Machine Learning for Creativity and Design (12/2018);2018;https://arxiv.org/abs/1811.09236;22.11.18;1;"Parametric generative deep models are state-of-the-art for photo and non-photo realistic image stylization. However, learning complicated image representations requires compute-intense models parametrized by a huge number of weights, which in turn requires large datasets to make learning successful. Non-parametric exemplar-based generation is a technique that works well to reproduce style from small datasets, but is also compute-intensive. These aspects are a drawback for the practice of digital AI artists: typically one wants to use a small set of stylization images, and needs a fast flexible model in order to experiment with it. With this motivation, our work has these contributions: (i) a novel stylization method called Fully Adversarial Mosaics (FAMOS) that combines the strengths of both parametric and non-parametric approaches; (ii) multiple ablations and image examples that analyze the method and show its capabilities; (iii) source code that will empower artists and machine learning researchers to use and modify FAMOS.";GAN, CV, Pattern Recognition
A Hierarchical Bayesian Model for Size Recommendation in Fashion;Wholesale & Retail;Machine Learning;Guigourès, Ho, Koryagin, Sheikh, Bergmann, Shirvany;RecSys 2018 (10/2018);2018;https://rguigoures.github.io/pdf/hierarchical-bayesian-model_final.pdf;07.10.18;1;We introduce a hierarchical Bayesian approach to tackle the chal-lenging problem of size recommendation in e-commerce fashion.Our approach jointly models a size purchased by a customer, andits possible return event: 1. no return, 2. returned too small 3. re-turned too big. Those events are drawn following a multinomialdistribution parameterized on the joint probability of each event,built following a hierarchy combining priors. Such a model allowsus to incorporate extended domain expertise and article charac-teristics as prior knowledge, which in turn makes it possible forthe underlying parameters to emerge thanks to sufficient data. Ex-periments are presented on real (anonymized) data from millionsof customers along with a detailed discussion on the efficiency ofsuch an approach within a large scale production system.;Bayesian
Disentangling Multiple Conditional Inputs in GANs;Education & Research;Machine Learning;Yildirim, Seward, Bergmann;KDD 2018 Fashion Workshop (08/2018);2018;https://arxiv.org/abs/1806.07819;20.06.18;1;In this paper, we propose a method that disentangles the effects of multiple input conditions in Generative Adversarial Networks (GANs). In particular, we demonstrate our method in controlling color, texture, and shape of a generated garment image for computer-aided fashion design. To disentangle the effect of input attributes, we customize conditional GANs with consistency loss functions. In our experiments, we tune one input at a time and show that we can guide our network to generate novel and realistic images of clothing articles. In addition, we present a fashion design process that estimates the input attributes of an existing garment and modifies them using our generator.;GAN, CV, Pattern Recognition
First Order Generative Adversarial Networks;Education & Research;Machine Learning;Seward, Unterthiner, Bergmann, Jetchev, Hochreiter;ICML 2018 (06/2018);2018;https://arxiv.org/abs/1802.04591;13.02.18;1;GANs excel at learning high dimensional distributions, but they can update generator parameters in directions that do not correspond to the steepest descent direction of the objective. Prominent examples of problematic update directions include those used in both Goodfellow's original GAN and the WGAN-GP. To formally describe an optimal update direction, we introduce a theoretical framework which allows the derivation of requirements on both the divergence and corresponding method for determining an update direction, with these requirements guaranteeing unbiased mini-batch updates in the direction of steepest descent. We propose a novel divergence which approximates the Wasserstein distance while regularizing the critic's first order information. Together with an accompanying update direction, this divergence fulfills the requirements for unbiased steepest descent updates. We verify our method, the First Order GAN, with image generation on CelebA, LSUN and CIFAR-10 and set a new state of the art on the One Billion Word language generation task. Code to reproduce experiments is available.;GAN
Syntax-Aware Language Modeling with Recurrent Neural Networks;Education & Research;Machine Learning;Blythe, Akbik, Vollgraf;arxiv (03/2018);2018;https://arxiv.org/abs/1803.03665;02.03.18;1;"Neural language models (LMs) are typically trained using only lexical features, such as surface forms of words. In this paper, we argue this deprives the LM of crucial syntactic signals that can be detected at high confidence using existing parsers. We present a simple but highly effective approach for training neural LMs using both lexical and syntactic information, and a novel approach for applying such LMs to unparsed text using sequential Monte Carlo sampling. In experiments on a range of corpora and corpus sizes, we show our approach consistently outperforms standard lexical LMs in character-level language modeling; on the other hand, for word-level models the models are on a par with standard language models. These results indicate potential for expanding LMs beyond lexical surface features to higher-level NLP features for character-level models.";NLP, Language Model
Street2Fashion2Shop: Enabling Visual Search in Fashion e-Commerce Using Studio Images;Wholesale & Retail;Machine Learning;Lasserre, Bracher, Vollgraf;ICPRAM 2018: Pattern Recognition Applications and Methods;2018;https://link.springer.com/chapter/10.1007/978-3-030-05499-1_1;05.01.19;1;Visual search, in particular the street-to-shop task of matching fashion items displayed in everyday images with similar articles, is a challenging and commercially important task in computer vision. Building on our successful Studio2Shop model [20], we report results on Street2Fashion2Shop, a pipeline architecture that stacks Studio2Fashion, a segmentation model responsible for eliminating the background in a street image, with Fashion2Shop, an improved model matching the remaining foreground image with “title images”, front views of fashion articles on a white background. Both segmentation and product matching rely on deep convolutional neural networks. The pipeline allows us to circumvent the lack of quality annotated wild data by leveraging specific data sets at all steps. We show that the use of fashion-specific training data leads to superior performance of the segmentation model. Studio2Shop built its performance on FashionDNA, an in-house product representation trained on the rich, professionally curated Zalando catalogue. Our study presents a substantially improved version of FashionDNA that boosts the accuracy of the matching model. Results on external datasets confirm the viability of our approach.;Visual search, Computer vision, Deep learning, Product matching, Fashion 
Studio2Shop: from photo shoots to fashion articles;Wholesale & Retail;Machine Learning;Lasserre, Rasch, Vollgraf;ICPRAM, Classification and Object Recognition (01/2018);2018;http://www.scitepress.org/PublicationsDetail.aspx?ID=hT0FJ9RWeJs=&t=1;;1;Fashion is an increasingly important topic in computer vision, in particular the so-called street-to-shop task of matching street images with shop images containing similar fashion items. Solving this problem promises new means of making fashion searchable and helping shoppers find the articles they are looking for. This paper focuses on finding pieces of clothing worn by a person in full-body or half-body images with neutral backgrounds. Such images are ubiquitous on the web and in fashion blogs, and are typically studio photos, we refer to this setting as studio-to-shop. Recent advances in computational fashion include the development of domain-specific numerical representations. Our model Studio2Shop builds on top of such representations and uses a deep convolutional network trained to match a query image to the numerical feature vectors of all the articles annotated in this image. Top-k retrieval evaluation on test query images shows that the correct items are most often found within a range that is sufficiently small for building realistic visual search engines for the studio-to-shop setting.;Computer Vision, Deep Learning, Fashion, Item Recognition, Street-to-shop, Pattern Recognition
Neural Simpletrons – Learning in the Limit of Few Labels with Directed Generative Networks;Education & Research;Machine Learning;Forster (ext.), Sheikh, Lücke (ext.);NIPS, Learning with Limited Data (LLD) Workshop (12/2017);2017;https://lld-workshop.github.io/papers/LLD_2017_paper_6.pdf;;1;;GAN
Stochastic Maximum Likelihood Optimization via Hypernetworks;Education & Research;Machine Learning;Sheikh, Rasul, Merentitis, Bergmann;NIPS, Bayesian Deep Learning Workshop (12/2017);2017;https://arxiv.org/abs/1712.01141;04.12.17;1;This work explores maximum likelihood optimization of neural networks through hypernetworks. A hypernetwork initializes the weights of another network, which in turn can be employed for typical functional tasks such as regression and classification. We optimize hypernetworks to directly maximize the conditional likelihood of target variables given input. Using this approach we obtain competitive empirical results on regression and classification benchmarks.;Bayesian, DL
GANosaic: Mosaic Creation with Generative Texture Manifolds;Education & Research;Machine Learning;Jetchev, Bergmann, Seward;NIPS, Machine Learning for Creativity and Design Workshop (12/2017);2017;https://arxiv.org/abs/1712.00269;01.12.17;1;This paper presents a novel framework for generating texture mosaics with convolutional neural networks. Our method is called GANosaic and performs optimization in the latent noise space of a generative texture model, which allows the transformation of a content image into a mosaic exhibiting the visual properties of the underlying texture manifold. To represent that manifold, we use a state-of-the-art generative adversarial method for texture synthesis, which can learn expressive texture representations from data and produce mosaic images with very high resolution. This fully convolutional model generates smooth (without any visible borders) mosaic images which morph and blend different textures locally. In addition, we develop a new type of differentiable statistical regularization appropriate for optimization over the prior noise space of the PSGAN model.;GAN, CV, Pattern Recognition
The Conditional Analogy GAN: Swapping Fashion Articles on People Images;Wholesale & Retail;Machine Learning;Jetchev, Bergmann;ICCV: Computer Vision for Fashion Workshop (10/2017);2017;https://arxiv.org/abs/1709.04695;14.09.17;1;We present a novel method to solve image analogy problems : it allows to learn the relation between paired images present in training data, and then generalize and generate images that correspond to the relation, but were never seen in the training set. Therefore, we call the method Conditional Analogy Generative Adversarial Network (CAGAN), as it is based on adversarial training and employs deep convolutional neural networks. An especially interesting application of that technique is automatic swapping of clothing on fashion model photos. Our work has the following contributions. First, the definition of the end-to-end trainable CAGAN architecture, which implicitly learns segmentation masks without expensive supervised labeling data. Second, experimental results show plausible segmentation masks and often convincing swapped images, given the target article. Finally, we discuss the next steps for that technique: neural network architecture improvements and more advanced applications.;GAN, CV, Pattern Recognition
CROWD-IN-THE-LOOP: A Hybrid Approach for Annotating Semantic Roles;Education & Research;Machine Learning;Wang (ext.), Akbik, Li (ext.), Xia (ext.), Xu (ext.);EMNLP (09/2017);2017;http://www.aclweb.org/anthology/D17-1205;;1;Crowdsourcing has proven to be an effective method for generating labeled data for a range of NLP tasks. However, multiple recent attempts of using crowdsourcing to generate gold-labeled training data for semantic role labeling (SRL) reported only modest results, indicating that SRL is perhaps too difficult a task to be effectively crowdsourced. In this paper, we postulate that while producing SRL annotation does require expert involvement in general, a large subset of SRL labeling tasks is in fact appropriate for the crowd. We present a novel workflow in which we employ a classifier to identify difficult annotation tasks and route each task either to experts or crowd workers according to their difficulties. Our experimental evaluation shows that the proposed approach reduces the workload for experts by over two-thirds, and thus significantly reduces the cost of producing SRL annotation at little loss in quality.;NLP, SVM, Classifier
Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms;Education & Research;Machine Learning;Xiao, Rasul, Vollgraf;arXiv (08/2017);2017;https://arxiv.org/abs/1708.07747;25.08.17;1;We present Fashion-MNIST, a new dataset comprising of 28x28 grayscale images of 70,000 fashion products from 10 categories, with 7,000 images per category. The training set has 60,000 images and the test set has 10,000 images. Fashion-MNIST is intended to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms, as it shares the same image size, data format and the structure of training and testing splits. The dataset is freely available at this URL: https://github.com/zalandoresearch/fashion-mnist;CV, Pattern Recognition
An LSTM-Based Dynamic Customer Model for Fashion Recommendation;Wholesale & Retail;Machine Learning;Heinz, Bracher, Vollgraf;RecTemp: Workshop (08/2017);2017;https://research.zalando.com/welcome/mission/publications/;;1;;LSTM, Recommender
Learning Texture Manifolds with the Periodic Spatial GAN;Education & Research;Machine Learning;Bergmann, Jetchev, Vollgraf;ICML (08/2017);2017;http://proceedings.mlr.press/v70/bergmann17a.html;;1;This paper introduces a novel approach to texture synthesis based on generative adversarial networks (GAN) (Goodfellow et al., 2014), and call this technique Periodic Spatial GAN (PSGAN). The PSGAN has several novel abilities which surpass the current state of the art in texture synthesis. First, we can learn multiple textures, periodic or non-periodic, from datasets of one or more complex large images. Second, we show that the image generation with PSGANs has properties of a texture manifold: we can smoothly interpolate between samples in the structured noise space and generate novel samples, which lie perceptually between the textures of the original dataset. We make multiple experiments which show that PSGANs can flexibly handle diverse texture and image data sources, and the method is highly scalable and can generate output images of arbitrary large size.;GAN
Texture synthesis with spatial generative adversarial networks;Education & Research;Machine Learning;Jetchev, Bergmann, Vollgraf;NIPS, Adversarial Learning Workshop (12/2016);2016;https://arxiv.org/abs/1611.08207;24.11.16;1;Generative adversarial networks (GANs) are a recent approach to train generative models of data, which have been shown to work particularly well on image data. In the current paper we introduce a new model for texture synthesis based on GAN learning. By extending the input noise distribution space from a single vector to a whole spatial tensor, we create an architecture with properties well suited to the task of texture synthesis, which we call spatial GAN (SGAN). To our knowledge, this is the first successful completely data-driven texture synthesis method based on GANs. Our method has the following features which make it a state of the art algorithm for texture synthesis: high image quality of the generated textures, very high scalability w.r.t. the output texture size, fast real-time forward generation, the ability to fuse multiple diverse source images in complex textures. To illustrate these capabilities we present multiple experiments with different classes of texture images and use cases. We also discuss some limitations of our method with respect to the types of texture images it can synthesize, and compare it to other neural techniques for texture generation.;GAN, CV, Pattern Recognition
Fashion DNA: Merging content and sales data for recommendation and article mapping;Education & Research;Machine Learning;Bracher, Heinz, Vollgraf;arXiv (09/2016);2016;https://arxiv.org/abs/1609.02489;08.09.16;1;"We present a method to determine Fashion DNA, coordinate vectors locating fashion items in an abstract space. Our approach is based on a deep neural network architecture that ingests curated article information such as tags and images, and is trained to predict sales for a large set of frequent customers. In the process, a dual space of customer style preferences naturally arises. Interpretation of the metric of these spaces is straightforward: The product of Fashion DNA and customer style vectors yields the forecast purchase likelihood for the customer-item pair, while the angle between Fashion DNA vectors is a measure of item similarity. Importantly, our models are able to generate unbiased purchase probabilities for fashion items based solely on article information, even in absence of sales data, thus circumventing the ""cold-start problem"" of collaborative recommendation approaches. Likewise, it generalizes easily and reliably to customers outside the training set. We experiment with Fashion DNA models based on visual and/or tag item data, evaluate their recommendation power, and discuss the resulting article similarities.";DL, Forecasting, Recommender
