{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle competition scraper\n",
    "\n",
    "this script scrapes the content of already stored competitions  \n",
    "as they have a different formatting than datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic store data to file function\n",
    "def store_data(data, file, mode='w', toJson=False):\n",
    "    if toJson:\n",
    "        data = json.dumps(data)\n",
    "    with open(file, mode, encoding='utf-8') as fp:\n",
    "        result = fp.write(data)\n",
    "        return result\n",
    "    \n",
    "# generic load data from file function\n",
    "def load_data(file, fromJson=False):\n",
    "    if os.path.isfile(file):\n",
    "        with open(file, 'r', encoding='utf-8', errors=\"ignore\") as fp:\n",
    "            data = fp.read()\n",
    "            if fromJson:\n",
    "                data = json.loads(data)\n",
    "            return data\n",
    "    else:\n",
    "        return 'file not found'\n",
    "\n",
    "# test text\n",
    "#print(store_data('Hello', '../data/repositories/mlart/test.txt'))\n",
    "#print(load_data('../data/repositories/mlart/test.txt'))\n",
    "\n",
    "# test json\n",
    "#print(store_data({'msg':'Hello World'}, '../data/repositories/mlart/test.json', toJson=True))\n",
    "#print(load_data('../data/repositories/mlart/test.json', fromJson=True))\n",
    "\n",
    "#store_data(result[0]['html'], '../data/repositories/kaggle/notebook.html')\n",
    "#store_data(result[0]['iframe'], '../data/repositories/kaggle/kernel.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to create folder create_folder\n",
    "def create_folder(path):\n",
    "    if not os.path.exists(os.path.dirname(path)):\n",
    "        try:\n",
    "            os.makedirs(os.path.dirname(path))\n",
    "            print(path + ' created')\n",
    "        except OSError as exc: # Guard against race condition\n",
    "            if exc.errno != errno.EEXIST:\n",
    "                raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Lyft 3D Object Detection for Autonomous Vehicles', 'subtitle': 'Can you advance the state of the art in 3D object detection?', 'type': 'Featured prediction Competition', 'organisation': 'Lyft', 'description': 'Self-driving technology presents a rare opportunity to improve the quality of life in many of our communities. Avoidable collisions, single-occupant commuters, and vehicle emissions are choking cities, while infrastructure strains under rapid urban growth. Autonomous vehicles are expected to redefine transportation and unlock a myriad of societal, environmental, and economic benefits. You can apply your data analysis skills in this competition to advance the state of self-driving technology.\\nLyft, whose mission is to improve people’s lives with the world’s best transportation, is investing in the future of self-driving vehicles. Level 5, their self-driving division, is working on a fleet of autonomous vehicles, and currently has a team of 450+ across Palo Alto, London, and Munich working to build a leading self-driving system (they’re hiring!). Their goal is to democratize access to self-driving technology for hundreds of millions of Lyft passengers.\\nFrom a technical standpoint, however,  the bar to unlock technical research and development on higher-level autonomy functions like perception, prediction, and planning is extremely high. This implies technical R&D on self-driving cars has traditionally been inaccessible to the broader research community.\\nThis dataset aims to democratize access to such data, and foster innovation in higher-level autonomy functions for everyone, everywhere. By conducting a competition, we hope to encourage the research community to focus on hard problems in this space—namely, 3D object detection over semantic maps. \\nIn this competition, you will build and optimize algorithms based on a large-scale dataset. This dataset features the raw sensor camera inputs as perceived by a fleet of multiple, high-end, autonomous vehicles in a restricted geographic area. \\nIf successful, you’ll make a significant contribution towards stimulating further development in autonomous vehicles and empowering communities around the world.', 'reward': '$25,000Prize Money', 'teams': '547 teams', 'date': 'Wed Nov 13 2019 00:59:00 GMT+0100'}\n"
     ]
    }
   ],
   "source": [
    "# scrape links from notebooks.html\n",
    "\n",
    "folder_base = '../data/repositories/kaggle/competitions/c/'\n",
    "folder = '3d-object-detection-for-autonomous-vehicles/'\n",
    "file_in = 'dataset.html'\n",
    "url = 'https://www.kaggle.com/c/3d-object-detection-for-autonomous-vehicles/notebooks?sortBy=voteCount'\n",
    "\n",
    "def scrape_dataset(html):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    result = {}\n",
    "    \n",
    "    partial = soup.find('div', {\"id\": \"site-content\"}) #class_=\"km-list km-list--avatar-list km-list--three-line\")\n",
    "    if partial == None:\n",
    "        return []\n",
    "    \n",
    "    result['title'] = soup.find('h1', class_='competition-header__title').text.strip()\n",
    "    result['subtitle'] = soup.find('h2', class_='competition-header__subtitle').text.strip()\n",
    "    result['type'] = soup.find('p', class_='competition-header__classification-text').text.strip()\n",
    "    try:\n",
    "        result['organisation'] = soup.find('span', class_='competition-header__organization-name').text.strip()\n",
    "    except:\n",
    "        result['organisation'] = ''\n",
    "    #result['teams'] = soup.find('', class_='').text.strip()\n",
    "    result['description'] = soup.find('div', class_='markdown-converter__text--rendered').text.strip()\n",
    "    #result['date'] = soup.find('', class_='').text.strip()\n",
    "    try:\n",
    "        result['reward'] = soup.find('div', class_='competition-header__prize').text.strip()\n",
    "    except:\n",
    "        result['reward'] = ''\n",
    "    \n",
    "    items = partial.find_all('li', class_='horizontal-list-item')\n",
    "    #print(len(items))\n",
    "    \n",
    "    for i, item in enumerate(items):\n",
    "        #print(i, item)\n",
    "        if 'team' in item.text:\n",
    "            result['teams'] = item.text.strip()\n",
    "        if 'ago' in item.text:\n",
    "            result['date'] = item.select('span>span')[0].get('title')\n",
    "            result['date'] = result['date'].split(' (')\n",
    "            result['date'] = result['date'][0]\n",
    "        \n",
    "        #print(link)\n",
    "    \n",
    "    return result\n",
    "\n",
    "html = load_data(folder_base+folder+file_in)\n",
    "if 'not found' in html:\n",
    "    print(html)\n",
    "links = scrape_dataset(html)\n",
    "print(links)\n",
    "#store_data(links, folder_base+folder+out, toJson=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/repositories/kaggle/competitions/c\\15-071x-the-analytics-edge-competition-spring-2015\\dataset.html\n",
      "meta {'title': '15.071x - The Analytics Edge (Spring 2015)', 'subtitle': 'Test your analytics skills by predicting which New York Times blog articles will be the most popular', 'type': 'Research prediction Competition', 'organisation': '', 'description': 'IMPORTANT NOTE: This competition is only open to students of the MITx free, online course 15.071x - The Analytics Edge.\\nWhat makes online news articles popular?\\nNewspapers and online news aggregators like Google News need to understand which news articles will be the most popular, so that they can prioritize the order in which stories appear. In this competition, you will predict the popularity of a set of New York Times blog articles from the time period September 2014-December 2014.\\nThe following screenshot shows an example of the New York Times technology blog \"Bits\" homepage:\\n\\nMany blog articles are published each day, and the New York Times has to decide which articles should be featured. In this competition, we challenge you to develop an analytics model that will help the New York Times understand the features of a blog post that make it popular.\\nTo download the data and learn how this competition works, please be sure to read the \"Data\" page, as well as the \"Evaluation\" page, which can both be found in the panel on the left.\\nAcknowledgements\\nThis competition is brought to you by MITx and edX.', 'reward': '', 'teams': '2,920 teams', 'date': 'Tue May 05 2015 01:59:00 GMT+0200'}\n",
      "output ../data/repositories/kaggle/competitions/c\\15-071x-the-analytics-edge-competition-spring-2015\\dataset.json\n",
      "limit reached 1\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# parse all competitions\n",
    "\n",
    "path = '../data/repositories/kaggle/competitions/'\n",
    "#path = '../data/repositories/kaggle/datasets/'\n",
    "file = 'dataset.html'\n",
    "#file_out = 'dataset.json'\n",
    "\n",
    "LIMIT = 1\n",
    "i = 0\n",
    "\n",
    "folders = os.listdir(path)\n",
    "for folder in folders:\n",
    "    subfolders = os.listdir(os.path.join(path,folder))\n",
    "    for subfolder in subfolders:\n",
    "        i += 1\n",
    "        item = os.path.join(path,folder,subfolder,file)\n",
    "        print(item)\n",
    "        if os.path.isfile(item):\n",
    "            html = load_data(item)\n",
    "            meta = scrape_dataset(html)\n",
    "            print('meta', meta)\n",
    "            output = item.replace('.html','.json')\n",
    "            print('output', output)\n",
    "            store_data(links, output, toJson=True)\n",
    "        \n",
    "        if i>=LIMIT:\n",
    "            print('limit reached', i)\n",
    "            sys.exit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
