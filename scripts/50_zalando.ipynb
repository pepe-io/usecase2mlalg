{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import platform\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic store data to file function\n",
    "def store_data(data, file, mode='w', toJson=False):\n",
    "    if toJson:\n",
    "        data = json.dumps(data)\n",
    "    with open(file, mode, encoding='utf-8') as fp:\n",
    "        result = fp.write(data)\n",
    "        return result\n",
    "    \n",
    "# generic load data from file function\n",
    "def load_data(file, fromJson=False):\n",
    "    if os.path.isfile(file):\n",
    "        with open(file, 'r', encoding='utf-8', errors=\"ignore\") as fp:\n",
    "            data = fp.read()\n",
    "            if fromJson:\n",
    "                data = json.loads(data)\n",
    "            return data\n",
    "    else:\n",
    "        return 'file not found'\n",
    "\n",
    "# test text\n",
    "#print(store_data('Hello', '../data/repositories/mlart/test.txt'))\n",
    "#print(load_data('../data/repositories/mlart/test.txt'))\n",
    "\n",
    "# test json\n",
    "#print(store_data({'msg':'Hello World'}, '../data/repositories/mlart/test.json', toJson=True))\n",
    "#print(load_data('../data/repositories/mlart/test.json', fromJson=True))\n",
    "\n",
    "#store_data(result[0]['html'], '../data/repositories/kaggle/notebook.html')\n",
    "#store_data(result[0]['iframe'], '../data/repositories/kaggle/kernel.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to create folder create_folder\n",
    "def create_folder(path):\n",
    "    if not os.path.exists(os.path.dirname(path)):\n",
    "        try:\n",
    "            os.makedirs(os.path.dirname(path))\n",
    "            print(path + ' created')\n",
    "        except OSError as exc: # Guard against race condition\n",
    "            if exc.errno != errno.EEXIST:\n",
    "                raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matches ['object detection', 'convolutional neural network', 'lstm', 'anomaly', 'detect', 'neural network', 'ML']\n",
      "tags ['Object Detection', 'NN', 'LSTM', 'ML', 'CNN']\n"
     ]
    }
   ],
   "source": [
    "# scan text for predefined terms\n",
    "\n",
    "text = 'We use LSTM for anomaly and object detection. As Convolutional Neural Networks are great for ML.'\n",
    "\n",
    "pd_ml_terms = pd.read_csv('../data/patterns/ml_terms.csv')\n",
    "ml_terms = pd_ml_terms['Term'].tolist()\n",
    "ml_slugs = pd_ml_terms['Slug'].tolist()\n",
    "ml_slugs = [x for x in ml_slugs if str(x) != 'nan']\n",
    "ml_tags = pd_ml_terms['Tag'].tolist()\n",
    "ml_tags = [x for x in ml_tags if str(x) != 'nan']\n",
    "\n",
    "#print(ml_tags)\n",
    "\n",
    "ml_libs = pd.read_csv('../data/patterns/ml_libraries.csv')\n",
    "ml_libs = ml_libs['Python Package'].tolist()\n",
    "\n",
    "def match_text(haystack, needles, toLower = False, unique = True):\n",
    "    \n",
    "    if toLower == True:\n",
    "        haystack = haystack.lower()\n",
    "        needles = [x.lower() for x in needles]\n",
    "    \n",
    "    if unique == True:\n",
    "        matches = {x for x in needles if x in haystack}\n",
    "        matches = list(matches)\n",
    "    else:\n",
    "        matches = [x for x in needles if x in haystack]\n",
    "    \n",
    "    return matches\n",
    "\n",
    "def match_tags(haystack):\n",
    "    df = pd.read_csv('../data/patterns/ml_terms.csv')\n",
    "    tags = []\n",
    "    \n",
    "    df.set_index('Term', inplace = True)\n",
    "    for item in haystack:\n",
    "        try:\n",
    "            tag = df.loc[item].get('Tag')\n",
    "            if not 'nan' in str(tag):\n",
    "                tags.append(tag)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    df.set_index('Slug', inplace = True)\n",
    "    for item in haystack:\n",
    "        try:\n",
    "            tag = df.loc[item].get('Tag')\n",
    "            if not 'nan' in str(tag):\n",
    "                tags.append(str(tag))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    #if 'ANN' in tags or 'CNN' in tags or 'RNN' in tags:\n",
    "    #    tags.remove('NN')\n",
    "    \n",
    "    return list(set(tags))\n",
    "\n",
    "#ml_slugs, ml_terms, ml_libs, match_text(haystack, needles, toLower = False, unique = True)\n",
    "needles = {\n",
    "    'ml_slugs': ml_slugs,\n",
    "    'ml_terms': ml_terms,\n",
    "    'ml_libs': ml_libs,\n",
    "}\n",
    "needles_need_str_lower = {\n",
    "    'ml_slugs': False,\n",
    "    'ml_terms': True,\n",
    "    'ml_libs': False,\n",
    "}\n",
    "\n",
    "matches = []\n",
    "\n",
    "matches.extend(match_text(text, ml_terms, True))\n",
    "matches.extend(match_text(text, ml_slugs, False))\n",
    "print('matches', matches)\n",
    "\n",
    "tags = match_tags(matches)\n",
    "print('tags', tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-12 16:08:03\n"
     ]
    }
   ],
   "source": [
    "# get file modifictaion date\n",
    "# https://stackoverflow.com/questions/237079/how-to-get-file-creation-modification-date-times-in-python\n",
    "\n",
    "def creation_date(path_to_file, datetime = True):\n",
    "    \"\"\"\n",
    "    Try to get the date that a file was created, falling back to when it was\n",
    "    last modified if that isn't possible.\n",
    "    See http://stackoverflow.com/a/39501288/1709587 for explanation.\n",
    "    \"\"\"\n",
    "    if platform.system() == 'Windows':\n",
    "        timestamp = os.path.getctime(path_to_file)\n",
    "    else:\n",
    "        stat = os.stat(path_to_file)\n",
    "        try:\n",
    "            timestamp = stat.st_birthtime\n",
    "        except AttributeError:\n",
    "            # We're probably on Linux. No easy way to get creation dates here,\n",
    "            # so we'll settle for when its content was last modified.\n",
    "            timestamp = stat.st_mtime\n",
    "        \n",
    "    if datetime == True:\n",
    "        timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(timestamp))\n",
    "\n",
    "    return timestamp\n",
    "    \n",
    "folder_base = '../data/repositories/kaggle/competitions/c/'\n",
    "folder = '3d-object-detection-for-autonomous-vehicles/notebooks/asimandia/lyft3d-inference-kernel/'\n",
    "notebook = 'notebook_02.html'\n",
    "kernel = 'kernel.html'\n",
    "print(creation_date(folder_base+folder+notebook))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fox jumped over the log.\n"
     ]
    }
   ],
   "source": [
    "# clear text formatting\n",
    "import re\n",
    "def clear_text(s):\n",
    "    s = s.replace('\\n',' ').replace('\\r','').replace('¶','').strip()\n",
    "    s = re.sub(\"\\s\\s+\" , \" \", s)\n",
    "    return s\n",
    "\n",
    "print(clear_text(\"The   fox jumped   over    the log.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 {'title': 'Contextual BERT: Conditioning the Language Model Using a Global State', 'authors': 'Denk, Peleteiro', 'publicate_at': 'Accepted to Coling – TextGraphs-14 workshop (2020)', 'year': '2020', 'link': 'https://arxiv.org/abs/2010.15778'}\n",
      "                                                title  \\\n",
      "0   Contextual BERT: Conditioning the Language Mod...   \n",
      "1   Towards User-in-the-Loop Online Fashion Size R...   \n",
      "2   Attention Gets You the Right Size and Fit in F...   \n",
      "3   Personalized Size Recommendations with Human i...   \n",
      "4   Task-Aware Representation of Sentences for Gen...   \n",
      "5   Outfit Generation and Recommendation – An Expe...   \n",
      "6           Learning Size and Fit from Fashion Images   \n",
      "7   Meta-learning for Size and Fit Recommendation ...   \n",
      "8   SizeNet: Weakly Supervised Learning of Visual ...   \n",
      "9   Transform the Set: Memory Attentive Generation...   \n",
      "10  Generating High-Resolution Fashion Model Image...   \n",
      "11  Eigendecompositions of Transfer Operators in R...   \n",
      "12  A Deep Learning System for Predicting Size and...   \n",
      "13  Learning Set-equivariant Functions with SWARM ...   \n",
      "14  A Bandit Framework for Optimal Selection of Re...   \n",
      "15  Copy the Old or Paint Anew? An Adversarial Fra...   \n",
      "16  A Hierarchical Bayesian Model for Size Recomme...   \n",
      "17  Disentangling Multiple Conditional Inputs in GANs   \n",
      "18        First Order Generative Adversarial Networks   \n",
      "19  FEIDEGGER: A Multi-modal Corpus of Fashion Ima...   \n",
      "20  ZAP: An Open-Source Multilingual Annotation Pr...   \n",
      "21  Syntax-Aware Language Modeling with Recurrent ...   \n",
      "22  The Projector: An Interactive Annotation Proje...   \n",
      "23  Street2Fashion2Shop: Enabling Visual Search in...   \n",
      "24  Studio2Shop: from photo shoots to fashion arti...   \n",
      "25  Neural Simpletrons – Learning in the Limit of ...   \n",
      "26  Stochastic Maximum Likelihood Optimization via...   \n",
      "27  GANosaic: Mosaic Creation with Generative Text...   \n",
      "28  The Conditional Analogy GAN: Swapping Fashion ...   \n",
      "29  CROWD-IN-THE-LOOP: A Hybrid Approach for Annot...   \n",
      "30  The Projector: An Interactive Annotation Proje...   \n",
      "31  Fashion-MNIST: a Novel Image Dataset for Bench...   \n",
      "32  An LSTM-Based Dynamic Customer Model for Fashi...   \n",
      "33  Learning Texture Manifolds with the Periodic S...   \n",
      "34  Texture synthesis with spatial generative adve...   \n",
      "35  Fashion DNA: Merging content and sales data fo...   \n",
      "\n",
      "                                              authors  \\\n",
      "0                                     Denk, Peleteiro   \n",
      "1               Lefakis, Koriagin, Lasserre, Shirvany   \n",
      "2                    Hajjar, Lasserre, Zhao, Shirvany   \n",
      "3               Lefakis, Koriagin, Lasserre, Shirvany   \n",
      "4                     Halder, Akbik, Krapac, Vollgraf   \n",
      "5   Celikik, Kirmse, Denk, Gagliardi, Mbarek, Pham...   \n",
      "6                       Karessli, Guigourès, Shirvany   \n",
      "7   Lasserre, Sheikh, Koriagin, Bergmann, Vollgraf...   \n",
      "8                       Karessli, Guigourès, Shirvany   \n",
      "9                         Jetchev, Bergmann, Yildirim   \n",
      "10              Yildirim, Jetchev, Vollgraf, Bergmann   \n",
      "11              Klus (ext.), Schuster, Muandet (ext.)   \n",
      "12  Sheikh, Guigourès, Koriagin, Ho, Shirvany, Vol...   \n",
      "13                                           Vollgraf   \n",
      "14      Merentitis, Rasul, Vollgraf, Sheikh, Bergmann   \n",
      "15                        Jetchev, Bergmann, Yildirim   \n",
      "16  Guigourès, Ho, Koryagin, Sheikh, Bergmann, Shi...   \n",
      "17                         Yildirim, Seward, Bergmann   \n",
      "18  Seward, Unterthiner, Bergmann, Jetchev, Hochre...   \n",
      "19                           Lefakis, Akbik, Vollgraf   \n",
      "20                                    Akbik, Vollgraf   \n",
      "21                            Blythe, Akbik, Vollgraf   \n",
      "22                                    Akbik, Vollgraf   \n",
      "23                        Lasserre, Bracher, Vollgraf   \n",
      "24                          Lasserre, Rasch, Vollgraf   \n",
      "25               Forster (ext.), Sheikh, Lücke (ext.)   \n",
      "26                Sheikh, Rasul, Merentitis, Bergmann   \n",
      "27                          Jetchev, Bergmann, Seward   \n",
      "28                                  Jetchev, Bergmann   \n",
      "29  Wang (ext.), Akbik, Li (ext.), Xia (ext.), Xu ...   \n",
      "30                                    Akbik, Vollgraf   \n",
      "31                              Xiao, Rasul, Vollgraf   \n",
      "32                           Heinz, Bracher, Vollgraf   \n",
      "33                        Bergmann, Jetchev, Vollgraf   \n",
      "34                        Jetchev, Bergmann, Vollgraf   \n",
      "35                           Bracher, Heinz, Vollgraf   \n",
      "\n",
      "                                         publicate_at  year  \\\n",
      "0   Accepted to Coling – TextGraphs-14 workshop (2...  2020   \n",
      "1                               FashionxRecsys (2020)  2020   \n",
      "2                               FashionxRecsys (2020)  2020   \n",
      "3   2nd ICML Workshop on Human in the Loop Learnin...  2020   \n",
      "4                          Accepted to Cooling (2020)  2020   \n",
      "5                   Accepted to FashionxRecsys (2020)  2020   \n",
      "6   Springer’s Special Issue on Fashion Recommende...  2020   \n",
      "7   Society for Industrial and Applied Mathematics...  2020   \n",
      "8   CVPR 2019, Workshop on Focus on Fashion and Su...  2019   \n",
      "9   NeurIPS 2019 Workshop on Machine Learning for ...  2019   \n",
      "10  ICCV 2019, Workshop on Computer Vision for Fas...  2019   \n",
      "11                Journal of Nonlinear Science (2019)  2019   \n",
      "12  Thirteenth ACM Conference on Recommender Syste...  2019   \n",
      "13                                    Arxiv (06/2019)  2019   \n",
      "14  NeurIPS 2018 Workshop on Deep Reinforcement Le...  2018   \n",
      "15  NeurIPS 2018 Workshop on Machine Learning for ...  2018   \n",
      "16                              RecSys 2018 (10/2018)  2018   \n",
      "17                KDD 2018 Fashion Workshop (08/2018)  2018   \n",
      "18                                ICML 2018 (06/2018)  2018   \n",
      "19                                LREC 2018 (05/2018)  2018   \n",
      "20                                LREC 2018 (05/2018)  2018   \n",
      "21                                    arxiv (03/2018)  2018   \n",
      "22  Proceedings of the 2017 Conference on Empirica...  2018   \n",
      "23  ICPRAM 2018: Pattern Recognition Applications ...  2018   \n",
      "24  ICPRAM, Classification and Object Recognition ...  2018   \n",
      "25  NIPS, Learning with Limited Data (LLD) Worksho...  2017   \n",
      "26    NIPS, Bayesian Deep Learning Workshop (12/2017)  2017   \n",
      "27  NIPS, Machine Learning for Creativity and Desi...  2017   \n",
      "28  ICCV: Computer Vision for Fashion Workshop (10...  2017   \n",
      "29                                    EMNLP (09/2017)  2017   \n",
      "30                                    EMNLP (09/2017)  2017   \n",
      "31                                    arXiv (08/2017)  2017   \n",
      "32                        RecTemp: Workshop (08/2017)  2017   \n",
      "33                                     ICML (08/2017)  2017   \n",
      "34      NIPS, Adversarial Learning Workshop (12/2016)  2016   \n",
      "35                                    arXiv (09/2016)  2016   \n",
      "\n",
      "                                                 link  \n",
      "0                    https://arxiv.org/abs/2010.15778  \n",
      "1                                                 NaN  \n",
      "2                                                 NaN  \n",
      "3                                                 NaN  \n",
      "4                                                 NaN  \n",
      "5                                                 NaN  \n",
      "6                                                 NaN  \n",
      "7   https://epubs.siam.org/doi/pdf/10.1137/1.97816...  \n",
      "8                    https://arxiv.org/abs/1905.11784  \n",
      "9                    https://arxiv.org/abs/1910.07236  \n",
      "10                   https://arxiv.org/abs/1908.08847  \n",
      "11  https://link.springer.com/article/10.1007/s003...  \n",
      "12                   https://arxiv.org/abs/1907.09844  \n",
      "13                   https://arxiv.org/abs/1906.09400  \n",
      "14                   https://arxiv.org/abs/1902.03657  \n",
      "15                   https://arxiv.org/abs/1811.09236  \n",
      "16  https://rguigoures.github.io/pdf/hierarchical-...  \n",
      "17                   https://arxiv.org/abs/1806.07819  \n",
      "18                   https://arxiv.org/abs/1802.04591  \n",
      "19         https://dblp.org/rec/conf/lrec/LefakisAV18  \n",
      "20            https://dblp.org/rec/conf/lrec/AkbikV18  \n",
      "21                   https://arxiv.org/abs/1803.03665  \n",
      "22           http://www.aclweb.org/anthology/D17-2008  \n",
      "23  https://link.springer.com/chapter/10.1007/978-...  \n",
      "24  http://www.scitepress.org/PublicationsDetail.a...  \n",
      "25  https://lld-workshop.github.io/papers/LLD_2017...  \n",
      "26                   https://arxiv.org/abs/1712.01141  \n",
      "27                   https://arxiv.org/abs/1712.00269  \n",
      "28                   https://arxiv.org/abs/1709.04695  \n",
      "29           http://www.aclweb.org/anthology/D17-1205  \n",
      "30  http://alanakbik.github.io/papers/EMNLP2017_de...  \n",
      "31                   https://arxiv.org/abs/1708.07747  \n",
      "32                                                NaN  \n",
      "33  http://proceedings.mlr.press/v70/bergmann17a.html  \n",
      "34                   https://arxiv.org/abs/1611.08207  \n",
      "35                   https://arxiv.org/abs/1609.02489  \n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# scrape publications list\n",
    "\n",
    "path_in  = '../data/repositories/manual/zalando.com/research-publications/index.html'\n",
    "path_out = '../data/datasets/zalando_publications_01.csv'\n",
    "\n",
    "def scrape_publication(html):\n",
    "    \n",
    "    \n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    snippet = soup.find('div', class_='entry-content')\n",
    "    \n",
    "    raw_items = snippet.find_all('div', class_='portelement')\n",
    "    items = []\n",
    "    for item in raw_items:\n",
    "        meta = {}\n",
    "        meta['title'] = item.find('h3').text.strip()\n",
    "        block = item.find('div', class_='description-block_2')\n",
    "        block = block.text.split('Authors:')\n",
    "        meta['authors'] = block[1].strip()\n",
    "        \n",
    "        b = block[0].replace('\\n','').strip()\n",
    "        meta['publicate_at'] = b\n",
    "        match = re.match(r'.*([0-9]{4})', b)\n",
    "        if match is not None:\n",
    "            meta['year'] = match.group(1)\n",
    "                    \n",
    "        link = item.find('div', class_='button-block')\n",
    "        if link != None:\n",
    "            link = link.find('a')\n",
    "            meta['link'] = link.get('href')\n",
    "        \n",
    "        #meta['link'] = url\n",
    "        #meta['date'] = soup.find('time', class_=\"ct-meta-element-date\").get('datetime')\n",
    "\n",
    "        # date formatting #\"2020-05-08T19:41:42+05:30\"\n",
    "        # ignore \"+05:30\"\n",
    "        #date_time_str = meta['date'].split('+')\n",
    "        #date_time_str = date_time_str[0]\n",
    "        #date_time_obj = datetime.datetime.strptime(date_time_str, '%Y-%m-%dT%H:%M:%S')\n",
    "        #meta['date'] = str(date_time_obj)\n",
    "\n",
    "        #meta['text'] = clear_text(text)\n",
    "        #meta['code'] = code\n",
    "        items.append(meta)\n",
    "    \n",
    "    \n",
    "    return items\n",
    "\n",
    "\n",
    "html = load_data(path_in)\n",
    "if 'file not found' in html:\n",
    "    print(html)\n",
    "meta = scrape_publication(html)\n",
    "print(len(meta), meta[0])\n",
    "df = pd.DataFrame(meta)\n",
    "print(df)\n",
    "df.to_csv(path_out, sep=';', index=False)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files: 14\n",
      "# 0 Adversarial-Learning.json\n",
      "# 1 Determinantal-Point-Processes.json\n",
      "# 2 Fashion-DNA.json\n",
      "# 3 Fashion-on-People-Images.json\n",
      "# 4 Fashion-Renderer.json\n",
      "# 5 Forecasting-Customers-Preference.json\n",
      "# 6 Generative-Fashion-Design.json\n",
      "# 7 Language-Modeling.json\n",
      "# 8 Personalized-Size-Recommendation.json\n",
      "# 9 Robust-Reinforcement-Learning.json\n",
      "# 10 Sample-Efficient-Reinforcement-Learning.json\n",
      "runtime: 0.09 seconds for 11 items\n",
      "(11, 15)\n",
      "  branche            category claps company        date date_scraped  \\\n",
      "0          Wholesale & Retail                             17.01.2021   \n",
      "1          Wholesale & Retail                             17.01.2021   \n",
      "2          Wholesale & Retail                             17.01.2021   \n",
      "3          Wholesale & Retail                             17.01.2021   \n",
      "4          Wholesale & Retail                01.10.2020   17.01.2021   \n",
      "\n",
      "                                         description field  \\\n",
      "0  We have an article embedding which encodes, in...         \n",
      "1  Determinantal Point Processes (DPPs) capture n...         \n",
      "2  To make the properties of a fashion item more ...         \n",
      "3  “How do I look?” – this is a question typicall...         \n",
      "4  “Fashion Renderer” creates a computer-generate...         \n",
      "\n",
      "                                                link source       subcategory  \\\n",
      "0  https://research.zalando.com/welcome/mission/r...         Machine Learning   \n",
      "1  https://research.zalando.com/welcome/mission/r...         Machine Learning   \n",
      "2  https://research.zalando.com/welcome/mission/r...         Machine Learning   \n",
      "3  https://research.zalando.com/welcome/mission/r...         Machine Learning   \n",
      "4  https://research.zalando.com/welcome/mission/r...         Machine Learning   \n",
      "\n",
      "  subfield                                               tags  \\\n",
      "0           [Fashion, DL, CV, Adversarial Learning, Research]   \n",
      "1                              [Fashion, Recommender, Search]   \n",
      "2           [Fashion, t-SNE, DNN, Recommender, Image Taggi...   \n",
      "3                                          [Fashion, GAN, CV]   \n",
      "4                                         [Fashion, StyleGAN]   \n",
      "\n",
      "                                                text  \\\n",
      "0  Deep learning computer vision models, based on...   \n",
      "1  Chic, shocking, trendy, or casual, Fashion mus...   \n",
      "2  Unlike a brick-and-mortar department store, on...   \n",
      "3  The overarching goal of this project is to adv...   \n",
      "4  At Zalando, we provide high-quality photograph...   \n",
      "\n",
      "                                               title  \n",
      "0                               Adversarial Learning  \n",
      "1                      Determinantal Point Processes  \n",
      "2      Improving Fashion Item Encoding and Retrieval  \n",
      "3  Swapping of Fashion on People Images with Gene...  \n",
      "4                                   Fashion Renderer  \n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# throw all json-files into a single csv\n",
    "\n",
    "path_in = '../data/repositories/manual/zalando.com/blog/'\n",
    "csv_out = '../data/database/zalando_blog_01.csv'\n",
    "\n",
    "path_in = '../data/repositories/manual/zalando.com/jobs/'\n",
    "csv_out = '../data/database/zalando_jobs_01.csv'\n",
    "\n",
    "path_in = '../data/repositories/manual/zalando.com/research-projects/'\n",
    "csv_out = '../data/database/zalando_projects_01.csv'\n",
    "\n",
    "path_in = '../data/repositories/manual/medium.com/Applications of Machine Learning in FinTech/'\n",
    "csv_out = '../data/database/medium_fintech_01.csv'\n",
    "\n",
    "path_in = '../data/repositories/manual/bcgdv.com/dv_hacks/'\n",
    "csv_out = '../data/database/bcgdv_hackaton_01.csv'\n",
    "\n",
    "path_in = '../data/repositories/manual/bcgdv.com/founded_company/'\n",
    "csv_out = '../data/database/bcgdv_founded_01.csv'\n",
    "\n",
    "article = load_data(path_in+'article.json', fromJson=True)\n",
    "quit = 0 # quit after n files processed / 0 ... no limit\n",
    "\n",
    "path_in = path_in+'items/'\n",
    "files = os.listdir(path_in)\n",
    "print('files:', len(files))\n",
    "i = 0\n",
    "\n",
    "runtime_start = time.time()\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for file in files:\n",
    "    path = os.path.join(path_in, file)\n",
    "    if os.path.isfile(path) and not '_preset' in file:\n",
    "        print('#', i, file)\n",
    "        i += 1\n",
    "\n",
    "        #print(' - ', j, 'author:', author, '/ notebook:', notebook)\n",
    "        data = {**article}\n",
    "        data.update(load_data(path, fromJson=True))\n",
    "        #print(data)\n",
    "\n",
    "        data['text'] = clear_text(data['text'])\n",
    "        if 'description' in data:\n",
    "            data['description'] = clear_text(data['description'])\n",
    "        if 'about' in data:\n",
    "            data['about'] = clear_text(data['about'])\n",
    "\n",
    "        # store item\n",
    "        df = df.append(data, ignore_index=True)\n",
    "\n",
    "        if quit!=0 and j>quit:\n",
    "            break\n",
    "        \n",
    "# drop duplicates\n",
    "#df = df.drop_duplicates(['link'])\n",
    "\n",
    "runtime_end = time.time()\n",
    "print('runtime:', round(runtime_end - runtime_start, 3), 'seconds for', i, 'items')\n",
    "print(df.shape)\n",
    "print(df.head())\n",
    "        \n",
    "# drop columns\n",
    "#df.drop(columns=['code', 'text'], inplace=True)\n",
    "#df.drop(columns=['text'], inplace=True)\n",
    "\n",
    "df.to_csv(csv_out, sep=';', index=False)\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
