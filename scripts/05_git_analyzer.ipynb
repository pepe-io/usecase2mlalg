{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base.py\n",
      "pfe.py\n"
     ]
    }
   ],
   "source": [
    "# dir walker\n",
    "\n",
    "dir1 = 'C:\\pepe\\share\\pepe\\projects\\bachelor\\data\\repositories\\git\\finnqiao\\cohort_online_retail'\n",
    "dir2 = 'C:\\pepe\\share\\pepe\\projects\\bachelor\\data\\repositories\\git\\arvindkarir\\retail'\n",
    "dir3 = 'C:\\\\pepe\\\\share\\\\pepe\\\\projects\\\\bachelor\\\\data\\\\repositories\\\\git\\\\crowdAI\\\\train-schedule-optimisation-challenge-starter-kit\\\\'\n",
    "dir4 = 'C:\\\\pepe\\\\share\\\\pepe\\\\projects\\\\bachelor\\\\data\\\\repositories\\\\git\\\\Lemma1\\\\DPFE\\\\'\n",
    "\n",
    "def dir_walk(dir):\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        #path = root.split(os.sep)\n",
    "        #print((len(path) - 1) * '-', os.path.basename(root))\n",
    "        for file in files:\n",
    "            #print(len(path) * '-', file)\n",
    "            #if '.ipynb' in file:\n",
    "            #    print(root, file)\n",
    "            if '.py' in file:\n",
    "                print(file)\n",
    "                \n",
    "dir_walk(dir4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'libs': ['json', 'pandas']}\n"
     ]
    }
   ],
   "source": [
    "# python code to package parser\n",
    "\n",
    "fp = 'C:\\\\pepe\\\\share\\\\pepe\\\\projects\\\\bachelor\\\\data\\\\repositories\\\\git\\\\crowdAI\\\\train-schedule-optimisation-challenge-starter-kit\\\\utils\\\\route_penalty.py'\n",
    "\n",
    "def analyze_pythoncode(code):\n",
    "    meta = {}\n",
    "    debug = False\n",
    "    \n",
    "    #print(code)\n",
    "    code = code.split('\\n')\n",
    "    \n",
    "    libs = []\n",
    "    for line in code:\n",
    "        # get libraries\n",
    "        words = line.split(' ')\n",
    "        if words[0] == 'import' or words[0] == 'from':\n",
    "            if debug: print('raw: ' + line.strip())\n",
    "            lib = line.split(' ')[1].split('.')[0].strip()\n",
    "            if ',' in lib:\n",
    "                lib = [elem.strip() for elem in lib.split(',')]\n",
    "                libs.extend(lib)\n",
    "                if debug: print('parsed: ['+', '.join(lib) + ']')\n",
    "            else:\n",
    "                libs.append(lib)\n",
    "                if debug: print('parsed: '+lib)\n",
    "\n",
    "    # make values unique\n",
    "    libs = np.unique(libs).tolist()\n",
    "    meta['libs'] = libs\n",
    "    \n",
    "    return meta\n",
    "\n",
    "def analyze_py(filepath):\n",
    "    meta = {}\n",
    "    \n",
    "    \n",
    "    with open(filepath) as fp:\n",
    "        content = fp.read()\n",
    "        \n",
    "    return analyze_pythoncode(content)\n",
    "    #print(libs)\n",
    "\n",
    "meta = analyze_py(fp)\n",
    "\n",
    "print(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'libs': ['base', 'collections', 'copy', 'datetime', 'joblib', 'matplotlib', 'networkx', 'numpy', 'os', 'pandas', 'pfe', 'pickle', 'random', 'scipy', 'seaborn']}\n"
     ]
    }
   ],
   "source": [
    "# Jupyter Notebook to python code parser\n",
    "\n",
    "fp = 'C:\\\\pepe\\\\share\\\\pepe\\\\projects\\\\bachelor\\\\data\\\\repositories\\\\git\\\\Lemma1\\\\DPFE\\\\DPFE-v0.1.ipynb'\n",
    "\n",
    "def analyze_ipynb(filepath):\n",
    "    meta = {}\n",
    "    py = ''\n",
    "    debug = True\n",
    "    \n",
    "    with open(filepath) as fp:\n",
    "        c = fp.read()\n",
    "        c = json.loads(c)\n",
    "        c = c['cells']\n",
    "       \n",
    "    for cell in c:\n",
    "        for source in cell['source']:\n",
    "            #print(source.strip())\n",
    "            py += source\n",
    "        py += '\\n\\n'\n",
    "        \n",
    "    #print(py)\n",
    "    return analyze_pythoncode(py)\n",
    "\n",
    "meta = analyze_ipynb(fp)\n",
    "\n",
    "print(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scipy'}\n"
     ]
    }
   ],
   "source": [
    "# python package pattern matching with limited set\n",
    "\n",
    "ml_libs = ['tensorflow','keras','pytorch','sklearn','nltk','mllib','theano','mxnet','lightgbm','scipy','caffe','cntk','auto_ml','OpenNN','h2o']\n",
    "matches = set(meta['libs']).intersection(ml_libs)\n",
    "if not bool(matches):\n",
    "    matches = {}\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "# python package pattern matching with extended set\n",
    "\n",
    "ml_libs = pd.read_csv('../data/ml_libraries.csv')\n",
    "ml_packages = ml_libs['Python Package'].tolist()\n",
    "\n",
    "matches = set(meta['libs']).intersection(ml_packages)\n",
    "if not bool(matches):\n",
    "    matches = {}\n",
    "print(matches)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
